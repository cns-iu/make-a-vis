AwardNumber,Title,NSFOrganization,Program(s),StartDate,LastAmendmentDate,PrincipalInvestigator,PI,AllPI,State,Organization,AwardInstrument,ProgramManager,EndDate,AwardedAmountToDate,Co-PIName(s),PIEmailAddress,OrganizationStreet,OrganizationCity,OrganizationState,OrganizationZip,OrganizationPhone,NSFDirectorate,ProgramElementCode(s),ProgramReferenceCode(s),ARRAAmount,SELECTOR1,Abstract
939454,BEACON:  An NSF Center for the Study of Evolution in Action,DBI,"SCI & TECH  CTRS (INTEG PTRS), CYBERINFRASTRUCTURE, STCs - 2010 Class, BEACON",8/1/2010,1/19/2018,Erik Goodman,"Goodman, E","Goodman, E|Lenski, R|Holekamp, K|Ofria, C|Pennock, R",MI,Michigan State University,Cooperative Agreement,George W. Gilchrist,7/31/2021,"$43,035,209.00 ","Richard Lenski, Kay Holekamp, Charles Ofria, Robert Pennock",goodman@egr.msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,BIO,"1297, 7231, 8005, 8017","019Z, 7317, 7433, 7634, 9171, 9251",$0.00 ,exceptionalFunding,"The Bio/computational Evolution in Action CONsortium (BEACON) is a Science and Technology Center (STC) that enables research on evolutionary dynamics in natural and artificial systems and training of multi-disciplinary scientists in bio/computation, with a unique focus on the intersection of evolutionary biology, computer science, and engineering. The Center will enhance the development of applications of computational methods in biology, the use of artificial intelligence in computer science, and the enhancement of genetic algorithms in engineering design. Evolution by natural selection defines an algorithmic approach to finding solutions for complex problems; computer scientists and engineers have harnessed similar algorithms to a diversity of challenges that require optimization over multiple competing dimensions. Likewise, biologists have begun to employ digital modeling of the evolutionary process to examine evolution of complex biological structures and patterns in areas such as paleontology and the gene networks, which defy experimental manipulation in vivo. The Center will promote these interdisciplinary efforts by coordinating activities through three thrust groups: (1) Evolution of Genomes, Networks, and Evolvability, (2) Evolution of Behavior and Intelligence, and (3) Evolution of Communities and Collective Dynamics. <br/><br/>This center has the potential to transform both biology and computational sciences by developing digital experiments to test and apply fundamental principles of evolutionary biology. The possible impacts will be far reaching: from cyber-security to everyday computing applications, from the evolution of disease resistance to the self-organization of social behavior. The BEACON center will train the next generation of interdisciplinary scientists and educate the public about evolution and its role in solving real-world problems through significant educational outreach for K12 students and science museums."
8920230,Center for Research in Cognitive Science,BCS,"LINGUISTICS, CROSS-DIRECTORATE  ACTIV PROGR, CISE RESEARCH INFRASTRUCTURE, ARTIFICIAL INTELL & COGNIT SCI, SPECIAL PROGRAMS-RESERVE, SCIENCE AND TECHNOLOGY CENTERS",2/1/1991,2/20/2002,Aravind Joshi,"Joshi, A","Joshi, A|Gleitman, L|Liberman, M",PA,University of Pennsylvania,Cooperative Agreement,Cecile Mckee,7/31/2002,"$20,878,702.00 ","Lila Gleitman, Mark Liberman",joshi@cis.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,SBE,"1311, 1397, 2885, 6856, 9145, 9171","0000, 1311, 2885, 6856, 9171, 9178, 9216, 9218, HPCC, OTHR, SMET",$0.00 ,exceptionalFunding,"                                                                                                            ABSTRACT                                                                                                                            This proposal from the University of Pennsylvania requests funds                to establish a Science Technology Center for Research in                        Cognitive Science.  The Director of the Center will be Professor                Aravind K. Joshi.                                                                                                                                               The Center for Research in Cognitive Science unites a diverse and               richly interconnected group from many traditional disciplines                   (computer science, linguistics, mathematics, philosophy, and                    psychology).  The goal of the research is to understand the                     processes and mechanisms by which human beings acquire knowledge                about their environment, store and retrieve that knowledge,                     communicate it to others, and apply it to carry out actions and                 manipulate their environment.                                                                                                                                   The research is organized into three separate but highly                        interrelated themes:  perception and action, language learning,                 and language processing.  Research in the area of perception and                action spans the processes involved in the first stages of visual               and auditory representation of spatial and spectral information,                to higher order representations of more complex attributes, to                  the storage and retrieval of such representations by the organism               as they are used in goal-oriented actions.  The study of language               learning focuses on how children develop the abstract                           representations of language on the basis of their visual and                    auditory perceptions.  The research in language processing                      combines investigation of formal systems with investigation of                  computational models, all in the context of empirical study of a                wide range of natural languages.                                                                                                                                Significant features of the perception and action research are                  its increasing fidelity to actual neural computation and its                    sophisticated computational modeling and related potential for                  contributing to artificial intelligence technology.  The language               learning research has significant potential for technological                   spin-off in machine learning and automatic acquisition of lexical               and grammatical information for language systems, crucial to the                development of grammars sufficient for the robust analysis of                   unconstrained text.  And the language processing research will                  have significant impact on the technological base for human-                    computer interaction, in particular the design of natural                       language interfaces for data base and expert systems and                        knowledge-rich systems in general.                                                                                                                              This Center will stimulate enhanced activity in precollege                      education and in the development of human resources."
1041707,Spatial Intelligence and Learning Center (SILC),SMA,"GEOGRAPHY AND SPATIAL SCIENCES, SCIENCE OF LEARN CTRS- CENTERS, REAL, Science Across Virtual Instits",10/1/2011,9/15/2017,Nora Newcombe,"Newcombe, N","Newcombe, N|Goldin-Meadow, S|Levine, S|Gentner, D|Hedges, L",PA,Temple University,Cooperative Agreement,Soo-Siang Lim,9/30/2018,"$18,306,816.00 ","Susan Goldin-Meadow, Susan Levine, Dedre Gentner, Larry Hedges",newcombe@temple.edu,1801 N. Broad Street,Philadelphia,PA,191226003,2157077547,SBE,"1352, 7278, 7625, 8077","5912, 5936, 5946, 5948, 7278, 8058, 9177",$0.00 ,exceptionalFunding,"The Spatial Intelligence and Learning Center (SILC) was established in the fall of 2006 as one of three second-cohort Science of Learning Centers. SILC's purpose is to develop the new science of spatial learning and to use this knowledge to transform STEM educational practice. Spatial learning is the acquisition of spatial knowledge and skills, and the use of spatial knowledge and skills to facilitate learning in both spatial and non-spatial domains. It provides the foundation for a wide range of reasoning skills in STEM-based activities, from solving mathematical problems to engineering new products to understanding graphical depictions of complex systems. Previous research shows that spatial skills are a strong predictor of entry into STEM disciplines in college and into STEM careers, that substantial improvement of spatial learning is possible, and that this improvement matters to STEM success. SILC has brought together researchers from multiple lines of work on spatial cognition and education and from a variety of traditional disciplines (e. g., cognitive science, psychology, artificial intelligence, linguistics, education, STEM disciplines), integrating them to achieve new insights. SILC researchers are developing a set of powerful tools for spatial learning, honing them into effective, deployable educational techniques and practices for STEM learning, including advanced technology (e.g., intelligent educational software), effective curriculum units (e.g., in elementary school mathematics), engaging activities (e.g., in children's museums), and spatial assessment instruments (e.g., testing children's spatial skills, testing adults' STEM-relevant spatial skills). Several of the insights, tools and products from SILC's initial funding period already hold transformational potential for spatial learning. Research and translational activities in the second and last funding period, from 2011-2016, will continue the investment in the science of spatial learning, in order to allow the fulfillment of this promise."
741315,System Engineering Risk Reduction,CNS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, Networking Technology and Syst, NetS RESEARCH RESOURCES",1/1/2008,12/22/2011,Brig 'Chip' Elliott,"Elliott, B'","Elliott, B'",MA,Raytheon BBN Technologies Corp.,Continuing grant,Joseph Lyles,12/31/2012,"$14,058,434.00 ",,celliott@bbn.com,10 Moulton Street,Cambridge,MA,21381119,6178738325,CSE,"1640, 1714, 7363, 7917","023F, 7363, 7917, 9218, HPCC",$0.00 ,exceptionalFunding,"This award funds risk reduction activities for a future, experimental network infrastructure that will allow researchers from diverse disciplines across computer and information science and engineering as well as from economics and the social sciences to escape today's Internet-circumscribed research environment. This infrastructure will allow researchers to program their own unique networks (i.e., multiple end-to-end ""slices"") that run on federated, heterogeneous backbones and edge networks to try out new protocols (that may or may not be TCP/IP-based), new architectures inspired by recent discoveries in economic game theory or artificial intelligence (that didn't exist when the Internet was first imagined), and/or new cross-layer research whereby functionalities that incorporate human values, such as information privacy or security, for example, become integral parts of the network architecture as opposed to an afterthought. The intention is for this infrastructure to be deeply instrumented so that researchers will be able to monitor their ongoing experiments, collect data on the use of novel protocols, designs and architectures, and analyze the emergent behaviors of traffic. Major outcomes from this project include 1) identification and reduction of technical risks, and 2) broadening and strengthening community participation in planning the experimental network infrastructure. Significant outreach activities will include the widest possible array of research and education communities in dialogue about the scope and scale of research on such an infrastructure, which promises to deepen their participation in the design process and helps to ensure that the future infrastructure meets their needs.  <br/><br/>"
1158862,RII: Enhancing Alabama's Research Capacity in Nano/Bio Science and Sensors,EPS,EPSCoR Research Infrastructure,9/1/2011,7/28/2016,Mahesh Hosur,"Hosur, M","Hosur, M",AL,Tuskegee University,Cooperative Agreement,Uma D Venkateswaran,8/31/2017,"$11,332,243.00 ",,mhosur@tuskegee.edu,1200 W Montgomery Road,Tuskegee Institute,AL,360881923,3347278233,O/D,7217,"0000, 1769, 7217, 9150, OTHR",$0.00 ,exceptionalFunding,"Abstract<br/><br/>Proposal Number:  EPS-0814103<br/><br/>Proposal Title: RII: Enhancing Alabama?s Research Capacity in Nano/Bio Science and Sensors  <br/><br/>Institution:   Alabama A&M University<br/><br/>Goals: This Research Infrastructure Improvement award will facilitate the creation of a statewide partnership among Alabama core research institutions to enhance R&D competitiveness in the emerging area of nano/bio science and molecular sensors. This partnership is designed to foster collaborative research, and to stimulate multidisciplinary education through four centers. Each center is designed to support and train new faculty, staff, and students in key nano- and biotechnology innovation areas aligned with the state?s economic development priorities outlined in the governor?s ?Plan 2010?.<br/><br/>Project Major Foci: The Tuskegee University led center will develop and characterize new  biodegradable nanostructured materials; the Auburn University led center will use organismal models to identify mechanisms of adaptation to natural and man-made environmental challenges; the University of Alabama in Birmingham led center will develop new optical and molecular sensing technologies; and the Alabama A&M University led center will use nanopatterning and nanofabrication techniques to control structure-property relationships in order to tailor materials properties for specific applications. An additional role of this center will be the integration of the findings of each center to catalyze innovation based economic development. <br/><br/>Intellectual Merit<br/>The centers will ensure reciprocal transfer of information and technology between the life sciences and engineering to catalyze novel research in both fields. Biological discovery will elucidate structural and functional principles in living systems that can serve as templates for pioneering the design and synthesis of nanomaterials. Likewise, advances in nanoscale detection, quantification, and nanoengineering will open new frontiers in the life sciences. <br/><br/>Broader Impacts<br/>The centers will establish statewide infrastructure that will foster collaboration, build partnerships, develop future STEM-enabled workforce, improve scientific literacy, and develop new economic opportunities. The centers research will likely have a major impact on the environment, homeland security, and industrial process control.<br/><br/>"
832782,"Collaborative Research: Computational Sustainability: Computational Methods for a Sustainable Environment, Economy, and Society",CNS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, EXPERIMENTAL EXPEDITIONS",8/15/2008,4/14/2015,Carla Gomes,"Gomes, C","Gomes, C|Hopcroft, J|Selman, B|Conrad, J|Shmoys, D",NY,Cornell University,Continuing grant,Ralph Wachter,7/31/2016,"$7,939,359.00 ","John Hopcroft, Bart Selman, Jon Conrad, David Shmoys",gomes@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,"1640, 1714, 7723","7723, 9178, 9218, 9251, HPCC",$0.00 ,exceptionalFunding,"Balancing environmental, economic, and societal needs for a sustainable future encompasses problems of unprecedented size and complexity.  With naturally occuring settings, global scale, dynamic and uncertain behavior, mixture of discrete and continuous effects, and highly interactive components, problems associated with sustaining the earth's resources can greatly benefit from computational methods and thinking.  There is a key role to be played by computing and information sciences in increasing the efficiency and effectiveness in the way humanity manages and allocates natural resources.  Toward that objective, this Expedition aims to establish and nurture a new field of study--Computational Sustainability--driven by a wide range of hard computational problems and critical challenges in the area of sustainability.  This applied theoretical Expedition will pursue interdisciplinary research across three computational sustainability themes: conservation and biodiversity; balancing socio-economic demands and the environment; and renewable energy.  With the view that natural problems may have a special structure discoverable by machine learning techniques that allows them to be solved even though they are NP-hard, this research attempts to stimulating new research synergies that cross boundaries and merge ideas from combinatorial optimization, dynamical systems, machine learning and constraint reasoning.  An ""Institute for Computational Sustainability"" will be based at Cornell to serve as the nexus of foundational science advancements and practical applications in sustainability.  Part of its mission and outreach is to establish a vibrant and diverse research community in the area of computational sustainability, drawing new students into the field from all backgrounds including students from underrepresented groups via summer research experiences and other such proactive activities."
814103,RII: Enhancing Alabama's Research Capacity in Nano/Bio Science and Sensors,EPS,EPSCoR Research Infrastructure,9/1/2008,8/4/2011,Mahesh Hosur,"Hosur, M","Hosur, M|Lawson, C|Hosur, M|Boykin, K|Bartol, F",AL,Alabama A&M University,Cooperative Agreement,Kelvin Chu,10/31/2011,"$6,000,000.00 ","Christopher Lawson, Mahesh Hosur, Karen Boykin, Frank Bartol",mhosur@tuskegee.edu,2nd Floor Carnegie Building,Normal,AL,357620285,2563728186,O/D,7217,"0000, 7217, 9150, OTHR",$0.00 ,exceptionalFunding,"Abstract<br/><br/>Proposal Number:  EPS-0814103<br/><br/>Proposal Title: RII: Enhancing Alabama?s Research Capacity in Nano/Bio Science and Sensors  <br/><br/>Institution:   Alabama A&M University<br/><br/>Goals: This Research Infrastructure Improvement award will facilitate the creation of a statewide partnership among Alabama core research institutions to enhance R&D competitiveness in the emerging area of nano/bio science and molecular sensors. This partnership is designed to foster collaborative research, and to stimulate multidisciplinary education through four centers. Each center is designed to support and train new faculty, staff, and students in key nano- and biotechnology innovation areas aligned with the state?s economic development priorities outlined in the governor?s ?Plan 2010?.<br/><br/>Project Major Foci: The Tuskegee University led center will develop and characterize new  biodegradable nanostructured materials; the Auburn University led center will use organismal models to identify mechanisms of adaptation to natural and man-made environmental challenges; the University of Alabama in Birmingham led center will develop new optical and molecular sensing technologies; and the Alabama A&M University led center will use nanopatterning and nanofabrication techniques to control structure-property relationships in order to tailor materials properties for specific applications. An additional role of this center will be the integration of the findings of each center to catalyze innovation based economic development. <br/><br/>Intellectual Merit<br/>The centers will ensure reciprocal transfer of information and technology between the life sciences and engineering to catalyze novel research in both fields. Biological discovery will elucidate structural and functional principles in living systems that can serve as templates for pioneering the design and synthesis of nanomaterials. Likewise, advances in nanoscale detection, quantification, and nanoengineering will open new frontiers in the life sciences. <br/><br/>Broader Impacts<br/>The centers will establish statewide infrastructure that will foster collaboration, build partnerships, develop future STEM-enabled workforce, improve scientific literacy, and develop new economic opportunities. The centers research will likely have a major impact on the environment, homeland security, and industrial process control.<br/><br/>"
960061,MRI-R2: Development of Common Platform for Unifying Humanoids Research,CNS,MAJOR RESEARCH INSTRUMENTATION,7/1/2010,4/17/2014,Youngmoo Kim,"Kim, Y","Kim, Y|Schaal, S|Regli, W|Gogotsi, Y|Hong, D",PA,Drexel University,Standard Grant,Rita V. Rodriguez,9/30/2015,"$5,999,997.00 ","Stefan Schaal, William Regli, Yury Gogotsi, Dennis Hong",ykim@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,1189,6890,"$5,999,997.00 ",exceptionalFunding,"""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."" <br/>Proposal #: 09-60061<br/>PI(s):  Kim, Youngmoo E., Gogotsi, Yury, Hong, Dennis H., Regli, William C., Schaal, Stefan<br/>Institution: Drexel University<br/>Title:    Development of Common Platform for Unifying Humanoids Research<br/>Project Proposed: <br/>This project, developing and disseminating HUBO+, a new common humanoid research platform instrument, enables novel and previously infeasible capabilities for future research efforts while working with a common instrument. HUBO will be the first homogeneous, full-sized humanoid to be used as a common research and education platform. Eight universities (Drexel, CMU, MIT, Ohio State, Penn, Purdue, Southern California, and VaTech), representing a critical mass of humanoids research within US, participate in this development of the world's first homogeneous full-sized humanoid team. Building upon unique expertise, the work extends current capabilities, resulting in six identical units, facilitating the following potentially transformative advances in robotics:<br/>- A state-of-the-art, standardized humanoid platform instrument with embedded capabilities for sensing, manipulation, and rapid locomotion, ideal for a broad range of future humanoids research<br/>- The ability, for the first time, to directly compare and across validate algorithms and methodologies and consistently benchmark results across research teams<br/>- Novel energy storage technology for mobile robotics incorporating supercapacitors for operations requiring high power density, far exceeding the capabilities of traditional battery-only power sources<br/>- A widely distributed platform that motivates, recruits, and trains a broad range of students spanning multiple disciplines, including artificial intelligence, digital, signal processing, mechanics, and control<br/>Humanoids, robots engineered to mimic human form and motion, open broad avenues of cross disciplinary research spanning multiple fields, such as mechanical control, artificial intelligence, and power systems. Common humanoids are rarely autonomous and are not-ready for unconstrained interaction with humans. The most compelling demonstrations are meticulously pre-programmed and painstakingly choreographed. A few common platforms have already advanced some research. Hence, having a consistent platform should facilitate rapid progress in areas needed for autonomy and natural interaction, including mobility, manipulation, robot vision, speech communication, and cognition and learning. However, although currently Japan and Korea are considered world leaders in design and construction of humanoids, best practices have not been developed for constructing multiple, identical humanoids. These conditions call for the making of an urgently needed benchmark providing evaluations and cross-validation of results. With this development and the servicing of 6 humanoids, this project aims to create knowledge and best practices contributing to robotics research, possibly leading to the standardization needed for ubiquity.<br/>Broader Impacts: <br/>The instrument enables US researchers to develop expertise in the design and construction of humanoids, while the distribution of the work activities ensures the broad dissemination of the knowledge. Humanoids research, inherently interdisciplinary and integrative, inspires young students. The graduate and undergraduates students participating are likely to receive a world-class training in robotics. Outreach partners, including several high-profile museums will introduce people of all ages to the exciting technologies of robotics, particularly useful in recruiting K-12 students into science, engineering, mathematics, etc. A partnership with the Science Leadership Academy (SLA), a magnet school with more than 63% underrepresented students, assures their involvement. With SLA, the project initiates an annual program modeled on a NASA-style experiment design competition, in which students use simulation tools to propose humanoids projects and activities. Selected winner(s) will have their proposed projects implemented on HUBO."
1545858,PIRE: International Program for the Advancement of Neurotechnology (IPAN),OISE,"CROSS-EF ACTIVITIES, PIRE",11/1/2015,8/10/2018,Euisik Yoon,"Yoon, E","Yoon, E|Wise, K|Buzsaki, G|Stuenkel, E|Quirk, G",MI,University of Michigan Ann Arbor,Continuing grant,Cassandra M. Dudka,10/31/2020,"$5,000,000.00 ","Kensall Wise, Gyorgy Buzsaki, Edward Stuenkel, Gregory Quirk",esyoon@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,O/D,"7275, 7742","5921, 5927, 5936, 5942, 5946, 7298, 7742",$0.00 ,exceptionalFunding,"This project entitled ""International Program for the Advancement of Neurotechnology (IPAN)"" is about understanding the complexity and mysteries of the brain. It is cited by many as the biggest scientific challenge of this century. In this International Program for the Advancement of Neurotechnology (IPAN), the researchers are creating a holistic system for studying brain activity by closely integrating hardware from leading neurotechnologists with novel software from leading neuroscientists.  Enabling this large-scale collaboration should accelerate the rate of discovery in neuroscience. This in turn will pave the way to improved treatments for neurological disorders and to breakthroughs in artificial intelligence in the next decade. The PIRE team will also provide advanced educational opportunities for undergraduates with the express purpose of recruiting future U.S. STEM (science, technology, engineering and mathematics) researchers. Graduate students and postdocs will also be enrolled in a unique cross-training program between neuroscience and neurotechnology laboratories. The resulting experience will prepare a new generation of globally-connected multi-disciplinary engineers and scientists while driving critical advances in neurotechnology.<br/><br/>IPAN is an explicit partnership of leading neuroscientists and technologists to develop and deliver a hardware and software system that fundamentally simplifies the ability of a neuroscientist to (i) identify recorded neuron types, (ii) reconstruct local neural circuits, and (iii) deliver biomimetic or synthetic inputs in a cell-specific targeted manner. This project teams the University of Michigan, New York University, Howard Hughes Medical Institute, and the University of Puerto Rico with the University of Freiburg,  the  University  of  Hamburg-Eppendorf,  the  Korea  Institute  of  Science  and  Technology, Singapore?s Institute for Microelectronics, and University College London.   Complementary strengths, world-class infrastructures, and strong student exchange programs are an important part of this IPAN team, with major thrusts in Technology, Neuroscience, and Education. The enabling technology to meet these three system goals (i-iii) will be next-generation neural probes equipped with novel optoelectronics, high-density recording interfaces, and low-noise multiplexed digital outputs. The neuroscience thrust will help define the technology from the onset and are developing novel software tools to accelerate the analysis of large neurophysiological data sets. The team includes leading system neuroscientists with unique  capabilities  specializing  in  memory,  sensory,  fear,  and  development, and  will  work  with technologists to validate both the technology and the software tools in distinctive neuroscience applications."
9983304,Digital Government:  COPLINK Center:  Information and Knowledge Management for Law Enforcement,IIS,"DIGITAL GOVERNMENT, CISE RESEARCH INFRASTRUCTURE, PART FOR ADVANCED COMP INFRA, INFORMATION & KNOWLEDGE MANAGE, DISASTER RESPONSE TEAMS, , , , ",7/1/2000,9/7/2004,Hsinchun Chen,"Chen, H","Chen, H|Zeng, D|Atabakhsh, H",AZ,University of Arizona,Continuing grant,Lawrence Brandt,9/30/2006,"$3,579,649.00 ","Daniel Zeng, Homa Atabakhsh",hchen@eller.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,"1706, 2885, 4066, 6855, 7293, V068, V424, V713, W295","1387, 9216, 9218, HPCC",$0.00 ,exceptionalFunding,"EIA-9983304<br/>Chen, Hsinchun<br/>University of Arizona<br/><br/>Digital Government: COPLINK Center: Information and Knowledge Management for Law Enforcement<br/><br/>The information and knowledge management problems facing many government agencies stem from barriers to access and utilization resulting from the content and format of information.  These problems make information (and eventually knowledge) creation and utilization and complex and daunting process.  New knowledge management technologies have started to emerge in a number of different applications and organizations, such as virtual enterprising, joint ventures, aerospace engineering and digital libraries.  However, there has been no systematic attempt to study the technical, social and managerial foundation, theory and methodology of knowledge management that can be adopted in various social and industrial contexts.  The COPLINK Center for Excellence aims to achieve the following two goals:  1) Develop knowledge management systems technologies and methodology that are appropriate for capturing, analyzing, visualizing and sharing law enforcement related information in social and organizational contexts.  The basis of such research will be grounded in information retrieval, computational linguistics, information visualization, artificial intelligence, multimedia systems, multi-agent systems, and telecommunications.  2) Study of organizational, social, cultural and methodological impacts and changes that organizations need to make to maximize and leverage on a law enforcement agency's investments in information and knowledge management.  The academic foundation for such research will be based on social informatics, decision theory, communication theory, cognitive psychology and managerial and organizational research.<br/>"
1020229,The Leonardo Project: An Intelligent Cyberlearning System for Interactive Scientific Modeling in Elementary Science Education,DRL,DISCOVERY RESEARCH K-12,8/15/2010,9/23/2011,James Lester,"Lester, J","Lester, J|Mott, B|Carter, M|Wiebe, E",NC,North Carolina State University,Continuing grant,helen martin,7/31/2015,"$3,499,410.00 ","Bradford Mott, Michael Carter, Eric Wiebe",lester@csc.ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,EHR,7645,"9177, SMET",$0.00 ,exceptionalFunding,"The project designs and implements technologies that combine artificial intelligence in the form of intelligent tutoring systems with multimedia interfaces to support children in grades 4-5 learning science. The students use LEONARDO's intelligent virtual science notebooks to create and experiment with interactive models of physical phenomena. With this technology, students' models 'come alive' as interactive multimedia artifacts that combine animation, sound, and narration. The curricular focus is on physical and earth sciences, and the technology supports multimodal interactive scientific modeling for four curricular units: forces and motion, magnetism and electricity, landforms, and weather and climate.  A central feature of this environment is PadMates, which are intelligent virtual tutors that support science learning through interactive scientific modeling.<br/><br/>The PIs investigate the cognitive mechanisms by which learning occurs.  Specifically, they study the central issues of problem solving (strategy use, divergent thinking, and collaboration) and engagement (motivation, situational interest, presence) with respect to achievement as measured by both science content knowledge and transfer. With diverse student populations in 60 classrooms drawn from both urban and rural settings, the studies determine precisely which technologies and conditions contribute most effectively to learning processes and outcomes.<br/><br/>The products include technologies and findings that should be the basis of a framework to inform the future development of similar systems. The impact should be substantial on all learners given the potential power of the technology to scaffold learning at an important developmental stage."
1068871,IGERT: Training Program in Wireless Intelligent Sensor Networks (WISeNet),DGE,IGERT FULL PROPOSALS,9/1/2011,8/13/2015,Silvia Ferrari,"Ferrari, S","Ferrari, S|Parr, R|Agarwal, P|Katul, G|Ferrari, S|Albertson, J",NC,Duke University,Continuing grant,Laura Regassa,8/31/2018,"$3,126,326.00 ","Ronald Parr, Pankaj Agarwal, Gabriel Katul, Silvia Ferrari, John Albertson",ferrari@cornell.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,EHR,1335,"110E, 1335, 9179, SMET",$0.00 ,exceptionalFunding,"This Integrative Graduate Education and Research Traineeship (IGERT) award supports the development of an interdisciplinary graduate training program in Wireless Intelligent Sensor Networks (WISeNet) at Duke University.  Recent advancements in wireless sensors are transforming many areas of science and engineering, spanning ecology, geosciences, robotics, and artificial intelligence.  Intellectual Merit: This program provides students with an interdisciplinary training that will prepare them to conduct research on novel intelligent methods and algorithms for wireless sensor networks.  The thematic basis is the development of intelligent sensors that process, store, and learn from data so as to improve their ability to gather information over time. <br/><br/>Broader impacts include unprecedented observation of environmental and ecological processes, and more effective and reliable use of sensors for defense and national security.  In collaboration with an Advisory Board of external and international collaborators, WISeNet faculty and students will rapidly transfer research findings into the curriculum, and develop integrated computational tools that directly support the WISeNet research goals.  The program will partner with Duke?s REU program and Graduate School to enhance diversity.  Students will receive a WISeNet graduate certificate that includes required laboratory and field experiments; new cross-disciplinary courses; and simulation, visualization, and virtual reality projects.  The program will develop a common research and educational experience for U.S. Ph.D. scientists and engineers working in the areas of sensor networks, environmental modeling and prediction, and computational intelligence, and provide students with an academic environment and placement opportunities where they can flourish at a global scale.<br/><br/>IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing innovative new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries."
1707316,NeuroNex Technology Hub: Multimodal Integrated Neural Technologies (MINT) - Connecting Physiology to Functional Mapping,DBI,"Engineering of Biomed Systems, CROSS-EF ACTIVITIES",9/1/2017,8/15/2018,Euisik Yoon,"Yoon, E","Yoon, E|Buzsaki, G|Weiland, J|Chestek, C|Gradinaru, V",MI,University of Michigan Ann Arbor,Cooperative Agreement,Reed Beaman,8/31/2019,"$3,100,000.00 ","Gyorgy Buzsaki, James Weiland, Cynthia Chestek, Viviana Gradinaru",esyoon@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,BIO,"5345, 7275",8091,$0.00 ,exceptionalFunding,"In order to understand how neural signals propagate to conduct specific functions in behaving animals and how individual neurons are physically connected in the context of behavior, advanced tools should be available at the hands of neuroscientists. The Multimodal Integrated Neural Technologies (MINT) hub aims to develop and provide tools that are able to read from and modulate neurons at multiple sites independently at high spatial and temporal resolutions. The hub will disseminate tools and methods to correlate the recorded cell activity with the structural connection. In this way, the connectivity of active cells can be visualized, labeled, and traced for detailed functional mapping. The mission of the MINT hub is to provide a collection of tools, synergistically developed, integrated, and available to the neuroscience community, to address one theme: connecting neurophysiology and structural analysis with a greater scale and resolution. The synergistic integration of these neurotechnology tools at the MINT Hub would accelerate the rate of discovery in neuroscience. This in turn can be expected to pave the way to improved treatments for neurological disorders and to breakthroughs in artificial intelligence, especially neuromorphic computing. The MINT hub will provide annual training workshops for new users to be familiar with new technologies and able to use them effectively. To achieve sustainability, the hardware tools will be actively marketed to the community and those with sustainable volume will be transitioned to commercialization partners. Importantly, this program will cross-train neuroscience and technology personnel during the course of this program, resulting in preparation of a new generation of multi-disciplinary engineers and scientists.<br/><br/>This hub uniquely combines high-density electrodes, chemical sensing, optical stimulation, and cell labeling. Fiberless high-density optoelectrodes can allow optical stimulation of individual or few neurons with high specificity and selectivity using monolithically integrated micro-LEDs or optical waveguides on multi-shank silicon probes. Carbon microthreads will be used to create advanced arrays that will dramatically increase the ability to record from interconnected neurons and label those cells with high accuracy. Advanced metal alloys will also be used to greatly enhance the signal-to-noise ratio of miniaturized electrodes. The MINT hub will innovate viral vector delivery and tissue clearing in the nervous system and combine these with multispectral labeling for intact cell phenotyping. Furthermore, an open-source software will be developed to improve the accuracy and efficiency of anatomical reconstruction for creating connectivity maps. The MINT hub will validate the developed tools and methods in three in-vivo experiments to exemplify what can be accomplished when the proposed modalities and methods are synergistically integrated. This NeuroTechnology Hub award is co-funded by the Division of Emerging Frontiers within the Directorate for Biological Sciences, and the Division of Chemical, Bioengineering, Environmental & Transport Systems within the Directorate for Engineering as part of the BRAIN Initiative and NSF's Understanding the Brain activities."
654014,IGERT: Incentive-Centered Design for Information and Communication Systems,DGE,IGERT FULL PROPOSALS,8/1/2007,8/31/2011,Yan Chen,"Chen, Y","Chen, Y|MacKie-Mason, J|Wellman, M|Chen, Y|Grosu, D|Borgers, T",MI,University of Michigan Ann Arbor,Continuing grant,Richard Boone,7/31/2014,"$3,000,000.00 ","Jeffrey MacKie-Mason, Michael Wellman, Yan Chen, Daniel Grosu, Tilman Borgers",yanchen@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,EHR,1335,"1335, 9179, SMET",$0.00 ,exceptionalFunding,"Exponential decreases in computation and communication costs induce marvelous new Internet services and social opportunities.  However, new forms of social engagement also create new problems.  This Integrative Graduate Education and Research Traineeship (IGERT) renewal will advance a principled, multi-disciplinary research method well-suited to make the Internet a place that is safe, fun and sustainable, with corresponding potential for improved social, economic, and political interaction.   Incentive-centered design is a science that aligns participants' incentives with system or social goals. Distributed and collaborative system performance depends critically on strategic choices that users make when interacting with the system or each other, yet mismatch between individual interests and system goals is pervasive.  This program takes a broad view of individual motivations, drawing on economic, psychological, and sociological theories, and combines these with the design and engineering sciences of artificial intelligence, software and networking.<br/><br/>The broader impacts go beyond research contributions to the design of socially-valuable Internet communities and services.  The joint Ph.D. program at the University of Michigan and Wayne State University (a metropolitan comprehensive institution) will train future scholars and teachers from a diverse array of socio-economic and cultural backgrounds.  In addition it includes a summer program for undergraduates from underrepresented groups, who in teams together with the IGERT trainees will develop submissions to international research competitions.  This program will increase the pool of students from underrepresented groups who are prepared for and motivated to pursue graduate education.  IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing innovative new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries.<br/>"
1516684,Increasing Learning and Efficacy about Emerging Technologies through Transmedia Engagement by the Public in Science-in-Society Activities,DRL,AISL,8/1/2015,7/19/2018,Edward Finn,"Finn, E","Finn, E|Gano, S|Wylie, R|Ostman, R|Guston, D",AZ,Arizona State University,Continuing grant,Alphonse T. DeSena,7/31/2019,"$2,999,999.00 ","Steve Gano, Ruth Wylie, Rae Ostman, David Guston",edfinn@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,EHR,7259,8244,$0.00 ,exceptionalFunding,"The range of contemporary ""emerging"" technologies with far-reaching implications for society (economic, social, ethical, etc.) is vast, encompassing such areas as bioengineering, robotics and artificial intelligence, genetics, neuro and cognitive sciences, and synthetic biology. The pace of development of these technologies is in full gear, where the need for public understanding, engagement and active participation in decision-making is great. The primary goal of this four-year project is to create, distribute and study a set of three integrated activities that involve current and enduring science-in-society themes, building on these themes as first presented in Mary Shelley's novel, Frankenstein, which will be celebrating in 2018 the 200th anniversary of its publication in 1818. The three public deliverables are: 1) an online digital museum with active co-creation and curation of its content by the public; 2) activities kits for table-top programming; and 3) a set of Making activities.  The project will also produce professional development deliverables: workshops and associated materials to increase practitioners' capacity to engage multiple and diverse publics in science-in-society issues.  The initiative is funded by the Advancing Informal STEM Learning (AISL) program, which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments. This includes providing multiple pathways for broadening access to and engagement in STEM learning experiences, advancing innovative research on and assessment of STEM learning in informal environments, and developing understandings of deeper learning by participants.<br/><br/>This project by Arizona State University and their museum and library collaborators around the country will examine the hypothesis that exposing publics to opportunities for interactive, creative, and extensive engagement within an integrated transmedia environment will foster their interest in science, technology, engineering and mathematics (STEM), develop their 21st century skills with digital tools, and increase their understanding, ability, and feelings of efficacy around issues in science-in-society.  These three distinct yet interlocking modes of interaction provide opportunities for qualitative and quantitative, mixed-methods research on the potential of transmedia environments to increase the ability of publics to work individually and collectively to become interested in and involved with science-in-society issues."
742504,"New, GK-12 Sustainable Energy Systems",DGE,GRAD TEACHING FELLOWS IN K-12,6/1/2008,6/7/2012,Beth Todd,"Todd, B","Todd, B|Wu, Z|Shearin, J|Midkiff, K|Johnson, P",AL,University of Alabama Tuscaloosa,Continuing grant,Laura Regassa,5/31/2014,"$2,982,282.00 ","Zhijian Wu, Jill Shearin, Kenneth Midkiff, Pauline Johnson",btodd.eng@gmail.com,801 University Blvd.,Tuscaloosa,AL,354870005,2053485152,EHR,7179,"7179, 9179, SMET",$0.00 ,exceptionalFunding,"GRADUATE TEACHING FELLOWS IN K-12 EDUCATION<br/>ABSTRACT<br/><br/>PROPOSAL #: 0742504<br/>PRINCIPAL INVESTIGATOR: Beth A. Todd <br/>INSTITUTION: University of Alabama, Tuscaloosa<br/>TITLE: GK-12 Sustainable Energy Systems<br/><br/>The two major goals of this multi-disciplinary project in engineering and mathematics are to 1)increase the professional caliber of our STEM (science, technology, engineering, and mathematics) graduate students and equip them with the skills and experiences to become future leaders in academia and industry; and 2)provide resources and support for the newly formed State of Alabama high school Engineering Academies and create materials that integrate engineering applications into existing high school and middle school science and math courses.  The multi-disciplinary theme of the project, Sustainability in Energy Systems, includes transformative research on alternative and traditional energy systems, including renewable resources in consideration of their environmental impact.   This project strongly emphasizes the integration of graduate research with K-12 education to collaboratively design and deliver K-12 STEM instruction. <br/><br/>Graduate fellows will work on-site in the Sumter County schools.  Sumter County ranks among the poorest counties in the state and nation by every measure of poverty, including school performance.  The faculty and student body at all Sumter Co. public schools are over 95% African American.  Fellows, working with K-12 teachers, will be challenged to connect with students from different socio-economic and cultural backgrounds in an appropriate way to enhance knowledge and engage, motivate and build confidence in the students regarding STEM careers.  In addition, materials developed for Sumter County schools will be offered to other state schools using real-time and archived cyber infrastructure resources."
903659,IGERT: Usable Privacy and Security,DGE,"IGERT FULL PROPOSALS, CYBERCORPS: SCHLAR FOR SER",8/15/2009,8/15/2012,Lorrie Cranor,"Cranor, L","Cranor, L|Bauer, L|Downs, J|Sadeh, N|Hong, J",PA,Carnegie-Mellon University,Continuing grant,Laura Regassa,7/31/2016,"$2,924,671.00 ","Ljudevit Bauer, Julie Downs, Norman Sadeh, Jason Hong",lorrie@acm.org,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,EHR,"1335, 1668","1335, 9179, SMET",$0.00 ,exceptionalFunding,"This Integrative Graduate Education and Research Traineeship (IGERT) project supports the development of an interdisciplinary graduate program at Carnegie Mellon University to train researchers in the field of usable privacy and security. The program will provide courses in security, privacy, human-computer interaction, artificial intelligence, economics, and psychology to complement the students' primary fields of study. There is growing recognition that privacy and security failures are often the results of cognitive and behavioral biases and human errors. Many of these failures can be attributed to poorly designed user interfaces or secure systems that have not been built around the needs and skills of their human operators; in other words, systems that have not made privacy and security usable. This IGERT will train cross-disciplinary researchers and develop methodologies, principles, and approaches that can be applied to diverse systems and applications. With social and economic activities becoming increasingly reliant on cyber infrastructure and with 60% of security breaches attributable to human failure, this IGERT addresses one of the most fundamental challenges faced by society today: designing usable secure systems. It does so by: (1) producing research advances that will provide for usable privacy and security in both current and future pervasive computing environments; (2) training a new generation of researchers to engage in interdisciplinary research on usable privacy and security and apply such research to real-world problems; (3) recruiting and training students underrepresented in traditional computer security and information assurance graduate programs.  IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing innovative new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries."
910908,HCC: Large: Intelligent Tracking Systems that Reason about Group Behavior,IIS,"INFO INTEGRATION & INFORMATICS, Cyber-Human Systems (CHS)",9/1/2009,3/5/2014,Margrit Betke,"Betke, M","Betke, M|Kunz, T|Wong, J|Sclaroff, S",MA,Trustees of Boston University,Standard Grant,Ephraim P. Glinert,8/31/2015,"$2,858,292.00 ","Thomas Kunz, Joyce Wong, Stan Sclaroff",betke@cs.bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,CSE,"7364, 7367","6890, 7925, 9215, 9216, HPCC","$2,858,292.00 ",exceptionalFunding,"""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).""<br/><br/>The ability to reason about the complexity of living organisms in diverse environments is one of the hallmarks of intelligence.  In this project the PI and her interdisciplinary team of investigators will design computer vision algorithms for intelligent tracking of large groups of living individuals in three-dimensional space.  She will develop specific systems for tracking groups of microorganisms, bats, birds, and humans.  And she will formulate machine learning methods for analyzing group behavior, specifically the conditions for formation and dispersal of groups, and the interactions of individuals within a group.  An important innovative aspect of this research is the systematic and comprehensive approach to reasoning about the motion of large groups of living organisms observed in video data, independently of whether they happen to be humans, animals, or cells.  Previous efforts in this area have typically focused on studying the behavior of a single type of organism, and on testing theories of behavior based predominately on simulations, without the appropriate analytical tools to automatically explore and quantify the vast number of visual data sets.  This project, on the other hand, will base research findings on the analysis of thousands of trajectories of individual group members moving in 3D space.  To this end, the PI and her team will collect video data in the field and in public spaces to ensure optimal data capture conditions.  They will use these data to develop robust solutions for the problem of matching hundreds of individual bats, birds, or people from frame to frame.  They will generate stereoscopic reconstructions of movement trajectories based on multiple calibrated cameras, and use machine learning to model group behavior and mine the trajectory data.  Finally, they will compare the findings of their reasoning system against current theories about the formation of groups and the interactions of individuals within a group.  A similar, systematic research strategy will be employed to address understanding of the behavior of single cells.  The team will design microscope imaging protocols, develop solutions for the segmentation and tracking of individual cells, and use statistical learning techniques to discover patterns and correlations in the behavior of the cells on physiologically relevant substrates.<br/><br/>Broader Impacts:  Understanding the processes by which groups of animals and microorganisms behave is crucial to the effective conservation of populations and ecosystems and the management of cellular environments.  Project outcomes will advance knowledge across the fields of computer vision, artificial intelligence, behavioral ecology, and biological engineering, and will provide new tools for answering urgent economic and ethical questions, for example about the mortality of birds and bats in wind energy facilities."
1725729,MRI: Development of an Instrument for Deep Learning Research,OAC,"MAJOR RESEARCH INSTRUMENTATION, CYBERINFRASTRUCTURE",10/1/2017,9/14/2017,William Gropp,"Gropp, W","Gropp, W|Campbell, R|Kindratenko, V|Peng, J",IL,University of Illinois at Urbana-Champaign,Standard Grant,Stefan Robila,9/30/2020,"$2,721,983.00 ","Roy Campbell, Volodymyr Kindratenko, Jian Peng",wgropp@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,"1189, 7231",1189,$0.00 ,exceptionalFunding,"This project will develop and deploy a novel instrument for accelerating deep learning research at the University of Illinois (UI). The instrument will integrate the latest computing, storage, and interconnect technologies in a purpose-built shared-use system. This Instrument will deliver unprecedented performance levels for extreme data intensive emerging fields of research with far-reaching impacts in many areas, such as computer vision, natural language processing, artificial intelligence, healthcare and education. The instrument development will be driven by the UI deep learning (DL) community needs and will be carried out in collaboration with IBM and Nvidia. The instrument will serve as a focal point for the rapidly growing DL research community at UI, enable expansion of several research programs at UI, and contribute to STEM education and training.<br/><br/>Specifically, the proposed instrument is a far-reaching cyberinfrastructure development for the research community and industry engaged with deep learning. The work will result in an advanced high-performing scalable instrument with capabilities far beyond those currently deployed in academia or industry to tackle large-scale deep learning projects. This instrument will serve as a focal point for a community-driven effort to advance the field of DL, integrating the work of computer scientists, systems engineers, and software developers. This project is transformative both in the systems architecture and domain science fields it will imbue, with new knowledge to be developed via new interactions and synergies that will emerge as part of this effort.<br/><br/>The proposed development of this well-integrated instrument will improve the quality and expand the scope of research and training, provide inter- and intra-organizational use amongst many disciplines, and engage private sector partners. The work will have deep and long-lasting effects on future computer architectures for compute- and data-intensive applications by making the blueprints of the novel system architecture of the instrument publically available. Access to the high-performance software developed through this project will aid numerous science domains that utilize DL frameworks. The unprecedented computational capabilities of many applications will make it possible to tackle complex science, engineering and societal problems in many important fields ranging from education, to healthcare, to artificial intelligence (AI). This project will strive to include participants from under-represented minority and female students, to make new discoveries, train, and educate a new generation of users fluent with DL tools and methodologies, contributing to the development of a highly educated, and diverse workforce with specialized skillsets. Finally, the work will enable new industry-academic collaborations benefiting both the scientific community and industry nationwide."
1144591,IGERT: Soft Material Robotics,DGE,"IGERT FULL PROPOSALS, NSF Research Traineeship (NRT), IGERT Chemistry, IGERT Physics, IGERT Materials Research",7/1/2012,7/20/2016,Barry Trimmer,"Trimmer, B","Trimmer, B|Kaplan, D",MA,Tufts University,Continuing grant,Laura Regassa,12/31/2018,"$2,709,035.00 ",David Kaplan,barry.trimmer@tufts.edu,136 Harrison Ave,Boston,MA,21111817,6176273696,EHR,"1335, 1997, 8062, 8063, 8064","1335, 9179, SMET",$0.00 ,exceptionalFunding,"IGERT: Soft Material Robotics.<br/><br/>This Integrative Graduate Education and Research Traineeship (IGERT) award creates an interdisciplinary graduate program to  develop advances in the field of soft robotics. These machines, inspired by animals, will be capable of complex tasks that are difficult to achieve with conventional robots, suitable for close interactions with humans, and able to work in environmentally sensitive locations. The research will cross traditional disciplinary boundaries, employing novel biomaterials, exploiting cellular processes and tissue engineering methods, and using control strategies derived from evolutionary principles ? approaches that are comparatively rare in conventional robotics.<br/><br/>Broader Impacts: The development of this new technology provides an exciting opportunity to train inventive and entrepreneurial future science and engineering leaders. IGERT trainees will train in multiple disciplines, including materials science, neuromechanics, mechanical control systems, computer science, artificial intelligence and product design. Novel collaborative training approaches include the formation of mentorship teams and an innovative problem solving-based model of education. IGERT trainees will exploit bioengineering approaches to machine design, fabricate and control new robotic devices to address a wide range of current medical, social and environmental challenges. For example, soft robots could be developed for internal medical diagnosis and delivery of therapeutics, or for search and rescue operations and bioremediation. The international partners, leaders in the emerging field of soft robots, will help trainees form collaborations and affiliations across the world. These students will bridge emerging areas of biology and engineering to create revolutionary new technologies including robots for human assistance and environmentally-friendly biodegradable robots. <br/><br/>IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to establish new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries, and to engage students in understanding the processes by which research is translated to innovations for societal benefit.<br/><br/>"
808767,INT2-Large: Collaborative Research: Developing Social Robots,IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",9/1/2008,7/22/2010,Javier Movellan,"Movellan, J","Movellan, J|Sa, Vd|Todorov, E|Bartlett, M",CA,University of California-San Diego,Standard Grant,Jeffrey Trinkle,8/31/2014,"$2,650,000.00 ","Virginia de Sa, Emanuel Todorov, Marian Bartlett",movellan@mplab.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,"1640, 7495","7717, 9215, HPCC",$0.00 ,exceptionalFunding,"The goal of this project is to make progress on computational problems that elude the most sophisticated computers and Artificial Intelligence approaches but that infants solve seamlessly during their first year of life. To this end we will develop a robot whose sensors and actuators approximate the levels of complexity of human infants.  The goal is for this robot to learn and develop autonomously a key set of sensory-motor and communicative skills typical of 1-year-old infants.  The project will be grounded in developmental research with human infants, using motion capture and computer vision technology to characterize the statistics of early physical and social interaction.  An important goal of this project is to foster the conceptual shifts needed to rigorously think, explore, and formalize intelligent architectures that learn and develop autonomously by interaction with the physical and social worlds.  The project may also open new avenues to the computational study of infant development and potentially offer new clues for the understanding of developmental disorders such as autism and Williams syndrome."
411449,HBCU-UP: STEM Academy at University of Arkansas at Pine Bluff,HRD,HIST BLACK COLLEGES AND UNIV,9/1/2004,6/17/2009,Mary Benjamin,"Benjamin, M","Benjamin, M|Colen, C|Orr, C|Willingham, W",AR,University of Arkansas at Pine Bluff,Continuing grant,Caesar R. Jackson,8/31/2009,"$2,552,700.00 ","Charles Colen, Clifton Orr, William Willingham",benjaminm@uapb.edu,1200 University Drive,Pine Bluff,AR,716012790,8705758751,EHR,1594,"7204, 9150, 9178, SMET",$0.00 ,exceptionalFunding,"Through the NSF Historically Black Colleges and Universities Undergraduate Program (HBCU-UP), the University of Arkansas at Pine Bluff (UAPB) will implement a project called STEM Academy.  The project will focus on four areas: recruitment and retention; faculty development; curriculum redesign and technology infusion; and research infrastructure.  The target student population includes University students as well as high school students.  The proposed STEM Academy is a comprehensive program that builds on the mission of the University.  As part of an HBCU-UP planning grant, a multidisciplinary University team including STEM faculty and administrators as well as University STEM students, high school students and teachers, and professionals working in STEM areas guided planning for this comprehensive HBCU-UP program. <br/><br/>Intellectual Merit: Research is an essential part of the STEM Academy and will be a central focus on the development of STEM curricula, the recruitment and retention of students in STEM areas, and the continuity of infrastructure support for STEM Academy activities.  Faculty professional development is seamlessly linked to the success of students in the STEM Academy. Workshops, seminars, and professional development opportunities will be provided to all STEM faculty.  Faculty will engage in pedagogy that will engage students with multiple learning styles in order to retain students in STEM areas.  Pedagogical training will be provided to the STEM faculty with STEM Academy faculty serving as mentors to junior faculty and as mentors and tutors to STEM undergraduates.  Each STEM area will have a Team Faculty Leader that will offer support to students in different disciplines and facilitate mentor-student relationship development. Faculty will be trained in the development of web-based courses, mentoring and tutoring students, e-mail listserv for dissemination of information and showcasing successes, and will be linked to research projects at partnering institutions.  The STEM Academy research activities will be a collaborative effort with institutions such as the National Center for Toxicological Research at Jefferson, AR; the National Rice Research Center at Stuttgart, AR; Jackson State University, Arkansas State University, and the University of Arkansas Medical Sciences.  First-year students will participate in a 10-week summer program that will prepare them for their major courses. STEM courses will be infused with technology and research activities providing new opportunities for both faculty and students to benefit from STEM Academy activities. New courses will also be established (e.g., Introduction to Research).  Each year, STEM faculty will receive competitive research funding from the STEM Academy serving as research seed funds to stimulate the development of sustainable research programs. <br/><br/>Broader Impacts: The STEM Academy will increase the number of students admitted to the University and majoring in STEM areas by 10% annually.  In addition the STEM Academy will increase the number of STEM undergraduates who complete their degrees by 50% over the duration of the five-year funding period.  By integrating research and education and infusing research funds to stimulate faculty research the STEM Academy will also involve 75% of the University STEM faculty and all STEM students in research activities over the duration of the five-year program.  While focused on a delineated population, this project will have a broader impact by refining the STEM curricula through the addition of review and practice sessions, laboratory upgrades, and the addition of a mathematics lab for teaching and research along with the infusion of technology, cooperative learning, and writing in the STEM disciplines.  These interventions will improve the science research, teaching and learning environment, not only for STEM majors but also for all University students who take STEM courses as major or general education requirements.  Unique to the STEM Academy is outreach to regional high school students.  The transition from high school to college will be specifically addressed by STEM Academy programs to ensure that students are integrated into the University community prior to starting their first year thus ensuring that these important and often under-served students are not lost but are provided every opportunity to gain entry into STEM careers.  The successful participation of undergraduate, and even high school students, in the STEM Academy will help to reduce the national under-representation of minorities, especially African Americans, in STEM careers."
730206,PIRE: Humanoids - Universally Accessible Infrastructures to Advance Capabilities,OISE,"COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE, PIRE",9/1/2007,9/13/2011,Alan C. Lau,"Lau, AC","Lau, AC|Maxwell, B|Blank, D|Lee, D|Lau, AC|Hong, D",PA,Drexel University,Continuing grant,R.  Clive Woods,8/31/2013,"$2,516,000.00 ","Bruce Maxwell, Douglas Blank, Daniel Lee, Alan C. Lau, Dennis Hong",lau@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,O/D,"7298, 7495, 7742","0000, 1589, 5942, 5978, 6840, 7299, 7495, 7566, 9162, 9251, OTHR",$0.00 ,exceptionalFunding,"0730206<br/>Oh<br/><br/>Humanoids are bipedal robots engineered to mimic human locomotion, balance and coordination.  The Honda ASIMO and KAIST HUBO are adult-sized humanoids that have captured public interest and have given researchers insight on issues ranging from balance disorders to cognition and perception.  This 5-year PIRE project teams U.S. and Korean universities (Drexel University, University of Pennsylvania, Virginia Tech, Swarthmore College, Bryn Mawr Women's College, Korea Advanced Institute of Science and Technology (KAIST), Seoul National University and Korea University) to advance humanoids.<br/><br/>The critical technical gap that prevents a vertical advance in robotics is the lack of universally available platforms to reproduce results and validate hypotheses.  This PIRE's goal is to provide humanoid platforms to a wide audience of researchers by developing a 3-tier tool set based on KAIST's HUBO humanoid: (1) virtual-HUBO is a free and open emulator for testing AI and IT concepts; (2) mini-HUBO is a low-cost 20-inch tall version of the full-sized humanoid for implementing algorithms; and (3) online-HUBO is a tethered version of the full-size humanoid that is accessible for researchers over the internet.  This 3-tier approach provides little to no barriers to entry to humanoid research.  These platforms will provide U.S. scientists and engineers the opportunity to leverage U.S. leadership in artificial intelligence (AI) and information technology (IT) to advance humanoid abilities in perception, cognition and social interaction.<br/><br/>To reach the next generation of robotic scientist and engineers, the PIRE team is working closely with the Philadelphia Please Touch Museum (PTM) to design exhibits featuring HUBO to inspire and motivate students to pursue science and engineering careers.<br/><br/>This PIRE project engages each member's unique resources, including electro-mechanical design (Korean collaborators), virtual-HUBO (Bryn Mawr), online-HUBO and co-op program (Drexel), mini-HUBO (Virginia Tech), advanced locomotion (UPenn) and human-robot interaction (Swarthmore).  The 6-month co-op cycles (twice per year) at KAIST provide 20 U.S. undergraduates with an international research experience to cultivate skills and appreciation for effective global teaming and research.   Shorter but more frequent visits by graduate students and faculty serve similarly functions but also ensure research goals and objectives are met.  Lastly, Drexel's School of Education and Senior Personnel assess student performance, global teaming, and engineering skill acquisition.  <br/><br/>This PIRE is supported by the Office of International Science and Engineering (OISE) and the Robust Intelligence (RI) Cluster of the Division of Information and Intelligent Systems (IIS) found within the Directorate for Computer and Information Science and Engineering (CISE).<br/>"
9983320,"Duke University Program for Vertically Integrated, Interdisciplinary Reseasrch",DMS,"OFFICE OF MULTIDISCIPLINARY AC, INFRASTRUCTURE PROGRAM",7/1/2000,9/29/2004,Harold Layton,"Layton, H","Layton, H|Kraines, D|Allard, W|Beale, JT|Bookman, J",NC,Duke University,Continuing grant,Henry A. Warchall,6/30/2006,"$2,389,032.00 ","David Kraines, William Allard, J. Thomas Beale, Jack Bookman",layton@math.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,MPS,"1253, 1260","0000, 1618, 9178, 9179, OTHR, SMET",$0.00 ,exceptionalFunding,"Abstract<br/>Bertozzi<br/><br/>The Duke Mathematics Department's VIGRE program was designed with NSF's stated objectives<br/>of ""increas(ing) interdisciplinary activities involving mathematics"" and ""encourag(ing) activities aimed at broadening undergraduate and graduate curricula"" in mind while maintaining existing disciplinary strengths.  Interdisciplinary research is a perfect setting for vertical integration and<br/>the Duke Mathematics Department has existing disciplinary strengths in algebraic geometry, analysis, differential equations, differential geometry, numerical analysis, probability, and topology.<br/><br/>We will use the team research model to enhance our graduate training program and our undergraduate and postdoctoral programs.  Graduate and undergraduate students will confront <br/>research problems early in their careers and will have ongoing exposure to them through their respective programs.  Advanced graduate students and postdocs will take on new roles as project leaders in vertically integrated research seminar courses and in team research groups.<br/>All students and postdocs will develop skills in computation, communication and collaboration as part of their mathematical training, thereby broadening the range of opportunities available<br/>to them as mathematical scientists.  The goal of the program is to have students and postdocs completing their programs with a broad scientific knowledge and clear understanding of the inner workings of a scientific team, as well as an academic research and teaching portfolio that will enhance their career advancement potential.<br/><br/>In the undergraduate program our goal is to increase students' enthusiasm for mathematics and its role in research at all levels of their training at Duke.  We will increase the number of first-year and major seminars aimed at exposing students to current topics of research.  Current seminar course topics include cryptography, physiology and medicine, geometry, and optimization.  New topics include heart dynamics, gravitational lensing, and artificial intelligence. A new Perspectives on Science seminar aimed at first-year women interested in mathematics, statistics and computer science will expose young students to current research of senior scientists, postdocs, and graduate students.<br/><br/>The cornerstone of the undergraduate VIGRE program is a new two-year intensive research program, entitled `Practical Research for Undergraduates with VIGRE' (PRUV, pronounced ""prove""), for advanced mathematics majors, which integrates course work, summer internships in a vertically integrated environment, and senior theses.  These improvements in the undergraduate program are targeted to involve more students in research activities.  We expect<br/>that one outcome will be more senior honors theses on research problems and more students choosing to apply to graduate school in the mathematical sciences.<br/><br/>For the graduate program, the VIGRE grant will be combined with Duke resources to support all first year students without teaching duties.  After the first year, the strongest VIGRE-eligible students will receive a one semester-per-year teaching release in order to direct more of their energy towards research.  All graduate students in the graduate program will have the opportunity to work in vertically integrated research teams, including postdocs, graduate students PRUV students, and at least one mathematics professor.  Those working on interdisciplinary problems <br/>will also collaborate with at least one professor from another discipline.  Current interdisciplinary activities include deforestation and aerosol dynamics, geometric computing, granular flow,<br/> heart dynamics, liquid films, photonic band gaps,  physiology and medicine,<br/> string theory, and uncertainty in porous flow, with Duke collaborators in the School of the Environment, Computer Science, Physics, Biomedical Engineering, Cell Biology, Civil and Environmental Engineering, and the Institute for Statistics and Decision Sciences. <br/><br/>Graduate teacher training currently begins in the first-year with students supervising<br/>calculus laboratories.  In order to shorten time to degree and increase retention, we will postpone teaching responsibilities and teacher training by one year for all graduate students.<br/>This will enable all first year graduate students to focus on fundamental course work required to pass the qualifying exam before the beginning of year two. The current teacher-training program will be expanded to include alternative teaching experiences for students and postdocs<br/>including outreach to high school teachers, and mentoring of undergraduate and graduate students. A new computational requirement will be part of their first-year curriculum. The graduate students currently run a weekly seminar with talks aimed at first and second year graduate students given by graduate students and postdocs. PRUV undergraduates will be encouraged to attend this seminar.<br/><br/>VIGRE postdocs will play a leadership role in the overall program. Each year, for the first three years, two VIGRE postdocs will be hired for three year terms.  These positions will parallel existing Duke funded Assistant Research Professors (ARP).  VIGRE Postdocs will have the opportunity to play a strong leadership role in the team research groups including mentoring graduate students and undergraduates and developing a well-defined independent research program.  They will also have the opportunity to take on a significant supporting role in at least one of the following activities:  (1) coordinating research seminars and workshops, (2) co-supervising summer PRUV students and graduate student internships, (3) helping undergraduates and graduate students in a writing workshop.<br/><br/>Postdocs and students will collaborate with high school teachers in Project CHISEL `Carolina High School Educational Leadership project'.  They will design modules for classroom use<br/>that will introduce high school students to the use of mathematics in current research.<br/><br/>Funding for this activity was provided by the Division of Mathematical Sciences and the MPS Office for Multidisciplinary Activity.<br/><br/>"
9108846,"State/Industry University Cooperative Research Center for Low-Cost, High-Speed Polymer Composites Processing",IIP,"INDUSTRY/UNIV COOP RES CENTERS, , CENTRAL & EASTERN EUROPE PROGR",9/1/1991,9/27/1999,Martin Hawley,"Hawley, M","Hawley, M",MI,Michigan State University,Cooperative Agreement,Win Aung,8/31/2001,"$2,264,892.00 ",,hawley@egr.msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,ENG,"4413, 5761, 5826, 5979","0000, 5761, 5915, 9146, 9163, 9165, AMPP, MANU, OTHR",$0.00 ,exceptionalFunding,"The widespread use of composites in the durable goods sector of the civilian economy has been limited due to high material and manufacturing costs. The principle research objective of the State Industry/University Cooperative Research Center for Low-Cost, High- Speed, Polymer-Matrix Composites Processing Center at the Michigan State University is to advance the research and technology transfer activities and to enhance the competitiveness of the producer and user industries in the State and surrounding areas. There are 42,000 plastics related jobs in the State of Michigan and this total is expected to rise to 52,000 by 1995. The State has targeted composites and plastics as a ""key"" growth area. The ""core"" research program will include the following technical thrust areas: Advanced Prepregging, Thermal Management and Novel Processing, Resin Transfer Molding, Reactive Processing of Natural and/or Recycled Constituents, and Artificial Intelligence Techniques for Composites Design and Processing. The strong presence of the automotive industry along with its large, medium, and small suppliers will provide a focus and realistic guidance to the research strategy. The development of knowledge- based processing systems in the form of computer software will play an important role in technology transfer. The participation of the University of Michigan, Wayne State University, Michigan Technological University, and the Michigan Molecular Institute in the ""core"" research program is a special feature of the center. Each participating company (28) in the center is providing one member to the Industrial Advisory Board. The Michigan Materials and Polymer Institute (MMPI), a private, not-for-profit industrial funding consortium will channel its industrial contributions and responsibility for this area to the center. The State of Michigan, industry and NSF will provide matching funds totalling $750,000 in the first year. An additional $184,000 will be provided by industry."
306194,Graduate and Postdoctoral Training in Probability Theory and its Applications,DMS,"INFRASTRUCTURE PROGRAM, PROBABILITY",9/1/2003,3/5/2007,Richard Durrett,"Durrett, R","Durrett, R|Lawler, G|Protter, P|Saloff-Coste, L|Resnick, S",NY,Cornell University,Continuing grant,Dean M. Evasius,8/31/2008,"$2,161,757.00 ","Gregory Lawler, Philip Protter, Laurent Saloff-Coste, Sidney Resnick",rtd@math.duke.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,MPS,"1260, 1263","0000, OTHR",$0.00 ,exceptionalFunding,"In recent years, there has been a tremendous expansion in the use of probability models in finance, geosciences, neuroscience, artificial intelligence and communication networks in addition to an increase in its <br/>use in traditional application areas in engineering disciplines, physics, ecology, genetics, and various fields of mathematics. This has created a strong demand for researchers trained in probability to develop new <br/>methodologies and to work in an interdisciplinary context. We propose a variety of activities to meet these needs. Graduate fellowships will enhance the training of new researchers at Cornell, where a cohort of more <br/>than 20 Ph.D. students exists and 4-6 students receive their Ph.D.'s in this subject each year. On a national scale, two yearly 2.5 day hot topics conferences will bring to Cornell a small group of established researchers and young investigators (in equal numbers). The conference will feature talks describing recent developments, and the young researchers will have a unique opportunity to discuss their research and open problems with the leaders in the field. A two week summer school featuring 4-6 lectures by three prominent researchers, two series of 1-3 on interdisciplinary opportunities, and a limited number of short talks by selected participants, will benefit a large number of graduate students and researchers (young and old) throughout the country.<br/><br/>This project will be under the direction of six probabilists from Math and Operations Research at Cornell (Durrett, Lawler, Protter, Resnick, Saloff-Coste, and Samorodnitsky). Their combined research covers a wide variety of topics in probability and its applications. However, to ensure that this is truly a national resource and covers all aspects of modern probability, they will receive advice from a nationwide committee of prominent researchers that represent a wide variety of specialties and many of the major probability groups throughout the country: David Aldous (U.C. Berkeley), Thomas Kurtz (U. of Wisconsin, Madison), Claudia Neuhauser (U. of Minnesota), Charles Newman (Courant Institute), Yuval Peres (U. C. Berkeley), Simon Tavare' (U. of Southern California)."
813541,Responsive Virtual Human Museum Guides,DRL,AISL,9/1/2008,7/26/2010,William Swartout,"Swartout, W","Swartout, W|Traum, D|Morie, J|Piepol, D|Lane, HC",CA,University of Southern California,Continuing grant,Arlene M. de Strulle,11/30/2012,"$2,062,116.00 ","David Traum, Jacquelyn Morie, Diane Piepol, H Chad Lane",swartout@ict.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,EHR,7259,"7259, 9177, SMET",$0.00 ,exceptionalFunding,"Proposal No.: DRL - 0813541 <br/>PI: Swartout, William <br/>Institution: University of Southern California <br/>Title: Responsive Virtual Human Museum Guides <br/><br/>Abstract<br/><br/>The University of Southern California's Institute for Creative Technologies and the Museum of Science, Boston will create life-sized, 3-D Virtual Humans that will interact with visitors as interpretive guides and learning facilitators at science exhibits.  Through the use of advanced artificial intelligence and intelligent tutoring techniques, Virtual Humans will provide a highly responsive functionality in their dialogue interpretation that will generate sophisticated interaction with visitors about the STEM content related to the exhibit. The project exemplifies how the confluence of science, technology, engineering, mathematics and education can creatively and collaboratively advance new tools and learning processes. The Virtual Human project will begin to present to the visitor a compelling, real life, interactive example of the future and of the related convergence of various interdisciplinary trends in technology, such as natural language voice recognition, mixed reality environments, para-holographic display, visitor recognition and prior activity recall, artificial intelligence, and other interdisciplinary trends. The 3-D, life-sized Virtual Humans will serve as museum educators in four capacities: 1) as a natural language dialogue-based interactive guide that can suggest exhibits to explore in specific galleries and answer questions about particular STEM content areas, such as computer science; 2) as a coach to help visitors understand and use particular interactive exhibits; 3) be the core focus of the Science behind the Virtual Humans exhibit; and 4) serve as an ongoing research effort to improve human and virtual human interactions at increasingly sophisticated levels of complexity. The deliverables will be designed to build upon visitor experiences and stimulate inquiry. A living lab enables visitors to become part of the research and development process. The project website will introduce visitors to the technologies used to build virtual humans and the research behind their implementation. The site will be augmented with videos and simulations and will generate user created content on virtual human characters. Project evaluation and research will collect language and behavioral data from visitors to inform the improvement of the virtual guide throughout the duration of the grant and to develop a database that directly supports other intelligent systems, and new interface design and development that will have broad impact across multiple fields.<br/><br/>"
941497,CDI Type II: Building a Virtual Micro/Nanosystems Design Community,CNS,"SPECIAL PROJECTS - CISE, Computer Systems Research (CSR, CDI TYPE II",10/1/2009,6/30/2010,Tamal Mukherjee,"Mukherjee, T","Mukherjee, T|Fedder, G|Aluru, N|Clark, J",PA,Carnegie-Mellon University,Standard Grant,M. Mimi McClure,9/30/2015,"$2,016,000.00 ","Gary Fedder, N Aluru, Jason Clark",tamal@ece.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"1714, 7354, 7751","7725, 9178, 9218, 9251, HPCC",$0.00 ,exceptionalFunding,"This project offers a web gateway designed to educate users about engineering micro/nanosystems through a freely accessible web-based gateway where user-generated models, example simulations, and design methodologies are shared.<br/><br/>Micro and nanosystems (MEMS and NEMS or N/MEMS) inspire children in the same way as bridges, trains, cars, and radios did in the past. For example, Nintendo Wii links  the physical and digital worlds through a MEMS accelerometer. The N/MEMS industry exceeds $5B in annual revenue and is well recognized as a growth business. However, critical gaps between novice and expert users, prediction and experiment, and length and time scales slow technological advances. This project team exploits this new-found interest in technology by building a virtual community which introduces how N/MEMS work and facilitates new designs by novices and experts. <br/><br/>To achieve the goals of this project, a multidisciplinary team offers a system of tutorials, guidelines, and a toolbox/simulator that can be used for creating, testing, and modeling designs for nanosystems. The target audience includes K12 students, undergraduates, graduate students, and scholars. The objective is to expose novice users to models and structures inherent in nanosystems using a 3-D interface that can be used directly by users to manipulate model components into visual representations. This system promises to offer novice users the opportunity to interrogate and apply complex physics models using an easy to use and intuitive graphical user interface. The system is expected to be useful to experts in this domain by enabling them to extend or add new nanosystems models. This project involves collaboration between computer scientists, mechanical scientists, and electrical engineers, at Carnegie Mellon University, University of Illinois, and Purdue University.<br/><br/>This novel framework, implemented online, is expected to be self-sustaining - piloted by its users. That is, users contribute to the Wiki-driven model and solution libraries, and to tutorials and templates. The 3D graphical user interface expedites system design and motivates novices at many educational levels to participate."
1058748,Collaborative Research: CI-ADDO-NEW: StarExec: Cross-Community Infrastructure for Logic Solving,CNS,"INFORMATION TECHNOLOGY RESEARC, COMPUTING RES INFRASTRUCTURE, TRUSTWORTHY COMPUTING, ALGORITHMIC FOUNDATIONS, SOFTWARE & HARDWARE FOUNDATION",9/1/2011,8/31/2015,Aaron Stump,"Stump, A","Stump, A|Tinelli, C",IA,University of Iowa,Standard Grant,Nina Amla,8/31/2017,"$1,959,838.00 ",Cesare Tinelli,aaron-stump@uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,"1640, 7359, 7795, 7796, 7798","7359, 7795, 7918, 7934, 7944",$0.00 ,normalFunding,"Logic solvers are software programs that can solve complex logical<br/>formulas fully automatically.  Problems in many areas of Computer<br/>Science, such as artificial intelligence, program analysis, security,<br/>hardware verification, and cyber-physical systems can be<br/>translated into logical formulas.  Those formulas can then be solved<br/>fully automatically by logic solvers. Over the past two decades, at<br/>least ten different logic-solving communities have emerged, based on<br/>different logical languages and solving techniques.  These communities<br/>have independently been building computing infrastructure to aid<br/>development and evaluation of their solvers: libraries of benchmark<br/>formulas, cluster-backed web services, annual competitions, and more.<br/>Such infrastructure also provides an important access point for<br/>users, who can find all the solvers at one site, or even run solvers<br/>on the infrastructure cluster to test their relative capabilities.<br/><br/>The goal of this research is to build a single piece of shared<br/>computing infrastructure called StarExec, which will be used by <br/>different logic solving communities.  StarExec will provide improved<br/>services for established logic-solving communities, and lower the<br/>entry barrier for new and emerging communities.<br/><br/>The StarExec infrastructure will consist of a custom web service<br/>interfacing to a medium-sized compute cluster.  This open-source<br/>service will allow multiple logic-solving communities to host<br/>benchmark libraries, run jobs comparing different solvers, and host<br/>competitions.  StarExec will leverage economies of scale to provide<br/>more sophisticated services than is feasible for most individual<br/>logic-solving communities.  A very important goal of StarExec is not<br/>just to collocate different logic-solving communities, but to unite<br/>them.  To this end, the StarExec team will develop formal<br/>specifications of both the syntax and proof-theoretic semantics of<br/>different communities' logical languages.  This will be done using a<br/>meta-language called LFSC (""Logical Framework with Side Conditions""),<br/>developed in previous NSF-funded research.  Translation of formulas<br/>between compatible fragments of different logics will be implemented,<br/>which will will enable a greater degree of integration between solver<br/>communities than was previously possible.  For example, it will be<br/>possible for solvers in one community to be run on benchmarks from<br/>another.  This integration will also aid users of logic solvers, who<br/>will have a greater variety of options, all in a common framework, for<br/>solving their problems.  The broader impact of the StarExec project<br/>will be to accelerate the development, adoption, and convergence of<br/>different logic-solving technologies.  This will enable faster<br/>progress in nationally important application areas such as artificial<br/>intelligence, verification, security, and cyber-physical systems,<br/>which increasingly depend on high-performance logic solvers."
325378,"ITR: Agent-Based Systems for Monitoring, Analysis, Diagnosis, and Control",CBET,"Proc Sys, Reac Eng & Mol Therm, INTERFAC PROCESSES & THERMODYN, ITR MEDIUM (GROUP) GRANTS",9/1/2003,7/23/2007,Ali Cinar,"Cinar, A","Cinar, A|Teymour, F|Hood, C",IL,Illinois Institute of Technology,Continuing grant,Maria Burka,8/31/2010,"$1,950,000.00 ","Fouad Teymour, Cynthia Hood",cinar@iit.edu,10 West 35th Street,Chicago,IL,606163717,3125673035,ENG,"1403, 1414, 1687","0000, 1652, 1687, 9216, OTHR, HPCC",$0.00 ,normalFunding,"Research: Driven by the growing worldwide competition for quality, productivity, and safety enhancement, attrition of experienced personnel, and increasing complexity of manufacturing processes, this research project addresses the need for software that can automate and integrate process supervision tasks such as data reconciliation, process and product quality monitoring, fault diagnosis, and control. Research on distributed artificial intelligence (DAI) and multi-layered, intelligent, and adaptive multiagent systems (MAS) will be carried out to develop a new framework for real-time supervision of distributed system operations. The stability, scalability, performance, and robustness of this framework will be explored, and test cases will be used to investigate the synergy between microreactor and computer networks to discover ways of enhancing their stability and productivity. Manufacturing process and computer network operations will be the application domains of this monitoring, analysis, diagnosis, and control with agent-based system (MADCABS) that automates knowledge extraction from data, analysis, and decision-making. The research will also focus on investigating emergence of behavior patterns in both the physical systems and MADCABS, introducing evolutionary dynamics in analysis, diagnosis and control by rewarding successful strategies over time, and enhancing the stability and robustness of MADCABS by designing it with adaptation capabilities.<br/>Multiple layers of agents will be used, where lower-level agents are performing local well-defined tasks such as data validation and higher-level agents performing more global tasks over wider regions of the supervised system. Agents are capable of acting, communicating with other agents, perceiving their environment, and determining behavior to satisfy their objectives. However, agents have only partial information about their environments and may initiate actions that could conflict with actions of other agents, leading to emergence of undesirable behavior of the supervised system. In this sense, the supervised system is viewed as a self-organized complex system comprised of the operating units of the process and layers of MADCABS agents acting upon them. Complex adaptive systems (CAS) studied often by using artificial life (AL) paradigms. CAS are known to exhibit emergence phenomena in which the global system displays properties and features not inherent to any of its components. Analysis and examination of the long-term behavior of the MADCABS supervised systems will be used to assess the compatibility levels of sets of agent characteristics and their optimal task orientation. <br/>The project is led by an interdisciplinary team of researchers with expertise in DAI, MAS, CAS, supervision of computer network and manufacturing process operations, and real-time KBS development. Argonne National Laboratory (ANL) is combining new modeling theories and software for studying CAS. Collaboration between IIT and ANL will provide a strong partnership with powerful resources to carry out the proposed research, education, and outreach activities. Research results will contribute to advancement of knowledge in CAS, MAS, DAI, and AL. The outcome of the research will provide a new approach for commercial software for supervision of process and computer network operations. Research on behavior and controllability of distributed microreactor networks will result in new approaches to analyze the viability of such systems and ability to manufacture high-value-added specialty chemicals. <br/><br/>Broader impact: The research results will be used to promote education and training activities in DAI, AL, and complex adaptive system operation and supervision. The methods and tools developed will have an impact on many CAS central to national concerns, such as energy distribution systems, ecosystems, and epidemics. Consequently, research results will be disseminated in the form of software, case studies, and practical training to university and industry researchers, high school teachers, students from underrepresented groups in science and engineering, and undergraduate students."
104695,INNOVATION,DRL,AISL,8/15/2001,7/17/2002,Beth Hoppe,"Hoppe, B","Hoppe, B|Robinson, T|Grant, W",NY,Educational Broadcasting Corporation,Continuing grant,Sandra H. Welch,7/31/2004,"$1,902,760.00 ","Tamara Robinson, William Grant",Hoppe@thirteen.org,825 Eighth Ave,New York,NY,100197435,2125603130,EHR,7259,"9180, SMET",$0.00 ,normalFunding,"The Educational Broadcasting Corporation (WNET in New York) is developing and producing a new public television project exploring cutting-edge technology. The project consists of an eight-part hourly broadcast component; six 60-second ""mini-programs;"" a World Wide Web component; and extensive educational outreach targeted to adults aged 25-39 and older. The topics for the eight programs in season one are:<br/><br/> Replacements - prosthetic devices and biologically electronic artificial body parts<br/> In Search of Eve - the race to decode the human genome<br/> Light of the 21st Century - Fiber Optics<br/> Nanotechnology - molecular manipulation of materials<br/> Technospy - technologies used to gain information<br/> Sports Technology - the pursuit of better equipment and training regimes<br/> Artificial Intelligence - efforts to create computers the mimic human intelligence<br/> Appropriate Technologies - technologies that use local, inexpensive material<br/><br/>Beth Hoppe, WNET's Director of Science Programs will serve as Executive Producer for the series. Each of the programs would be produced by an independent producer selected by WNET. Content advisors include: Angela Christiano, Departments of Dermatology, Genetics and Development, Columbia University; Sheila Sen Jasanoff, Harvard University JFK School of Government; Horace Freeland Judson, Center for History of Recent Science, George Washington University; Michio Kaku, theoretical physicist, CUNY and host, Explorations radio series; Wilfred Pinfold, Microprocessor Research Labs, Intel Corp.; and Barbara Wilson, chief technologist, NASA's Jet Propulsion Laboratory"
1020152,Collaborative Research: INK-12: Teaching and Learning Using Interactive Ink Inscriptions in K-12,DRL,DISCOVERY RESEARCH K-12,9/1/2010,8/31/2016,Kimberle Koile,"Koile, K","Koile, K",MA,Massachusetts Institute of Technology,Standard Grant,Margret Hjalmarson,2/28/2017,"$1,891,343.00 ",,kkoile@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,EHR,7645,"7645, 9177, SMET",$0.00 ,normalFunding,"The research project continues a collaboration between MIT's Center for Educational Computing Initiatives and TERC focusing on the enhancement of K-12 STEM math and science education by means of technology that supports (1) creation of what are termed ""ink inscriptions""--handwritten sketches, graphs, maps, notes, etc. made on a computer using a pen-based interface, and (2) in-class communication of ink inscriptions via a set of connected wireless tablet computers. The project builds on the PIs' prior work, which demonstrated that both teachers and students benefit from such technology because they can easily draw and write on a tablet screens, thus using representations not possible with only a typical keyboard and mouse; and they can easily send such ink inscriptions to one another via wireless connectivity. This communication provides teachers the opportunity to view all the students' work and make decisions about which to share anonymously on a public classroom screen or on every student's screen in order to support discussion in a ""conversation-based"" classroom.  Artificial intelligence methods are used to analyze ink inscriptions in order to facilitate selection and discussion of student work.<br/><br/>The project is a series of design experiments beginning with the software that emerged from earlier exploratory work. The PIs conduct two cycles of experiments to examine how tablets affect students learning in 4th and 5th grade mathematics and science.  The project research questions and methods focus on systematic monitoring of teachers' and students' responses to the innovation in order to inform the development process. The PIs collect data on teachers' and students' use of the technology and on student learning outcomes and use those data as empirical evidence about the promise of the technology for improving STEM education in K-12 schools.  An external evaluator uses parallel data collection, conducting many of the same research activities as the core team and independently providing analysis to be correlated with other data.  His involvement is continuous and provides formative evaluation reports to the project through conferences, site visits, and conference calls.  <br/><br/>The primary products are substantiated research findings on the use of tablet computers, inscriptions, and networks in 4th and 5 grade classrooms.  In addition the PIs develop models for teacher education and use, and demonstrate the utility of artificial intelligence techniques in facilitating use of the technology.  With the addition of Malden Public Schools to the list of participating districts, which includes Cambridge Public Schools and Waltham Public Schools from earlier work, the project expands the field test sites to up 20 schools' classrooms."
1880,Incorporating the Center for Advanced Control of Energy and Systems at Arizona State University into the Power Systems Engineering Research Center (PSerc),IIP,"INDUSTRY/UNIV COOP RES CENTERS, , , , , , , , , ",8/1/2000,6/23/2008,Gerald Heydt,"Heydt, G","Heydt, G",AZ,Arizona State University,Continuing grant,Rathindra DasGupta,7/31/2009,"$1,890,508.00 ",,heydt@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,ENG,"5761, H108, H232, T313, T479, T752, T846, V105, V638, V915","0000, 1049, 122E, 127E, 1325, 7218, 9102, 9177, 9178, 9251, EGCH, OTHR, SMET",$0.00 ,normalFunding,"EEC-0001880<br/>Arizona State University<br/>Heydt<br/><br/>It is proposed to bring the Arizona State University portion of the Center for the Advanced Control of Energy and Power Systems (ACEPS) into the Power Systems Engineering Research Center (Pserc). Both these efforts focus on research in electric power engineering. The ASU portion of ACEPS will bring expertise to Pserc in the areas of electric power quality, high voltage engineering, and power electronics. These areas are believed to beneficially supplement the existing Pserc power engineering efforts. Additionally, ASU-ACEPS will bring expertise in power system instrumentation and control, and power system analysis. <br/><br/>The combined center is expected to be one of the largest power engineering efforts in the world, focusing on questions of power systems, deregulation of the power industry, power quality, transmission and distribution , and the efficient use of power infrastructure. An educational component of the program is proposed in the form of graduate and undergraduate student training and research and bringing advanced concepts in power engineering into the undergraduate classroom"
205633,ITR: Non-Cooperative Computing: Foundational Problems at the Interface of Computer Science and Game Theory,IIS,ITR MEDIUM (GROUP) GRANTS,7/15/2002,6/16/2009,Yoav Shoham,"Shoham, Y","Shoham, Y|Wilson, R|Koller, D|Feinberg, Y",CA,Stanford University,Continuing grant,William Bainbridge,6/30/2010,"$1,799,945.00 ","Robert Wilson, Daphne Koller, Yossi Feinberg",shoham@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,1687,"1657, 9216, HPCC",$0.00 ,normalFunding,"This project brings together two disciplines, computer science and artificial intelligence on the one hand, and economics and game theory on the other, and by doing so addresses some fundamental problems of computing in the Internet era. Some of the problems addressed are rooted directly in today's Internet applications: How do you charge for network usage so as to smooth out peaks in the demand? How do you incent people to contribute personal information and recommendations in recommender systems and discretionary databases? While this project is motivated by its potential application to electronic commerce, the focus is on foundational matters. Computing in the Internet era means computing in the context of multiple  self-interested entities, which in turn means that reasoning about computing must take the incentives of these entities into account. This, in turn, calls for a fundamental integration of ideas from computer science (such as fault tolerance, fairness, verification, algorithms, complexity, graphical models of uncertainty, machine learning) with elements of game theory (such as mechanism design, equilibrium analysis, game representations, learning, and agency theory). The outcome is expected to benefit electronic commerce, but also more fundamentally to help lay the foundations for a new area of research called ""non-cooperative computing."""
9401156,A Next-Generation Infrastructure for Integrating Computing  and Communications,EIA,"CISE RESEARCH INFRASTRUCTURE, EXPERIMENTAL SYSTEMS/CADRE",8/15/1994,6/22/1998,David Culler,"Culler, D","Culler, D",CA,University of California-Berkeley,Continuing grant,Stephen Mahaney,7/31/2000,"$1,786,341.00 ",,culler@cs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,"2885, 4725","9218, HPCC",$0.00 ,normalFunding,"9401156  Ferrari        This award provides support for the development of Titan, a computing  system consisting of an integrated ensemble of computing and communication  elements, organized to provide the user with a number of services.  These  services will include multimedia capabilities in delivery vehicles; storage and  communication; large computing power; large storage space; innovative parallel  languages, debuggers, and libraries; and high accessibility from both mobile and  fixed locations.  The experimental facilities requested include workstations and  servers constituting the backbone of the distributed system providing cycles to  the user, ATM switches for linking workstations and servers, a video editing  system, a massive storage unit, and equipment for linking the network to the  currently available CM-5 parallel computer.                The proposed research projects fall into three areas:  network and  communications; distributed supercomputer projects which are mainly concerned  with providing parallel computing to every user through a combined architecture,  operating systems, and programming language effort; and multimedia services which  requires integrating systems support, software support, and artificial  intelligence tools to create, store, play, edit, search, input, and output  multimedia objects.  The networking, multimedia, and computing aspects of Titan  form will form the infrastructure for a number of computationally intensive  applications."
85945,ITR: Exploiting Style as Retrieval and Classification Mechanism,IIS,"INFORMATION TECHNOLOGY RESEARC, INFORMATION & KNOWLEDGE MANAGE",9/1/2000,10/8/2004,William Birmingham,"Birmingham, W","Birmingham, W|Simoni, M|Jagadish, H",MI,University of Michigan Ann Arbor,Continuing grant,Maria Zemankova,2/28/2005,"$1,784,255.00 ","Mary Simoni, H. Jagadish",wpb@eecs.umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,"1640, 6855","1655, 1661, 9178, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"Vast musical databases are currently accessible over computer networks (e.g., the Web), creating a need for sophisticated methods to search and organize these databases. Because music is a multifaceted, multi-dimensional medium, it demands specialized representations, abstractions and processing techniques for effective search that are fundamentally different from those used for other retrieval tasks. By exploiting reductionist theories of musical structure and performance (i.e., musical style), this project will develop hierarchical, stochastic music representations and concomitant storage and retrieval mechanisms that are well-suited to music's unique characteristics, and are both musically and psycho-acoustically plausible. A software system exploiting these representations and retrieval mechanisms will be developed that accepts sonic input, compares abstractions of this input to those in a database of digital recordings, returns sonic samples of the database that best match the query, and allows the user to refine the query using music/acoustic-based interfaces of varying degrees of complexity. This research will yield a working music-search engine will application to e-commerce and will provide new scientific knowledge in terms of algorithms and mathematic models in the fields of databases, information retrieval, artificial intelligence, signal processing and perception, for music search and retrieval, which will generalize to other multimedia processing tasks.<br/><br/>"
9873442,"KDI: New Algorithms, Architectures and Science for Data Mining of Massive Astrophysics Sky Surveys",DMS,"COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT, KDI OPPORTUNITY FUND",10/15/1998,9/14/1998,Andrew Moore,"Moore, A","Moore, A|Spirtes, P|Nichol, R|Faloutsos, C|Wasserman, L",PA,Carnegie-Mellon University,Standard Grant,Michael H. Steuerwalt,9/30/2001,"$1,600,000.00 ","Peter Spirtes, Robert Nichol, Christos Faloutsos, Larry Wasserman",awm@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,MPS,"1271, 2865, 8876","0000, 1337, 1339, 9218, 9263, HPCC, OTHR",$0.00 ,normalFunding,"Moore<br/>9873442<br/>     There many massive databases in industry and science, and<br/>this is particularly true for Astrophysics.  There are many kinds<br/>of questions that physicists and other users wish to ask the<br/>databases in real time, e.g., 'find outliers'; 'find clusters';<br/>'find patterns'; 'classify the data records into N predetermined<br/>classes.'  Wide-ranging statistics and machine learning<br/>algorithms similarly need to query databases, sometimes millions<br/>of times for a single inference.  With millions or billions of<br/>records (such as the new generation of astrophysics sky surveys)<br/>this can be intractable using current algorithms.  This project<br/>aims to make repeated statistical querying of huge datasets<br/>computationally feasible by transforming massive databases into<br/>condensed representations that permit the rapid answering of such<br/>questions.  To achieve these goals, the investigator and his<br/>colleagues explore ways in which tools from statistics (such as<br/>Bayesian networks), databases (such as kd-trees/R-trees), and<br/>Artificial Intelligence (such as AD-trees and rule-finders) can<br/>help, how they scale up, and how they can be combined.<br/>     The investigators intend to help automate the process of<br/>scientific discovery for astrophysical data sources in which<br/>there is too much information for any unaided human to have a<br/>chance of spotting patterns, regularities, or anomalies.<br/>Government and industry in the U.S. have invested heavily in<br/>ingenious new ways to gather information in all branches of<br/>science and industry, from cell biology to the flows of capital<br/>in international commerce.  Scientists and analysts who have<br/>worked so hard to gather magnitudes more data than they had ten<br/>years ago are now faced with an equally daunting task: exploiting<br/>it fully.  It is ironic that in fields such as astrophysics there<br/>is now so much data that no human has enough time to even see a<br/>tiny fraction of it.  The job of discovering new relationships,<br/>anomalies, and even causation, must now be at least partly turned<br/>over to computers.  The investigators comprise a team of<br/>statisticians, computer scientists, and astronomers who have each<br/>already made progress in this direction.  This team develops new<br/>algorithms to squeeze as much information as possible from<br/>trillion-byte astrophysics databases such as the Sloane Sky<br/>Survey.  They also make sure that the resulting technology is<br/>deployed elsewhere in science and industry.<br/><br/>"
431330,AToL: Collaborative Research on Ant Phylogeny: A Comprehensive Evolutionary Tree for the World's Premier Social Organisms,DEB,"BE: NON-ANNOUNCEMENT RESEARCH, ASSEMBLING THE TREE OF LIFE",10/1/2004,8/4/2008,Philip Ward,"Ward, P","Ward, P|Fisher, B|Brady, S|Schultz, T",CA,University of California-Davis,Continuing grant,Charles Lydeard,9/30/2011,"$1,555,139.00 ","Brian Fisher, Sean Brady, Ted Schultz",psward@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,BIO,"1629, 7689","7689, 9169, EGCH",$0.00 ,normalFunding,"Abstract<br/>EF 0431330<br/>Philip Ward, University of California at Davis<br/><br/><br/>Originating in the Cretaceous Period and outliving the dinosaurs, ants are one of the greatest success stories in the history of life on Planet Earth.  Numbering approximately 20,000 species, ants dominate many terrestrial environments and in some habitats they constitute 15 to 20% of the total weight of all animals combined.  Perhaps the major factor contributing to the ubiquity and importance of ants is their complex, cooperative societies.  Ants are involved in intimate biological interactions with countless other organisms, and exhibit many remarkable behaviors, including agriculture of fungi, harvesting of seeds, herding and ""milking"" of other insects, cooperative hunting in packs, slave-making, and communal nest weaving.  The parallels between these behaviors in ants and those found in humans have inspired public and scientific curiosity alike.  Human understanding of ants suffers, unfortunately, from a lack of scientific research on ant history and genetics.  This research project will remedy this problem by reconstructing the history of ants, from the Age of Dinosaurs to the present, using evidence both from ant anatomy and ant DNA.  Techniques unavailable to previous generations of ant researchers, such as PCR amplification and DNA sequencing of genes, will be used to gather molecular data.  Some of these data will come from newly discovered genes, which will also yield broad insights about the genetics of other animals.  These data will be analyzed using state-of-the-art computing algorithms and hardware in order to reconstruct the ""family tree"" of all major lineages of ants.  Dates for major events in the history of ants will be inferred by combining fossil evidence with molecular dating techniques.  These results will be integrated with the large body of pre-existing data on ant ecology and behavior, in order to cast new light on ant biology and to suggest new pathways for future investigation.<br/><br/>This project will have a substantial impact on both science and society.  This work will involve university and museum faculty, postdoctoral researchers, graduate and undergraduate students, and technical staff who will interact during all stages of the project with an international team of scientific collaborators.   <br/>The study of ant biology occupies a central role in a diverse number of disciplines including ecology, conservation biology, molecular biology and genetics, chemical communication, biodiversity studies, and artificial intelligence research.  As just one example, ant diversity has become a leading indicator of habitat quality in conservation biology, so a better understanding of the history and genetics of ants will increase our ability to make informed conservation decisions.  The information generated by this project will be disseminated through scientific publications, as well as through a book geared towards a more general audience.  The scientific results from this project also will be presented in user-friendly internet interfaces on the World-Wide Web, which will be made available to all interested members of the scientific community and the general public.<br/>"
1007962,Emerging Research-Empirical Research--An Integrated Model of Cognitive and Affective Scaffolding for Intelligent Tutoring Systems,DRL,REAL,9/15/2010,7/26/2012,James Lester,"Lester, J","Lester, J|Boyer, K|Wiebe, E",NC,North Carolina State University,Continuing grant,Finbarr Sloane,8/31/2014,"$1,542,275.00 ","Kristy Boyer, Eric Wiebe",lester@csc.ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,EHR,7625,"9177, 9251, SMET",$0.00 ,normalFunding,"One-on-one human tutoring is remarkably effective.  Seminal studies have shown that tutoring is significantly more effective than group instruction and may provide unparalleled opportunities for learning.  A central, unanswered research question is, ""How do expert tutors provide effective cognitive and motivational support over the course of long-term tutorial interactions to improve learning?"" With a curricular focus of college-level computer science education, this project will see the design and evaluation of a computer-based intelligent tutoring system, JavaTutor, which leverages artificial intelligence to provide both cognitive and motivational support.  The project will be conducted at North Carolina State University in conjunction with three partner institutions: Meredith College, Shaw University, and St.  Augustine's College.  <br/><br/>The project has three major thrusts.  First, the research team will conduct a semester-long observational study of cognitive and affective tutorial support provided by expert human tutors interacting with students in a fully-instrumented online tutoring environment.  The environment will log all tutorial conversations, problem-solving traces, and affective data streams including physiological signals, posture, and facial expressions.  Second, the research team will develop an empirically grounded, integrated model of cognitive and affective scaffolding using machine learning techniques including hidden Markov modeling.  Third, they will validate the integrated model of cognitive and affective scaffolding in a semester-long experiment with the JavaTutor intelligent tutoring system.  Four versions of the JavaTutor system will be deployed and compared.  It is hypothesized that over the course of a semester, the version with an integrated model of cognitive and motivational scaffolding will outperform each of the other models on both cognitive and affective student outcomes and yield differential effects across learner groups, accruing particularly significant benefit to low-performing and female students.<br/><br/>The products of this project include findings and technologies that will inform the future development of intelligent tutoring systems.  By promoting rich learning interactions through integrated cognitive and motivational scaffolding, the project will create new learning environment technologies that promote high levels of achievement and find broad application in STEM education.  It is anticipated that the resulting intelligent tutoring system technologies will serve as a foundation for the next generation of educational software that both complements and expands the impact of classroom teachers.  The impact should be significant given the effectiveness of human tutoring and the potential power of these new technologies to support learning."
1727894,"SNM: Manufacturing Autonomy for Directed Evolution of Materials (MADE-Materials) for Robust, Scalable Nanomanufacturing",CMMI,"SNM - Scalable NanoManufacturi, NANOMANUFACTURING",9/1/2017,5/21/2018,David Hoelzle,"Hoelzle, D","Hoelzle, D|Shtein, M|Barton, K",OH,Ohio State University,Standard Grant,Khershed Cooper,8/31/2021,"$1,502,521.00 ","Max Shtein, Kira Barton",hoelzle.1@osu.edu,Office of Sponsored Programs,Columbus,OH,432101016,6146888735,ENG,"025Y, 1788","081E, 083E, 084E, 116E, 9178, 9231, 9251",$0.00 ,normalFunding,"The development and manufacturing of cutting edge materials typically involves time-consuming materials and process design phases, followed by extensive testing of samples to adjust process conditions as the manufacturing scales up from the lab, to pilot plan, to industrial process scale. These distinct steps drive up the cost barrier to introduction of new and improved materials into the industrial pipeline and increase the cost of domestically manufactured advanced nanomaterials. Fortunately, recent developments in numerical modeling, additive manufacturing, and rapid testing of materials suggest that a new approach to material development and nanomanufacturing, where the previously distinct and time-consuming phases could be carried out nearly instantaneously to arrive at optimal material structure as well as process conditions for its manufacture. The focus of this award is to revamp the traditional, open-loop synthesis of nanostructured materials by: 1) using a versatile 3-D printing approach to manufacture these nanomaterials and nanostructures, 2) incorporate material property characterization directly into the printing process, and 3) use an artificial intelligence (AI) algorithm to adjust on the fly process conditions to achieve desired material properties. These concepts and components will be integrated into technical coursework, hands-on research opportunities, and outreach workshops to a broad range of students and the public. The co-PIs plan to leverage existing outreach and educational activities through their group's collaboration with a local museum, as well as curricular and extracurricular activities.<br/> <br/>The approach and framework is an investigation of process modeling, materials synthesis and characterization, and system design to autonomously discover new material configurations and reduce manufacturing defects and uncertainty. This AI framework will ""understand"" process-structure-property relationships, manufacturing constraints, and, importantly, statistical variations in material properties and manufacturing quality. The intellectual merit of this study is the discovery of general nanomanufacturing tools and feedstocks, with supervisory genetic algorithms, that autonomously correct for defects and compensate for innate manufacturing inaccuracies by a search for alternative designs; this is in contrast to standard tools that minimize uncertainty (e.g. environmental controls) or rely on post-fabrication characterization with human intervention. The framework will be tested using nanoscale additive manufacturing (AM) as the fundamental manufacturing tool and nanostructured metamaterials as the application. The paradigm and nanoscale metamaterials made via this approach have far-reaching impacts on scalable nanomanufacturing for integrated systems. The paradigm of systems that autonomously evolve parameters to meet construct specifications is extensible to macroscale additive manufacturing and pharmaceuticals where the process parameter space and chemistries available is vast, and design is not intuitive. Additive nanomanufacturing has the potential to transform metamaterial design by enabling design in 3-dimensions (3D) with multiple materials, creating complex composite metastructures."
206377,Windows on Research,DRL,AISL,7/1/2002,5/29/2003,Marco Molinaro,"Molinaro, M","Molinaro, M",CA,University of California-Berkeley,Continuing grant,Sandra H. Welch,12/31/2005,"$1,488,216.00 ",,mmolinaro@ucdavis.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,EHR,7259,"9180, SMET",$0.00 ,normalFunding,"The University of California, Berkeley is developing ""Windows on Research,"" a two-year experimental exhibit project at the Lawrence Hall of Science focused on engaging and informing the public about current scientific research. The project will develop and evaluate different media to translate the leading edge of nanotechnology research for the science center audience by featuring live demonstrations and presentations, physical- and technology-based exhibits, and Internet-based exhibits. Formative evaluation of all products, including ongoing public focus groups and surveys, will be used to establish which of the several media, alone or combined, work best to communicate research content. The project team also is developing new assessment tools to test usability and effectiveness of the artificial intelligence and technology-based components in conveying content. The results of this prototype effort to present ongoing research in a museum setting will be disseminated to the informal science education field.<br/><br/>The PI, Marco Molinaro, and the team from the Lawrence Hall of Science will work closely with scientists representing research in a number of nanotechnology fields. These scientists bring expertise in the areas of materials science, chemistry, education, bioengineering, mechanical engineering, molecular and cell biology, geochronology and isotope geochemistry, and psychology."
508002,BE/CNH:   Urban Landscape Patterns:    Complex Dynamics and Emergent Properties,BCS,"BE: NON-ANNOUNCEMENT RESEARCH, DYN COUPLED NATURAL-HUMAN, ENVIR SOCIAL & BEHAVIOR SCIENC, ERE General",9/15/2005,8/1/2007,Marina Alberti,"Alberti, M","Alberti, M|Redman, C|Wu, J|Handcock, M|Marzluff, J",WA,University of Washington,Standard Grant,Thomas J. Baerwald,8/31/2010,"$1,448,862.00 ","Charles Redman, Jianguo Wu, Mark Handcock, John Marzluff",malberti@u.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,SBE,"1629, 1691, 5209, 7304","1689, 1691, 9169, 9232, 9278, EGCH",$0.00 ,normalFunding,"Urban development in the United States is profoundly changing landscape patterns and biodiversity and is simultaneously affected by these changes.  Little is known about the interactions between patterns and processes in human dominated landscapes, however.  One of the least understood aspects of urban landscape dynamics is the way in which local interactions of humans and biophysical processes generate the landscape patterns of metropolitan regions.  Studying the relationships between these interactions and the resulting urban landscape patterns is critical to plan and manage urban growth in ways that minimize the ecological impacts on ecosystems while sustaining economically and socially viable urban communities.  This research project will examine urban landscapes as emergent phenomena that result from local interactions of human agents, real estate markets, built infrastructure, and biophysical factors like land cover, geomorphology, and natural disturbance regimes to develop a theory of urban landscape dynamics.  The study will employ complex systems, patch dynamics, hierarchical theory, and an agent-based modeling approach to study coupled human-natural dynamics and empirically test this approach in two different bioregions (Seattle and Phoenix).  The models will be developed and used to test hypotheses regarding emergent properties of urban landscapes and to enhance basic understanding of humans-ecological interactions in urban landscapes across scales.  Urban landscapes exhibit some fundamental features of complex self-organizing systems.  They are highly heterogeneous, spatially nested, and hierarchically structured.  The urban spatial structure can be described as a cumulative and aggregate pattern that results from numerous local decisions involving a large number of adaptive agents interacting among themselves and with biophysical factors.  These behaviors eventually can lead to different metropolitan patterns.  This research will address four questions:  (1) How do dynamic landscape systems evolve to generate emergent patterns that are evident in urban landscapes?  (2) What nonlinearities, thresholds, discontinuities, and path dependencies explain divergent trajectories of urban landscapes?  (3) How do emergent urban landscape patterns influence biodiversity and ecosystem functioning?  (4) How can planning integrate this knowledge to develop sustainable urban landscape patterns?  The model implementation will be based on a dynamic probabilistic relational model (DPRM) in which parameters and spatial rules are estimated empirically from two longitudinal land-cover and land-use data sets developed for the Seattle and Phoenix metropolitan areas.<br/><br/>The project will have significant theoretical and practical impacts.  It will develop a better understanding of complex human-ecological dynamics leading to development patterns such as sprawl, one of the most pressing and controversial problem in the United States.  The project will also contribute to advancing biocomplexity science.  The findings of this research will have an impact on both the social and natural sciences particularly the study of development patterns, land-use change, ecological resilience, and public policy in urbanizing regions.  This project will also employ new computational techniques that are of importance to a broad range of disciplines studying human dynamics, ecology, and artificial intelligence.  The findings will also aid planning and management of urban regions by providing simulation tools to assess the ecological impacts and feedback of alternative strategies for urban development and ecological conservation.  This project is supported by an award resulting from the FY 2005 special competition in Biocomplexity in the Environment focusing on the Dynamics of Coupled Natural and Human Systems.<br/><br/>"
9906600,CISE MII: Institutional Infrastructure in Support of        Computer and Software Engineering with Special Focus on     Human-Computer Interface Research and Information Processing,CNS,CISE RESEARCH INFRASTRUCTURE,8/15/1999,4/7/2005,Malek Adjouadi,"Adjouadi, M","Adjouadi, M|Roig, G|Pasztor, A|Barreto, A|Martinez, M",FL,Florida International University,Continuing grant,Rita V. Rodriguez,7/31/2006,"$1,437,770.00 ","Gustavo Roig, Ana Pasztor, Armando Barreto, Maria Martinez",adjouadi@fiu.edu,11200 SW 8TH ST,Miami,FL,331990001,3053482494,CSE,2885,"2886, 9218, HPCC",$0.00 ,normalFunding,"9900660<br/>Adjouadi, Malek<br/>Barreto, Armando<br/>Pasztor, Ana<br/>Martinez, Maria<br/>Roig, Gustavo<br/>Florida International University (FIU)<br/><br/>Development of an Institutional Infrastructure with Special Focus on Human-Computer Interfaces and Information Processing<br/><br/>This award enables the establishment of a multidisciplinary educational infrastructure with key innovations in engineering that promote an environment with effective learning strategies based on bridging instructional activities with research facilities. The award drives an ambitious program that focuses on FIU's strengths in the areas of human-computer interface research to include those persons with disabilities; key aspects of information processing (image and signal), including real-time applications; hardware-software integration; distributed processing, and data structures.  A supplemental instruction component is included to tackle head-on the failure rates in those SEM ""high risk"" courses (failure rates exceeding 30%), which are critical foundations for Computer Science and Engineering. Within the proposed infrastructure, a comprehensive pipeline is established to attract more students in engineering and to redress at FIU the national trend showing limited graduation rates in Computer Science and Engineering.  The project also addresses the recruitment and retention of students from groups traditionally underrepresented in Computer Science and Engineering, namely women, Hispanics and African Americans. In addition to these educational enhancements, the impact of the project will be extended through expected research results in distributed processing, and image and signal processing, particularly in their application to human-computer interfaces for individuals with disabilities.<br/><br/>Through this effort, Florida International University is expected to develop further its computing science and engineering research capabilities involving minority students in greater numbers, paving the way for eventual conferring of more doctoral degrees, not only to Hispanic students, but also to African American, and disabled students. It is hoped that through these efforts, the nation might find a successful model that will help in building a better racially and ethnically balanced technological enterprise for the benefit of its present and future generations.<br/> <br/>"
1122504,DIP: Teaching Writing and Argumentation with AI-Supported Diagramming and Peer Review,IIS,"NATIONAL SMETE DIGITAL LIBRARY, Cyberlearn & Future Learn Tech",9/1/2011,4/9/2012,Kevin Ashley,"Ashley, K","Ashley, K|Litman, D|Schunn, C",PA,University of Pittsburgh,Standard Grant,Tatiana D. Korelsky,8/31/2017,"$1,390,735.00 ","Diane Litman, Christian Schunn",ashley@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,"7444, 8020","7444, 8045, 8842, 9251",$0.00 ,normalFunding,"The PIs are investigating the design of intelligent tutoring systems (ITSs) that are aimed at learning in unstructured domains. Such systems are not able to do as much automatically as ITSs working in traditionally narrow and well-structured domains, but rather they need to share responsibilities for scaffolding learning with a teacher and/or peers. In the work proposed, the three PIs, who share expertise in automated natural language understanding, intelligent tutoring systems, machine learning, argumentation (especially in law), complex problem solving, and engineering education, are integrating intelligent tutoring, data mining, machine learning, and language processing to design a socio-technical system (people and machines working together) that helps undergraduates and law students write better argumentative essays. The work of helping learners derive an argument is shared by the computer and peers, as is the work of helping peer reviewers review the writing of others and the work of learners to turn their argument diagrams into well-written documents. Research questions address the roles computers might take on in promoting writing and the technology that enables that, how to distribute scaffolding between an intelligent machine and human agents, how to promote better writing (especially the relationship between diagramming and writing), and how to promote learning through peer review of the writing of others. <br/><br/>This project is bringing together outstanding researchers from a variety of different disciplines -- artificial intelligence, law education, engineering and science education, and cognitive psychology -- to address an education issue of national concern -- writing, especially writing that makes and substantiates a point -- and to explore ways of extending intelligent tutoring systems beyond fact-based domains. It fulfills all aims of the Cyberlearning program -- to imagine, design, and learn how to best design and use the next generation of learning technologies, to address learning issues of national importance, and to contribute to understanding of how people learn."
9215983,Hampton University Experimental Laboratory for Promoting    Education and Research (HELPER),EIA,"CISE RESEARCH INFRASTRUCTURE, SPECIAL PROGRAMS-RESERVE",10/15/1992,8/14/1996,Mary Ellis,"Ellis, M","Ellis, M",VA,Hampton University,Continuing grant,Rita V. Rodriguez,3/31/1998,"$1,336,850.00 ",,mary.ellis@hamptonu.edu,100 E. Queen Street,Hampton,VA,236680108,7577275363,CSE,"2885, 9145","0000, 2886, 9178, OTHR, SMET",$0.00 ,normalFunding,"This award provides infrastructure support for the development of               the research and educational activities of the Hampton University               Experimental Laboratory for promoting Education and Research.  The              support includes computing resources, as well as awards to                      undergraduate and graduate students.  The investigators will be                 conducting research in the areas of (1) high-speed/parallel                     computing, (2) software engineering, (3) computer graphics, and (4)             artificial intelligence/expert system development."
1227245,DIP: Using dynamic formative assessment models to enhance learning of the experimental process in biology,IIS,Cyberlearn & Future Learn Tech,10/1/2012,7/13/2015,Eli Meir,"Meir, E","Meir, E|Abraham, J|Li, Z|Klopfer, E",MT,SimBiotic Software,Standard Grant,kevin lee,9/30/2016,"$1,333,395.00 ","Joel Abraham, Zhushan Li, Eric Klopfer",emeir@simbio.com,1280 S Third St. W,Missoula,MT,598010000,6173147701,CSE,8020,"8045, 8842",$0.00 ,normalFunding,"This project seeks to develop a dynamic formative assessment method for use with virtual labs. The research focuses on how to constrain a virtual lab experience to be amenable to automated feedback on relatively open-ended responses students are generating while still giving students an appropriate exploratory experience. The technology innovation question is how to do that with validity and reliability. The team is focusing on how to use available artificial intelligence technologies to make it possible to provide good feedback, both to learners working in these environments and to their teachers. PIs are adding dynamic formative assessment capabilities to  virtual lab experiences that are already extensively used in undergraduate and high-school biology classes.<br/><br/>This is an automated assessment project, focusing on assessing learner understanding and capabilities in situations where learners are exploring, having, and using ideas as they are learning STEM content and practices. There are several ways one could approach automated assessment for situations where learners are acting in a fairly unconstrained way -- design algorithms that can interpret and make inferences from free text, or find ways to design the environment in such a way that learners can explore, develop, and record as needed for deep learning but where they have a more constrained way of expressing themselves or limitations in what they can do that don't constrain the learning or engagement. This project seeks to find a sweet spot -- a happy medium where learners can explore, try things out, have ideas, refine ideas, and use ideas with significant freedom but just enough constraint for already-existing artificial intelligence algorithms to interpret what learners are doing, why they are doing it, and what they mean to express. Learning how to do this is essential to designing the learning environments of the future.<br/><br/>There is broad acknowledgement that more attention must be given in STEM fields to the teaching of higher-order thinking skills, including experimental design, data interpretation and evidence-based judgment. Timely formative assessment is a crucial component of such learning, but formative assessment is impossible for a teacher to do for a whole class of individuals at the time when it will have the most effect (when students are engaging in or have just finished engaging in such activities) and too labor intensive to be done regularly in large high school and introductory-level college classes. This project is therefore developing techniques for automatically providing immediate formative assessment as students are conducting simulation-based experiments and reasoning about their results. The investigation focuses on helping students learn to conduct experiments and interpret results within the discipline of biology; lessons learned will be applicable across STEM domains at the high-school and college levels."
701519,Formation of CITeR-UA to Add Deception and Credibility Assessment to the Center for Identification Technology Research,IIP,"INDUSTRY/UNIV COOP RES CENTERS, , , , , , , , , ",4/1/2007,8/13/2010,Judee Burgoon,"Burgoon, J","Burgoon, J|Nunamaker, J",AZ,University of Arizona,Continuing grant,Glenn H. Larsen,3/31/2012,"$1,330,985.00 ",Jay Nunamaker,jburgoon@cmi.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,ENG,"5761, H440, H459, I339, I448, J196, S117, S118, T974, T978","0000, 1049, 116E, 122E, 5761, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"The University of Arizona (UA) is partnering with the Center for Identification Technology Research (CITeR) at West Virginia University (WVU) to create a second research site that focuses on deception and credibility assessment. This will strengthen CITeR by complementing the center's research on identification and authentication by bringing together faculty, industry, and government agencies with interests in detecting deception, identifying individuals who pose security threats, and developing tools for assessing individual credibility. <br/><br/>The urgent need to better understand deception and its detection was unassailable long before 9/11 brought into high relief national security threats posed by terrorist plots and deceptions. The daily reporting of fraudulent business practices, political chicanery, telemarketing scams, internet predation, and identity theft has only served to reinforce the need for concerted attention to this critical and multifaceted topic. Yet at present there is little coordination of effort among government agencies or in the academic community to address issues related to identification of deception. Moreover, the topic begs for a multidisciplinary approach, so that technical expertise can be integrated with rigorous social science research to derive solutions and detection tools. CITeR-UA addresses these needs by assembling a multidisciplinary, multi-institutional collaboration among researchers and graduate students whose skills and interests intersect with those at CITeR-WVU. <br/><br/>UA is uniquely equipped to lead the deception and credibility aspect of this effort with its state-of-the-art DOD-funded Deception Detection Laboratory for conducting experiments and its Integrated Multimedia System with terabyte server for capturing, editing, storing, and analyzing multimedia data.<br/>"
1728370,SNM: Large-area Printing and Integration of Metal Nanowires and Organic Semiconductors for Stretchable Electronics and Sensors,CMMI,SNM - Scalable NanoManufacturi,7/1/2017,6/23/2017,Yong Zhu,"Zhu, Y","Zhu, Y|Dong, J|O'Connor, B",NC,North Carolina State University,Standard Grant,Khershed Cooper,6/30/2021,"$1,296,937.00 ","Jingyan Dong, Brendan O'Connor",yong_zhu@ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,ENG,025Y,"081E, 083E, 084E",$0.00 ,normalFunding,"Stretchable electronics and sensors, such as electronic skin, have wide ranging transformative applications in autonomous artificial intelligence (e.g. robots), medical diagnostics, and prosthetic devices capable of providing at least the same level of sensory perception as the biological equivalent. For example, for electronic skin to meet these expectations, a large number of distributed tactile sensors that are able to stretch and conform to curvilinear objects are required. Moreover, electronics that is conformal to human skin and deform in response to human motion requires stretchability. The functional requirements of stretchable electronics and sensors can be met through nano-enabled technologies, but their successful production requires innovation in scalable manufacturing and integration of processing methods. This Scalable NanoManufacturing (SNM) research project aims to investigate a scalable nanomanufacturing approach to fabricate large-area, high-resolution, stretchable electronics and sensor arrays by heterogeneous integration of metal nanowires and organic semiconductors. The research conducted as part of this award is integrated into interdisciplinary education for the involved students, course curriculum, and K-12 outreach. The project strongly encourages underrepresented students to participate in all aspects of the research.<br/><br/>Advancing the scalable nanomanufacturing of stretchable electronic skin requires: (1) stretchable functional materials (conductors, semiconductors), (2) a manufacturing strategy to integrate heterogeneous nanomaterials into a stretchable platform, and (3) optimal device design and integrated operation capabilities in both electronic and mechanical functionality. To meet these needs, the research investigates metal nanowires and polymer semiconductor material platforms. Stretchable conductors are achieved through forming nanowire-elastomer composites. Printing metal nanowires in large scale with high resolution is challenging. Here nanowire processing focuses on the fundamental understanding of the nanowire ink properties, ink-substrate interactions, and exploration of methods such as gravure and electrohydrodynamic printing. Approaches to achieve high-performance intrinsically stretchable polymer semiconductors are investigated with a focus on blending conjugated polymers with a secondary polymer matrix. Polymer semiconductor processing focuses on a combination of solution casting and advanced transfer printing methods. Device architecture and integrated manufacturing strategies are optimized to achieve high performance electronic-skin."
428241,ITR-(NHS)-(DMC):  A National Center of Excellence for Infectious Disease Informatics,IIS,"ITR FOR NATIONAL PRIORITIES, INFO INTEGRATION & INFORMATICS",10/1/2004,4/14/2010,Hsinchun Chen,"Chen, H","Chen, H|Zeng, D|Eidson, M|Gotham, I|Lynch, C",AZ,University of Arizona,Continuing grant,Sylvia J. Spengler,9/30/2011,"$1,290,166.00 ","Daniel Zeng, Millicent Eidson, Ivan Gotham, Cecil Lynch",hchen@eller.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,"7314, 7364","9178, 9216, 9251, HPCC, SMET",$0.00 ,normalFunding,"Infectious disease outbreaks, either naturally occurring  or caused by terror attacks, pose a critical threat to public health and national security. Information systems and infectious disease informatics (IDI) research are playing an increasingly important role in developing a comprehensive approach to prevent, detect, respond to, and manage infectious disease outbreaks. Computerized datasets on infectious diseases are currently used for disease reporting, including those developed by various federal, state, and local health, agriculture, and environment/wildlife agencies. However, such datasets are typically not interoperable, particularly in across jurisdiction and across species contexts, reducing their effective use in data modeling and analysis, disease surveillance, and disease management-related decision-making. In addition, the information management environment used by public health officials and researchers to analyze large amounts of infectious disease data and develop predictive models needs major improvements.<br/><br/>A partnership has been developed with expertise in IDI, mission-critical Web-based interoperable systems, data security and access control, advanced data mining and visualization techniques, disease surveillance and predictive modeling, and information systems evaluation. The partnership includes: (1) the Artificial Intelligence Laboratory at the University of Arizona, (2) the Information Systems Group at the University of Utah, (3) the New York State Department of Health and its partner Health Research, Inc., and (4) the California State Department of Health Services and its partner PHFE Management Solutions.<br/><br/>Building on ongoing IDI research and infrastructure development efforts, research is aimed at (a)  developing an integrated and scalable information sharing, monitoring, and analysis environment across jurisdictions and species for major infectious diseases, (b) developing novel data analysis, surveillance, and visualization techniques to meet the critical needs of IDI, and (c) gaining a systematic understanding of related policy, user evaluation, and technology adoption issues.<br/><br/>The intended intellectual contributions are threefold: (1) developing and evaluating system performance and scalability models and related algorithms needed for the efficient operation of large-scale realtime information query and monitoring/surveillance systems such as the NIDII, (2) developing and evaluating a set of novel spatio-temporal data analysis and online surveillance techniques which can be used in both IDI and other applications needing similar capabilities (e.g., crime analysis), and (3) developing a comprehensive user evaluation and technology adoption framework and conducting a detailed user evaluation and organizational impact study of the developed IDI system and related technologies.<br/><br/>The proposed work will have the following major broader impacts: (a) The research team will develop a working infectious disease information system across jurisdictions and disease types, providing an integrated data sharing, access, analysis, visualization, and surveillance environment for researchers, public health officials, and law enforcement and national security officials who need to assess risk of and respond to biological terror attacks. (b) The work will bring together previously disparate research and practitioner communities to conduct IDI research of significant practical relevance. In addition, it will foster cross-fertilization between law enforce and national security research and IDI.<br/><br/>"
1456382,"SBIR Phase II:  A Question of Numbers: Numeracy, Learning, and Learning about Learning",IIP,SMALL BUSINESS PHASE II,3/1/2015,6/28/2017,Brent Milne,"Milne, B","Milne, B",CO,Simbulus Inc,Standard Grant,Rajesh Mehta,8/31/2019,"$1,275,000.00 ",,brent.milne@simbulus.com,2017 10TH ST STE B,Boulder,CO,803025186,3034496284,ENG,5373,"115E, 165E, 5373, 7218, 8031, 8032, 9102, 9177",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project aims to answer the presidential call to ""create digital tutors that are as effective as personal tutors."" More than any other subject, mathematical learning is cumulative, and as students fall behind their classmates, new material becomes less comprehensible and they can face an ever-widening gap to their peers. Formative assessment (FA) practices have been well established as effective in closing these gaps and informing teacher decision-making. While the influx of mobile computing devices has enormous potential to help facilitate change in education, the potential is heavily dependent on the availability of proven, research-backed software and services. This project will help close achievement gaps by providing students with adaptive, personalized instruction and also providing teachers with valuable FA techniques, data, and suggestions. More broadly, the data will yield opportunities to research and model student understanding and to analyze the learning process, enabling additional research into effective practices for the teaching and learning of mathematics. With its strong customer value propositions and innovations that will enable new forms of software-enhanced teaching and learning, this project will also create significant commercial value within the educational market. <br/><br/>This project will create digital learning environments that go beyond current state-of-the-art systems to deliver adaptively selected instructional video segments and highly interactive problems, and do so while maintaining a flow of content that feels natural - as if the learning was occurring in the presence of an actual tutor. The ability of the system to adapt to the needs of an individual student is based upon a real-time assessment of student understanding and leverages cutting edge research from the fields of formative assessment, machine learning, artificial intelligence and big data. The ability to model student understanding and analyze the learning process will lead to the creation of new learning analytics tools and enable additional research into effective practices for the teaching and learning of mathematics. The proposed research will seek to demonstrate, in a randomized crossover trial, the effectiveness of the adaptive, online system over a control treatment. The researched solutions will also employ novel FA implementations such as collaborative review and white-boarding (via wireless communication), record and playback of teacher work, use of student sentiment, groupings of peers for collaborative work, and models of student understanding that incorporate teacher input (teacher plus software in the FA loop)."
325428,ITR:  Monitoring Emotions while Students Learn with AutoTutor,IIS,ITR MEDIUM (GROUP) GRANTS,9/15/2003,7/3/2007,Arthur Graesser,"Graesser, A","Graesser, A|Kort, B|Reilly, R|Picard, R|Franklin, S",TN,University of Memphis,Continuing grant,Kenneth C. Whang,8/31/2009,"$1,256,000.00 ","Barry Kort, Robert Reilly, Rosalind Picard, Stanley Franklin",a-graesser@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,1687,"1657, 9218, 9251, HPCC",$0.00 ,normalFunding,"This research investigates emotions during the process of learning and reasoning while college students interact with complex learning environments.  College students learn about introductory computer literacy or conceptual physics on the web by an intelligent tutoring system, called AutoTutor. AutoTutor helps learners construct explanations that answer difficult questions by interacting with them in natural language and by helping them use simulation environments.  AutoTutor has an animated conversational agent and a dialog management facility that attempts to comprehend the learner's contributions and to respond with appropriate dialog moves (short feedback, pumps, hints, prompts for information, assertions, answers to student questions, suggestions for actions, summaries).  The emotions of the learner are monitored during this learning process by integrating state-of-the-art affect sensing technology with AutoTutor.  Confusion, frustration, boredom, interest, excitement, and other learner emotions are classified on the basis of facial actions, body posture, pressure on the mouse, speech acts in dialog, mastery of the material, and the timing of interactions.  One strand of research develops the affect-sensing technologies and tests their validity in classifying the learner emotions. A second line of research investigates whether learning gains and learner impressions are influenced by dialog moves of AutoTutor that are constrained by the learner's emotional state. <br/><br/>This research will advance education and natural language dialog technologies through a system that promotes deep learning of material in a fashion that is sensitive to the learners' emotions.  A learning environment that monitors learner emotions is likely to be more motivating and personally relevant to the learner.     <br/>"
9503064,CISE Research Infrastructure: Effective Information Access: Computer Science Research Fundamental to Creation of a      National Information Infrastructure,EIA,"CISE RESEARCH INFRASTRUCTURE, HUMAN COMPUTER INTER PROGRAM",8/1/1995,7/24/2001,Deepak Kapur,"Kapur, D","Kapur, D",NM,University of New Mexico,Continuing grant,Rita V. Rodriguez,7/31/2002,"$1,250,000.00 ",,kapur@cs.unm.edu,"1700 Lomas Blvd. NE, Suite 2200",Albuquerque,NM,871310001,5052774186,CSE,"2885, 6845","9216, 9218, HPCC",$0.00 ,normalFunding,"9503064  Hollan    This award provides support for visualization facilities, servers to support distributed simulation, and a high-speed cluster network.  In addition the University of New Mexico will establish a National Information Infrastructure (NII) Experimental Laboratory in the Science and Engineering Library to serve as a shared research testbed, as well as to facilitate efforts in distributed simulation and research collaborations in Biology, with the Santa Fe Institute and the National Laboratories.  The Laboratory equipment will include graphics workstations connected via a high-performance local area network to high-end symmetric multiprocessing systems, an SGI Power Onyx and Power Challenge, and to remote high-performance facilities at the Maui High Performance Computing Center's IBM SP-2, the Sandia National Laboratory's Intel Paragon, and the Los Alamos National Laboratory's CM-5.    The University will build on its existing strengths in adaptive computation, human computer interaction, information analysis, and simulation to focus on adaptive multiscale interfaces; distributed computation, communication, and security for network-based applications; data mining and filtering; and improved access to distributed simulation."
411776,Learning to Teach: The Next Generation of Intelligent Tutor Systems,DRL,RESEARCH ON LEARNING & EDUCATI,8/15/2004,7/1/2006,Beverly Woolf,"Woolf, B","Woolf, B|Barto, A|Mahadevan, S|Arroyo, I|Fisher, D",MA,University of Massachusetts Amherst,Continuing grant,John Cherniavsky,7/31/2008,"$1,241,545.00 ","Andrew Barto, Sridhar Mahadevan, Ivon Arroyo, Donald Fisher",bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,EHR,1666,"9177, SMET",$0.00 ,normalFunding,"The primary objective of this project is to develop new methods for optimizing an automated pedagogical agent to improve its teaching efficiency through customization to individual students based on information about their responses to individual problems, student individual differences such as level of cognitive development, spatial ability, memory retrieval speed, long-term retention, effectiveness of alternative teaching strategies (such as visual vs. computational solution strategies), and degree of engagement with the tutor. An emphasis will be placed on using machine learning and computational optimization methods to automate the process of developing efficient Intelligent Tutoring Systems (ITS) for new subject domains. The approach is threefold.<br/>First, a methodology based on hierarchical graphical models and machine learning will be developed and evaluated for automating the creation of student models with rich representations of student state based on data collected from populations of students over multiple tutoring episodes. Second, methods will be developed and evaluated for deriving pedagogical decision strategies that are effective and efficient not just over the short-term (from one math problem to the next one), but over the long-term where retention over a period of at least one month is the objective. Third, a systematic study will be conducted of the role that known and powerful latent and instructional variables can have on performance through their inclusion in student models. Research in cognitive and educational psychology clearly shows the critical role that latent variables such as short-term memory and engagement play in learning, and that instructional variables such as over-learning and review, and massed and distributed practice have on the rate at which material is learned. The investigators jointly have strengths in the areas of intelligent tutoring, machine learning and optimization, and cognitive, mathematical and educational psychology, strengths that are needed in order to make the synergistic advances that are being proposed. Our preliminary simulations and classroom experiments suggest that we can significantly reduce the time it takes students to learn new material based on improved pedagogical decisions.<br/>For intellectual merit, he proposed research should advance fundamental knowledge of the learning and teaching of basic mathematics and more advanced algebra and geometry. It should add to the set of growing statistical and computational techniques that are available to estimate the complex hidden hierarchical structures that govern human behavior. The research should also significantly broaden the capabilities of machine learning systems by addressing learning scenarios that are grounded on the real and challenging problem of mathematics education than the abstract scenarios typically studied at present. For broader impact, this foundational educational research will lead to the broadening of participation of underrepresented groups, especially women, in a variety of science, technology, engineering and mathematics (STEM) disciplines. It will advance discovery and understanding of learning and engagement as predictors of individual differences in learning and will result in intelligent tutors that are more sensitive to individual differences. It will unveil the extent to which students of different genders and cognitive abilities learn more efficiently with different forms of teaching. This research will benefit society as machine learning methods, which provide a core technology for building complex systems, will be applicable to a variety of teaching systems."
1346066,SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention,IIS,Smart and Connected Health,10/1/2013,6/4/2015,Peter Pirolli,"Pirolli, P","Pirolli, P|Youngblood, GM",CA,Palo Alto Research Center Incorporated,Standard Grant,Sylvia J. Spengler,10/31/2017,"$1,231,070.00 ",Gregory Michael Youngblood,ppirolli@ihmc.us,3333 Coyote Hill Road,Palo Alto,CA,943041314,6508124055,CSE,8018,"8018, 8062, 9251",$0.00 ,normalFunding,"Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br/><br/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups.  Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br/><br/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory."
9873465,KDI: Computational Models and Coordinated Neuroimaging of   Learning and Cognitive Function,BCS,"HUMAN COGNITION & PERCEPTION, NEURAL SYSTEMS CLUSTER, DIGITAL SOCIETY&TECHNOLOGIES, Integrative Activities in Phys",10/1/1998,12/2/2002,Walter Schneider,"Schneider, W","Schneider, W|Lewis, R|Fiez, J|Anderson, J",PA,University of Pittsburgh,Standard Grant,Guy Van Orden,9/30/2003,"$1,200,000.00 ","Richard Lewis, Julie Fiez, John Anderson",wws+@imap.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,SBE,"1180, 5500, 6850, 9134","0000, 1096, 1337, 8888, OTHR",$0.00 ,normalFunding,"This research advances the mapping of human brain function and the development of computational models of brain structures involved in human cognition. Brain imaging, utilizing functional magnetic resonance imaging (fMRI), allows task and process related tracking of brain activity. Cognitive modeling allows the prediction of human behavior in complex intellectual tasks. This project will bring together researchers who represent distinct and successful cognitive modeling architectures with researchers who are at the forefront of fMRI imaging, in an effort to relate cognitive function to human cortical dynamics.<br/><br/>A set of complex tasks will be identified which involve various aspects of learning, problem solving, and language, and for which models exist in one or more architectures. Brain imaging studies will be conducted with people performing all of these tasks. The complex tasks will include: rule learning, strategy learning, memory retrieval, problem solving, and language processing. To provide further constraints, the same people will also be imaged as they perform simpler ""pure function"" tasks. Models will be developed in the various cognitive architectures that address both the brain imaging data and the behavioral data from these tasks.<br/><br/>The mapping and computational understanding of human brain function can have  important implications for education, artificial intelligence, and treatment of mental disorders. Understanding the brain structures involved in higher level cognition and how they interact will provide a better foundation for optimizing human performance and duplicating those functions in computers. An understanding of the neural basis of complex cognition has the potential for making brain research enhance education in the critical areas of skill acquisition and learning. It will also assist in the diagnosis and correction of brain dysfunction such as dyslexia and learning disabilities.<br/>"
9216172,A Laboratory for Joint Research in Artificial Intelligence  and Parallel Computing,EIA,CISE RESEARCH INFRASTRUCTURE,4/1/1993,7/10/1997,Michael Quinn,"Quinn, M","Quinn, M|Lewis, T|Dietterich, T|D'Ambrosio, B",OR,Oregon State University,Continuing grant,Stephen Mahaney,9/30/1998,"$1,191,283.00 ","Theodore Lewis, Thomas Dietterich, Bruce D'Ambrosio",quinn@eecs.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,2885,"0000, 2887, 9218, HPCC, OTHR",$0.00 ,normalFunding,"     This Institutional Infrastructure award is for the support of              research projects in artificial intelligence and parallel                       computing.  The infrastructure consists of a parallel computer and              the staff to maintain the computer.  The projects supported by this             award include learning algorithms, real time decision making, data-             parallel compilers, and parallel programming support environments.                                                                                                   Parallel computers are research tools in two senses. The                   first is that they provide a substantial increase in computational              power.  The second is that they act as an experimental vehicle for              new systems software that needs to be developed in order to use the             computers effectively.  This award addresses both questions.  The               artificial intelligence research needs the computing power while                the compiler and support environment work needs the experimental                vehicle."
1456093,SBIR Phase II:  A virtual role-playing simulation for social emotional learning using artificially intelligent characters and crowdsourcing,IIP,SMALL BUSINESS PHASE II,3/1/2015,8/26/2017,Geoff Marietta,"Marietta, G","Marietta, G",MA,"Giant Otter Technologies, Inc.",Standard Grant,Rajesh Mehta,5/31/2018,"$1,165,984.00 ",,geoff@giantotter.com,212 Elm St,Somerville,MA,21442959,4102946786,ENG,5373,"110E, 116E, 165E, 169E, 5373, 8031, 8032, 8042, 9102, 9251",$0.00 ,normalFunding,"This SBIR Phase II project will develop novel 3D web and mobile role-playing simulations that can improve social skills in children. Virtual characters participate in nuanced conversations with students, powering a transformational experience for practicing and assessing communication skills.  Rigorous evaluations have demonstrated the feasibility and efficacy of teaching perspective-taking and social skills through simulated role-playing, beneficial to students struggling with autism spectrum disorder (ASD), attention deficit hyperactivity disorder (ADHD), or bullying.  These simulations will disrupt the multi-billion dollar market for social emotional learning (SEL) by allowing students to learn and practice social skills as they would with teachers or therapists, but at a fraction of the cost.  Current solutions for practicing and assessing social skills rely on face-to-face interaction, which is costly and difficult to scale.  Producing socially rich, open-ended simulations has previously been infeasible, due to technical challenges required to replicate the complexity of human language.  This project overcomes these barriers using an innovative technology with the potential to revolutionize how people learn and practice social skills by delivering real-time personalized feedback at scale.  Future applications of the social behavior capture (So-Cap) technology that underlies this project range from contextually aware intelligent personal assistants to socially aware robotics.<br/> <br/>This project's unprecedented ability to respond authentically to open-ended natural language input relies on an innovative crowdsourced approach to artificial intelligence (AI), which imbues machines with the ability to understand dialogue in context and engage in extended conversations covering multiple topics.  Individualized responses are tailored to user input by drawing from a massive database of recorded human dialogue, captured from online role-playing.  The process for mining meaningful patterns from this data also employs crowdsourcing, relying on non-experts hired online to cluster and annotate words, utterances, and events.  A computational model formed by these patterns powers a real-time conversational engine, which selects responses by combining AI techniques including plan recognition and case-based planning.  The goal of this research is to pioneer a practical, repeatable process for democratizing the production of social simulations, minimizing cost while maximizing societal impact by providing social skills practice at scale."
1514490,CHS: Medium: Transforming Scientific Presentations with Co-Presenter Agents,IIS,Cyber-Human Systems (CHS),7/1/2015,9/1/2017,Timothy Bickmore,"Bickmore, T","Bickmore, T|Fell, H",MA,Northeastern University,Continuing grant,Ephraim P. Glinert,6/30/2019,"$1,164,306.00 ",Harriet Fell,bickmore@ccs.neu.edu,360 HUNTINGTON AVE,BOSTON,MA,21155005,6173733004,CSE,7367,"7367, 7924",$0.00 ,normalFunding,"Although journal and conference articles are recognized as the most formal and enduring forms of scientific communication, oral presentations are central to science because they are the means by which researchers, practitioners, the media, and the public hear about the latest findings thereby becoming engaged and inspired, and where scientific reputations are made.  Yet despite decades of technological advances in computing and communication media, the fundamentals of oral scientific presentations have not advanced since software such as Microsoft's PowerPoint was introduced in the 1980's.  The PI's goal in this project is to revolutionize media-assisted oral presentations in general, and STEM presentations in particular, through the use of an intelligent, autonomous, life-sized, animated co-presenter agent that collaborates with a human presenter in preparing and delivering his or her talk in front of a live audience.   The PI's pilot studies have demonstrated that audiences are receptive to this concept, and that the technology is especially effective for individuals who are non-native speakers of English (which may be up to 21% of the population of the United States).  Project outcomes will be initially deployed and evaluated in higher education, both as a teaching tool for delivering STEM lectures and as a training tool for students in the sciences to learn how to give more effective oral presentations (which may inspire future generations to engage in careers in the sciences).<br/><br/>This research will be based on a theory of human-agent collaboration, in which the human presenter is monitored using real-time speech and gesture recognition, audience feedback is also monitored, and the agent, presentation media, and human presenter (cued via an intelligent wearable teleprompter) are all dynamically choreographed to maximize audience engagement, communication, and persuasion.  The project will make fundamental, theoretical contributions to models of real-time human-agent collaboration and communication.  It will explore how humans and agents can work together to communicate effectively with a heterogeneous audience using speech, gesture, and a variety of presentation media, amplifying the abilities of scientist-orators who would otherwise be ""flying solo.""  The work will advance both artificial intelligence and computational linguistics, by extending dialogue systems to encompass mixed-initiative, multi-party conversations among co-presenters and their audience.  It will impact the state of the art in virtual agents, by advancing the dynamic generation of hand gestures, prosody, and proxemics for effective public speaking and turn-taking.  And it will also contribute to the field of human-computer interaction, by developing new methods for human presenters to interact with autonomous co-presenter agents and their presentation media, including approaches to cueing human presenters effectively using wearable user interfaces."
934327,"Collaborative Research: I/UCRC for Safety, Security, and Rescue Research",CNS,"SPECIAL PROJECTS - CISE, INDUSTRY/UNIV COOP RES CENTERS",8/1/2009,10/26/2016,Nikolaos Papanikolopoulos,"Papanikolopoulos, N","Papanikolopoulos, N|Isler, I|Gini, M|Roumeliotis, S|Morellas, V",MN,University of Minnesota-Twin Cities,Continuing grant,Thyagarajan Nandagopal,4/30/2017,"$1,110,399.00 ","Ibrahim Isler, Maria Gini, Stergios Roumeliotis, Vassilios Morellas",npapas@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,"1714, 5761","0000, 1049, 115E, 116E, 122E, 152E, 5761, 7218, 8032, 8036, 8039, 8042, 8046, 9177, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"0934327 University of Minnesota (UMN); Nikolas Papanikolopoulos <br/>0934413 University of Denver (UD); Richard Voyles<br/>   <br/>The purpose of this proposal is to renew and expand the Center for Center for Safety, Security and Rescue Research (SSR-RC) as an NSF Industry/University Cooperative Research Center.  This proposal is based upon UMN's successful completion of five years of operation of the SSR-RC; and the commitment by companies to join a research site at the University of Denver. UMN will be the lead research site for SSR-RC with the University of Pennsylvania (joined the Center a few years ago) and the University of Denver as research partners.  <br/> <br/>This proposal covers the renewal for the second-five years of UMN and the expansion to include UD.  The proposed Center will provide integrative robotics, sensing, and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, transportation safety, and emergency response to mass casualty-related events.  The Center is built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, human factors, and psychology at the three institutions.  The renewed and expanded Center will be successful because it builds on existing strengths developed during the first five years of operation.  The Center will also educate and train researchers for industry and government. <br/><br/>The broader impact of the proposed center is to radically improve homeland defense in all dimensions.  The proposed Center will encourage collaboration, and will nurture an emerging field of research and the associated industries, thus helping to establish the challenges of the field and acceptable research and evaluation methodologies.  SSR-RC will expose students and faculty to state-of-the-art research projects of value to the industry, and plans to attract large companies to the SSR domains and energize innovative start-up companies.  Students will have opportunities for industrial internships with members.  Faculty in the SSR-RC will continue to aggressively recruit women and minority graduate students through the various I/UCRC supplemental programs, and to host annual summer camps for middle-schoolers from under-represented groups.   <br/><br/>"
99559,"LIGO Data Analysis, Detector Characterization and Gravitational Wave Astronomy",PHY,LIGO RESEARCH SUPPORT,8/1/2001,5/13/2005,Lee Finn,"Finn, L","Finn, L",PA,Pennsylvania State Univ University Park,Continuing grant,Beverly K. Berger,7/31/2007,"$1,092,756.00 ",,LSF5@PSU.Edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,MPS,1252,"0000, OTHR",$0.00 ,normalFunding,"This proposal addresses research in LIGO data analysis leading to gravitational wave astronomy.  In particular, methods for removing instrumental noise from the LIGO data stream, preparatory to its analysis will be developed.  This work, called ""data conditioning"", is critical to the success of the LIGO since the gravitational wave signals are expected to be weak and would most likely be totally masked by instrumental noise.  Several methods are proposed for conditioning LIGO data including the use of ""artificial intelligence"" tools for time-ordered data.  In addition, LIGO data will be analysed to <br/>1. set upper limits on the gravitational wave strength from known pulsars,<br/>2. search for unanticipated sources of gravitational waves,<br/>3. combine data from the three LIGO detectors synthesized to perform as a single detector.<br/>On technique for identifying gravitational wave signals in the data stream invloves the use of filters designed to pick out a signal with specific characteristics.  Several innovative methods are proposed for the development of non-linear filters in the presence of non-Gaussian noise, involving the use of techniques to determine the most appropriate likelihood function for use when non-normal moments of the data distribution are known."
1019841,Collaborative Research: INK-12:  Teaching and Learning Using Interactive Ink Inscriptions in K-12,DRL,DISCOVERY RESEARCH K-12,9/1/2010,2/3/2017,Andee Rubin,"Rubin, A","Rubin, A",MA,TERC Inc,Standard Grant,Margret Hjalmarson,6/30/2017,"$1,065,548.00 ",,andee_rubin@terc.edu,2067 Massachusetts Avenue,Cambridge,MA,21401339,6178739600,EHR,7645,"7645, 9177, SMET",$0.00 ,normalFunding,"The research project continues a collaboration between MIT's Center for Educational Computing Initiatives and TERC focusing on the enhancement of K-12 STEM math and science education by means of technology that supports (1) creation of what are termed ""ink inscriptions""--handwritten sketches, graphs, maps, notes, etc. made on a computer using a pen-based interface, and (2) in-class communication of ink inscriptions via a set of connected wireless tablet computers. The project builds on the PIs' prior work, which demonstrated that both teachers and students benefit from such technology because they can easily draw and write on a tablet screens, thus using representations not possible with only a typical keyboard and mouse; and they can easily send such ink inscriptions to one another via wireless connectivity. This communication provides teachers the opportunity to view all the students' work and make decisions about which to share anonymously on a public classroom screen or on every student's screen in order to support discussion in a ""conversation-based"" classroom.  Artificial intelligence methods are used to analyze ink inscriptions in order to facilitate selection and discussion of student work.<br/><br/>The project is a series of design experiments beginning with the software that emerged from earlier exploratory work. The PIs conduct two cycles of experiments to examine how tablets affect students learning in 4th and 5th grade mathematics and science.  The project research questions and methods focus on systematic monitoring of teachers' and students' responses to the innovation in order to inform the development process. The PIs collect data on teachers' and students' use of the technology and on student learning outcomes and use those data as empirical evidence about the promise of the technology for improving STEM education in K-12 schools.  An external evaluator uses parallel data collection, conducting many of the same research activities as the core team and independently providing analysis to be correlated with other data.  His involvement is continuous and provides formative evaluation reports to the project through conferences, site visits, and conference calls.  <br/><br/>The primary products are substantiated research findings on the use of tablet computers, inscriptions, and networks in 4th and 5 grade classrooms.  In addition the PIs develop models for teacher education and use, and demonstrate the utility of artificial intelligence techniques in facilitating use of the technology.  With the addition of Malden Public Schools to the list of participating districts, which includes Cambridge Public Schools and Waltham Public Schools from earlier work, the project expands the field test sites to up 20 schools' classrooms."
1734938,"NCS-FO: Neuroimaging to Advance Computer Vision, NLP, and AI",IIS,"GVF - Global Venture Fund, Core R&D Programs, IntgStrat Undst Neurl&Cogn Sys",8/15/2017,8/7/2017,Jeffrey Siskind,"Siskind, J","Siskind, J|Wilbur, R|Malaia, E",IN,Purdue University,Standard Grant,Kenneth C. Whang,7/31/2020,"$1,000,000.00 ","Ronnie Wilbur, Evguenia Malaia",qobi@purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,"054Y, 7980, 8624","5946, 5980, 6869, 8089, 8091, 8551, 8817",$0.00 ,normalFunding,"It is often said that a picture is worth a thousand words. Frequently, to search for what is needed, whether images or objects in those images, words are needed instead. Getting accurate labels for efficient searches is a longstanding goal of computer vision, but progress has been slow. This project employs new methods to significantly change how picture-word labeling is accomplished by taking advantage of the best picture recognizer available, the human brain. Through functional magnetic resonance imaging and electroencephalography, brain activity of humans looking at pictures/videos is recorded and then used to improve performance on artificial intelligence (AI) tasks involving computer vision and natural language processing. Current systems use machine learning to train computers to recognize objects (nouns) and activities (verbs) in images/video, which are then used to describe events. Reasoning tasks (e.g., solving math problems) can then be done. These systems are trained on specially prepared datasets with samples of nouns for objects, verbs for activities, sentences describing events, and exam questions and answers. A novel paradigm using humans to perform the same tasks while their brains are scanned allows determination of neural patterns associated with those tasks. The brain activity patterns, in turn, are used to train better computer systems.<br/><br/>The central hypothesis is that understanding human processing of grounded language involving predication and its use during reasoning will materially improve engineered computer vision, natural language processing, and AI systems that perform image/video captioning, visual question answering, and problem solving.  Scientific and engineering goals include developing models of human language grounding and reasoning consistent with neuroimaging, to improve engineered systems integrating language and vision that support automated reasoning.  The main scientific question is to understand mechanisms by which predicates and arguments are identified, linked, and used for reasoning by the human brain.  The hypothesis, that predicate-argument linking in visual and linguistic representations are accomplished similarly, and that this then supports reasoning and problem solving, will be tested using multiple neuroimaging modalities, and machine learning algorithms to decode ""who did what to whom"" from brain scans of subjects processing linguistic and visual stimuli.  The iterative approach will involve understanding information integration at the neural level, to improve machine learning performance on AI tasks by training computers to perform increasingly complex tasks with neuroimaging data from stimuli derived from large-scale natural tasks.  Using identical datasets for human and machine performance will support translation of scientific advances to engineering practice involving integration of computer vision and natural language processing.<br/><br/>This award is cofunded by the Office of International Science and Engineering."
9303150,Parallel Computing and Complex Systems,EIA,CISE RESEARCH INFRASTRUCTURE,9/1/1993,7/8/1997,Jacques Cohen,"Cohen, J","Cohen, J|Storer, J",MA,Brandeis University,Continuing grant,Stephen Mahaney,2/28/1999,"$1,000,000.00 ",James Storer,jc@cs.brandeis.edu,415 SOUTH ST MAILSTOP 116,WALTHAM,MA,24532728,7817362121,CSE,2885,"9218, HPCC",$0.00 ,normalFunding,"9303150  Cohen       This award is for the acquisition of a parallel computer and  several high performance work stations to support research in the  Computer Science Department of Brandeis University.  The department  is engaged in three major areas of research:  Parallelism and  Languages, Data Compression, and Artificial Intelligence.  The  department is part of the Brandeis Center for Complex Systems and  the theme of parallelism and the study of large complex systems is  common to all three groups.         The research topics to be explored by the parallel programming  group include the design and analysis of parallel algorithms; and  the design and implementation of high level parallel languages  which facilitate the rapid construction of programs that can easily  be verified to be correct and which can be compiled to run  efficiently on MIMD and SIMD machines.  Research topics of the data  compression group include adaptive vector quantization with  variable size vectors, adaptive video compression, issues in coding  theory that include error resilient communication, the design of  high speed data compression hardware, and context prediction for  lexicography.  Research topics for the AI group include data  extraction from existing databases and text corpora, the role of  memory in storing extracted data, and the construction of  integrated agents that are data driven and exhibit goal directed  behavior."
1249349,2012 Waterman Award,CCF,INFORMATION TECHNOLOGY RESEARC,9/1/2012,8/29/2012,Scott Aaronson,"Aaronson, S","Aaronson, S",MA,Massachusetts Institute of Technology,Standard Grant,Dmitry Maslov,8/31/2017,"$1,000,000.00 ",,aaronson@csail.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,1640,"0000, 041P",$0.00 ,normalFunding,"The National Science Foundation (NSF) is pleaserd to announce the selection of MIT's Scott Aaronson, an Associate Professor of Electrical Engineering and Computer Science, to receive its 2012 Alan T. Waterman Award.  Dr. Aaronson works with the Computer Science and Artificial Intelligence Laboratory, MIT's largest interdepartmental lab. <br/><br/>The Waterman Award is the National Science Foundation's (NSF) highest honor. The annual award recognizes outstanding researchers under the age of 35 in any field of science or engineering NSF supports. This is the first year that two awardees have been selected. <br/><br/>In addition to a medal, each of this year's awardees will receive a $1 million grant---twice the amount of last year's award---over a five-year period for further advanced study in his field.<br/><br/>Prof. Aaronson, a theoretical computational scientist, pursues research interests that focus on the limitations of quantum computers and computational complexity theory more generally.  His research addresses a variety of topics, including the information content of quantum states, the physical resources needed for quantum computers to surpass classical computers, and the barriers to solving computer science's vexing P versus NP question, that is, whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer."
1726306,Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students,DUE,IUSE,9/1/2017,7/21/2017,Tracy Hammond,"Hammond, T","Hammond, T|Shryock, K|Valentine, S",TX,Texas A&M Engineering Experiment Station,Standard Grant,Heather Watson,8/31/2022,"$988,683.00 ","Kristi Shryock, Stephanie Valentine",hammond@tamu.edu,TEES State Headquarters Bldg.,College Station,TX,778454645,9798477635,EHR,1998,"8209, 8244, 9178",$0.00 ,normalFunding,"Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
905232,HCC: Medium: Intelligent Agents for Protecting Users in Cyberspace,CNS,TRUSTWORTHY COMPUTING,9/1/2009,7/5/2011,Adele Howe,"Howe, A","Howe, A|Ray, I|Byrne, Z",CO,Colorado State University,Continuing grant,Sylvia J. Spengler,8/31/2015,"$985,396.00 ","Indrajit Ray, Zinta Byrne",howe@cs.colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,CSE,7795,"7924, 9102, 9178, 9218, 9251, HPCC",$0.00 ,normalFunding,"This interdisciplinary project studies the nature of the risks inherent in normal activity on the Internet, the perception of those risks, the judgment about trade-offs in behavior and the design of a personalized agent that can alert users to risky behavior and help to protect them. The key insight is that adequate security and privacy protection requires the concerted efforts of both the computer and the user. The interdisciplinary research team combines expertise from psychology, computer security and artificial intelligence to propose MIPA (MIxed Initiative Protective Agent) -- a semi-autonomous, intelligent and personalized agent approach that leverages psychological studies of what users want/need and what security and privacy risks are imminent. The techniques will be developed for and tested on a real problem that challenges the current state of the art in artificial intelligence, security and user models.<br/><br/>As it is becoming increasingly difficult for users to protect themselves and understand the risks they are taking on the Internet, this project has the potential to positively impact system design to effectively enhance user security. Focusing on home computer users (college students and senior citizens), the proposed research will investigate how they perceive, use and can best be served by Internet application software. Results could improve the experiences of these users as well as significantly advance techniques in intelligent agents and computer security. Additionally, because home users and machines tend to be the weak link in security, protecting them may better protect others."
1416907,IBSS: New Methods for Investigating the Formation of Individual and Shared Concepts and Their Dynamic Dispersion Across Related Societies,SMA,Interdiscp Behav&SocSci IBSS,9/1/2014,8/29/2014,Kimberly Jameson,"Jameson, K","Jameson, K|Narens, L|Komarova, N|Wodarz, D",CA,University of California-Irvine,Standard Grant,Brian D. Humes,2/28/2019,"$980,923.00 ","Louis Narens, Natalia Komarova, Dominik Wodarz",kjameson@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,SBE,8213,"8213, 8605",$0.00 ,normalFunding,"This interdisciplinary research project will develop and test new mathematical models that explore the ways through which conceptual meaning is represented in languages as those languages change in complexity over time.  The project investigators also will examine the ways such meaning is shared among groups of individuals in societies.  The project's models will describe the dynamic development of concepts as a geometric system and will provide methods for understanding the linguistic representation of concepts and the ways semantic meaning from one community can be influenced by that of neighboring communities.  Although this project will focus on the ways that color terms have evolved within languages and societies, the insights and information from this project will apply beyond the domain of color representation to any set of concepts in which objects have a similarity structure that can be assessed and described mathematically.  Examples of the kinds of situations where the approach and methods to be developed during this project will have utility are the following:  (1) the development of unambiguous and formally scalable artificial intelligence and robotic analogs of human classification and categorization systems; (2) the development of a global communication methodology that could be used to enhance  rapid global information messaging capabilities; and (3) the construction of standardized systems for information representation in critical systems, such as medical diagnostic systems and transportation systems. <br/><br/>The formation and communication of concepts permeate a diverse range of human activities.  They play roles in education systems; in the organization and design of transportation systems; in the physical and virtual design of retail markets and consumer goods; in classifications of quality and risk in medical diagnoses; in business performance; and in social values.  Psychologists, linguists, anthropologists, computer scientists, and other scholars have studied concepts by focusing on specific examples of concept formation while trying to understand how such conceptual systems are formed.  One specific concept that has received attention is how color terms ""evolve"" and how their conceptual meaning is understood and shared by members of a society.  Conceptualization of color is an important special case because color stimuli can be precisely measured and easily duplicated, and the human perceptual space of a million colors can be described with mathematical precision.  This project will focus on the development and testing of mathematical models that capture the ways color term concepts are categorized and shared.  The models to be designed and tested will use geometric formalisms for characterizing meaning in general and will specifically demonstrate their use by investigating color terms and concepts.  Testing will use data from a wide variety of societies, including the Mesoamerican Color Survey (MCS), a database of systematically collected categorization behaviors of 900 individuals who have communicated with one or more of 116 endangered or developing languages that are at various stages of color lexicon development.  The MCS is largely in hand-written form, and one product of this project will be its full digitalization using modern computer science crowd-sourcing methods.  Full digitalization of the MCS database will make it available for use by the global scientific community for the first time.  This project is supported through the NSF Interdisciplinary Behavioral and Social Sciences Research (IBSS) competition."
1532846,NCS-FO: A circuit theory of cortical function,ECCS,"Engineering of Biomed Systems, IntgStrat Undst Neurl&Cogn Sys",8/1/2015,8/10/2015,Charles Gilbert,"Gilbert, C","Gilbert, C|Freiwald, W|Reeke, G",NY,Rockefeller University,Standard Grant,Kenneth C. Whang,7/31/2019,"$970,091.00 ","Winrich Freiwald, George Reeke",gilbert@rockefeller.edu,1230 YORK AVENUE,NEW YORK,NY,100656399,2123278309,ENG,"5345, 8624","004E, 8089, 8091, 8551",$0.00 ,normalFunding,"This project aims to develop and test a new conceptual framework for understanding brain function, and informing biologically based artificial intelligence systems.  The underlying theory holds that the properties of any neuron and any cortical area are not fixed but undergo state changes with changing perceptual task, expectation and attention.   Because of the multiple routes by which this top-down information can be conveyed, each neuron is essentially a microcosm of the brain as a whole.   <br/><br/>In this framework, a neuron is viewed as an adaptive processor rather than merely a link in a labeled line, taking on functions that are required for performing the current task.  The theory accounts for cortical function at the circuit level.  Through an interaction between feedback and intrinsic connections neurons select inputs that are relevant to a task and suppress inputs that are irrelevant.  The experiments will combine visual psychophysics, fMRI, large scale high density electrode array recordings and optogenetic manipulation.  These techniques will be used to measure changes in effective connectivity between cortical areas and the relationship between effective connectivity and the information represented by neurons at different recording sites as animals perform different visual recognition tasks.  Computational models will be developed to account for how task-dependent gating of connections can be achieved and will reproduce the functional dynamics observed experimentally.  Though the experiments will focus on the visual modality, the findings from the work will formulate a general theory of brain function that is broadly applicable to the brain as a whole."
803481,III-Medium: Reading the Web: Utilizing Markov Logic in Open Information Extraction,IIS,"INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS",9/1/2008,3/2/2012,Oren Etzioni,"Etzioni, O","Etzioni, O|Domingos, P|Mausam, M|Soderland, S",WA,University of Washington,Continuing grant,Maria Zemankova,8/31/2012,"$963,716.00 ","Pedro Domingos, Mausam Mausam, Stephen Soderland",etzioni@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"1640, 7364","1640, 7364, 7495, 9215, 9216, 9251, HPCC",$0.00 ,normalFunding,"This project adresses the challenge of automatically extracting high-quality knowledge bases from text corpora.  Previous work, led by Prof. Etzioni, developed KnowItAll (http://www.cs.washington.edu/research/knowitall), an unsupervised, domain-independent, scalable system that learns from the Web in an open-ended fashion.  Another project, led by Prof. Domingos, has formalized and fully implemented a powerful framework called Markov Logic Networks (MLNs) (see http://www.cs.washington.edu/ai/srl.html) that enable inference and learning in large, first-order models.  This project integrates KnowItAll and MLNs to build large-scale ontologies from text corpora: extracting relational tuples, using joint inference to merge and validate the tuples, mapping extracted phrases to a taxonomy, and using probabilistic inference rules to answer queries about the ontology.<br/><br/>Consider, for example, the query ""how many Nobel Laureates where born in Europe?""  In response, Google merely provides documents matching the keywords in the query.  KnowItAll can only identify people who are explicitly identified as Nobel Laureates and Europeans.  This project investigates a system that utilizes both information extraction and probabilistic reasoning to identify candidate answers, not explicitly stated in the text, and their likelihood of being correct.  As a simple example, the system concludes that Einstein was born in Europe based on the sentence ""Einstein was born in Ulm, Germany"". The query ""what foods help prevent osteoporosis?"" is answered using a multi-step reasoning chain regarding the ingredients of the food and their ability to prevent the disease.<br/><br/>The broader impact of this research includes novel methods of building knowledge bases automatically. Such knowledge bases (after some manual tuning, perhaps) could be used to support a wide range of applications from question-answering systems, to knowledge-based systems for medical applications, to background knowledge in support of machine reading of text.  The knowledge bases created by this project will be made freely available to the research community as a Web-site and also as a Web-based API via the project Web site (http://www.cs.washington.edu/research/knowitall/ReadingTheWeb/).<br/>"
1539011,VEC: Medium: Large-Scale Visual Recognition: From Cloud Data Centers to Wearable Devices,IIS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE",10/1/2015,9/18/2017,Jia Deng,"Deng, J","Deng, J|Pipe, K|Wenisch, T|Tang, L|Mars, J",MI,University of Michigan Ann Arbor,Continuing grant,Maria Zemankova,9/30/2018,"$960,000.00 ","Kevin Pipe, Thomas Wenisch, Lingjia Tang, Jason Mars",jiadeng@cs.princeton.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,"1640, 1714","002Z, 1640, 7924",$0.00 ,normalFunding,"Advances in computer hardware and software promise to revolutionize the ways in which society interacts with visual information. However, visual recognition systems are limited by the lack of a practical means to classify the millions of concepts that arise in visual scenes and thus efficiently recognize when a small number of these concepts appear in a given scene. Furthermore, while real-time processing of visual data could significantly expand our perception of our surroundings, state-of-the-art vision systems cannot currently be implemented on wearable devices such as smartphones due to the limited heat dissipation (e.g., no fans or liquid cooling) and power such devices can provide. This research will overcome these challenges by developing artificial intelligence (AI) systems that efficiently manage the resources most crucial for high-performance wearable-based visual recognition, including the wearable device's real-time power consumption and computation. These systems will be empowered to initiate bursts of intense computation that are thermally managed by materials within the wearable device which are engineered to melt during heavy heating and solidify between bursts. Moreover, the AI systems will govern the communication between the device and external (cloud-based) computation resources as well as large-scale visual concept databases housed in data centers, thus providing extreme performance in a wearable form factor. Central concepts of this work will be integrated in undergraduate and graduate coursework, and a demonstration system will be made available to the research community and used in educational modules for high school students.<br/><br/>This effort seeks to advance the core capabilities of large-scale visual recognition by co-designing visual models and computing infrastructure. The goal is to enable encyclopedic, real-time visual recognition through seamless integration of visual computing on wearable devices and in the cloud. The PIs envision a wearable visual recognition system that continuously captures live video input while providing intelligent, real-time assistance through automatic or on-demand visual recognition by means of a combination of computation at the device and offloading to the cloud. Such a system is not currently feasible due to a number of fundamental challenges. First, the severe energy and thermal constraints of wearable devices render them incapable of performing the intensive computation necessary for visual recognition. Second,  it remains an open question how to support encyclopedic recognition in terms of both visual models and data center infrastructure. In particular, it remains unclear how current visual models, although highly successful at recognizing 1,000 object categories, can scale to millions or more distinct visual concepts. Moreover, such an encyclopedic visual model must be supported through data center infrastructure, but little progress has been made on how to build such infrastructure. This project addresses these fundamental challenges through an interdisciplinary approach integrating computer vision, hardware architecture, VLSI design, and heat transfer. The PIs will investigate three research thrusts. In Thrust 1, the PIs will develop a new type of deep neural networks that allow resource-efficient execution of modules. This new framework provide a unified way to design, learn, and run scalable visual models that can maximize the utility of recognition subject to resource constraints, such as latency, energy, or thermal dissipation of a wearable device. In Thrust 2, the PIs will design and fabricate a visual processing chip capable of computational sprinting (bursts of extreme computation well above steady-state thermal dissipation capabilities), leveraging the new framework developed in Thrust 1. In Thrust 3, the PIs will design datacenter infrastructure that supports large-scale hierarchical indexing of visual concepts for encyclopedic recognition, with a focus on latency, throughput, and energy efficiency. Finally, the PIs will build a demonstration system to evaluate the proposed algorithms, software, and hardware components and to assess the overall performance of an end-to-end system. The project web site (http://mivec.eecs.umich.edu/) will provide access to the results of this research including technical reports, datasets, and source code."
1713439,Applying Game Design Principles for Supporting Computational Literacy Experiences in Museum Exhibits,DRL,AISL,9/1/2017,8/16/2017,Matthew Berland,"Berland, M","Berland, M|Lyons, L|Cannady, MA",WI,University of Wisconsin-Madison,Standard Grant,Catherine Eberbach,8/31/2020,"$951,474.00 ","Leilah Lyons, Matthew A. Cannady",mberland@wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,EHR,7259,8244,$0.00 ,normalFunding,"Becoming computationally literate is increasingly crucial to everyday life and to expanding workforce capacity. Research suggests that computational literacy--knowing what, when, how, and why to use the ideas of computer science, in combination with the capacity to view problems and potential solutions through the lens of computational structures and procedures--can be supported through digital game play. This project aims to develop a social and creative exhibit game that foregrounds aspects of computer science, specifically artificial intelligence (AI) and computer programming, in ways that enable youth to explore, construct, and share computational complex systems content with one another and other museum visitors. To play the game, pairs of youth visitors will use code cards to program the behavior of AI animals in a virtual forest. As they do so, youth will engage with computational literacy practices, such as basic computer programming, describing their computational ideas, and doing computational problem solving with their friends. Their activity will be projected on a large screen as a strategy for enabling youth to test, rehearse, and communicate their computational ideas and to also interest other visitors into computational problem solving.<br/><br/>Using multi-perspective and iterative design-based research, university learning scientists, museum practitioners, and game developers will pursue research questions around how science museums can better engage youth who are traditionally underrepresented in computer science in complex computational practices. Data sources will include interactive-log data, observations of visitor interactions with the game, visitor interviews, and visitor surveys. A multimodal and mixed methods approach that searches for convergences between qualitative analysis, quantitative analysis, and learning analytics will be used to generate research findings. Changes in computational literacy will be assessed by evaluating what problems visitors choose to solve with programming, how they frame those problems, and their selections from among possible solutions, what they program, how they program, and how they describe programming ideas. The results of this project will include: 1) a social, interactive gameplay experience that supports the development of computational literacy; 2) design principles for game-based exhibits that facilitate development of computational literacy; and 3) new knowledge of variations in design and gameplay across diverse gameplay users, including those from underrepresented groups in computer science. It is anticipated that 1,000 museum youth visitors will directly participate in the study.  <br/><br/>This project is funded by the Advancing Informal STEM Learning (AISL) program, which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments. This includes providing multiple pathways for broadening access to and engagement in STEM learning experiences, advancing innovative research on and assessment of STEM learning in informal environments, and developing understandings of deeper learning by participants."
1353757,IDBR Type A: Miniaturized Two-photon Microscopy for Deep Brain Imaging: An Integrated Circuit Design Using Electrowetting Optics,DBI,"INSTRUMENTAT & INSTRUMENT DEVP, BIOPHOTONICS, IMAGING &SENSING, CROSS-EF ACTIVITIES",4/1/2014,3/1/2016,Juliet Gopinath,"Gopinath, J","Gopinath, J|Gibson, E|Bright, V|Restrepo, D",CO,University of Colorado at Boulder,Continuing grant,Robert Fleischmann,3/31/2019,"$945,874.00 ","Emily Gibson, Victor Bright, Diego Restrepo",juliet.gopinath@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,BIO,"1108, 7236, 7275",8007,$0.00 ,normalFunding,"An award is made to the University of Colorado to do deep brain imaging using a novel miniature nonlinear microscope. Optical imaging methods combined with fluorescent markers offer the unprecedented ability to study functioning of the complex neural networks in the brain down to the resolution of individual neurons. However, due to light scattering in tissue, over 75% of the brain cannot be studied. Technology that offers the path for high resolution deep brain functional imaging is urgently needed in order to further advance the fundamental understanding of how the brain works. This project will investigate a fiber-optic imaging instrument incorporating adaptable optics. The miniature fiber-optic imaging system implanted minimally-invasively will enable visualization of thousands of neurons deep in the brain. The large volume of imaging is important for understanding the complex interconnections involved in neural networks while access to new regions of the brain will open up study in important areas of the brain that are currently not accessible with other techniques.<br/><br/>The work is interdisciplinary in nature, combining aspects of biology, materials science, physics, and engineering and will provide excellent opportunities for students to broaden their scientific knowledge outside of a specific discipline. The PI's will disseminate the results of their work through teaching and education outreach that includes student groups, undergraduate research opportunity programs and summer programs for under-represented undergraduates. Beyond basic research, results from this project will be used to further the understanding of brain function, advance artificial intelligence, and treat neurological disorders."
513102,"D^3: New Directions, Dimensions, and Domains for Computer Science",CNS,"SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, COLLABORATIVE RESEARCH, SCI TESTBEDS, IIS SPECIAL PROJECTS",6/1/2005,8/1/2005,Fred Roberts,"Roberts, F","Roberts, F",NJ,Rutgers University New Brunswick,Standard Grant,Harriet G. Taylor,9/30/2011,"$936,271.00 ",,froberts@dimacs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,"1714, 2878, 7298, 7368, 7484","9200, 9218, HPCC",$0.00 ,normalFunding,"Rutgers University has received a Special Projects award to support  a portion of the infrastructure of the DIMACS Center. DIMACS was founded as the Center for Discrete Mathematics and Theoretical Computer Science. As the Center has grown and matured, it has greatly expanded its scope, culminating in the D3 Project: New Directions, Dimensions, and Domains for Computer Science.<br/><br/>The D3 Project aims at providing a resource for the national computer science community through innovative research and educational programs with a broad scope and impact. The programs will emphasize new directions in areas such as information and data management,  artificial intelligence, and trusted computing. In-depth investigation of emerging trends in areas such as privacy, security, and sensors will open up new dimensions for computer science.  Applications of computer science and closely-related areas of mathematics and statistics will explore new domains in biology, chemistry, physics, engineering, public heath, business, and the social sciences. <br/><br/><br/>"
325812,"Collaborative Research: ITR: Software for Interpretation of Cosmogenic Isotope Inventories - Combination of Geology, Modeling, Software Engineering and Artificial Intelligence",EAR,"ITR MEDIUM (GROUP) GRANTS, ITR FOR NATIONAL PRIORITIES",9/15/2003,9/9/2004,Elizabeth Bradley,"Bradley, E","Bradley, E|Anderson, K",CO,University of Colorado at Boulder,Standard Grant,Enriqueta Barrera,8/31/2009,"$933,622.00 ",Kenneth Anderson,lizb@cs.colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,"1687, 7314","0000, 1652, 1661, 1687, 2884, 4444, 9215, HPCC, OTHR",$0.00 ,normalFunding,"This project aims to improve the accuracy of geological chronologies based on cosmogenic isotope data. It combines research on computer models of the effects of various processes on the rate of accumulation of cosmogenic isotopes in geological formations, the development of a database of data (such as isotope abundances) and environmental parameters useful for cosmogenic isotope dating (such as solar output and the state of the terrestrial magnetic field at different times), and an artificial intelligence (AI) system to support the use of cosmogenic isotope accumulation models in dating. The AI system will act as an expert system guiding the user in the choice of modeling tools and data, and integrating the selected models and data. The combined AI/database/modeling system will be built using a component-based architecture to make it simpler to modify and extend as new processes and data sets are added.<br/><br/>Because of the central importance to geological inference of establishing the age of geological structures, this project, if successful should be helpful in a number of problems in research and applied geology. The project will also strengthen the connections between the geological and computer science research communities, both by virtue of the collaboration itself and by demonstrating the potential for exploiting information technology to further geological research."
705898,RI:  Dynamic Discrete Choice Networks -- An Artificial Intelligence Approach to Modeling Dynamic Travel Behavior,IIS,INFO INTEGRATION & INFORMATICS,10/1/2007,4/23/2010,Alan Borning,"Borning, A","Borning, A|Waddell, P|Fox, D|Layton, D",WA,University of Washington,Standard Grant,Vijayalakshmi Atluri,6/30/2012,"$931,964.00 ","Paul Waddell, Dieter Fox, David Layton",borning@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7364,"7364, 7495, 9216, 9251, HPCC",$0.00 ,normalFunding,"Project Summary<br/>The goals of the proposed research are twofold: first, to advance the state of the art in artificial intelligence and cognitive sciences by developing novel probabilistic reasoning techniques; and second, to use these techniques in building better transportation models, which can then be used to help inform public deliberation regarding major infrastructure decisions. Problems of maintaining or replacing aging infrastructure, or adding new infrastructure to meet the needs of population growth and urban expansion of metropolitan areas, are becoming increasingly difficult to solve, in part because the cost is extremely large, and in part because the political discourse over alternative solutions is contentious and reflects divergent assumptions and values. Often, a major source of disagreement is cost; but another is rooted in differing assumptions about how people would adjust their travel in response to changed circumstances in both the short and long term, and how much congestion would result. Current transportation models used in operational analysis and planning are too behaviorally simple to be very useful in addressing these questions. Recent research advances have provided improvements in behavioral representation in these kinds of choice situations, but to date these nnovations are not integrated and are computationally not feasible for large-scale application. During the last decade, the artificial intelligence community has developed a set of techniques that enable fine-grained activity recognition from sensor data; among the most advanced and successful are approaches based on Dynamic Bayesian networks and statistical relational learning. The research team will build on this foundation, integrating these AI techniques with the Discrete Choice Models used in econometric approaches, to yield a new, hybrid reasoning system: Dynamic Discrete Choice Networks. This technique will be applied to the challenging domain of modeling dynamic travel choices of individuals, such as the number of trips, scheduled time of departure, destinations, modes, and routes and to predict how these choices change under dynamically updated travel conditions. <br/><br/>Intellectual Merit<br/><br/>The merit of this proposal is grounded in the research challenges in the artificial intelligence and urban modeling areas. This project advances the state of the art in artificial intelligence and cognitive sciences by developing novel probabilistic reasoning techniques that are well suited for modeling the complex combinations of factors involved in human decision making in the commonsense domain of daily travel. By integrating this modeling power into probabilistic temporal models, Dynamic Discrete Choice Networks will provide an extremely general and flexible framework for learning and recognizing human activities from sensor data and for understanding how everyday human decision making adapts to a constantly changing environment.<br/><br/>Broader Impacts<br/><br/>UrbanSim has the potential to significantly aid in public deliberation over major decisions regarding transportation replacement or expansion of transportation infrastructure, managing urban development, planning for response to mitigate the effects of events such as hurricane Katrina or a major earthquake, and other issues. UrbanSim is Open Source and freely available, and has already attracted considerable interest and use. Because of their improved ability to recognize and analyze human activities from raw sensor data, Dynamic Discrete Choice Networks will have applications to other significant domains as well, such as eldercare and long term health monitoring."
640837,Project ARIES: An Integrated Digital Collaboratory to Support the Economic Valuation of Ecosystem Services,DBI,ADVANCES IN BIO INFORMATICS,4/1/2007,2/2/2011,Jon Erickson,"Erickson, J","Erickson, J|Ceroni, M|Krivov, S|Portela, R|Batker, D",VT,University of Vermont & State Agricultural College,Continuing grant,Julie Dickerson,3/31/2011,"$929,556.00 ","Marta Ceroni, Sergey Krivov, Rosimeiry Portela, David Batker",jon.erickson@uvm.edu,85 South Prospect Street,Burlington,VT,54050160,8026563660,BIO,1165,"1165, 9123, 9150, 9184, BIOT",$0.00 ,normalFunding,"The University of Vermont and State Agricultural College is awarded a grant to develop ARIES (Assessment and Research Infrastructure for Ecosystem Services), a web-enabled framework capable of guiding its users through all phases of ecosystem services assessment. The tool will allow users to define of an area and social context of interest, and guide them through the analysis of existing valuation and geographical data to obtain an ecosystem service provision assessment, with the spatially-explicit estimation of the correspondent, immediate and projected economic values. Through a coordinated IT and interdisciplinary field effort the project will extend the capability of a previously developed database for ecosystem services with an expert framework that captures knowledge on ecosystem assessment and valuation into formal rules. These rules will be presented to users and applied to ongoing case studies to help creating ecosystem services assessments for specific contexts. Case studies in Puget Sound, Madagascar, and Mexico will provide both developed and undeveloped contexts to populate, test, and validate the framework. Through this framework, the team will develop momentum for a sustainable initiative for transparent and fair ecosystem service valuation.  The project team includes collaborators from Conservation International, and Earth Economics, both 501(c)3 not-for-profit organizations."
443924,Collaborative Research:   I/UCRC:    Safety Security Rescue Research Center (SSR-RC),IIP,"CISE RESEARCH RESOURCES, INDUSTRY/UNIV COOP RES CENTERS, , , , , , , , ",8/15/2004,4/3/2008,Robin Murphy,"Murphy, R","Murphy, R",FL,University of South Florida,Continuing grant,Rathindra DasGupta,12/31/2008,"$918,326.00 ",,murphy@cse.tamu.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,ENG,"2890, 5761, T036, T539, T540, T672, V718, V758, V886, V990","0000, 1049, 122E, OTHR",$0.00 ,normalFunding,"This multi-university Industry/University Cooperative Research Center for Safety, Security and Rescue Research located at the University of South Florida and the University of Minnesota will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, firefighting, transportation safety, and emergency response to mass casuality-related activities.  The need for safety, security, and rescue technologies has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics in February 2003.  <br/><br/>The Center will be built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at the University of South Florida (the lead institution) and the University of Minnesota.<br/>"
427129,ITR - (EVS+NHS) - (dmc + int):  Knowledge Infusion,CCF,ITR FOR NATIONAL PRIORITIES,9/1/2004,6/3/2011,Leslie Valiant,"Valiant, L","Valiant, L",MA,Harvard University,Continuing grant,Balasubramanian Kalyanasundaram,8/31/2012,"$908,049.00 ",,valiant@seas.harvard.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,CSE,7314,"9216, HPCC",$0.00 ,normalFunding,"The goal of the proposed research is to extend the reach of machine learning technology so that it can enable computers to perform a broader span of tasks than currently. In particular the goal is to enable machines to extract knowledge from data into a form such that robust reasoning can be done on it. Currently representations on which reasoning can be done on a large scale are typically programmed and the results suffer from brittleness -  they do not behave well in unforeseen situations. In the proposed approach, which is called knowledge infusion, the goal is to acquire the rules on which reasoning will be <br/>done by a combination of programming and learning, and to have a continuous process of learning and checking against an environment to ensure that the rules are reliable. The goal is to handle unaxiomatized or commonsense knowledge, which encompasses the bulk of knowledge that humans handle everyday, as embodied in speech or text, replete as these often are with inconsistencies, ambiguities and errors. This can be distinguished from knowledge that is known to be axiomatizable, such as most knowledge of a mathematical nature. Axiomatized knowledge, in general, can be easily programmed, and computers can usually fully exploit such knowledge up to any inherent computational complexity limitations of the problem at hand. <br/> <br/>The most central aims of the research are the development of algorithms that realize knowledge infusion and are computationally efficient and effective even for very large datasets. Also central is the identification of what the fundamental limits of the phenomenon are. The techniques used will be from theoretical computer science, and experimentation on large datasets will be carried out as needed. <br/> <br/>The goal is to be able to infuse into machines commonsense knowledge about the world on a large scale and in a way such that the machines will be able to reason with it with a controlled level of robustness. Success in this endeavor can be expected to have applications in almost all areas of computing that involve either human interaction with a computer, or computation on data that was generated by or has reference to humans. Hence there are numerous connections with the national priority areas EVS and NHS, and with the technical focus areas int and dmc. <br/> <br/>Broader Impact: <br/> <br/>If successful the results of the research will help enhance the effectiveness of computers to handle commonsense or unaxiomatized information about the world. This would extend the usefulness of computers to new areas and contribute to prosperity (EVS). It would also enable large datasets to be analyzed automatically with greater functionality than hitherto (NHS). <br/><br/>"
9313624,Institutional Infrastructure Minority Institutions Program: Establishment of an Institutional Infrastructure:  Center   for Advanced Technology and Education (CATE),EIA,CISE RESEARCH INFRASTRUCTURE,9/1/1993,8/13/1998,Malek Adjouadi,"Adjouadi, M","Adjouadi, M|Arefi, F|Roig, G|Holmes, D|Deng, Y|Evangelist, M",FL,Florida International University,Continuing grant,Stephen Mahaney,2/28/1999,"$900,044.00 ","Farahangiz Arefi, Gustavo Roig, Dawn Holmes, Yi Deng, Michael Evangelist",adjouadi@fiu.edu,11200 SW 8TH ST,Miami,FL,331990001,3053482494,CSE,2885,"2886, 9178, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"9313624 Adjouadi      This award provides infrastructure support for the development of research and educational activities in the Department of Electrical and Computer Engineering, and in the School of Computer Science at Florida International University.  The management of the program will be by the Center for Advanced Technology and Education (CATE), a state of the art research facility to integrate critical technology areas in computer and information science and engineering.  Project will involve software engineering, computer vision, neural networks, artificial intelligence and robotics applications, and computer aided education.  The unifying theme to the work will be concurrent processing. In the course of the projects both the graduate and undergraduate programs will be enhanced and revitalized. ***"
9720314,Learning and Intelligent Systems:  Simulating Tutors with   Natural Dialog and Pedagogical Strategies,BCS,LEARNING & INTELLIGENT SYSTEMS,9/15/1997,9/24/1997,Arthur Graesser,"Graesser, A","Graesser, A|Kreuz, R|Garzon, M|Marks, W|Franklin, S",TN,University of Memphis,Standard Grant,Steven Breckler,8/31/2001,"$900,000.00 ","Roger Kreuz, Max Garzon, William Marks, Stanley Franklin",a-graesser@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,SBE,8888,"0000, 1180, 1311, 1332, 8888, OTHR",$0.00 ,normalFunding,"This project is being funded through the Learning and Intelligent Systems (LIS) Initiative.  The long-term practical objective of the research is to develop a fully automated computer tutor. The tutor would be able to (a) extract meaning from the contributions that the student types into a keyboard and (b) formulate dialog contributions with pedagogical value and conversational appropriateness. The tutor's discourse moves include: pumping, prompting, hinting, questioning, answering, summarizing, splicing in correct information, providing immediate feedback, and rewording student contributions. The dialog contributions of the tutor would be in different formats and media: printed text, synthesized speech, simulated facial movements, graphic displays, and animation. Such an achievement will require an interdisciplinary integration of theory and empirical research from the fields of cognitive psychology, discourse processing, computational linguistics, artificial intelligence, human-computer interaction, and education. The tutoring topics will be in the domains of computer literacy and introductory medicine.  Previous attempts to develop a fully automated tutor have been seriously challenged by some technical and theoretical barriers. These include (a) the problem of interpreting natural language when it is not well-formed semantically and grammatically, (b) the problem of world knowledge being immense, open-ended and incomplete, and (c) the lack of research on human tutorial dialog. Recent advances have dramatically reduced these barriers, so it is time to revisit the mission of developing an automated tutor. According to the recent research on human tutoring, a key feature of effective tutoring lies in generating discourse contributions that assist learners in actively constructing explanations, elaborations, and mental models of the material. The proposed research will advance scientific understanding of how a tutor can manage a smooth, polite dialog that promotes deep learning of the material."
1262814,"CI-ADDO-EN: Smart Home in a Box: Creating a Large Scale, Long Term Repository for Smart Environment Technologies",CNS,COMPUTING RES INFRASTRUCTURE,8/1/2013,7/19/2013,Diane Cook,"Cook, D","Cook, D",WA,Washington State University,Standard Grant,Sylvia J. Spengler,7/31/2017,"$900,000.00 ",,cook@eecs.wsu.edu,280 Lighty,PULLMAN,WA,991641060,5093359661,CSE,7359,"7359, 7364, 7918",$0.00 ,normalFunding,"There is considerable current interest in developing smart environment technologies. Such efforts present research challenges in, and integration of research outcomes from, diverse disciplines including artificial intelligence, pervasive computing, robotics, interfaces, middleware, and sensor networks. The lack of availability of large-scale sharable data sets from smart environments is a major stumbling block for rapid advances in this area. Against this background, this project aims to develop and deploy a data and tool repository needed by the smart environment research community.<br/><br/>The anticipated results of this infrastructure project include 1) a streamlined, do-it-yourself smart home kit, 2) a web interface to upload, access, and annotate smart environment data, 3) meta data including functional assessment scores and energy usage, and 4) software tools to recognize, visualize, and analyze home-based behaviors. The investigators aim to assess the impact of the  resulting repository (CASAS) using measures such as number and diversity of researchers utilizing the repository, number of datasets and tools contributed to the repository, research, education, and commercial advances related to the repository, and publication citations to the repository.<br/><br/>Broader impacts of the project include (i) the do-it-yourself smart home toolkit, data sets and software tools that enable research and educational efforts by a large community of researchers in artificial intelligence, pervasive computing, robotics, interfaces, middleware, and sensor networks; (ii) enhanced opportunities for researchers in cognitive psychology, gerontology, and sociology to contribute to interdisciplinary research in smart environments; and (iii) enhanced research-based training opportunities for students from underrepresented groups. The datasets, software tools and educational materials that result from this work will be made available as part of the CASAS repository at http://ailab.wsu.edu/casas/."
1727303,CI-EN: Enhancement of a Large-scale Multiagent Simulation Tool,CNS,COMPUTING RES INFRASTRUCTURE,9/1/2017,7/11/2017,Sean Luke,"Luke, S","Luke, S|Simon, R|Crooks, A",VA,George Mason University,Standard Grant,James Donlon,8/31/2020,"$896,303.00 ","Robert Simon, Andrew Crooks",sean@cs.gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,7359,7359,$0.00 ,normalFunding,"An agent-based simulation is a software simulation of many independent actors (people, robots, animals, companies, etc.) interacting in complex ways.  For example, one might build a simulation of a swarm of ants, a school of fish, a large group of robots collectively building a house, a city of people under siege by a large medieval army, or the spread of urban legends over a social network. These kinds of simulations are used for everything from building software for swarms of delivery robots, to understanding the spread of disease in third-world slums, to predicting the impact of climate change on human migration patterns.  Similarly, these simulations help researchers and policy makers in engineering and robotics, in artificial intelligence, and in the biological and social sciences.  Such simulations can get very large, with large numbers of actors.  This project involves building a software tool to assist in the development of large-scale agent-based simulations spread over potentially many separate computers, and to make it easy for them to place their agents in simulated locations on the Earth.  At the same time the tool will be easy to use for high school and undergraduate students.<br/><br/>The project will develop a distributed agent-based modeling tool for constructing large simulations of swarms and groups of agents.  The project enhances an existing, successful open-source Java multiagent simulation library called MASON.  MASON is designed to run on a single machine; but the enhanced version will also allow distribution over many machines.  The enhanced tool will also include facilities for embedding agents in geographical information systems (GIS), model optimization and automation, interfaces for alternative programming languages targeting the Java Virtual Machine, statistics facilities, internal testing and verification, and integration with software tools.  The enhancement will not only provide a distributed simulation facility for researchers in the social sciences, biology, and engineering, but will also improve on MASON's graphical interface and language facilities to make it easier to use as a teaching tool."
9725251,"Predictive, Sensor-Assisted Wireless Multimedia Systems",CNS,SPECIAL PROJECTS IN NET RESEAR,9/15/1997,5/12/1999,Stephen Wicker,"Wicker, S","Wicker, S|Fine, T|Halpern, J",NY,Cornell University,Standard Grant,Taieb Ben Znati,8/31/2001,"$892,465.00 ","Terrence Fine, Joseph Halpern",wicker@ece.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,4095,"9218, 9251, HPCC",$0.00 ,normalFunding,"ABSTRACT    NCR-9725251  Stephen Wicker, Terrence Fine, and Joseph Halpern  Cornell University  Predictive, Sensor-Assisted Wireless Multimedia Systems    The PCS systems of the future will provide a variety of services to mobile users, including voice, high speed data, video, e-mail, teleconferencing, and the transfer of medical Images.  The intelligent PCS network will be required to provide channel access with a minimum of call blocking, negotiate quality of service, allocate resources, and track users throughout their sessions.  It is proposed to develop a series of expert systems that will optimize random access, resource allocation, and mobility management protocols.  These expert systems will use a number of technologies and techniques from the fields of neural networks, artificial intelligence, and knowledge representation.    There are three levels of agents in the proposed intelligent PCS network: mobile user, Base Station Controller (BSC), and the Mobile Switching Center (MSC). It is assumed that the PCS system is cellular, with several BSC's interacting with a single MSC.  It is proposed to determine a means for representing and exploiting the information available to each type of agent.    At the physical layer, in-band transmitted power levels will be tracked by a grid of low-cost sensors (radiometers).  The sensors will provide power measurements as a function of time and location.  In the proposal it is shown that this information can be used in the development of a BSC-based intelligent ALOHA multiple access scheme.  Neural networks are described that can efficiently use the sensor data to estimate the number of users involved in individual collision events.  This information is used in turn to estimate the number of backlogged users and to select an optimal backoff algorithm, thus maximizing Aloha channel throughput.    The sensor grid can also be used by the BSC and MSC to support resource allocation, handoffs, and the tracking of scheduled user transmissions.  In the proposed  research program, sensor-based expert systems will be developed for three distinct phases of PCS operation: system planning and layout, multiple access, and adaptive resource allocation.    Higher level information can be acquired and used at the BSC's and the MSC.  The BSC's will obtain information regarding the local users' bandwidth and quality of service requirements as a function of time. The BSC's will also track local channel conditions, and develop a detailed propagation model for the cell.  The model will be used to as an aid to power control within the cell.  The BSC is expected to act as an autonomous agent in local resource allocation and power control.      The MSC will be responsible for allocating resources between cells.  An allocation protocol will be developed to move resources between cells in response to traffic information acquired by the BSC's and passed to the MSC.  The BSC's will also pass propagation and user tracking information to the MSC.  The MSC will use this information to create a global propagation and user tracking model that will support the handoff decision process.  An effort will be made to develop usage tendency profiles for individual users.  The collection of user profiles will be used to develop models for global resource allocation."
1661356,Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution,DBI,ADVANCES IN BIO INFORMATICS,9/1/2017,8/30/2017,Todd Vision,"Vision, T","Vision, T",NC,University of North Carolina at Chapel Hill,Standard Grant,Peter H. McCartney,8/31/2020,"$880,522.00 ",,tjv@bio.unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,BIO,1165,9150,$0.00 ,normalFunding,"The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
1636848,"BD Spokes: SPOKE: SOUTH: Collaborative:  Using Big Data for Environmental Sustainability:  Big Data + AI Technology = Accessible, Usable, Useful Knowledge!",IIS,"BD Spokes -Big Data Regional I, INFORMATION TECHNOLOGY RESEARC",10/1/2016,9/7/2017,Ashok Goel,"Goel, A","Goel, A",GA,Georgia Tech Research Corporation,Standard Grant,Beth Plale,9/30/2019,"$870,445.00 ",,ashok.goel@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,"024Y, 1640","028Z, 043Z, 7433, 8083, 9251",$0.00 ,normalFunding,"Protecting the environment is among the biggest challenges facing our society. As the effects of environmental degradation, global warming and climate change continue to grow, there is an increasingly urgent and critical need for research and education in biological diversity, ecological modeling and environmental sustainability. On one hand, professional and citizen scientists need ready access to large-scale biological, ecological and environmental data for modeling, simulation and analysis. On the other, college teachers and students in biology and ecology need to access large-scale data in a form meaningful to them. The various audiences will engage with big data in different ways and so a variety of knowledge-building tools are needed. This project brings together two dozen scientists from a dozen institutions in academia, government and industry to address the problem of translating big data into meaningful knowledge in support of research and education in environmental sustainability.  <br/><br/>Encyclopedia of Life  (EOL) is the world's largest database of biological species and other biodiversity information. EOL also works closely with scores of other biodiversity datasets such as BISON, GBIF, and OBIS. This project seeks to make EOL and related biodiversity data sources accessible, usable, and useful, by integrating extant artificial intelligence tools for information extraction, modeling and simulation, and question answering. The focus of this project will be on the data engineering required for this integration and construction of a resulting EOL+ system. The project team will provide access to EOL+ such that users can build their own tools and services on top of EOL+. The team will work with the NSF South Big Data Hub to organize yearly workshops for building and supporting a community of users of EOL+. Professional and citizen scientists, and teachers and students alike, will be able to access EOL+ through NSF's South Big Data Hub webportal, and use it for modeling and analysis, explanation and prediction, as well as education and workforce development in biological diversity, ecological modeling and environmental sustainability."
133994,CAREER:  Collaborative Knowledge Spaces for Filtering Information,IIS,"DIGITAL SOCIETY&TECHNOLOGIES, IIS SPECIAL PROJECTS, , ",2/1/2002,3/3/2006,Jonathan Herlocker,"Herlocker, J","Herlocker, J",OR,Oregon State University,Continuing grant,William Bainbridge,1/31/2008,"$860,122.00 ",,herlock@cs.orst.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,"6850, 7484, V252, V463","0000, 1045, 1187, 9139, 9178, 9216, 9218, 9251, HPCC, OTHR, SMET",$0.00 ,normalFunding,"This research project will develop techniques and systems that answer the following question, independent of content type: ""What items have the highest probability of being both interesting and relevant to my information need?"" Whether or not an item (document, resource, etc) is ""interesting"" for a given information need will depend on the user's background and taste. Book and web page recommenders will be built and evaluated that predict relevance and interest based on content and interest ratings entered by each member of a large Internet community. A content rating indicates how much a user believes that a relationship exists between an item and a content attribute while an interest rating specifies the user's level of interest in an item. Affinities between users' interests and users' perception of content relationships will be leveraged to transfer recommendations implicitly between users. The career development plan involves a) the development of a graduate focus in ""Intelligent Information Systems,"" which allies approaches from artificial intelligence, information retrieval, and human computer interaction against problems of information overload, and b) development of a summer REU program with the goal of increasing the number of broadly educated US Citizens (particularly women) in Ph.D. computing graduate programs.<br/><br/>"
1344768,SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention,IIS,Smart and Connected Health,10/1/2013,5/12/2017,Robert Kraut,"Kraut, R","Kraut, R|Mengshoel, O",PA,Carnegie-Mellon University,Standard Grant,Sylvia J. Spengler,9/30/2017,"$846,572.00 ",Ole Mengshoel,kraut@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,8018,"8018, 8062, 9251",$0.00 ,normalFunding,"Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br/><br/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups.  Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br/><br/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory."
224401,CISE Research Resources: R4: Rescue Robots for Research and Response,CNS,CISE RESEARCH RESOURCES,10/1/2002,12/18/2007,Robin Murphy,"Murphy, R","Murphy, R",FL,University of South Florida,Continuing grant,Rita V. Rodriguez,9/30/2008,"$823,269.00 ",,murphy@cse.tamu.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,CSE,2890,"9218, HPCC",$0.00 ,normalFunding,"EIA 0224401<br/>Murphy, Robin R.<br/>University of South Florida <br/><br/>Title: CISE RR: R4: Rescue Robots for Research and Response <br/><br/>This project, developing and maintaining robotics kits for nationwide research, aims at facilitating research into robot-assisted urban search and rescue (USAR) by providing resources to overcome barriers presenting research involvement (lack of access to domain experts and meaningful sites combined with the need for expensive specialized equipment), while at the same time increasing the availability of mobile robots for an emergency response. This work supports the<br/>Expansion of existing caches of robots suitable for USAR research in two different regions,<br/>Training on these robots, data collection, and access to these robots and data sets via the Internet,<br/>Field data collection exercises with fire rescue professionals at USAR sites, and<br/> Loan of robots to individual researchers. <br/>The work facilitates groups, without rescue robots or access to domain experts, to have access to data and/or work directly with USAR robots and rescue experts in the field. <br/><br/>Rescue robotics is a complex domain in need of fundamental breakthroughs in distributed computing, networking and communications, software engineering and interoperability, real-time multi-threaded control, user interfaces and human-robot interaction, robotics, sensors, and artificial intelligence (AI). Hence, the Computing Research Association declared this research area a ""grand challenge."" Four types of research equipment, micro-robots, mini-robots, image processing and video capturing equipment, and sensors, enable researchers to collect the data and evaluate their work in the cited areas. In addition to integrating existing technology and eliciting effective cooperation between professionals and researchers in the case of an emergency, the project provides education in robotics for homeland defense, and the potential to safeguard lives of rescue workers and locate victims."
1237077,SHB: Type II (INT): Collaborative Research: Creating Learning Systems with Mobile Technology to Improve Coordination in Perioperative Services,IIS,"SERVICE ENTERPRISE SYSTEMS, INFO INTEGRATION & INFORMATICS, Smart and Connected Health",10/1/2012,12/15/2017,Kevin Taaffe,"Taaffe, K","Taaffe, K|Greenstein, J|Fredendall, L",SC,Clemson University,Standard Grant,Sylvia J. Spengler,6/30/2018,"$821,066.00 ","Joel Greenstein, Lawrence Fredendall",taaffe@clemson.edu,230 Kappa Street,CLEMSON,SC,296345701,8646562424,CSE,"1787, 7364, 8018","7364, 8018, 8023, 8062, 9150, 9251",$0.00 ,normalFunding,"This project proposes to create a framework using a combination of mobile technology, learning systems, data analytics, education, and training to enhance cooperation and coordination of staff within and across perioperative services departments (POS).  Perioperative services comprise surgery preparation, operating rooms, post-anesthesia care, sterile processing and a variety of other services, such as radiology and endoscopy.  The specific objectives of this project are to: (1) enhance communication and coordination among POS staff to improve the quality of care by gathering and using important workflow milestones and introducing artificial intelligence techniques through the use of a smart-app, (2) analyze workflow data gathered with smart-apps using data analytics to provide intuitive displays of real-time information for frontline staff and a daily performance dashboard for managers, and (3) induce behavioral and cultural change in healthcare systems through training and education. While existing  information technology capabilities such as natural language processing, artificial intelligence, and speech recognition technology are promising developments in computing, their uses in health care are limited and thus need to be thoroughly investigated before they can be used in health care effectively. To accomplish these objectives, the research team will work closely with the partnering healthcare organizations, Greenville Hospital System (GHS), Palmetto Health (Palmetto), and the Medical University of South Carolina (MUSC), in developing the tools and models which will be pilot-tested at these organizations by their staff.  <br/><br/>The developed tools and models will be widely disseminated among health care providers in South Carolina. In addition, the smart-apps and agent-based simulation model will provide the team with a teaching and training tool that can be used in the classroom at Clemson University and the University of South Carolina (USC) to teach students across a variety of fields, such as business, engineering, science and healthcare students about information and workflow management techniques."
1725743,SPX: CISIT: Computing In Situ and In Memory for Hierarchical Numerical Algorithms,CCF,SPX: Scalable Parallelism in t,10/1/2017,9/11/2017,George Biros,"Biros, G","Biros, G|John, L|Gerstlauer, A",TX,University of Texas at Austin,Standard Grant,M. Mimi McClure,9/30/2020,"$800,000.00 ","Lizy John, Andreas Gerstlauer",gbiros@gmail.com,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,042Y,"026Z, 9229",$0.00 ,normalFunding,"High performance computing holds an enormous promise for revolutionizing science, technology, and everyday life through modeling and simulation, statistical inference, and artificial intelligence.  Despite the numerous successes in software and hardware technologies, energy efficiency barriers have become a major hurdle towards more powerful computers -- from mobile devices all the way to supercomputers. The originally natural separation between the memory subsystem and the central processing unit (CPU) of a computer has emerged as one the main reasons for energy inefficiency. Data movement between the memory and the CPU requires orders of magnitude more energy than the computations themselves. To address these challenges, this project will consider novel architectural design paradigms and algorithms that are aimed at blurring these traditional boundaries between separated memory and computation subsystems and, by distributing computations to be performed directly in the memory or as part of the memory data transfers, achieve order of magnitude gains inenergy efficiency and performance. This project will investigate such novel approaches in the context of a class of methods in computational mathematics, which appear at the core of many problems in computational science, large-scale data analytics, and machine learning.<br/><br/>Specifically, this project will focus on data-driven rather than compute-driven co-design of algorithms and architectures for the construction, approximation, and factorization of hierarchical matrices. The end-goal of the project is the design of a novel architecture, CISIT (for ``Computing In Situ and In Transit''), that specifically aims to address acceleration of both computation and data movement in the context of hierarchical matrices. CISIT will uniquely combine traditional general-purpose CPU and GPU cores with: (1) acceleration of core algorithmic primitives using custom hardware; (2) in-situ computing capabilities that will comprise both processing in or near main memory as well as computing within on-chip caches and memory close to the cores; (3) novel in-transit compute capabilities that will enable cutting down on and in many cases completely eliminating unnecessary roundtrip data transfers by processing of data transparently as it is transferred between main memory and local compute cores across the cache hierarchies. Upon success, CISIT will influence future architectural implementations.  Along with the research activities, an educational and dissemination program will be designed to communicate the results of this work to both students and researchers, as well as a more general audience of computational and application scientists."
513057,A Renewed and Expanded Scholarship for Service Program at Mississippi State University,DUE,CYBERCORPS: SCHLAR FOR SER,8/1/2005,3/16/2010,Rayford Vaughn,"Vaughn, R","Vaughn, R|Dampier, D",MS,Mississippi State University,Standard Grant,Victor P. Piotrowski,7/31/2011,"$800,000.00 ",David Dampier,ray.vaughn@uah.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,EHR,1668,"9150, 9178, SMET",$0.00 ,normalFunding,"Mississippi State University (MSU), a 2001 NSA Center of Academic Excellence in Information Assurance Education (CAE/IAE) is administering a four-year Federal Cyber Service Scholarship for Service (SFS) program in collaboration with Jackson State University, a Historically Black College or University (HBCU) located within the State of Mississippi. MSU will also work with Tuskegee University to advance Tuskegee's IA program. The program is housed within the MSU College of Engineering by the Computer Science Department. The Department of Computer Science has a robust interdisciplinary information assurance research program, involving faculty from the areas of software engineering, artificial intelligence, and high performance computing (see http://www.cs.msstate.edu/~security). <br/><br/>Intellectual merit. The MSU SFS program offers a multiyear build-up of the SFS scholarship program designed to increase the number of graduates entering the federal information assurance (IA) workforce, while at the same time extending the IA course offerings outside the current Computer Science and Electrical and Computer Engineering student base to other departments and students across campus in the business school and social science disciplines. This expansion matches the evolution of the IA field and trains better prepared IA professionals.<br/><br/>Broader impact. The collaboration between MSU and JSU is enhancing the IA curriculum at JSU by making additional courses and IA faculty available to JSU students, and by providing an opportunity for JSU students to become SFS scholars. The collaboration is helping to increase the diversity of the federal IA workforce."
1152678,SBIR Phase II:  Commercial Development of An Intelligent Modular Robot Platform for Research and Education,IIP,SMALL BUSINESS PHASE II,4/1/2012,12/11/2014,Graham Ryland,"Ryland, G","Ryland, G",CA,"Barobo, Inc.",Standard Grant,Glenn H. Larsen,12/31/2014,"$796,678.00 ",,gryland@barobo.com,"813 Harbor Blvd, Suite 335",West Sacramento,CA,956912201,9167158840,ENG,5373,"115E, 116E, 1591, 165E, 169E, 5373, 7218, 8031, 8036, 9102, 9179, 9231, 9251",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project will study the feasibility for commercialization of an intelligent reconfigurable modular robot system called iMobot, which was originally developed at the University of California, Davis. Robotics has grown beyond automation to encompass systems that are self-reliant, reconfigurable, mobile, intelligent, and aware of their environment. iMobot has four degrees of freedom capable of full mobility and assembly into clusters. Because of its flexibility, modularity, and reconfigurability iMobot is an ideal platform for many research and teaching programs at colleges and universities. iMobot allows researchers to study artificial intelligence, swarm technology, robot collaboration, mobile networking, sensor fusion, gait simulation, and programming for re-configurability. Each module has am open architecture, with a processor capable of embedded Linux. Users can customize software and accessories for their specific needs.  Proposed product feasibility research includes adaptable connectivity between modules, intelligent plug-and-play sensors, a robust and lightweight chassis, along with re-configurability. In this proposed Phase II project, a professional design team will develop necessary technology related to assembling into clusters including mechanical design, electrical interface, sensors, algorithms, control and control software and customer interface.<br/><br/>The broader impact/commercial potential of this project is great. This proposed project will be one of the first attempts to scale up an intelligent reconfigurable modular robot for commercial deployment. The initial market for iMobot will be for university research and teaching. With a standardized hardware base using an open architecture users will be able to more widely share their work with each other, and create a valuable open educational resource. The future release of different iMobot versions will be for life-saving rescue and search operations in the first responder system, and for K-12 education. Robotics is an interdisciplinary field. The unique full mobility and reconfigurability of iMobot are very appealing. Modules can be used alone or in collaboration with others, making it a flexible and scalable educational tool. Because of the homogeneous nature of modular robotics, the cost of manufacturing is reduced through production of a large volume of similar parts. By introducing students to interesting robotic projects with affordable hardware platforms, which involve a variety of math, physics, information technology, and engineering principles, we can excite their imagination and give them confidence to pursue STEM careers, especially for underrepresented and economically disadvantaged groups."
325329,ITR: Knowledge-Enhanced Discovery System (KEDS): Incorporating Background Knowledge for Scientific Discovery,IIS,"ITR MEDIUM (GROUP) GRANTS, INFO INTEGRATION & INFORMATICS",9/15/2003,5/18/2011,Marie desJardins,"desJardins, M","desJardins, M|Wagstaff, K",MD,University of Maryland Baltimore County,Continuing grant,Sylvia J. Spengler,8/31/2012,"$795,640.00 ",Kiri Wagstaff,mariedj@cs.umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,CSE,"1687, 7364","1687, 9218, 9251, HPCC",$0.00 ,normalFunding,"The KEDS project is developing a toolkit for scientific discovery, which refers to the identification of new predictive models for a set of phenomena of interest from observational data about those phenomena. KEDS goes beyond existing methods by incorporating background knowledge (such as dependencies between variables, partial models, and information about the task for which the learned models will be used) into the learning process, and by providing analysis tools to aid the user in understanding, evaluating, and comparing the learned models.<br/><br/>KEDS provides a more flexible, interactive approach to scientific discovery than current tools. The interactive techniques in KEDS are also being applied to science education, supporting an iterative process in which students refine their mental models, based on personalized, targeted feedback from the system.<br/><br/>The impact of the project will be an advance in how information technology is used in scientific investigations and science education. In particular, KEDS will support a more interactive style of scientific discovery, which will allow human domain experts to integrate their previous knowledge into the discovery process more effectively. Expected results include improved interactive methods for scientific discovery and science education, data sets and benchmarks for interactive scientific discovery, and a documented software package. The KEDS system is currently being applied to astronomy science domains, but the underlying techniques have broad applicability to many other science domains, including earth sciences, biology and medicine, chemistry, and materials science."
1110970,SoCS: Studying the Computability of Emotions by Harnessing Massive Online Social Data,IIS,"Cyber-Human Systems (CHS), SOCIAL-COMPUTATIONAL SYSTEMS",8/1/2011,6/13/2017,Michelle Newman,"Newman, M","Newman, M|Li, J|Adams, R|Newman, M",PA,Pennsylvania State Univ University Park,Continuing grant,William Bainbridge,12/31/2017,"$784,821.00 ","Jia Li, Reginald Adams, Michelle Newman",mgn1@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,CSE,"7367, 7953","7367, 7953, 9251",$0.00 ,normalFunding,"The emergence of massive human-rated and commented visual data has opened avenues for exploring fundamental questions in artificial intelligence beyond the horizon.  This project tackles the challenge of automatically inferring visual aesthetics and emotions and inventing new systems that assist creative and decision-making activities of the general public.  An interdisciplinary team, with expertise in visual modeling, data mining, psychology, and computational sciences will build tools to distill information from a combination of visual, textual, and numerical data.  Visual features, selected based on published literature and consultation with domain experts, will be extracted for discriminating types of emotions.  The resulting systems can select and rank visual information based on aesthetics and emotions.<br/><br/>Intellectual Merits: This project will allow computer scientists to gain understanding of next-generation computerized visual aesthetics and emotion assessment systems.  The complex inter-relationship among content, context, and subjectivity in aesthetics and emotion assessment makes the corresponding learning problems especially challenging, which is likely to trigger innovation in machine learning and statistical modeling. Such capabilities will fundamentally change the way visual information is analyzed, processed, and managed.  The project will advance our understanding of the computability of emotions, and lead to new applications that can be used in a variety of settings.<br/><br/>Broader Impacts: The research will have a transformative impact in the fields of information retrieval, human-computer interaction, information processing, consumer electronics, and design. The technology can also be used to refine multimedia content that serves as education resources.  The project will disseminate research findings, generate new software implementations and collected datasets, and provide online services that can be used by researchers, educators, and industry. Education efforts include developing an interdisciplinary curriculum, training cross-disciplinary scientists, and involving underrepresented groups in research."
9720304,Learning and Intelligent Systems: An Integrated Approach to Concept Learning in Humans and Machines,BCS,LEARNING & INTELLIGENT SYSTEMS,10/1/1997,4/30/2001,Brian Ross,"Ross, B","Ross, B|Murphy, G|DeJong, G|Pitt, L|Rosengren, K",IL,University of Illinois at Urbana-Champaign,Standard Grant,Guy Van Orden,9/30/2002,"$775,000.00 ","Gregory Murphy, Gerald DeJong, Leonard Pitt, Karl Rosengren",bross@s.psych.uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,SBE,8888,"0000, 1180, 6856, 8888, OTHR",$0.00 ,normalFunding,"This project is being funded through the Learning and Intelligent Systems (LIS) Initiative.  Concepts are essential for intelligent thought and action. The goal of the project is an integrated view of concept learning in humans and machines. The primary focus will be combining psychological experimentation with artificial intelligence modeling to examine the interaction of world knowledge and empirical information during concept learning. The representation of concepts consists of feature regularities observed in the instances and of features inferred from world knowledge. However, current theories focus on only one type of feature and do not consider how learning each might affect the other. Additional work will examine how the use of concepts (such as those used for problem solving) may affect learning, how prior knowledge may be restructured to accommodate new information, and how concepts may change with age and experience. Computational learning theory will be adapted to provide a mathematical characterization of the learning process.  The view of concept learning that results from this work will be integrated in that it will (a) investigate and account for a wide variety of concept learning results that are often studied separately, and (b) pool the research strengths of psychology, artificial intelligence machine learning, and computational learning theory. The first goal will place greater constraints on theoretical accounts, suggest new possibilities, and help to decide among competing explanations. The second goal will lead to a theory that is psychologically and computationally plausible, yet sufficiently rigorous to be analyzed with the mathematical tools of computational learning theory. Such a theory will contribute to the generation of new knowledge by broadening the understanding of concept learning in each of the fields, and by promoting new research issues and approaches in each field through interdisciplinary work."
349630,SBIR Phase II:     Artificial Intelligence Software for Student Assessment in Chemistry Education,IIP,"RESEARCH ON LEARNING & EDUCATI, SMALL BUSINESS PHASE II, EDUCATIONAL RESEARCH INITIATIV, PROGRAM EVALUATION",2/1/2004,8/9/2006,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Ian M. Bennett,1/31/2007,"$770,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,"1666, 5373, 7180, 7261","7218, 9177, 9178, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research Phase II project builds Phase I work on development of meaningful interactive tutoring and assessment capabilities for chemistry education software.  Despite clearly articulated teacher and student demand for improvement, this area has been repeatedly identified as that where existing offerings are weakest.  Quantum Simulations proposes a new and different approach, adapting and incorporating new concepts from artificial intelligence (AI).  More than just assigning a grade, meaningful opportunities will be created for students to learn directly from the assessment itself.  The proposed technology will benefit all students; however, it is specifically targeted to help those who have the greatest need--such as students of average or marginal performance and students from historically underserved groups-- by lowering barriers to accessing high-quality science instructional software.  Quantum  Simulations has partnered with members of the Department of Education's STAR Schools program to further these goals.<br/><br/>Quantum Simulations' customers include textbook publishers, software providers, hardware vendors and distance learning companies.  A prominent textbook publisher, Holt, Rinehart and Winston, has entered into a long-term contract and has partnered with Quantum Simulations to commercialize this Phase II technology, resulting in rapid dissemination to an established end user base.<br/>"
519959,NetS-ProWiN: An Enabling Technology for Wireless Networks - The VT Cognitive Engine,CNS,Networking Technology and Syst,9/1/2005,9/30/2009,Charles Bostian,"Bostian, C","Bostian, C|Ball, S|Hsiao, M|MacKenzie, A",VA,Virginia Polytechnic Institute and State University,Continuing grant,Sajal Das,8/31/2010,"$766,250.00 ","Sheryl Ball, Michael Hsiao, Allen MacKenzie",bostian@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,CSE,7363,"7389, 9178, 9215, 9218, 9251, HPCC",$0.00 ,normalFunding,"This project develops the enabling technology for wireless networks consisting of intelligent nodes sharing a distributed knowledge base and capable of both individual and collective reasoning and learning.   The nodes are cognitive radios: intelligent machines that can determine the best way to operate in a given situation and configure themselves accordingly. Cognitive radios consist of a software defined radio (one that uses digital circuitry rather than analog components to generate, transmit, receive, and process radio frequency waveforms) and a cognitive engine, the brain that reads the radio's ""meters"" and turns the radio's ""knobs"" to obtain a desired outcome. Like living creatures, cognitive radios are aware of their surroundings, their own and their peers' capabilities, and the governing social constraints.  Their actions arise from a rational process that predicts probable consequences and remembers past successes and failures.<br/><br/>The project's approach to cognitive networking is based on a tiered system of modeling, learning, action, and feedback. It offers the first large scale tests of cognition in a well-defined network environment, providing quantitative answers to very practical questions like ""Can cognitive techniques allow Wi-Fi like services in locally unoccupied TV channels?"" Important research outcomes will include full implementation of a cognitive engine that can make any wireless network cognitive, an implementation of that engine for the widely available and low cost GNU Radio (a software defined radio developed for such experiments), and a quantitative assessment of the performance advantages of cognitive wireless networks.  <br/>"
1738291,SBIR Phase II:  Independent Science Learning through Serious Games with Expert Avatars and Complementary Stories,IIP,SMALL BUSINESS PHASE II,9/15/2017,5/10/2018,Peter Solomon,"Solomon, P","Solomon, P|Thompson, K",CT,THEBEAMER LLC,Standard Grant,Rajesh Mehta,8/31/2019,"$759,990.00 ",Kenneth Thompson,prsolomon@comcast.net,87 Church St,East Hartford,CT,61083720,8602125071,ENG,5373,"079E, 5373, 8031, 8032, 8039, 8240",$0.00 ,normalFunding,"This SBIR Phase II project will provide an engaging independent-learning platform which weaves science into an exciting story for ages eight to thirteen. The platform combines a time-travel adventure game, a complementary book, and in-game avatars for important scientists (like Albert Einstein) that can answer students' questions.  It is aimed at the need for educating more science and engineering professionals by tapping into children's strong interest in games to augment current science curricula that students often find boring and uninteresting. The story is about STARDUST (atoms) and its formation and history in the universe.  It engages students by taking them back in time to identify trillions of atoms they personally inherited from Einstein and the last T-Rex.  Besides school use, the game's independent learning and engagement allows distribution directly to children for recreational use, adding another avenue for science learning, and a sustainable business model for the Company through school and commercial sales.  The technology can also support independent learning in underperforming schools. The development of the scientist avatar artificial intelligence technology will have wide application for many other educational and training requirements.  <br/><br/>The innovation is a unique platform for independent learning about the sweeping science saga of atoms during the history of the Universe and Earth, and the connection of each student to that history through the trillions of atoms they inherited from prior beings like Albert Einstein and the last T-Rex.  The platform combines video games, a complementary fictional story book (based on the science) that acts as game introduction and player guide, and in-game avatars (like Albert Einstein and Henrietta Leavitt) that can provide verbal answers to students' spoken questions.  The artificial intelligence backing the scientist avatars includes learning manager software that guides student learning and provides assessments of progress in achieving pre-established learning goals. Four players cooperate in time travel adventures, exploring the human body, the Earth, and the Universe to find out what STARDUST is (atoms), how and when it was created (in the Big Bang and supernovae), how it got into Einstein, and from him to others (e.g., the carbon cycle). Excellent test results for the Phase I prototype game suggests a successful start at creating good player engagement. The project will continue to combine learning and engagement in 10 additional episodes with new scientist avatars including female and minority scientists."
1738441,SBIR Phase II:  Pushing the Boundaries of Intelligent Assistants for Financial Services,IIP,SMALL BUSINESS PHASE II,9/15/2017,9/18/2017,Michael Laurenzano,"Laurenzano, M","Laurenzano, M",MI,"Clinc, Inc",Standard Grant,Peter Atherton,8/31/2019,"$750,000.00 ",,mike@clinc.com,1940 Hedgenettle Ct.,Ann Arbor,MI,481039689,8582053027,ENG,5373,"5373, 8033",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project is in providing state-of-the-art tools allowing anyone to build and deploy domain specific commercial intelligent virtual assistant (IVA) solutions. These tools allow others to understand how IVAs should be architected and integrate IVA technology into their offerings. IVAs have shown promise in numerous commercial domains including financial services, healthcare, education, law enforcement, and retail, to name a few, reducing the barrier to knowledge access within domains by providing a medium for people to converse naturally with sophisticated computer and information systems.<br/><br/>This Small Business Innovation Research (SBIR) Phase II project will address the significant technological challenges involved when scaling the domains and capabilities of an Intelligent Virtual Assistant (IVA). This project will innovate in designing scalable artificial intelligence models capable of learning and identifying hundreds or thousands of learned concepts, and designing the accompanying system architecture to support the growing compute demand of sophisticated algorithms. Specifically, the project aims at achieving: (1) Scalable Intelligence: the ability to handle hundreds or thousands of competencies and extractable semantic concepts, allowing users to interact with the system with unbounded, unconstrained language; (2) Customizable Intelligence: the ability to allow customers to (semi-) automatically train and (re)train and customize the intelligence on demand (adding new competencies, identifying new slot-value pairs, modify responses); (3) Conversational Complexity: support multi-turn conversations, where the context from prior utterances is used to refine and understand what the end-user is trying to accomplish; and (4) Scalable System Infrastructure: enhance open source IVA software infrastructure to seamlessly scale up and down the computational resources allocated for each intelligence engine based on load."
1111047,Using Gaze Cues to Build Partner Models for Collaborative Behavior,IIS,SOCIAL-COMPUTATIONAL SYSTEMS,8/1/2011,7/26/2012,Gregory Zelinsky,"Zelinsky, G","Zelinsky, G|Brennan, S|Samaras, D",NY,SUNY at Stony Brook,Continuing grant,William Bainbridge,7/31/2015,"$749,999.00 ","Susan Brennan, Dimitrios Samaras",gregory.zelinsky@stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,CSE,7953,7953,$0.00 ,normalFunding,"The ability to interact remotely over the Internet is redefining the nature of collaboration.  Many collaborative activities require coordinating attention and action with another person moment-by-moment; without the benefit of being physically present with another person these sorts of collaborations are difficult to conduct efficiently.  This project explores using human eye gaze to create partner models for mediating time-critical collaborative activities.  A partner model is a dynamically learned description of what a partner is trying to do - for example, what someone may be looking for, or what they consider to be relevant within a task. <br/><br/>Intellectual Merit: Many tasks and events are implicit or poorly defined, requiring that partner models be learned from evidence unfolding as part of a person's ongoing behavior.  Eye trackers will be used to determine the task-relevant objects that a person chooses to look at (and not look at); through analysis of these gaze patterns and the properties of the objects, human and computer partners will learn a model of what this person is attempting to do.  Various tasks will be explored, such as searching for a new and/or ambiguous moving target specified only by incomplete semantic descriptions, or monitoring a complex dynamic environment for unusual events, defined by atypical target movements and relationships between people and objects.  The findings will advance the fields of human-computer interaction, psycholinguistics, artificial intelligence, object and event detection by humans and computers, and multimodal human communication.<br/><br/>Broader Impacts:  The results of the project will facilitate the development of new tools that can help people with their tasks, by, for example, finding and highlighting objects in a scene that match the viewer's goals and helping the viewer track moving targets.  The results will also lead to new tools for remote collaboration, with the goal being to make coordination at a distance as efficient as face-to-face interaction.  The tools and techniques from the project are expected to benefit a variety of applications, including the development of assistive technologies for people with communication impairments and the creation of better security screening procedures.  The project will provide training and research experiences for Stony Brook University's racially, ethnically, and economically diverse students, including women and others underrepresented in science and engineering."
826701,"Thinking About, and Interacting with Living and Mechanical Agents",BCS,HSD - DYNAMICS OF HUMAN BEHAVI,9/15/2008,9/10/2008,Daniel Levin,"Levin, D","Levin, D|Adams, J|Biswas, G|Saylor, M",TN,Vanderbilt University,Standard Grant,Amber L. Story,2/28/2014,"$749,991.00 ","Julie Adams, Gautam Biswas, Megan Saylor",daniel.t.levin@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,SBE,7319,"0000, OTHR",$0.00 ,normalFunding,"Recent advances in artificial intelligence and robotics are confronting individuals of all ages with a series of category-defying entities that combine features of living and nonliving things. As such, these entities increasingly challenge people's basic understanding of mind and intelligence. The goal in this project is to explore adults' and children's beliefs about a range of living and mechanical agents, and to test how these beliefs affect people's ability to track, remember, and understand mechanical agents in two specific computer interfaces.  First, it will explore a computer interface designed to allow a human operator to interact with and control a set of semi-autonomous robots.  The second environment will be a teachable agent system in which middle school children learn about complex science phenomena, such as river ecosystems, by actively teaching an animated software agent.<br/><br/>This project represents one of the few research programs to empirically test people's understanding of living and artificial agents, and it will employ a conceptual framework that starts with na???ve understandings of mind (e.g. ""Theory of Mind"") and applies them to engineered environments where these understandings are used. This framework describes the conditions under which participants apply different agent concepts, and can help understand how these beliefs might change over time as people interact with novel agents. Although the framework is not yet a complete theory, it represents a broadened approach to reasoning about both typical and novel living and mechanical agents that goes beyond existing dual-process models of Theory of Mind. These experiments also make links between concepts about agents, and the deployment of these concepts in realistic high-load perceptual tasks, so they can make an important contribution to our basic understanding of how knowledge affects vision.<br/><br/>The findings from this project may have important implications for educating both children and adults to deal with novel intelligent decision making technologies that move beyond the simple command-and-response cycle inherent to most current computer applications. Previous research by the PIs has already documented ways in which different people vary in their approach to these technologies (e.g. older and younger adults seem to have subtly different beliefs about the nature of computer intelligence), so this project may help improve the accessibility of novel agent-technologies to a wide range of different populations. More generally, because this research uses interactive educational tools and realistic robot-command systems to explore agent-understanding, it has the potential to improve user interfaces supporting social learning environments that focus on self-regulated learning, and that facilitate the effectiveness of human-machine emergency response teams. These technologies confront users with challenges to their most basic understandings of intelligence and thinking, and our research has the potential to guide both children and adults as they become successful users and creators of the interactive technologies of the future.<br/>"
449743,CAREER: Model-Based fMRI of Human Object Recognition,BCS,COGNEURO,7/1/2005,6/2/2009,Maximilian Riesenhuber,"Riesenhuber, M","Riesenhuber, M",DC,Georgetown University,Continuing grant,Peter M. Vishton,6/30/2011,"$742,316.00 ",,mr287@georgetown.edu,37th & O St N W,Washington,DC,200571789,2026250100,SBE,1699,"0000, 1045, 1187, OTHR",$0.00 ,normalFunding,"Object recognition is a fundamental cognitive task that is performed effortlessly countless times every day, such as when gauging a conversation partner's facial expression, looking for a friend's face in a crowd, or reading the words of this abstract. All these tasks depend on the visual system's ability to recognize specific objects, despite significant variations in their appearance due to changes in lighting, position, viewpoint, or the simultaneous presence of other objects. Importantly, the visual system is not hard-wired but can be trained for specific tasks, e.g., detecting terrorist camps in satellite images or tumors in X-ray films. Despite the apparent ease with which we see, visual recognition is widely acknowledged to be a very difficult computational problem. From a biological systems perspective, visual recognition involves several levels of understanding, from the computational level, to the levels of cellular and biophysical mechanisms and the level of neuronal circuits, up to the level of behavior. Computational approaches to visual recognition are becoming increasingly important to integrate data from different experiments and levels of description (such as electrophysiology, brain imaging, and behavior) into one coherent, quantitative framework that can then be used to provide rigorous hypotheses for further experiments. With a CAREER award from the National Science Foundation, Dr. Maximilian Riesenhuber is continuing his work on a computational model of object recognition in cortex. He is applying this model to study how visual experience and training on specific tasks shape the brain's representation of the external world and its object recognition capabilities, and how the visual system can successfully recognize objects, even in the presence of interfering stimuli. In particular, the model is being used to provide detailed hypotheses on how training on specific object recognition tasks (ranging from the discrimination of novel stimuli to categorization and object recognition in visual clutter) can modify processing at different levels of the visual system, and how these changes are related to improvements in behavioral performance. This leads to a set of hypotheses that are to be tested with human volunteers in a series of behavioral and brain imaging experiment, using the same stimuli and tasks as in the simulations. Importantly, simulations and experiments are tightly integrated so that experimental results from simpler tasks can be used to refine the model, which can then be used to provide more specific hypotheses for more complex tasks.<br/>The results of this research will be relevant for the design of machine vision systems in artificial intelligence that better mimic how humans see, for the development of human-machine interfaces that optimally leverage the brain's ability to process visual information, and for applications involving human training on object recognition tasks ranging from baggage screening to satellite image analysis. Understanding the neural circuitry involved in object recognition in the typical brain is also important for understanding and ultimately treating object recognition deficits in neural disorders such as autism, schizophrenia, and dyslexia. A key element of the CAREER award is Dr. Riesenhuber's plan to use the same computational model that forms the basis of the research effort as an educational tool by developing a model-based curriculum in integrative cognitive neuroscience. <br/>"
1561655,Collaborative Research: Big Data from Small Groups: Learning Analytics and Adaptive Support in Game-based Collaborative Learning,DRL,Core R&D Programs,10/1/2016,8/24/2017,James Lester,"Lester, J","Lester, J",NC,North Carolina State University,Continuing grant,John Cherniavsky,9/30/2021,"$739,564.00 ",,lester@csc.ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,EHR,7980,8244,$0.00 ,normalFunding,"This is a research project supporting a new model of Computer Supported Collaborative Learning (CSCL) that combines the advantages of game based learning with problem based learning. Good game based learning environments combine rich scenarios with engaging activities to serendipitously provide student learning. These learning environments also provide an opportunity for players to collaborate in reaching their game goals. Good problem based learning environments provide support for the solution of complex and ill-structured problems. The combination of these two types of learning environments promise to provide the engagement and richness of game based learning with the support environment to engage students in authentic science. Both of these environments are computer based so the actions and interactions of the students and teachers are captured for analysis. Applying learning analytics to the captured data provides information on student learning for the teacher, provides learning information to the student for self-reflection and improved learning, and provides information for the system designer to improve the effectiveness of the new CSCL environment.<br/><br/>The scientific problem domain is environmental science for middle school students. The CSCL environment is a  game based learning environment that incorporates problem based learning. The interaction between the CSCL environment and the student is enhanced by the collection of data on the student based on cognitive, affective, and metacognitive states that are inferred using artificial intelligence technologies. Specific strategies are employed to help students construct explanagions, reason effectively, and become self-directed learners. Key outcomes of the project include a model of collaborative scaffolding for game based learning that is usable in classrooms to help students learn STEM content and learning analytics designed to support the teacher in the roles of guide and collaborator. A goal of the project is wide dissemination of the CSCL system."
416128,Tracking Multimodal Communication in Humans and Agents,IIS,"ADVANCED LEARNING TECHNOLOGIES, EDUCATIONAL RESEARCH INITIATIV, HUMAN LANGUAGE & COMMUNICATION, ROBUST INTELLIGENCE",9/1/2004,6/10/2008,Max Louwerse,"Louwerse, M","Louwerse, M|Steedman, M|Hu, X|Bard, E|Graesser, A",TN,University of Memphis,Standard Grant,Kenneth C. Whang,8/31/2008,"$735,949.00 ","Mark Steedman, Xiangen Hu, Ellen Bard, Arthur Graesser",mlouwers@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,"1707, 7180, 7274, 7495","9150, 9178, 9215, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"TRACKING MULTIMODAL COMMUNICATION IN HUMANS AND AGENTS<br/><br/>This project investigates multimodal communication in humans and agents, focusing on two linguistic modalities - prosody and dialog structure, which reflect major communicative events, and three non-linguistic modalities -  eye gaze, facial expressions, and body posture. It aims to determine<br/>1. which of the non-linguistic modalities align with events marked by prosody and dialogue structure, and with one another;<br/>2. whether, and if so when, these modalities are observed by the interlocutor;<br/>3. whether the correct use of these channels actually aids the interlocutor's comprehension.<br/>Answers to these questions should provide a better understanding of the use of communicative resources in discourse and can subsequently aid the development of more effective animated conversational agents.<br/><br/>The outcomes of our observations will be modeled on controlled elicited dialog. To assure robust information on the interplay of modalities, we control the base conditions, genre, topic, and goals of unscripted dialogs. An ideal task for this is the Map Task, where dialog participants work together to reproduce on one player's map a route preprinted on the other's.  The two maps, however, are slightly different, so that each player holds information important to the other. This scenario triggers a highly interactive, incremental and multimodal conversation.<br/><br/>In the proposed project a basic corpus of Map Task dialogues will be collected while recording spoken language, posture, facial expressions, and eye gaze. Hand gestures, discouraged by the task, will be recorded where they occur. These findings will be used in the Behavior Expression Animation Toolkit (BEAT) in order to augment the current intelligent system AutoTutor. AutoTutor has been developed for a broad range of tutoring environments that coach the student in following an expected set of descriptions or explanations.  The coach-follower roles in the Map Task scenario make it possible to easily change the scenario for AutoTutor. In a series of usability experiments interactions of dialog participants with AutoTutor will be recorded. These experiments allow us to record not only the participant's impressions, but also his or her efficiency (the time to complete map, latency to find named objects, deviation of the instruction follower's drawn route from the instruction giver's model), and communicative behavior (discourse structure, gaze, facial expressions, etc.).<br/><br/>The research resulting from this project will benefit a large variety of fields, including cognitive science, computational linguistics, artificial intelligence, and computer science. In addition, the integration of the modalities into a working model will advance the development and use of intelligent conversational systems. <br/><br/>"
1534190,SBIR Phase II:  Assistive Digital Vision for the Blind,IIP,SMALL BUSINESS PHASE II,9/15/2015,9/14/2015,Arman Ghodousi,"Ghodousi, A","Ghodousi, A",VA,Ghodousi LLC,Standard Grant,Muralidharan S. Nair,8/31/2017,"$730,331.00 ",,arman@g-technologygroup.com,5702 General Washington DR.,Alexandria,VA,223120000,4805443192,ENG,5373,"5373, 6840, 8035, 9139, HPCC",$0.00 ,normalFunding,"The broader impact/commercial potential of this project is to address the unmet needs of blind and visually impaired population in order to increased their mobility independence with the aid of an intelligent wearable electronic device, compatible with the white cane, in a simple and cost-effective manner. The outcome of this project will contribute to scientific and technological understanding of environmental sensing and process automation by developing an integrated system comprised of sensors and underlying algorithms capable of gathering, processing, and interpreting environmental data and communicating relevant information to the user. The envisioned product can potentially meet the needs of 2.1% of the U.S. population who are considered legally blind, as well as make further contribution to the field of robotics, artificial intelligence, and other assistive technologies wherein a better understanding of the environment is desired.          <br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project seeks to create a state of the art wearable device for the visually impaired that will enhance their situational awareness through the use of multiple sensors and intelligent algorithms. The main research objective is to develop an intelligent  wearable device that will provide ability to detect above ground obstacles and recognize various categories of objects. In spite of significant technological breakthroughs, leading to many product innovations, there is very little technological progress for the visually impaired despite increased population longevity and significant demand for products that promote independent living. The proposed project will address the needs of the visually impaired in an intuitive and automated manner."
968566,SoCS:  Creation of a Framework for Computational Gaming,SES,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CCF, SOCIAL-COMPUTATIONAL SYSTEMS",10/1/2010,6/16/2011,Anind Dey,"Dey, A","Dey, A",PA,Carnegie-Mellon University,Standard Grant,Frederick M Kronz,9/30/2014,"$721,000.00 ",,anind@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,SBE,"1640, 2878, 7953","7953, 9178, 9215, 9251, SMET",$0.00 ,normalFunding,"Leveraging crowdsourcing to collect data is becoming more common. Human Computation, in particular, has looked at how to use artificial intelligence on data collected from people playing games, to validate that useful data has been collected on a very large scale. This work will investigate a new form of artificial-intelligence based crowdsourced games called Computational Gaming, in which questions will be posed without knowing what the answers are beforehand. Questions that require human judgment will be posed in the context of a game, and machine learning will be used to determine what questions to pose to which players and how to determine whether the responses are valid.<br/><br/>Intellectual Merit. This project will demonstrate the validity of Computational Gaming through two examples in text and image labeling, delineating a set of guiding design principles for building and evaluating future Computational Gaming designs, and producing a toolkit that supports and encourages the use of these design principles for building Computational Gaming systems.<br/><br/>Potential Broader Impacts. The project will create, both more quickly and more cheaply, databases of human-labeled data; it will also do so for a wider variety of problems than currently exists. The framework and toolkit for Computational Gaming will be valuable for game designers, for researchers in many domains that need labeled data, and for the users for whom the research is being conducted."
856058,Major: Computational Creativity: Building a Model of Machine Generated Humor,IIS,CreativeIT,6/1/2009,6/8/2009,Kristian Hammond,"Hammond, K","Hammond, K|Birnbaum, L",IL,Northwestern University,Standard Grant,Ephraim P. Glinert,5/31/2013,"$712,883.00 ",Larry Birnbaum,hammond@cs.northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7788,"6890, 7655, 9215, HPCC","$712,883.00 ",normalFunding,"""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).""<br/><br/>Computational creativity has been a goal of artificial intelligence since nearly its inception.  But while many interesting models have been developed, and some of these have even produced interesting creative works, most have been built on foundations that either don't scale, or don't easily scope across different domains, or both.  In this project the PI will explore an alternative in which creativity, and in particular humor, is modeled as a layered system of intelligent control, using case-based reasoning, of simple retrieval and filtering mechanisms.  Specifically, this is an effort, in the realm of believable comedy agents, in which the issues of control and breadth are decoupled and handled by two very different sorts of systems.  For control, the PI will use a variant of case-based planning to provide task-level guidance to content acquisition, evaluation, transformation, combination, and presentation; for breadth, he will employ lexical technologies from information retrieval that will be used to mine online resources spanning a wide variety of domains.  The PI's goal is to provide a model of creativity and humor that works in much the same way that a professional comedy writer or improvisational performer does.  These professionals ""mine"" their memories for experiences, but they do not merely ""free associate.""  Instead, they employ a set of conventions or techniques that can be applied and scoped across any domain to produce a specific comedic effect.  Modeling human skill in this way will result in a robust and scalable system that is able to provide breadth of coverage (through well understood and scalable information retrieval techniques), without sacrificing the power of control provided by the reasoning system.  In effect, it will be funny no matter what it is talking about.  This research will improve our understanding of creative processes through an examination of machine-generated content, and the creation of new content and content forms derived from existing resources.  It will also support the development of new technologies to support human creativity, in that the resulting models and systems will enable high-level authoring of new kinds of interactive ""information"" experiences.<br/><br/>Broader Impacts:  The PI expects that at least two broad societal impacts will derive from this work.  First, he will actually create intelligent comedic performance agents and deploy them both on- and off-line for the enjoyment and illumination of everyday citizens.  Second, this research will attract, develop, and produce an equally new type of AI researcher whose vision of the mind scopes beyond the confines of a single machine.  In particular, the goal is to attract a broader set of students (including the underrepresented group of women in engineering) from communications studies and theater, who want to do research on the machine as a device for communication and creative expression made possible and supported by the mediation of intelligent systems.  The PI believes this is a crucial step in the development of AI as a field, drawing in a next generation of creative and innovative thinkers who will be able to bring new light into the world of semantics and inference while building artifacts with artistic power."
1724101,S&AS: FND: Reliable Semi-Autonomy with Diminishing Reliance on Humans,IIS,"S&AS - Smart & Autonomous Syst, ROBUST INTELLIGENCE",9/1/2017,5/29/2018,Shlomo Zilberstein,"Zilberstein, S","Zilberstein, S|Biswas, J",MA,University of Massachusetts Amherst,Standard Grant,Irene Sattler,8/31/2020,"$707,512.00 ",Joydeep Biswas,shlomo@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"039Y, 7495","046Z, 9251",$0.00 ,normalFunding,"Building reliable autonomous systems that can construct and execute plans to achieve some assigned goals, without human intervention, has been the hallmark of artificial intelligence and robotics since their inception.  Reliable autonomy is becoming increasingly important as it enables innovative new applications in areas such as transportation, health, and sustainable living.  Despite substantial progress, there are still considerable barriers to the long-term, large scale deployment of fully autonomous systems such as self-driving cars or mobile service robots.  These barriers range from technological and economic constraints to ethical and legal issues.  This project offers a comprehensive approach to circumvent these barriers by building semi-autonomous systems that rely on rich forms of human assistance, ranging from advice to constant supervision of the system with the possibility of taking over control.  The project develops techniques to assure the safety of such systems when human assistance is delayed and to reduce their reliance on human assistance over time.  Additionally, the project contributes to training of undergraduate and graduate students in this interdisciplinary area, mentoring of students with special attention to underrepresented groups, outreach activities to local schools, and strengthening of industrial collaborations.<br/><br/>The project answers fundamental questions about the feasibility, efficiency, and scalability of planning and learning algorithms to support semi-autonomous systems.  The main thrusts of the project are (1) develop techniques that can delegate autonomy to a system with some restrictions, and provide strong guarantees that these restrictions will be respected and that the system will maintain a safe state even when human assistance is delayed; (2) develop planning and learning algorithms that are cognizant of the availability of rich forms of human assistance and can effectively factor such assistive actions into the overall plan; (3) handle the high computational complexity of optimizing the interaction with humans under uncertainty and partial observability by creating a hierarchical multi-objective decision model; and (4) leverage human assistance to enable robust and accurate mapping and navigation in new areas, while reducing the reliance on human supervision over time.  The project evaluates these capabilities in complex realistic settings involving a campus-scale robot deployment, a driving simulator, and autonomous vehicles in collaboration with Nissan."
1514253,RI: Medium: Sentential Decision Diagrams,IIS,"ROBUST INTELLIGENCE, Unallocated Program Costs",7/1/2015,5/15/2018,Adnan Darwiche,"Darwiche, A","Darwiche, A",CA,University of California-Los Angeles,Continuing grant,James Donlon,6/30/2019,"$705,865.00 ",,darwiche@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,"7495, 9199","7495, 7924, 9251",$0.00 ,normalFunding,"Logical and probabilistic reasoning are now routinely used in various fields of computer science and engineering, including artificial intelligence in particular. These modes of reasoning currently underlie systems that perform automated diagnosis, planning, software and hardware verification, web information extraction, bioinformatics, vision and robotics. This project aims at advancing the state of the art in logical and probabilistic reasoning, to allow scientists and engineers to learn and reason with much larger models than is currently possible. The project is based on a particular computational paradigm, known as knowledge compilation, which transforms knowledge into forms that facilitate their efficient processing by reasoning and learning algorithms. The results expected from this project will provide domain-independent, highly scalable, tools and techniques for addressing computational problems that arise in healthcare, industrial automation, and information management. The project will also provide a context for training graduate students in the computational paradigm of knowledge compilation, and will target the integration of this paradigm into computer science curricula.<br/><br/>More specifically, the project aims to develop a new framework for knowledge compilation based on the recently discovered Sentential Decision Diagram (SDD). The SDD is a target compilation language, which generalizes the Ordered Binary Decision Diagram (OBDD) that has been quite influential in many areas of computer science and engineering. This project has two parts. The first part is concerned with developing the SDD compilation language further, both theoretically and practically. On the theoretical side, there is a number of pending of questions relating to lower and upper bounds on SDDs, in addition to questions that must be answered to fully understand their relation to OBDDs. On the practical side, the SDD package needs to be extended to enhance its scalability and to provide new functionality that is needed for fully exploiting SDDs in a wider spectrum of applications. The second part of the project is concerned with a more recent discovery: The probabilistic SDD (PSDD). This compilation language aims at inducing probability distributions over propositional theories, in a very principled and efficient manner. Our objective here is to develop PSDDs into a mature tool, with a corresponding public package, for learning tractable probabilistic models under massive logical constraints, and for compiling probabilistic graphical models into PSDDs for the purpose of more scalable probabilistic reasoning.<br/>"
1561486,Collaborative Research:  Big Data from Small Groups: Learning Analytics and Adaptive Support in Game-based Collaborative Learning,DUE,Core R&D Programs,10/1/2016,9/13/2017,Cindy Hmelo-Silver,"Hmelo-Silver, C","Hmelo-Silver, C|Glazewski, K",IN,Indiana University,Continuing grant,John Cherniavsky,9/30/2021,"$700,560.00 ",Krista Glazewski,chmelosi@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,EHR,7980,8244,$0.00 ,normalFunding,"This is a research project supporting a new model of Computer Supported Collaborative Learning (CSCL) that combines the advantages of game based learning with problem based learning. Good game based learning environments combine rich scenarios with engaging activities to serendipitously provide student learning. These learning environments also provide an opportunity for players to collaborate in reaching their game goals. Good problem based learning environments provide support for the solution of complex and ill-structured problems. The combination of these two types of learning environments promises to provide the engagement and richness of game based learning with the support environment to engage students in authentic science. Both of these environments are computer based so the actions and interactions of the students and teachers are captured for analysis. Applying learning analytics to the captured data provides information on student learning for the teacher, provides learning information to the student for self-reflection and improved learning, and provides information for the system designer to improve the effectiveness of the new CSCL environment.<br/><br/>The scientific problem domain is environmental science for middle school students. The CSCL environment is a  game based learning environment that incorporates problem based learning. The interaction between the CSCL environment and the student is enhanced by the collection of data on the student based on cognitive, affective, and metacognitive states that are inferred using artificial intelligence technologies. Specific strategies are employed to help students construct explanagions, reason effectively, and become self-directed learners. Key outcomes of the project include a model of collaborative scaffolding for game based learning that is usable in classrooms to help students learn STEM content and learning analytics designed to support the teacher in the roles of guide and collaborator. A goal of the project is wide dissemination of the CSCL system."
226344,An Active Object-Based Digital Library for Microeconomics Education,DUE,NATIONAL SMETE DIGITAL LIBRARY,10/1/2002,9/23/2002,James Cox,"Cox, J","Cox, J|Chen, H|Zeng, D|Austin, J|Swarthout, J",AZ,University of Arizona,Standard Grant,Myles G. Boylan,4/30/2005,"$699,996.00 ","Hsinchun Chen, Daniel Zeng, James Austin, James Swarthout",jccox@gsu.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,EHR,7444,"7444, 9178, SMET",$0.00 ,normalFunding,"Students from a variety of disciplines take Microeconomics courses to learn how various types of markets function and how enterprises and consumers make buying and selling decisions in these markets. As such, Microeconomics education plays an important role in preparing future business leaders and practitioners and serves as part of general business and social sciences training for students in other fields of study. Currently, Microeconomics courses are typically taught in a traditional lecture format. Recent developments in economic theory and electronic commerce, however, call for significant innovations in course content design and delivery. An emerging trend is to allow the students to actively participate in economic decision-making through various market institutions, including recently emerging Internet-based online market institutions, to gain hands-on experience and acquire economic insights. Constructivist learning theory supports this educational approach.  It promises to revolutionize the way in which Microeconomics courses will be taught in this new Millennium. Although several efforts have been initiated to create online Microeconomics contents, including experimentation tools and software, they have been developed in a system development and content collection paradigm that is closed and therefore cannot scale. In this project we are creating a Digital Library (DL)-based, open approach to deal with the challenges of developing an extensible and scalable collection of Microeconomics related contents. <br/>(a) From the perspective of the application domain, i.e., Microeconomics, we are making contributions in creating new types of digital contents, including simulated IT-enhanced market institutions and intelligent trading systems implemented as software agents. These agents are emerging as part of the IT-enhanced electronic market institutions that have the potential of greatly reducing economic transaction costs and improving the quality of economic decision-making. <br/>(b) From the viewpoint of the National STEM Digital Library, we are creating an Open Archives Initiative (OAI)-compliant collection of Microeconomics education contents that incorporates experimental software and automated e-commerce agents. A major DL research task that we are undertaking is the development of a metadata representation of active objects such as software modules (e.g., economics experimental software). This research has the potential of being applied in other DL collections involving software and simulation environments. <br/>(c) From the educational viewpoint, we are developing new integrated Microeconomics curricula leveraging the developed active objected-based DL. We are studying the impact of these new curricula, and investigating related changes in course management and teaching methodologies. We are combining research, teaching, and evaluation expertise and resources from several academic departments and labs at the University of Arizona. Four key contributing entities are: (1) the Economic Science Lab, a premier institution on experimental economics methodology and applications, (2) the Artificial Intelligence Lab, a leading institution on DL, Internet computing, and software agents, (3) the Hoffman E- Commerce Lab, an instructional and research facility focusing on e-commerce teaching and research, and (4) the University Faculty Center for Instructional Innovation, a teaching evaluation facility with emphasis on the impact of IT on education. <br/>"
1738375,SBIR Phase II:  Mobile Manipulation Hospital Service Robots,IIP,SMALL BUSINESS PHASE II,9/15/2017,9/6/2018,Andrea Thomaz,"Thomaz, A","Thomaz, A",TX,"Diligent Droids, LLC",Standard Grant,Nancy Kamei,2/29/2020,"$699,985.00 ",,athomaz@diligentdroids.com,2418 Spring Ln PO Box 5017,Austin,TX,787034480,6177847154,ENG,5373,"169E, 5373, 8018, 8042",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project on hospital service robots is improving the quality of care in hospital systems that are under increased pressure to provide high-quality patient-centric care while functioning as profitable businesses. Hospitals face a shortage of qualified nurses and high rates of nurse turnover. Nurses play a critical role in communicating care plans, educating patients, and guarding against medical errors. The amount of time they spend in direct care activities is a key determinant of patient satisfaction, better patient outcomes, fewer errors, and shorter lengths of stay. In the face of nursing shortages across the U.S., it is increasingly important to have nurses performing at the 'top of their license'. Reducing the amount of time they spend on non-nursing tasks is crucial to this goal. Automation could address these challenges and labor shortage by allowing clinical staff to focus on providing skilled care. The proposed project aims to develop technology that is general-purpose enough to transfer to other markets, such as long term care facilities and, eventually, individual consumers. Robots that perform assistive tasks in homes could increase the feasibility of independent living for many older adults.<br/><br/><br/>The proposed project will establish the technical and commercial feasibility of developing hospital service robots that act as assistants on acute care units, enabling nurses to spend more time at the bedside with patients. This project will make technical advances along three dimensions: the ability of the proposed robot to autonomously navigate within nursing units and across the hospital (navigation capabilities); to easily adapt its manipulation skills to specific tasks and to physical characteristics of a particular hospital/unit (adaptive learning of manipulation skills); and to work alongside humans in a socially acceptable manner, including appropriate navigation in crowded hallways, speech, and eye gaze behaviors that communicate the robot's intentions (socially intelligent interoperability). The team intends to collaborate closely with a single partner hospital to iteratively improve the reliability and robustness of the artificial intelligence software suite developed with NSF funding and to deploy production-quality versions of the three core competencies. The final 6 months will involve a long-term deployment, with the robot autonomously working on an acute care unit of the partner hospital. The impact of the robot on unit staff and workflows will be documented, with the ultimate goal of developing a service robot that hospital staff view as a competent member of the care team."
224465,CISE Research Resources: QPQ: An Open Source Deductive Software Repository,CNS,CISE RESEARCH RESOURCES,10/1/2002,3/8/2004,Natarajan Shankar,"Shankar, N","Shankar, N|Stickel, M",CA,SRI International,Continuing grant,Rita V. Rodriguez,9/30/2006,"$699,980.00 ",Mark Stickel,shankar@csl.sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,CSE,2890,"9218, HPCC",$0.00 ,normalFunding,"EIA 0224465<br/>Shankar, Natarajan<br/>Stickel, Mark E.<br/>SRI International <br/><br/>Title: CISE RR: QPQ: An Open Source Deductive Software Repository <br/><br/>This project, establishing a deductive software repository, aims at making software more available, reliable, durable, higher quality, uniform. Deductive software consists of symbolic routines for logical manipulations including decision procedures, solvers, rewriters, model checkers, and theorem provers. It serves as the semantic foundation for many scientific and engineering applications in areas such as hardware and software verification, program synthesis and analysis, data- and knowledge-based systems, artificial intelligence, linguistics, and e-commerce. This work outlines an initiative for deductive software components called QPQ (""quid pro quo"") as a marketplace for publishing, exchanging, and refining deductive software components. The refereed publication and distribution of such scientific software components in open source often yields higher quality, greater visibility, and accelerated productivity. Efficient implementation of deductive algorithms, an extremely complex and delicate task, requires serious investment in basic infrastructure such as concrete and abstract syntax, syntactic tools (parsers, typecheckers, pretty-printer), primitive operations (substitution, matching, unification, normalization), and advanced operations (constraint satisfaction, forward and backward chaining, rewriting, simplification, decision procedures, induction methods). Potential impacts include availability, reliability, quality, durability, productivity, visibility, uniformity, synergy, serendipity, and history. The following principles will be employed in running the repository: authenticity, uniqueness, access, relevance, format, quality and version control, and academic credit. QPQ is already recognized as a valuable resource for research and education in deductive software. With its role in facilitating the semantic web and through other applications of logico-symbolic computing, the QPQ repository might become crucial to society."
1726377,MRI: Development of Monitors for Alaskan and Canadian Auroral Weather in Space (MACAWS),AGS,MAJOR RESEARCH INSTRUMENTATION,9/15/2017,9/1/2017,Anthea Coster,"Coster, A","Coster, A",MA,Northeast Radio Observatory Corp,Standard Grant,S. Irfan Azeem,8/31/2020,"$698,287.00 ",,acoster@haystack.mit.edu,77 Massachusetts Ave,Cambridge,MA,21394307,6172531975,GEO,1189,"1189, 1521, 4444",$0.00 ,normalFunding,"This Major Research Instrumentation development award is for the creation of a network of ground-based receivers that can use satellite navigation signals to provide crucial information about the Earth's ionosphere.  This network will include 35 sites in Alaska and Canada, bringing additional measurements to a data-sparse region.  The development activities also include making the system dynamic, adaptable, and autonomous.  Improving the amount and quality of data will help to answer many questions about the basic ionospheric processes, which could lead to improvements in the robustness of satellite navigation systems.  Many of the receivers will also be placed at schools, providing an educational benefit to the students.<br/><br/>The goal of this development award is to provide a ground-based sensor web network that provides both real-time and historical Global Navigation Satellite Systems (GNSS) ionospheric data products for use in geospace science and space weather monitoring in currently unsampled or under-sampled auroral/polar regions in North America.  A sensor web is a dynamic, adaptable, and autonomous network of sensors that can use artificial intelligence to react in real time to information from its instruments.  Thirty-five GNSS receivers will be deployed in Alaska and Canada to retrieve Total Electron Content (TEC) and scintillation statistics.  The project will result in the creation of a unified North American TEC map, development and deployment of triggering algorithms for highly dynamic periods, and the distribution of real-time TEC data to users.  Four specific scientific topics would be addressed: 1) What mechanism is responsible for the formation of polar cap patches?  And how do polar cap patches exit the night-side polar cap?  What is the relationship of the tongue of ionization to polar cap patches? 2) What contribution does the lower atmosphere make to variability in the high-latitude ionosphere? 3) What causes the irregularities that form at the front of the tongue of ionization in the nightside polar ionosphere?  What causes the irregularities that form with the SED plume as observed by SuperDarn? 4) What are the specific auroral and sub-auroral mechanisms that produce GPS scintillations?"
1002748,MAJOR:  Assistive Artificial Intelligence to Support Creative Filmmaking in Computer Animation,IIS,"Cyber-Human Systems (CHS), CreativeIT",9/1/2010,8/31/2010,Mark Riedl,"Riedl, M","Riedl, M|Nitsche, M",GA,Georgia Tech Research Corporation,Standard Grant,William Bainbridge,8/31/2014,"$695,485.00 ",Michael Nitsche,riedl@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,"7367, 7788",7788,$0.00 ,normalFunding,"This project will explore approaches to artificial intelligence that can support creative digital filmmaking, an extremely rich new form of expression and communication. The most accessible variant of digital filmmaking is ""machinima"" - cinematic movies created by manipulating avatars in 3D computer game worlds. Due to the allure of cheap, quick, and easy movie making, and the accessibility of high-fidelity graphics through video games technologies, machinima has grown into a mainstream form of creative expression and sharing. However, machinima has a high threshold of entry. This is due only partly to technical tools, which are cheap and easily acquired; digital filmmaking also has a high threshold of skill requirements. In general, creativity is collaborative, with creators often seeking feedback and critique from others. Intelligent systems can also participate in the feedback loop of creative practice by suggesting, autonomously creating, and critiquing digital media.<br/><br/>The goal of this research is to reduce the technological and skill barriers to complex, but rich forms of digital expression such as filmmaking, thereby increasing the creative productivity of amateur creators. Its approach is to develop digital media production tools that are instilled with computational models of creative practice and intuitive interfaces informed by empirical studies. The anticipated result is a greater understanding of creative processes involving feedback and critique, models of cognitive and emotive processes in human recipients of creative artifacts, and understanding about the tradeoffs of interface modalities involving intelligent participatory systems. The project is organized around two major, interrelated thrusts: (1) develop cognitive and computational models of feedback and critique as a means toward intelligent systems that participate in creative endeavors; (2) study how the creative abilities of amateur and expert digital filmmakers are affected by production interfaces along dimensions of (a) degree of constraint in cinematic control and (b) modes of intelligent participatory support.<br/><br/>It is anticipated that the resultant models and implementations will serve as next-generation creativity support tools to be adopted by the amateur digital filmmaking and machinima communities. By achieving its research goals, this project will demonstrate a technique for lowing the threshold of entry to a form of digital media creation. Lowering the threshold of machinima production, in particular, will open the practice to populations of users historically underrepresented in computing such as women, who are attracted to storytelling but often discouraged by highly technical ""hacker"" skills. As an expressive form, digital filmmaking is a powerful medium for communication, can be used as a draw to computing, and can be integrated into a wide repertoire of activities including entertainment and education.  Resultant models and implementations may also impact the growing practice of previsualization in the movie and television industries. The approach will result in a model for incorporating intelligent creative assistance into other forms of expressive digital media."
78854,CADRE:  A Tool for Transforming WordNet into a Core Knowledge Base,EIA,EXPERIMENTAL SYSTEMS/CADRE,7/1/2000,7/3/2000,Dan Moldovan,"Moldovan, D","Moldovan, D|Harabagiu, S",TX,Southern Methodist University,Standard Grant,Mita D. Desai,8/31/2001,"$695,400.00 ",Sanda Harabagiu,moldovan@utdallas.edu,6425 BOAZ,Dallas,TX,752750302,2147682030,CSE,4725,"4725, 9218, HPCC",$0.00 ,normalFunding,"EIA-0078854<br/>Moldovan, Dan I<br/>Southern Methodist University<br/><br/>CADRE: A Tool for Transforming WordNet into a Core Knowledge Base<br/><br/>  This project extends a popular database of English words to make it more useful in such tasks as question answering, information retrieval, and summarization.  Wordnet is a lexical database for English that has been widely adopted in artificial intelligence and computational linguistics for a variety of practical applications.  The basic elements of WordNet are sets of words that are linked according to semantic relations:  synonomy, antonymy, superordination, and so forth.  WordNet is publicly available, widely used, and is currently being into a multilingual database.<br/><br/>This project will develop a set of tools that can be applied to current and future versions of WordNet to extend it for knowledge processing applications.  The extensions are enhancements of the glosses that currently contain definitions, comments, and examples of sets of words that are linked in WordNet.  Enhanced glosses will be syntactically parsed, will have each word tagged with its part of speech, and will themselves be linked with other glosses that describe related concepts.<br/>"
1343940,SCH: EXP: Intelligent Clinical Decision Support with Probabilistic and Temporal EHR Modeling,IIS,Smart and Connected Health,1/1/2014,11/12/2014,Sriraam Natarajan,"Natarajan, S","Natarajan, S|Grannis, S|Hauser, K|Natarajan, S",IN,Indiana University,Standard Grant,Sylvia J. Spengler,12/31/2017,"$686,411.00 ","Shaun Grannis, Kris Hauser, Sriraam Natarajan",sriraam.natarajan@utdallas.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,CSE,8018,"8018, 8061",$0.00 ,normalFunding,"Clinical decision support has the potential to reduce healthcare costs and improve patient outcomes, while shedding light into policy questions surrounding healthcare costs and practices in the US.  This project aims to develop intelligent clinical decision support techniques for recommending optimal action plans - including both diagnostic tests and medical interventions - for treating chronic disease, performing multi-step and adaptive treatments, and modifying long-term health habits. In an effort to integrate evidence-driven decision-making with established clinical practices, the research will develop disease-agnostic artificial intelligence techniques that combine data from large electronic health records (EHRs) with recommendations from human experts. A prototype decision support system will be tested on three clinical settings - cardiology, clinical depression, and emergency room readmission - using existing EHR datasets and consultation with domain experts from clinical partners. Outcomes-driven and cost-driven optimized decisions will be compared to current clinical practice. This exploratory research will provide the groundwork for follow-up projects in decision support information presentation, integration with clinical workflow and IT systems, and making the transition from retrospective studies to clinical trials.  Other broader impacts include workshops for healthcare applications of AI, and women and minority students will be recruited and mentored in graduate and undergraduate computer science research.<br/><br/>The technical approach of this research builds on state-of-the-art machine learning and artificial intelligence methods to automatically learn, simulate, and reason about patient-specific treatment plans.  Such methods must be simultaneously probabilistic and temporal.  Probabilistic techniques are needed to handle significant uncertainties in clinical diagnoses and outcomes, much like a human clinician would.  Temporal techniques are needed to consider sequences of future decisions over the course of treatment, rather than decisions at single time points.  More specifically, this project will consider the use of statistical relational learning (SRL) techniques to mine for probabilistic, temporal patterns in large electronic health records, and these patterns will be used in partially-observable Markov decision processes (POMDPs) that exhaustively search for optimal treatment sequences. Recent results indicate that SRL achieves superior performance to other machine learning methods in predicting cardiac arrest from demographic and lifestyle observations, and POMDP treatment plans outperform existing fee-for-service practices by reducing costs by 50% and improving outcomes by 40% on a clinical depression dataset.  By combining SRL and POMDPs, specifically, using SRL to learn a disease progression model used by the POMDP, this project aims to achieve further improvements in recommendation quality and computational scalability for complex treatments.  Furthermore, because EHRs may suffer from limited or missing data, clinical decision support tools should follow established practices and expert knowledge when necessary.  To do so, new workflows for integrating expert knowledge into SRL and POMDPs will be explored.  Evaluation will be performed on a variety of disease scenarios in conjunction with clinical partners at Marshfield Clinic, Centerstone, Wake Forest School of Medicine, and South Bend Memorial Hospital."
1541029,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,ICER,EarthCube,9/1/2015,7/28/2015,Julien Emile-Geay,"Emile-Geay, J","Emile-Geay, J|Gil, Y",CA,University of Southern California,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$684,779.00 ",Yolanda Gil,julieneg@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,$0.00 ,normalFunding,"Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.<br/><br/>Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines."
1607486,US-German Research Proposal: Neurocomputation in the Visual Periphery: Experiments and Models,IIS,"CRCNS, ROBUST INTELLIGENCE",12/1/2016,9/19/2017,Ruth Rosenholtz,"Rosenholtz, R","Rosenholtz, R",MA,Massachusetts Institute of Technology,Continuing grant,Kenneth C. Whang,11/30/2019,"$681,746.00 ",,rruth@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,"7327, 7495","7327, 8089, 8091",$0.00 ,normalFunding,"Peripheral vision comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception -- what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to ""crowding,"" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. This project will examine the nature of the encoding in visual cortex, through development and testing of a set of models of peripheral vision. These models will be targeted at answering key questions about the neurobiological mechanisms. The collaborating investigators, in the US and Germany, will develop models and create a benchmark dataset of behavioral results to be explained. The models and dataset will be made freely available, to aid other researchers and to inform the development of applications such as heads up displays and user interfaces. This work will provide insight into what features are encoded in visual cortex, as well as what tradeoffs may have led the visual system to develop that encoding. Understanding those tradeoffs may inform computer vision which, like human vision, faces constraints on processing capacity. <br/><br/>The development of new model variants will be based on insights from neurophysiology, natural image statistics, sparse coding, and the recent success of convolutional neural networks in artificial intelligence. The investigators will gather benchmark behavioral phenomena far richer than existing crowding datasets, through a combination of studying natural image tasks and model-driven experiments. They will then compare predictions of the new models, as well as of Dr. Rosenholtz's existing high-performing model of peripheral vision, on the benchmark dataset. Doing so will identify the best-performing model(s), and answer key questions about the nature of pooling computations and of non-linear operators, and about the complexity, nature, and purpose of the features encoded by peripheral vision.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)."
325929,"Collaborative Research: ITR: Software for Interpretation of Cosmogenic Isotope Inventories - Combination of Geology, Modeling, Software Engineering and Artificial Intelligence",EAR,"SCEC, ITR MEDIUM (GROUP) GRANTS, GEOINFORMATICS",9/15/2003,9/9/2003,Marek Zreda,"Zreda, M","Zreda, M",AZ,University of Arizona,Standard Grant,Enriqueta Barrera,8/31/2009,"$678,375.00 ",,marek@hwr.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,GEO,"1571, 1687, 7255","1652, 1661, 1687, 2884, 4444, 9215, HPCC",$0.00 ,normalFunding,"This project aims to improve the accuracy of geological chronologies based on cosmogenic isotope data.  It combines research on computer models of the effects of various processes on the rate of accumulation of cosmogenic isotopes in geological formations, the development of a database of data (such as isotope abundances) and environmental parameters useful for cosmogenic isotope dating (such as solar output and the state of the terrestrial magnetic field at different times), and an artificial intelligence (AI) system to support the use of cosmogenic isotope accumulation models in dating.  The AI system will act as an expert system guiding the user in the choice of modeling tools and data, and integrating the selected models and data.  The combined AI/database/modeling system will be built using a component-based architecture to make it simpler to modify and extend as new processes and data sets are added.<br/><br/>Because of the central importance to geological inference of establishing the age of geological structures, this project, if successful should be helpful in a number of problems in research and applied geology.  The project will also strengthen the connections between the geological and computer science research communities, both by virtue of the collaboration itself and by demonstrating the potential for exploiting information technology to further geological research."
1704860,AF: Large: Collaborative Research: Nonconvex Methods and Models for Learning: Toward Algorithms with Provable and Interpretable Guarantees,CCF,ALGORITHMIC FOUNDATIONS,6/1/2017,5/16/2017,Sanjeev Arora,"Arora, S","Arora, S|Singer, Y|Hazan, E",NJ,Princeton University,Continuing grant,Rahul Shah,5/31/2022,"$669,782.00 ","Yoram Singer, Elad Hazan",arora@cs.princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,7796,"7925, 7926",$0.00 ,normalFunding,"Artificial Intelligence along with Machine Learning are perhaps the most dominant research themes of our times - with far reaching implications for society and our current life style. While the possibilities are many, there are also doubts about how far these methods will go - and what new theoretical foundations may be required to take them to the next level overcoming possible hurdles. Recently, machine learning has undergone a paradigm shift with increasing reliance on  stochastic optimization to train highly non-convex models -- including but not limited to deep nets. Theoretical understanding has lagged behind, primarily because most problems in question are provably intractable on worst-case instances. Furthermore, traditional machine learning theory is mostly concerned with classification, whereas much practical success is driven by unsupervised learning and representation learning. Most past theory of representation learning was focused on simple models such as k-means clustering and PCA, whereas  practical work uses vastly more complicated models like autoencoders, restricted Boltzmann machines and deep generative models. The proposal presents an ambitious agenda for extending theory to embrace and support these practical trends, with hope of influencing practice. Theoretical foundations will be provided for the next generation of machine learning methods and optimization algorithms. <br/><br/>The project may end up having significant impact on  practical machine learning, and even cause a cultural change in the field -- theory as well as practice -- with long-term ramifications. Given the ubiquity as well as  economic and scientific implications of machine learning today, such impact will extend into other disciplines, especially in (ongoing) collaborations with researchers in neuroscience. The project will train a new generation of machine learning researchers, through an active teaching and mentoring plan at all levels, from undergrad to postdoc. This new generation will be at ease combining cutting edge theory and applications. There is a pressing need for such people today, and the senior PIs played a role in training/mentoring several existing ones.<br/> <br/>Technical contributions will include new theoretical models of knowledge representation and semantics, and also frameworks for proving convergence of nonconvex optimization routines. Theory will be developed to explain and exploit the interplay between representation learning and supervised learning that has proved so empirically successful in deep learning, and seems to underlie new learning paradigms such as domain adaptation, transfer learning, and interactive learning. Attempts will be made to replace neural models with models with more ""interpretable""  attributes and performance curves.  All PIs have a track record of combining theory with practice. They  are also devoted to a heterodox research approach, borrowing from all the past phases of machine learning: interpretable representations from the earlier phases (which relied on logical representations, or probabilistic models), provable guarantees from the middle phase (convex optimization, kernels etc.), and an embrace of nonconvex methods from the latest deep net phase. Such eclecticism is uncommon in machine learning, and may give rise to new paradigms and new kinds of science."
1741431,BIGDATA: IA: Distributed Semi-Supervised Training of Deep Models and Its Applications in Video Understanding,IIS,Big Data Science &Engineering,9/1/2017,7/7/2018,Boqing Gong,"Gong, B","Gong, B|Wang, L|Shah, M",FL,University of Central Florida,Standard Grant,Aidong Zhang,8/31/2020,"$662,431.00 ","Liqiang Wang, Mubarak Shah",bgong@icsi.berkeley.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,8083,"7433, 8083",$0.00 ,normalFunding,"This project investigates semi-supervised training of deep neural network models using large-scale labeled and unlabeled data in a distributed fashion. Deep neural networks have recently been widely deployed in artificial intelligence and related scientific fields, largely attributing to well-labeled big datasets and improved computing capabilities. However, the unlabeled data, which is often bigger, is inherently ruled out by the prevailing supervised training of the deep models. It is indeed highly challenging to model the unlabeled parts of many recent and emerging datasets, which are often unstructured and distributed over different nodes of a network (e.g., the videos captured by a camera network). This project aims to explore how to effectively use the unlabeled and distributed data to complement the discriminative cues of the labeled data, to jointly learn accurate and robust deep models. The research seamlessly unifies machine learning, computer vision, and parallel computing, and fosters unique interdisciplinary research and education programs for the graduate and undergraduate students.<br/><br/>Despite the progress on semi-supervised learning and deep learning, the confluence of these two is mostly studied on a small scale in single-machine environment. However, many new datasets easily grow beyond the computation or even storage capacity of a single machine. Hence, it becomes a pressing need to investigate the semi-supervised learning of deep models on parallel computing platforms. To better account for this scenario, this project develops improved network architectures to facilitate the parallel training, and the training procedure developed adaptively switches between synchronized and asynchronized modes for optimal efficiency. The main idea is to incorporate a parametric distribution to the neural network and use covariate matching to coordinate the network behaviors across different machines. The researchers also explore a novel application, extreme-scale spatial-temporal action annotation of video sequences, to benchmark the algorithms and frameworks in this project."
1534770,SBIR Phase II:  A Game-Based Leadership Program,IIP,SMALL BUSINESS PHASE II,9/1/2015,1/26/2017,Robert Brown,"Brown, R","Brown, R",NC,Triad Interactive Media,Standard Grant,Ben Schrag,8/31/2017,"$659,682.00 ",,robert@triadinteractivemedia.com,1601 Guilford College Road,Jamestown,NC,272829383,3369085884,ENG,5373,"5373, 8031, 8032, 8043, 8240, 9117",$0.00 ,normalFunding,"This Small Business Innovation Research Phase II project is an online, game-based program to improve the leadership skills of individuals in science, education, the military, government, and industry. Leadership skills are key to innovation, efficiency, and effectiveness in all organizations. The program being developed is built on a proven leadership model and converts that traditional model into a role-playing game. The empirically tested model consists of three basic strategies and six practices that expand leaders' perspectives and enhance their problem-solving skills. The program uses a futuristic narrative, 3D-animated multimedia, and challenging leadership dilemmas to engage learners, who play the role of a novice world leader. The program provides instruction in leadership, and then learners apply their new leadership skills to build an alliance among warring factions and collectively solve a global problem. A series of game quests test learners' understanding, and they receive immediate feedback on all decisions and actions. Learners communicate through social media tools with other players and, at the end, participate in a virtual synchronous debriefing exercise with peers and trained facilitators to ensure full comprehension. An administrative dashboard provides real-time performance data. The game is scalable, accessible, and designed for repeat playability.<br/><br/>The most profound innovation of this project is that it conceptualizes, designs, and develops a system of game mechanics and algorithms that mimic the facilitator-led human aspect of a research-based, face-to-face model of leadership training. This design entails building out a backend system as an artificial intelligence tool designed to guide users engaging with instructional materials, anticipate player actions, make recommendations on actions and anticipated actions, and provide feedback similar to guidance an on-site facilitator would provide. Furthermore, the game logic supports multiple paths to success, with some paths being more efficient, optimal, elegant, or otherwise more appropriate choices. The game logic and technical design are built to reflect problem solving and leadership in the real world, which is largely based on open-ended decision making. The game mechanics and related backend technology are designed to support open-ended decision-making, thus making game play both more engaging and authentic for players. A final innovation is the linking of an asynchronous online video game learning experience with virtual facilitator-led synchronous debriefing, which can be done on a worldwide scale.  The program will be tested as a global collaboration exercise with both high school students and corporate leaders."
624219,DRU: Inter-organizational Decision Making and Organization Design for Improved ICT Coordination in Disaster Relief,CMMI,"HSD - DEC, RISK & UNCERTAINTY",1/1/2007,4/5/2010,Carleen Maitland,"Maitland, C","Maitland, C|Yen, J|Tapia, A|Beamon, B",PA,Pennsylvania State Univ University Park,Standard Grant,Dennis Wenger,8/31/2011,"$656,000.00 ","John Yen, Andrea Tapia, Benita Beamon",cmaitland@ist.psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,ENG,7322,"037E, 042E, 1041, 116E, 5946, 7293, 9102, 9146, 9251, CVIS, MANU",$0.00 ,normalFunding,"Highly complex decision making involving multiple organizations, which have both shared and private interests, pose many challenges in the critical area of disaster relief as well as for organizational scholars. In particular, it is difficult to understand how the structure, distribution of decision rights, and governance of a multi-organization coordination body influences decision making processes and outcomes. Also, systematic assessment of the effects of improved decision making for related activities, such as the provision of goods in a supply chain, presents a significant challenge. This research will address these problems in the context of decision making for information and communication technology (ICT) coordination in humanitarian relief, an area which, as exemplified by the communication failures in the relief effort for hurricane Katrina, requires significant attention.<br/><br/>This multi-disciplinary research project integrates software-based intelligent agent research on information sharing and decision making with a study of organization designs that influence information sharing, and analytic assessments of the industry-level performance improvements resulting from improved decision making. The coordination bodies who will participate in this study are the International Working Group for Emergency Capacity Building (IWG ECB), consisting of representatives from the largest international humanitarian relief agencies, including CARE, Oxfam and Save the Children, among others, and HumaniNet, consisting of primarily smaller agencies. Data gathered from these organizations using qualitative methods, will then be used to modify an agent-based architecture to perform sensitivity analyses of the effects of these designs on decision making, generating recommendations for improved designs. Subsequently, the outputs of the simulation will be used in analytic models to predict the effects of decision making improvements on disaster relief supply chain performance. Together, our research on decision making will contribute badly needed knowledge in the critical area of disaster relief, while making fundamental advancements to theories of organization science, artificial intelligence and logistics."
1741472,BIGDATA: F: Audio-Visual Scene Understanding,IIS,Big Data Science &Engineering,9/1/2017,8/24/2017,Chenliang Xu,"Xu, C","Xu, C|Duan, Z",NY,University of Rochester,Standard Grant,Maria Zemankova,8/31/2021,"$650,000.00 ",Zhiyao Duan,chenliang.xu@rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,8083,"7433, 8083",$0.00 ,normalFunding,"Understanding scenes around us, i.e., recognizing objects, human actions and events, and inferring their spatial, temporal, correlative and causal relations, is a fundamental capability in human intelligence. Similarly, designing computer algorithms that can understand scenes is a fundamental problem in artificial intelligence. Humans consciously or unconsciously use all five senses (vision, audition, taste, smell, and touch) to understand a scene, as different senses provide complimentary information. For example, watching a movie with the sound muted makes it very difficult to understand the movie; walking on a street with eyes closed without other guidance can be dangerous. Existing machine scene understanding algorithms, however, are designed to rely on just a single modality. Take the two most commonly used senses, vision and audition, as an example, there are scene understanding algorithms designed to deal with each single modality. However, no systematic investigations have been conducted to integrate these two modalities towards more comprehensive audio-visual scene understanding. Designing algorithms that jointly model audio and visual modalities towards a complete audio-visual scene understanding is important, not only because this is how humans understand scenes, but also because it will enable novel applications in many fields. These fields include multimedia (video indexing and scene editing), healthcare (assistive devices for visually and aurally impaired people), surveillance security (comprehensive monitoring of the suspicious activities), and virtual and augmented reality (generation and alternation of visuals and/or sound tracks). In addition, the investigators will involve graduate and undergraduate students in the research activities, integrate research results into the teaching curriculum, and conduct outreach activities to local schools and communities with an aim to broader participation in computer science. <br/><br/>This project aims to achieve human-like audio-visual scene understanding that overcomes the limitations of single-modality approaches through big data analysis of Internet videos. The core idea is to learn to parse a scene into elements and infer their relations, i.e., forming an audio-visual scene graph. Specifically, an element of the audio-visual scene can be a joint audio-visual component of an event when the event shows correlated audio and visual features. It can also be an audio component or a visual component if the event only appears in one modality. The relations between the elements include spatial and temporal relations at a lower level, as well as correlative and causal relations at a higher level. Through this scene graph, information across the two modalities can be extracted, exchanged and interpreted. The investigators propose three main research thrusts: (1) Learning joint audio-visual representations of scene elements; (2) Learning a scene graph to organize scene elements; and (3) Cross-modality scene completion. Each of the three research thrusts explores a dimension in the space of audio-visual scene understanding, yet they are also inter-connected. For example, the audio-visual scene elements are nodes in the scene graph, and the scene graph, in turn, guides the learning of relations among scene elements with structured information; the cross-modality scene completion generates missing data in the scene graph and is necessary for good audio-visual understanding of the scene. Expected outcomes of this proposal include: a software package for learning joint audio-visual representations of various scene elements; a web-deployed system for audio-visual scene understanding utilizing the learned scene elements and scene graphs, illustrated with text generation; a software package for cross-modality scene completion based on scene understanding; and a large-scale video dataset with annotations for audio-visual association, text generation and scene completion. Datasets, software and demos will be hosted on the project website."
208712,Conservation of Total Synaptic Weights by Heterosynaptic Potentiation and Depression,IOS,"NEURONAL AND GLIAL MECHANISMS, NEURAL SYSTEMS CLUSTER",7/15/2002,3/10/2006,Denis Pare,"Pare, D","Pare, D",NJ,Rutgers University New Brunswick,Continuing grant,Diane M. Witt,6/30/2007,"$649,903.00 ",,pare@axon.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,BIO,"1192, 5500","1096, 1192, 9183, BIOT",$0.00 ,normalFunding,"0208712<br/>Denis Pare <br/><br/>Understanding memory, that is, how the brain stores information, is a major challenge of contemporary neuroscience. Indeed, the brain contains an astronomical number of nerve cells that communicate by specialized structures called synapses. Most neurons make synapses on hundreds to thousands of other neurons and reciprocally. Much evidence suggests that memory depends on changes in the strength or efficacy of individual synapses distributed across a large population of synapses. It was shown that when a neuron contributes to excite another nerve cell beyond a certain level, the synapse between these two cells becomes more efficient (or stronger). However, when synapses with such properties are introduced in computer models of neuronal networks, problems of stability develop because the reinforcement of synapses increases the likelihood that they will be further reinforced, leading the network into unchecked excitation. Thus, the question is how does the brain prevent runaway increases in the strength of synapses? This proposal tests the possibility that when particular synapses are strengthened, other synapses to the same cells are depressed. Thus, experience would modify the relative strength of synapses, but the total strength of synapses to any given neuron would remain stable. The proposed work will examine the intracellular mechanisms that allow the strength of individual synapses to change while keeping the total impact of synapses to target cells within normal bounds. This will be achieved by recording neurons in brain slices kept alive in a dish. Understanding how the brain keeps the weight of plastic synapses within normal bounds would have important implications for artificial intelligence and robotics where adaptable computer programs simulating neuronal networks constitute the most promising approach toward progress"
412830,Hypothesis Formation and Testing in an Interpretive Domain: a Model and Intelligent Tutoring System,IIS,"ADVANCED LEARNING TECHNOLOGIES, ARTIFICIAL INTELL & COGNIT SCI",9/15/2004,7/24/2008,Kevin Ashley,"Ashley, K","Ashley, K",PA,University of Pittsburgh,Continuing grant,Kenneth C. Whang,8/31/2009,"$649,810.00 ",,ashley@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,"1707, 6856","9218, HPCC",$0.00 ,normalFunding,"Hypothesis Formation and Testing in an Interpretive Domain:<br/>a Model and Intelligent Tutoring System<br/><br/>Abstract<br/><br/>Since the days of Bacon and Galileo, formulating hypotheses about natural phenomena and testing them against empirical data have been cornerstones of the natural sciences. As a cognitive framework, hypothesis formation and testing are also important in legal reasoning. The legal domain, however, is different from natural science and mathematics in a significant respect. Determining whether a hypothesized rule and proposed outcome are consistent with past legal decisions is much more a matter of interpretation. The aims of this project are to (1) design and evaluate an Artificial Intelligence (AI) cognitive model of framing and testing hypotheses in an interpretive domain, legal reasoning, and (2) incorporate the model in an intelligent tutoring system (ITS) to teach law students the process. <br/>The project builds upon two recent developments: (1) a newly invented means to frame and evaluate hypotheses predicting the outcomes of new cases based on an AI database of existing precedents; (2) a convenient, on-line corpus of U.S. Supreme Court oral arguments in aural and written form, including many concrete examples of legal hypothesis framing and testing. In response to an advocate's proposed hypothesis of how the case should be decided, the Justices often challenge it by posing hypotheticals, sometimes forcing the advocate to modify or abandon the hypothesis. <br/>By studying these examples, the researchers, participating law students and law faculty will schematize and model the process of framing and testing legal hypotheses, implement it computationally, evaluate it empirically, and use it to design the ITS. <br/>The tutor will implement the model in various legal domains, each with a body of legal rules, issues, precedents, and principles, operationalized in a way that supports hypothesis formulation, prediction, testing, and explanation. Using the model, it will guide and challenge students' arguments. It will predict outcomes of cases, help students construct tests and rationales justifying the prediction, and help them evaluate the hypothesis by posing or responding to hypothetical challenges.<br/>The researchers will evaluate the project's success in terms of: (1) the accuracy of the model's predictions for new cases and the extent it improves case retrieval; (2) how well model-generated arguments compare to those in the Supreme Court oral arguments or generated by law students; (3) how well ITS-trained students compare to a control group taught the same process using conventional law school methods; (4) whether ITS-trained students generate more accurate self-explanations of the Supreme Court oral arguments.<br/> This work extends AI techniques to a much less well-structured domain than natural science and mathematics, one more like the common sense domains AI has yet to address.  By using AI to investigate empirically a cognitive phenomenon, framing and testing hypotheses in an interpretive domain, it will contribute to research in AI & Law, Case-based Reasoning, AI & Education, and Cognitive Science."
1709351,CDS&E: D3SC: The Dark Reaction Project:  A machine-learning approach to exploring structural diversity in solid state synthesis,DMR,"CONDENSED MATTER & MAT THEORY, Theory, Models, Comput. Method, DATANET",9/1/2017,7/26/2017,Joshua Schrier,"Schrier, J","Schrier, J|Norquist, A|Friedler, S",PA,Haverford College,Standard Grant,Daryl W. Hess,8/31/2020,"$645,288.00 ","Alexander Norquist, Sorelle Friedler",jschrier@haverford.edu,370 Lancaster Avenue,Haverford,PA,190411336,6108961000,MPS,"1765, 6881, 7726","054Z, 7433, 8084, 9177",$0.00 ,normalFunding,"NONTECHNICAL SUMMARY<br/>This award receives funds from the Division of Materials Research, the Chemistry Division and the Office of Advanced Cyberinfrastructure. This award supports research and education that uses data-centric methods to enable the prediction of metal oxide compounds with desired properties. Organically-templated metal oxides have a tremendous degree of structural diversity and compositional flexibility. This allows chemists to tune the structures, properties, and symmetries of these compounds to optimize their performance in specific applications that include catalysis, molecular sieving, gas adsorption, and nonlinear optics.  However, new compounds are typically created by a trial-and-error procedure, and creating novel compounds with specific structures is a grand challenge in solid state chemistry.  This project will develop artificial intelligence techniques for computers called machine learning techniques that can be used to predict the conditions for chemical reactions that will increase structural diversity and lead to specific structural features.  This project will also develop machine learning techniques that generate human-readable explanations about the formation mechanism, which will be tested in the laboratory.<br/> <br/>The primary impact of this project will be to decrease the amount of time and to lower the cost of discovering new materials with specific structural features, which in turn help bring new materials for applications to market more quickly.  This project is an example of a collaboration among synthetic chemists, computational chemists, and computer scientists and as a model it may be directly transferred to a wide range of disciplines and avenues of investigation. Undergraduate student research opportunities and curricular developments will be involved throughout the project, thus contributing to the scientific workforce.<br/> <br/>TECHNICAL SUMMARY <br/>This award receives funds from the Division of Materials Research, the Chemistry Division and the Office of Advanced Cyberinfrastructure. This award supports research and education that uses data-centric methods to enable the prediction of metal oxide compounds with desired properties. Hydrothermal synthesis is widely used to create new metal oxide materials with a wide range of functional properties and applications.  This project will advance the field by developing software infrastructure for associating the results of X-ray diffraction experiments with individual reactions, extracting structural outcome descriptors from this data, and then determining the extent to which these structural outcomes can be predicted from reaction description data.  This will be achieved by developing structural outcome descriptors for geometric properties, non-covalent interaction properties, and electron-density properties, then building machine learning models that correlate these outcomes to reaction conditions, and finally testing the quality of these predictions experimentally.  Active learning and auditable and interpretable models will be incorporated into the workflows to help synthetic chemists select better (more insightful/novel) reactions in an interactive fashion."
1520031,"IBSS: The Spread and Impact of Moral Messages: Machine Learning, Network Evolution, and Behavioral Prediction",SMA,Interdiscp Behav&SocSci IBSS,8/15/2015,8/15/2017,Jesse Graham,"Graham, J","Graham, J|Graham, J|Dehghani, M|Vaisey, S",CA,University of Southern California,Standard Grant,Thomas J. Baerwald,1/31/2019,"$640,267.00 ","Jesse Graham, Morteza Dehghani, Stephen Vaisey",jesse.graham@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,SBE,8213,"8213, 8605",$0.00 ,normalFunding,"In the immediate aftermath of the 2013 Boston Marathon tragedy, hundreds of thousands of prosocial acts were evident on social media, such as reposted links for blood donation sites, information regarding how to get in touch with loved ones, and even offers to provide food and shelter for those in need. Far from isolated acts, these behaviors occurred within social networks, amid shared moral messages of empathy and solidarity.  This interdisciplinary research project will examine how people respond to public crises and how moral reactions shape these responses in social networks.  The project will contribute new theoretical insights and methodological advances in moral psychology, network sociology, computer science, and other fields.  It will enhance understanding of how moral concerns spread through social networks and explore new theoretical frameworks dealing with human moral decision making and group dynamics.  These theoretical frameworks will guide the development of artificial intelligence techniques for building descriptive models of morality, and the new methods of sentiment analysis and machine learning will be used to assess theoretical models of moral concerns and social influence in networks.  By examining factors influencing the spread of moral messages and participation in prosocial activities, such as charitable giving, the project may help increase the well-being of individuals in emergency situations.  The project also will facilitate future inquiry into how the public and persistent nature of social media may provide new ways to understand and forecast social change.<br/><br/>The interdisciplinary science of morality has developed well-validated measures of moral concerns using a number of different approaches, such as Moral Foundations Theory and Schwartz's Values Circumplex.  Empirical research in this field usually has assessed moral judgments via questionnaires gathering information well after actions have occurred, however.  Sociology has done more to assess behavior as it occurs but has used even more limited measures.  Recent innovations in computer science offer new ways to gather information about the structure of moral judgments and large-scale behavior in natural settings as well as the relationships between the two.  The investigators will employ these new computer-based methods to examine texts from social media in order to examine the structure of moral concerns and values without relying on preset questionnaires.  They will investigate the network dynamics of the spread of moral messages and behaviors, and they will determine how moral content in social media can predict real-world behavior at both individual and societal scales. The investigators will couple machine learning and sentiment analysis techniques with theories about moral cognition and social dynamics.  Among questions they will pursue are how well everyday moral judgments (made without researcher prompting) correspond with dominant psychological theories of morality and whether it is possible to model and predict how moral influence can lead to subsequent prosocial or antisocial behavior.  This project is supported through the NSF Interdisciplinary Behavioral and Social Sciences Research (IBSS) competition."
1629559,"XPS: FULL: Broad-Purpose, Aggressively Asynchronous and Theoretically Sound Parallel Large-scale Machine Learning",CCF,Exploiting Parallel&Scalabilty,9/1/2016,2/6/2018,Eric Xing,"Xing, E","Xing, E|Gibson, G",PA,Carnegie-Mellon University,Standard Grant,Aidong Zhang,8/31/2020,"$625,379.00 ",Garth Gibson,epxing@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,8283,,$0.00 ,normalFunding,"Many artificial intelligence (AI) applications such as image understanding and natural language processing rely on Machine Learning (ML) methods to automatically extract valuable knowledge from Big Data (Big Learning). Efficient ML requires not only expertise in advanced mathematical models and algorithms, but also experiences with large computer clusters where issues such as machine failures, memory/network bottlenecks, inter-machine latencies must be properly handled through complex system programming. Such demand on ""dual skill"" often prevents democratizing large-scale AI to wide user communities, and necessitates a new framework that bridges ML and the distributed computing environment of a cluster with a single-machine-like simple interface, allowing ML practitioners to be agnostic about the backend details, and able to quickly prototype or deploy ML programs on clusters. Solutions to such a need remain rare. In this project the PIs develop a new general purpose framework for ML on distributed systems, offering highly efficient and theoretically justified protocols (e.g. communication, scheduling, and partitioning functions) to orchestrate a heterogeneous computer cluster to become programmable and act like a single big computer, and execute distributed ML programs correctly and at a speed orders of magnitude faster than current systems such as Hadoop and Spark. With this new framework, data scientists will be able to conduct ML analytics with complex models on massive data without the need for dedicated engineering and infrastructure teams, allowing Big Learning more readily accessible to society.<br/> <br/>Specifically, over a four year span, the proposed research focuses on three technical aims: (1) Building a System Framework for Big Learning, by developing a new architecture that supports both data- and model-parallel execution of large ML programs, using intelligent scheduler, parameter server, and consistency controller that are configurable to provide flexible options for model/data parallelization, synchronization schemes, load balance, fault tolerance, and multi-instance tenancy; (2) Building a Multi-Level-Abstraction Programming Interface, which supports easy parallel programming of both basic and advanced ML algorithms for large-scale applications; and (3)Conducting theoretical analysis of distributed ML algorithms on the proposed system, based on unique insights such as block consistency and error-tolerance under bounded synchronism. The goal is to develop a system framework to achieve general, automatic, and effective parallelization of ML programs."
1124535,DIP: Collaborative Research: A Personalized Cyberlearning System Based on Cognitive Science,IIS,"NATIONAL SMETE DIGITAL LIBRARY, Cyberlearn & Future Learn Tech",9/1/2011,5/20/2014,Richard Baraniuk,"Baraniuk, R","Baraniuk, R|Padley, P|Vardi, M|Johnson, D|Burrus, CS",TX,William Marsh Rice University,Standard Grant,christopher hoadley,8/31/2015,"$610,150.00 ","Paul Padley, Moshe Vardi, Don Johnson, C. Sidney Burrus",richb@rice.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,CSE,"7444, 8020","8045, 8842, 9251",$0.00 ,normalFunding,"Investigators from Rice University and Duke University will build a Personalized Cyberlearning System, designed around three principles from cognitive science (retrieval practice, spacing, and enhanced feedback), that leverages advances in machine learning and makes use of an existing instructional content material and problem set database aimed at undergraduate engineering students. The system will use artificial intelligence methods to optimize practice and feedback for students. Research will seek to advance knowledge, in a real-world setting, about a range of issues concerning how feedback facilitates learning, how individual differences come in to play, as well as those more specifically aimed at the development of the learning technology system itself.<br/><br/>The project is important as part of the effort to harness the vast quantities of information on the web to personalize instruction for a wide range of learners. Moreover, the development of such cyberlearning technologies holds promise for opening up STEM education for motivated self-learners while also allowing access to a large volume of material for a range of students who might not otherwise have it."
839216,Operation and Application of High-Resolution Full-Disk Global Halpha Network,AGS,SOLAR-TERRESTRIAL,3/1/2009,12/12/2012,Haimin Wang,"Wang, H","Wang, H|Yurchyshyn, V",NJ,New Jersey Institute of Technology,Continuing grant,Ilia I. Roussev,2/28/2015,"$606,752.00 ",Vasyl Yurchyshyn,haimin.wang@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,1523,"0000, OTHR",$0.00 ,normalFunding,"The Principal Investigator (PI) has assembled an international collaboration to operate a high resolution, full-disk, global H-alpha telescope network (GHN), to monitor solar activity round-the-clock. A prior NSF award in 2000 allowed the network to include three stations in the United States, China, and Austria. This effort will continue that collaboration and extend the network to seven stations without additional cost. These seven stations are at Big Bear Solar Observatory (BBSO) in the United States, Kanzelh???he Solar Observatory (KSO) in Austria, Meudon Observatory and Pic-du-Midi Observatory in France, Yunnan Astronomical Observatory (YNAO) and Huairou Solar Observing Station (HSOS) in China, and Catania Astrophysical Observatory (CAO) in Italy. <br/><br/>The PI's team will continue to operate GHN in order to provide valuable data to the solar-terrestrial community and to carry out research programs on solar filaments, flares, and coronal mass ejections (CMEs). GHN will be complementary to the operation of a number of NASA missions, such as Hinode (Solar-B), STEREO (Solar TErrestrial RElations Observatory), and SDO (Solar Dynamics Observatory). The PI will also investigate the important role of magnetic reconnection in large scale solar eruptions that travel through the corona and into interplanetary space.<br/><br/>The international aspect of GHN is important for improving global space weather observations and forecasts. This project will support a number of Ph.D. students who are using GHN data for their thesis work. An undergraduate student will participate in BBSO observations during the summer and carry out research during the academic year. GHN data processing uses artificial intelligence techniques developed within a multidisciplinary collaboration among students and faculty working in solar physics, computer sciences, and mathematics."
958482,II-EN: A compute cluster and software tools for Monte-Carlo methods in artificial intelligence,CNS,COMPUTING RES INFRASTRUCTURE,7/1/2010,3/10/2010,Thomas Dietterich,"Dietterich, T","Dietterich, T|Fern, A|Tadepalli, P|Wong, WK|Tumer, K",OR,Oregon State University,Standard Grant,todd leen,6/30/2014,"$600,000.00 ","Alan Fern, Prasad Tadepalli, Weng-Keen Wong, Kagan Tumer",tgd@cs.orst.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7359,"9218, HPCC",$0.00 ,normalFunding,"The project supports acquisition of a hardware cluster and development of software frameworks to support Monte Carlo methods in articial intelligence, for tasks such as model compilation through machine learning over the results of Monte Carlo simulation, application of Monte Carlo methods to solve single-agent and multi-agent sequential decision making problems, and integration of machine learning methods into Monte Carlo search to improve real-time decision making. These software frameworks will include implementations of baseline and state-of-the-art algorithms for each task, with a goal of release with generic APIs and open-source availability to make it easy for other researchers to add new methods and to connect external simulators to the frameworks.  <br/><br/>The algorithms and tools have many important applications, including (a) optimization of forest management to jointly minimize the risk of catastrophic fires and maximize biological and economic benefits, (b)design and validation of multiagent control methods for reducing congestion in air traffic control, (c) design and validation of multiagent control methods for micro air vehicles, and (d)modeling spatio-temporal distribution of species to support management of endangered and threatened species. The hardware cluster and software frameworks will be integrated into the undergraduate and graduate curriculum at Oregon State University, as well as various outreach beyond Oregon State."
133568,CAREER: Detecting Interchangeability Relations in Constraint Satisfaction Problems and Exploiting them in Problem Solving and Interactions with Users,IIS,"ARTIFICIAL INTELL & COGNIT SCI, EPSCoR Co-Funding",6/1/2002,5/29/2002,Berthe Choueiry,"Choueiry, B","Choueiry, B",NE,University of Nebraska-Lincoln,Standard Grant,Douglas H. Fisher,5/31/2008,"$600,000.00 ",,choueiry@cse.unl.edu,151 Prem S. Paul Research Center,Lincoln,NE,685031435,4024723171,CSE,"6856, 9150","1045, 9150, 9216, HPCC",$0.00 ,normalFunding,"This is a Faculty Early Career Development (CAREER) award.  This project will improve our ability to solve problems in constraint satisfaction, which is a central paradigm for modeling and solving various problems in computer science, engineering, and management.  It will do so by designing and evaluating algorithms that discover and exploit the structure embedded in the model of a decision problem formulated as a Constraint Satisfaction Problem (CSP).  In particular, the work will investigate how symmetry relations, specified as interchangeability, can be used to build compact and faithful abstractions of CSPs.  The goal of these investigations is not only to enhance the performance of solving CSPs, but also to support interactions with human users by allowing them to build and navigate over landscapes of solution spaces.  Such techniques will institute a new paradigm in problem solving by making a computer perform as an active, informed assistant rather than as a passive black box.  The project's education plan combines curriculum development, course teaching, and individual mentoring of students.<br/><br/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century.  Constraint satisfaction is most commonly used in scheduling and resource allocation applications, as well as in artificial intelligence planning and collaborative problem-solving.  Therefore, this research will improve the techniques available to solve very difficult practical problems in a variety of fields.<br/>"
534662,Decision-Theoretic Methods for Personalized Adaptive Information Selection and Display,IIS,"Cyber-Human Systems (CHS), COLLABORATIVE SYSTEMS",10/15/2005,11/6/2007,Yoav Shoham,"Shoham, Y","Shoham, Y|Klemmer, S",CA,Stanford University,Continuing grant,Ephraim P. Glinert,9/30/2009,"$600,000.00 ",Scott Klemmer,shoham@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,"7367, 7496","7496, 9218, HPCC",$0.00 ,normalFunding,"The number and size of simultaneously accessible information sources available to users continuously grows with advances in information technology, dramatically increasing the information processing burden on decision makers at all levels.  Dynamically focusing user attention to a manageable subset of information that is ""most valuable"" at a given situation and time, and properly displaying this information, could have a crucial impact on the quality of the decisions s/he makes.  To address this challenging problem, we need to make systems aware of and responsive to the general and current needs and preferences of the user.  In this project, the PI will develop new preference elicitation and reasoning technology for use in large-scale information integration and decision support systems that provide user-oriented selection, transformation, and integration of information arriving from multiple, heterogeneous, dynamically changing information sources.  The goal is to support each user's personalized information needs while avoiding information overload yet remaining responsive to the user's changing interests and context, and to the available data sources in near real time.  To this end, the PI will exploit and enhance recent developments in graphical qualitative models for preference representation, algorithms for constrained optimization, knowledge compilation strategies, and decision-theoretic frameworks for information processing and integration.  He will build on his team's extensive prior work in the areas of decision-theoretic artificial intelligence, modeling and reasoning about people's decision strategies, and human-computer interaction.  Effectiveness of the new technology will be demonstrated in an interactive application for field biologists.<br/><br/>Broader Impacts:  The novel preference-based presentation techniques to be developed in this research will in the short run significantly aid field biologists-who gather large quantities of heterogeneous information while in the field but have limited methods for working with this information-by providing them with richer capture and comprehension of information without overload.  In the longer run, these same user interface techniques will be of value across other scientific disciplines as well.  Furthermore, they will be of value in diverse applications such as helping managers monitor information about their organization in real time, or helping rescue teams make time-critical decisions by providing team members with information that is sensitive to their current context, their role, and the team's state.  More generally, this work will help people effectively utilize the abundant information available to them without drowning in it."
1724392,S&AS: FND: Long-Term Planning and Robust Plan Execution for Multi-Robot Systems,IIS,S&AS - Smart & Autonomous Syst,9/1/2017,7/27/2017,Sven Koenig,"Koenig, S","Koenig, S|Ayanian, N",CA,University of Southern California,Standard Grant,James Donlon,8/31/2020,"$599,999.00 ",Nora Ayanian,skoenig@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,039Y,"046Z, 9102",$0.00 ,normalFunding,"How can multi-robot teams maneuver in tight and cluttered environments when ""no plan survives contact"" with reality?  Traditional approaches plan for idealized situations and must patch up maneuvers when sensors or actuators are imprecise, making them neither robust nor safe.  This project, a collaboration of PIs from artificial intelligence and robotics, will investigate fundamental research to capture and use timing and uncertainty constraints in  large robot navigation and coordination problems.  The target applications are just-in-time manufacturing and automated warehousing, but the results will extend beyond to many applications of smart and autonomous systems that need reliable and safe planning.  <br/><br/>The project will study Multi-Agent Path Finding (MAPF), which is an NP-hard planning problem that belongs to a class of important planning problems, namely multi-agent navigation problems with temporal and spatial constraints.  The research will relax simplifying assumptions typically made by MAPF solvers, namely that plan execution is perfect and stops once all robots have reached their goal locations.  Many AI planning methods that have been developed are not used on robots, since planning/scheduling uses idealized models of the environment and plan execution is never perfect, and there is often insufficient time for re-planning if execution deviates from the plan. This project will develop well-founded planning and plan-execution methods, based on probabilistic and temporal reasoning, that fuse ideas from robotics and artificial intelligence.  In particular, the PIs will combine advances in planning algorithms from the AI community, namely Simple Temporal Networks (STN), and adapt them to the robotics domain by adding timely execution constraints, as well as sensor, actuator, and model uncertainties.   They will make project results (such as papers, videos and code) available on their web pages, present tutorials on their research results to the artificial intelligence and robotics research communities, develop teaching material for multi-robot planning, and integrate undergraduate students into their research activities."
827764,Neural Basis of Active Perception in Natural Environment,BCS,"COLLABORATIVE RESEARCH, CRCNS, ",10/1/2008,7/28/2010,Laurent Itti,"Itti, L","Itti, L|Munoz, D",CA,University of Southern California,Continuing grant,Peter M. Vishton,9/30/2012,"$596,821.00 ",Doug Munoz,itti@pollux.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,SBE,"7298, 7327, H448","0000, 7298, 7327, OTHR",$0.00 ,normalFunding,"Understanding how animals perceive and act upon complex natural environments is one of the most pressing challenges in neuroscience, with applications that have potential to revolutionize not only our understanding of the brain, but also machine vision, artificial intelligence, and robotics. Until now, studying the neural basis of active vision - how visual stimuli give rise to eye movements under diverse task conditions - has largely been restricted to simplified laboratory stimuli, presented to overtrained animals performing stereotypical tasks. With funding from the National Science Foundation, the Canadian Institute of Health Research, and the National Geospatial Intelligence Agency, Dr. Douglas Munoz at Queens University in Canada and Dr. Laurent Itti at the University of Southern California will combine neurophysiology and computational modeling to investigate free viewing in natural environments. Using multi-electrode arrays, this project will record in a deep brain structure, called the superior colliculus (SC). The SC is a layered structure comprising several well-understood neural maps, from purely sensory representations in the superficial layers, to sensorimotor representations linked to the control of eye movements in the deeper layers. The project will start by characterizing responses of neurons in the SC under simple stimulus conditions: When the animal is simply looking at a central fixation cross on a display while small isolated patterns are presented at other visual locations; when the animal searches for an oddball item among an array of distracting items; and when the animal inspects natural images and video clips. The project will extend the investigators' salience map theories and models, and develop a new model of the SC. The complete model will predict, from any image or video clip, which visual locations are more salient, task-relevant, and candidate targets for eye movements.<br/><br/>The project leverages a cross-disciplinary collaboration between a neurophysiology lab (co-PI Douglas P. Munoz) and a computational modeling lab (PI Laurent Itti). This will allow, through the combination of experiments and modeling, the interpretation of an otherwise undecipherable mass of data collected during natural viewing. Conversely, the theories will guide further experiments. Coupling multi-unit recording with modeling during free-viewing of natural videos has never been attempted before, and it is expected that it will lead to new understanding of how percepts map into actions under natural conditions. The project will support undergraduate and graduate students, and post-doctoral researchers, who will benefit from exposure to combined physiological and computational techniques, as will the investigators' teaching. In addition to publications, all theory and algorithm source code will be freely distributed, and data will be available through the CRCNS data sharing web site. This research is hence expected to lead to new and broadly accessible fundamental advances in the understanding of how animals use visual information to guide behavior, and how one could build machines which act in similar ways when faced with the complex natural world."
1729720,The Development of Relational Processing in Infancy,BCS,"Science of Learning, DS - Developmental Sciences",8/15/2017,8/22/2017,Susan Hespos,"Hespos, S","Hespos, S|Forbus, K|Gentner, D",IL,Northwestern University,Standard Grant,Soo-Siang Lim,7/31/2020,"$596,080.00 ","Kenneth Forbus, Dedre Gentner",hespos@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,SBE,"004Y, 1698","059Z, 1698",$0.00 ,normalFunding,"Analogical ability is the ability to make relational comparisons between objects, events, or ideas, and to see common relational patterns across them.  It is a cornerstone of higher reasoning ability, and is essential for learning mathematics and science.  This project  investigates the nature of this ability and how it develops in infants, tracing its development over the first year of life.  Delineating the conditions that promote relational learning in young infants, will lead to insights into how best to promote relational learning in children and in adults who show lags in abstract learning. One result of the proposed studies will be a set of methods and tools that can be used by teachers and caregivers to support relational learning. For example, this research can serve as a springboard for developing targeted interventions for young children diagnosed with language delay, as well as those diagnosed with autistic spectrum disorders.  Another result will be a better understanding of how to build artificial intelligence systems that learn more like people, with far less data than today's systems require.<br/><br/>The starting point for this proposal is a recent demonstration that 7- and 9-month-old infants can form abstract same and different relations, and apply them to new objects.  The preliminary studies suggest that even 3-month-old infants are capable of relational learning; however, they are highly vulnerable to distraction by the interestingness of the objects in the pairs.  The new research will use four series of experiments to trace infants' ability to learn abstract relations.  The first will examine the processes that promote relational learning in 3-month-olds.  The second will investigate the conditions that support spontaneous comparison and learning in 7- and 9-month-olds.  The third series will test how language influences relational learning- specifically, whether naming relations can improve learning, and whether naming objects can impede relational learning.  The fourth series of experiments will investigate the generalizability of these effects by testing a variety of abstract relations.  Computational modeling of the learning patterns found in our studies will provide complementary insights on these processes. Taken together, these studies will reveal information critical to understanding analogical processes and the origin and evolution of higher-order cognition."
963478,RI: Medium: Collaborative Research: Game Theory Pragmatics,IIS,ROBUST INTELLIGENCE,7/15/2010,7/14/2010,Yoav Shoham,"Shoham, Y","Shoham, Y|Wilson, R",CA,Stanford University,Standard Grant,Hector Munoz-Avila,6/30/2014,"$590,272.00 ",Robert Wilson,shoham@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7495,7924,$0.00 ,normalFunding,"The past decade has seen unprecedented interaction between artificial intelligence and game theory, with exciting intellectual problems, technical results, and potentially important applications. However, this thriving interaction has thus far not challenged in a fundamental way some of the basic assumptions of game theory, to include various forms of equilibrium as the fundamental strategic concept. Equilibrium specifies conditions under which the strategic choices of agents are in some sense stable. Equilibria are clever and beautiful constructs, but they embody strong idealized assumptions and as a result their applicability to complex, realistic games (i.e., formalizable 'social' interactions) is limited. Arguably computer science can provide alternative modeling foundations, or at least significantly contribute to them. <br/><br/>This project explores several complementary directions, to include: alternatives to equilibrium as game solution criteria; replacing analysis of large, complex games with analysis of their abbreviated or approximate versions; using machine-learning techniques to model the extent to which agent behavior is strategic, adaptive, or otherwise intelligent; investigating the role of strategic reasoning in controlled but rich environments, such as Computational Billiards, which involves continuous state and actions spaces as well as control uncertainty. One of the outreach and educational components of this project is organizing and participating in an annual Computational Billiards competition. Applications range from electronic commerce to social networks to peer-to-peer systems to online games, and in general all settings in which individual interests intertwine with computational elements."
1237080,SHB: Type II (INT): Collaborative Research: Creating Learning Systems with Mobile Technology to Improve Coordination in Perioperative Services,IIS,"INFO INTEGRATION & INFORMATICS, Smart and Connected Health",10/1/2012,7/28/2014,Nathan Huynh,"Huynh, N","Huynh, N|Vidal, J",SC,University South Carolina Research Foundation,Standard Grant,Sylvia J. Spengler,9/30/2018,"$585,916.00 ",Jose Vidal,huynhn@cec.sc.edu,1600 Hampton Street,COLUMBIA,SC,292080001,8037777093,CSE,"7364, 8018","7364, 8018, 8062, 9150, 9251",$0.00 ,normalFunding,"This project proposes to create a framework using a combination of mobile technology, learning systems, data analytics, education, and training to enhance cooperation and coordination of staff within and across perioperative services departments (POS).  Perioperative services comprise surgery preparation, operating rooms, post-anesthesia care, sterile processing and a variety of other services, such as radiology and endoscopy.  The specific objectives of this project are to: (1) enhance communication and coordination among POS staff to improve the quality of care by gathering and using important workflow milestones and introducing artificial intelligence techniques through the use of a smart-app, (2) analyze workflow data gathered with smart-apps using data analytics to provide intuitive displays of real-time information for frontline staff and a daily performance dashboard for managers, and (3) induce behavioral and cultural change in healthcare systems through training and education. While existing  information technology capabilities such as natural language processing, artificial intelligence, and speech recognition technology are promising developments in computing, their uses in health care are limited and thus need to be thoroughly investigated before they can be used in health care effectively. To accomplish these objectives, the research team will work closely with the partnering healthcare organizations, Greenville Hospital System (GHS), Palmetto Health (Palmetto), and the Medical University of South Carolina (MUSC), in developing the tools and models which will be pilot-tested at these organizations by their staff.  <br/><br/>The developed tools and models will be widely disseminated among health care providers in South Carolina. In addition, the smart-apps and agent-based simulation model will provide the team with a teaching and training tool that can be used in the classroom at Clemson University and the University of South Carolina (USC) to teach students across a variety of fields, such as business, engineering, science and healthcare students about information and workflow management techniques."
725895,Collaborative Research: Interactive Deception and its Detection through Multimodal Analysis of Interviewer-Interviewee Dynamics,BCS,"HSD - DYNAMICS OF HUMAN BEHAVI, ",10/1/2007,9/18/2007,Judee Burgoon,"Burgoon, J","Burgoon, J|Nunamaker, J",AZ,University of Arizona,Standard Grant,Amber L. Story,9/30/2011,"$584,950.00 ",Jay Nunamaker,jburgoon@cmi.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,SBE,"7319, S005","7319, 9102, 9215, HPCC",$0.00 ,normalFunding,"Deception is a pervasive feature of social life yet often goes undetected because deceivers capitalize on features of the interpersonal communication process. They adjust their verbal and nonverbal behavior over the course of an interaction in ways that evade detection. To uncover the complexities and dynamics of the communication processes that make successful deception or detection possible, collaborative research will be conducted by a multidisciplinary team of communication, linguistics, psychology, computer science, and management information systems researchers from the University of Arizona, University of Chicago, Michigan State University, and Rutgers University. They will be joined by international experts from the University of Cologne, Imperial College London, and University of Iceland. The project will develop a theoretical model of interpersonal deception that shifts emphasis from stable individual behaviors to dynamic interaction patterns. It will create five test beds by measuring the verbal and nonverbal features from video-recorded interpersonal communication experiments. The five experiments are a cheating experiment, a mock theft experiment, deceptive interviews, a group collaboration task, and a narration task. Measurement will consist of extensive automated and human-annotated measurement of visual, vocal, and verbal features. As part of the annotation work, the team will refine and validate software for automated measurement of nonverbal and verbal features. Theory-driven hypothesis tests and exploratory tests will be conducted on the measured communication behaviors to identify dynamic adaptation patterns using time-series, Bayesian-based Theme analyses, and artificial intelligence data mining techniques. The project will advance the scientific infrastructure for studying deception by forming the largest international and multidisciplinary research team of deception experts of its kind, integrating the knowledge and methods of multiple disciplines, refining computer-aided analysis of human communication, making progress in automating deception detection, and educating new investigators through laboratory exchanges. Society will benefit from a more valid picture of deception that can guide training and detection efforts in public, business, government, and security settings."
132003,SBIR Phase II: Advanced Software for Interactive Chemistry Tutoring,IIP,SMALL BUSINESS PHASE II,2/15/2002,3/22/2004,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Sara B. Nerlove,1/31/2005,"$582,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,5373,"9177, 9178, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project will produce a set of completed and commercially viable intelligent tutoring systems for chemistry education, building upon a rule-based, model-tracing, cognitive modeling tutor prototype for chemical equation balancing. Teachers, students, parents and administrators state that existing chemistry education software does not satisfy their need for truly interactive and on-demand computer instruction. Current approaches are rigid and linear, offering only a limited number of fixed and statically scripted problems. They do not deal with the individual student's own work in any meaningful or intelligent way. By simulating reasoning using chemical principles rather than compiling a database of problems and answers, artificial intelligence methods can provide a route to overcoming these serious fundamental limitations. Although the technology proffered by Quantum Simulations, Inc. is technology that will assist all students, those students of average or marginal performance will benefit the most.<br/><br/>Creating tutoring systems that can function as guides and not just as graders of student work is an important step in realizing the full value of computers in education. The proposed work takes a significant step in this direction. Moreover, the technology has been designed in a general way such that it can be applied to other educational topics beyond chemistry and can work together in a synergistic, value-added fashion with other tools and curricula in a multi-resource learning environment. Quantum Simulations, Inc., customers are driven by strong end user needs and include textbook publishers, software provides, and distance learning companies."
87977,"CRCD:  Constructive, Inquiry-Based, Multimedia Learning in Computer Science Education",CNS,"ENGINEERING EDUCATION, RES EXP FOR TEACHERS(RET)-SITE, CISE EDUCAT RES & CURRIC DEVEL, CISE RESEARCH INFRASTRUCTURE",10/1/2000,7/3/2003,Glenn Blank,"Blank, G","Blank, G|Pottenger, W|Kessler, GD",PA,Lehigh University,Continuing grant,Anita J. LaSalle,9/30/2004,"$578,000.00 ","William Pottenger, G. Drew Kessler",gdb0@lehigh.edu,Alumni Building 27,Bethlehem,PA,180153005,6107583021,CSE,"1340, 1359, 1709, 2885","0000, 7218, 9152, 9178, 9218, 9251, 9299, HPCC, OTHR, SMET",$0.00 ,normalFunding,"0087977<br/>Blank, Glenn D.<br/>Lehigh University<br/><br/>CRCD:  Development of a Web-based Integrated Learning Environment for Manufacturing Engineering Education<br/><br/>This project combines research in inquiry-based learning with emerging concepts in textual content identification and classification to the development of a multimedia learning system. The project applies a multimedia framework to the teaching of introductory and upper-level computer science courses for students with diverse learning styles, gender, and cultural backgrounds. In particular, the project concentrates on one introductory computer science course and two upper-level undergraduate/introductory graduate level courses, Object-Oriented Software Engineering and Artificial Intelligence with Applications in Textual Data Mining. Applying current research in data mining algorithms and knowledge base creation, a reference-librarian avatar guides learners through course content using a multimedia interface that seamlessly connects learners, networks, knowledge repositories and human instructors.<br/>"
1209589,SoCS: Collaborative Research: A Human Computational Approach for Improving Data Quality in Citizen Science Projects,IIS,SOCIAL-COMPUTATIONAL SYSTEMS,8/1/2012,11/21/2012,Steven Kelling,"Kelling, S","Kelling, S|Lagoze, C|Gomes, C",NY,Cornell University,Standard Grant,William Bainbridge,7/31/2015,"$575,366.00 ","Carl Lagoze, Carla Gomes",stk2@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7953,7953,$0.00 ,normalFunding,"A unique interdisciplinary team of computer scientists, information scientists, ornithologists, project managers, and programmers will develop a novel network between machine learning methods and human observational capacity to explore the synergies between mechanical computation and human computation. This is called a Human/Computer Learning Network, and while the focus is to improve data quality in broad-scale citizen-science projects, the network has the potential for wide applicability in a variety of complex problem domains. The core of this network is an active learning feedback loop between machines and humans that dramatically improves the quality of both, and thereby continually improves the effectiveness of the network as a whole. The Human/Computer Learning Network will leverage the contributions of broad recruitment of human observers and process their contributed data with artificial intelligence algorithms leading to a total computational power far exceeding the sum of their individual parts. This work will use the highly successful eBird citizen-science project as a testbed to develop the Human/Computer Learning Network. eBird engages a global network of volunteers who submit tens of millions of bird observations annually to a central database.<br/>This research addresses three fundamental data quality challenges in citizen-science. These are: 1) reducing errors in identification or classification of objects; 2) identifying and quantifying the differences between individual observers; 3) reducing the spatial bias prevalent in many citizen-science projects. To address these challenges, the project will build on advances in artificial intelligence that now provide the opportunity to study systems through the generation of models that can account for enormous complexity. Preliminary work on observer classification will be extended by developing new multi-label machine learning classification algorithms that provide better ecological interpretations and more accurate predictions. In addition, the research will develop new active learning algorithms by constructing sampling paths that will optimize volunteer survey efforts to maximize overall spatial coverage, and incentivize participation via crowdsourcing techniques. Finally, it will study how participants can improve the quality of their observations based on the feedback and information provided by the artificial intelligence. <br/><br/>Broad-scale citizen-science projects can recruit extensive networks of volunteers, who act as intelligent and trainable sensors in the environment to gather observations. Artificial intelligence processes can dramatically improve the quality of the observational data that volunteers can provide by filtering inputs based on observers' expertise, a judgment that is based on aggregated historical data. By guiding the observers with immediate feedback on observation accuracy and customization of observation worksheets, the artificial intelligence processes contribute to advancing expertise of the observers, while simultaneously improving the quality of the training data on which the artificial intelligence processes make their decisions. The results of the project will have significant benefit for all citizen science and broader impact in an emerging world of ubiquitous computing in which human-machine partnerships will become increasingly common."
1661456,Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution,DBI,ADVANCES IN BIO INFORMATICS,9/1/2017,8/30/2017,Hilmar Lapp,"Lapp, H","Lapp, H",NC,Duke University,Standard Grant,Peter H. McCartney,8/31/2020,"$569,764.00 ",,hilmar.lapp@duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,BIO,1165,9150,$0.00 ,normalFunding,"The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
9454149,Computational Aspects of Cognitive Science                  Focus Area:  Human Computation,DGE,GRADUATE TRAINEESHIPS PROGRAM,9/15/1994,8/7/2000,Claire Cardie,"Cardie, C","Cardie, C|Lust, B|Zabih, R",NY,Cornell University,Continuing grant,Paul W. Jennings,8/31/2001,"$562,500.00 ","Barbara Lust, Ramin Zabih",cardie@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,EHR,7173,"9179, SMET",$0.00 ,normalFunding,"  We propose to create a novel predoctoral training program at the  interface of Computer Science and Cognitive Science at Cornell  University.  While this interface has been crowded lately with  ""fuzzy-engineering"" approaches typically identified as Artificial  Intelligence (common-sense reasoning, neural nets, etc.), we plan  to focus, instead, on ""formal-scientific"" aspects, including the  formal modeling of computational and inference processes, computer-  human interface and computer science education studies, vision and  robotics, learning theory, and intelligent information retrieval.   We argue that         1.  both disciplines, Computer Science and Cognitive Science,            will benefit from such a program,              and         2.  Cornell is uniquely suited to accommodate such a program.    Indeed, we hope that the proposed program would serve as a model of  how and engineering field and a liberal-arts field can leverage  each other and ultimately lead to both (1) engineering artifices  that pay more  attention to the human user and (2) a better formal  understanding of human thought process    The proposal is organized in four parts.  First, we present several  con=crete and promising research directions.  Each module is  concrete in that at least one current doctoral student or faculty  member is interested in pursuing the topic; each module is  promising in that progress will depend on and advance both  participating disciplines.  Second, we briefly portray the current  infrastructure at Cornell and we present the structure of the  proposed program.  Third, we present a plan for recruiting and,  fourth, we justify the need for funding."
9454155,GRT/The Learning Sciences Ph.D. Program: Building a Scientific Infrastructure for Applications of Advanced Technologies for Teaching and Learning,DGE,GRADUATE TRAINEESHIPS PROGRAM,9/15/1994,7/9/1998,Brian Reiser,"Reiser, B","Reiser, B",IL,Northwestern University,Continuing grant,Paul W. Jennings,8/31/2000,"$562,500.00 ",,reiser@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,EHR,7173,"9179, SMET",$0.00 ,normalFunding,"New insights from cognitive scientific studies of learning and significant advances in the nature of computer technology make the Learning Sciences a critical area of study for innovations in teaching and learning based on sound theory and evidence. The Learning Sciences Ph.D. program is a new interdisciplinary doctoral program launched at Northwestern University's School of Education and Social Policy in 1991 with over twenty newly-hired faculty (in the disciplines of Education, Computer Science, and Psychology) targeting the training of a new generation of professionals in the field. Faculty and students in the program are engaged in research to advance the scientific understanding and practice of learning and education, and the theory, design, construction, and assessment of innovative technologies and learning environments for schools and workplaces. The Learning Sciences Ph.D. comprises a cohesive training program integrating substantive treatment of three areas of specialization in its core coursework, methodological foundations, and research apprenticeships: (1) the study of social contexts of learning which investigates the social, contextual, and cultural dynamics of learning in situation ranging from classrooms to out-of-school setting, (2) the study of cognition, developing scientific models of the structures and processes by which domain knowledge and skills are acquired and (3) the study of learning technologies, which concentrates on the theory-guided design and use of multimedia computing, artificial intelligence, and communications technologies for supporting learning and teaching processes. This proposal describes the graduate training program in Learning Sciences and our plans for aggressive recruiting to attract underrepresented groups to this field in the context of Northwestern's recent dramatic increases in minority doctoral program enrollment."
9980062,KDI: Temporal Abstraction in Reinforcement Learning,ECCS,KDI-COMPETITION,9/15/1999,8/18/1999,Andrew Barto,"Barto, A","Barto, A|Moore, J",MA,University of Massachusetts Amherst,Standard Grant,Radhakisan S. Baheti,8/31/2003,"$560,000.00 ",John Moore,barto@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,ENG,8877,"0000, 1347, 8877, OTHR",$0.00 ,normalFunding,"This project investigates a new approach to learning, planning, and representing knowledge at multiple levels of temporal abstraction.  It develops methods by which an artificial reinforcement learning system can model and reason about persistent courses of action and perceive its environment in corresponding terms, and it develops and examines the validity of models of animal behavior related to this approach.  The project's objectives are to develop the mathematical theory of the approach, to refine, extend, and conduct validation studies of related models of animal behavior, to examine the theory's relationship to control theory and artificial intelligence, and to demonstrate its effectiveness in a number of simulated learning tasks.<br/><br/>Most current reinforcement learning (RL) research uses a framework in which an agent has to take a sequence of actions paced by a single, fixed time step: actions take one step to complete, and their immediate consequences become available after one step (modeled as a Markov decision process, or MDP).  This makes it difficult to learn and plan at different time scales. Some RL research instead uses a generalization of this framework (semi-Markov decision processes, or SMDPs) in which actions take varying amounts of time to complete, and the existing theory specifies how to model the results of these actions and how to plan with them.  However, this approach is limited because temporally extended actions are treated as indivisible and unknown units.  For the greatest flexibility and best performance, it is necessary to look inside temporally extended actions to examine or modify how they are comprised of lower-level actions, which is not considered in existing approaches.<br/><br/>This project, by contrast, will model extended courses of action as SMDP actions overlaid upon a base MDP.  These courses of action, called options, can then be treated as if they were primitive actions; existing RL can be applied almost unchanged.  This approach enables options to be analyzed at both the MDP and SMDP levels and introduces new issues at the interface between the levels.  This approach is appealing because of its simplicity, similarity to previous approaches using primitive actions, and its solid mathematical foundation in MDP and SMDP theory.  This is being developed further into a general approach to hierarchical and multi-time-scale planning and learning.<br/>"
1351892,CAREER: Characterizing Object Recognition Machinery in a Newborn Visual System,BCS,DS - Developmental Sciences,4/15/2014,8/14/2017,Justin Wood,"Wood, J","Wood, J",CA,University of Southern California,Continuing grant,Chalandra Bryant,3/31/2019,"$559,086.00 ",,justin.wood@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,SBE,1698,"1045, 1698",$0.00 ,normalFunding,"How does early experience shape how we process and interpret visual information? Two major limitations have made this question difficult to answer. First, researchers can typically collect only a few data points from newborns, which prevents precise measurement of the infants' visual cognitive abilities. Second, human infants cannot ethically be raised in controlled environments from birth, which prevents researchers from studying how specific experiences shape the newborn mind. <br/><br/>To overcome these limitations, Dr. Wood has developed a new controlled-rearing method using a non-human animal model. This method can be used to measure all of a newborn's behavior (24 hours/day, 7 days/week) with high precision (9 samples/second) within strictly controlled environments. With support from this NSF CAREER award, Dr. Wood will use the new controlled-rearing method to characterize how newborns recognize objects at the onset of visual object experience. <br/><br/>Dr. Wood's laboratory will use a two-pronged approach. First, the lab will perform a series of controlled-rearing experiments with newborn chickens. Studies of chickens can inform human cognitive development because chickens and humans have similar neural processing systems for sensory information. These controlled-rearing experiments will reveal how specific visual experiences shape newborns' object recognition abilities. The findings will provide the foundation for a new, publicly-accessible database that describes how specific sensory experiences relate to specific behaviors in a newborn organism. <br/><br/>Second, the lab will build biologically-inspired computational models of newborns' object recognition behavior, using state-of-the-art techniques from artificial intelligence. These models will make predictions that can be compared to the data from the controlled-rearing experiments. This will help identify how the visual system processes objects. This approach integrates ideas from developmental psychology, vision science, and computational neuroscience, providing a unified framework for studying the origins of object recognition and other visual cognitive abilities."
9812591,Learning Sensorimotor Control of Balance and Locomotion,ECCS,"CONTROL, NETWORKS, & COMP INTE",9/1/1998,9/28/1999,Mark Spong,"Spong, M","Spong, M|DeJong, G|Hutchinson, S|Sreenivas, R|Rosengren, K",IL,University of Illinois at Urbana-Champaign,Standard Grant,Radhakisan S. Baheti,8/31/2002,"$558,982.00 ","Gerald DeJong, Seth Hutchinson, Ramavarapu Sreenivas, Karl Rosengren",mspong@utdallas.edu,1901 South First Street,Champaign,IL,618207406,2173332187,ENG,1518,"0000, 1339, 8888, OTHR",$0.00 ,normalFunding,"9812591<br/>Spong<br/>The goal of this project is to investigate new computational methods for learning sensorimotor control in bipedal locomotion.  The overarching theme of the project is the integration of cross-fertilization of ideas from engineering, psychology, and kinesiology. The PI's will utilize techniques from control theory and artificial intelligence to improve their understanding of the dynamics and control of human movement and the mechanisms by which humans learn sensorimotor control, while at the same time utilize studies of human movement to aid the development of improved learning and control techniques for multi-degree-of-freedom mechanical systems.  Further applications of their computational methods might include more dextrous and useful robots and more effective diagnostic and physical therapy approaches for disabled humans, as well as better balance training and falls prevention programs for elderly and individuals with balance deficits.<br/><br/>They have assembled a team of researchers with expertise in robotics, nonlinear and hybrid control theory, discrete event dynamical systems, machine learning and artificial intelligence, computer vision, developmental psychology and perceptual-motor coordination to explore these research issues from both the robotic and the human side and to integrate concepts from these diverse disciplines into a coherent theory of learning control in multi-degree-of-freedom anthroopmorphic systems.<br/><br/>They will study the problems of postural control, balance, gain initiation, and gait transition.  The goal will be to develop models of the feedback control and learning mechanisms involved first in the control of balance and then in locomotion.  The models will be developed using data generated from human movement studies and will be based on recent techniques of hybrid control  theory, such as supervisory control and logic-based switching control.  Machine learning techniques of artificial intelligence will be used to learn switching control strategies from observed data.  The novelty of the research lies in:<br/><br/>- The integration of human movement studies with analytical studies based on the most recent concepts of nonlinear dynamics and control theory, hybrid control theory, and discrete event systems theory.<br/><br/>- The pre-eminent role attached to sensing for balance control and control of walking.<br/><br/>- The use of machine learning methods of artificial intelligence to learn hybrid and switching control strategies.<br/><br/>- The combination of experimental and analytical research.  <br/>***  <br/>"
1655300,Discovering Hierarchical Representations for Action Understanding,BCS,"GVF - Global Venture Fund, PERCEPTION, ACTION & COGNITION",8/1/2017,4/5/2017,Hongjing Lu,"Lu, H","Lu, H",CA,University of California-Los Angeles,Standard Grant,Betty H. Tuller,7/31/2020,"$555,792.00 ",,hongjing@ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,SBE,"054Y, 7252","5946, 5980, 7252",$0.00 ,normalFunding,"A major issue in the psychological sciences is understanding how people can infer the intentions of others. Humans are remarkably adept at predicting the actions of other people and making inferences about their intention and goals. The present investigation examines how humans make such inferences from the physical movements of others. The work is guided by a computational theory of biological motion understanding that quantifies what aspects of actions allow observers to make inferences about the meaning of actions and what might come next. The larger goal is to explain how perception and reasoning operate synergistically to infer hidden goals and intentions. These findings will guide development of the next generation of intelligent machine-vision systems, useful in forensic sciences as well as many other real-world applications. Such systems will need to perform challenging tasks that currently are difficult and time-consuming for humans (for example, automated interpretation of human actions recorded in low-resolution surveillance video). The project will also help to identify individual differences in action understanding, potentially revealing the nature of the impairments in action understanding observed in people with autism disorder. In addition, the project will provide a unique training opportunity for students who are interested in interdisciplinary research at the interface between cognitive science and artificial intelligence and will provide an in-depth international research experience for a graduate student and postdoctoral fellow.<br/><br/>The research will integrate advanced psychophysical methods with sophisticated computational approaches. A key aim is to develop a unified theory based on a hierarchical non-parametric Bayesian framework, specifying the fundamental computational mechanisms involved in perception of human actions and reasoning about them. More generally, the project will use human body movements as an underutilized approach to understanding general problems in learning: how to construct, use and transform hierarchical representations to support human perception and cognition. Three aims are particularly noteworthy. First, the project will integrate computational modeling approaches with behavioral experiments to investigate the critical connection between perceptual and cognitive systems. Second, the project uses action stimuli derived from motion capture data in the real world as the visual input (CCTV images collected in the UK and secured at the University of Glasgow). By avoiding the limitations of studies that use restricted examples and constrained environments, the investigators maximize the likelihood that the findings will generalize to real-world situations. Third, the project will develop significant extensions of Bayesian approaches in order to study complex visual processes by combining generative models with probabilistic constraints.  This award is co-funded by the Perception, Action, and Cognition Program and the Office of International Science and Engineering."
910278,Simplifying complexity:  Analyzing students' models of biological systems,DRL,REAL,9/15/2009,8/11/2012,Tammy Long,"Long, T","Long, T|Urban-Lurain, M|Speth, EB|Momsen, J",MI,Michigan State University,Continuing grant,Celestine Pea,8/31/2015,"$552,584.00 ","Mark Urban-Lurain, Elena Bray Speth, Jennifer Momsen",longta@msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,EHR,7625,"9177, SMET",$0.00 ,normalFunding,"This research project responds to the changing nature of biological science, which has become less fragmented and more focused on models of complex interacting systems. The investigators will study a framework that they hypothesize is well-suited to facilitating students thinking about complex systems across the biological span from sub-cellular genetic processes to evolution and ecology. <br/><br/>The selected framework is Structure-Behavior-Function Theory (SBF), in which a system is represented by the component elements of its structure, the processes that these components perform, and the overall function or purpose of the system. The framework originated in the Artificial Intelligence literature, as an effective strategy for reasoning about designed systems such as electrical circuits. In this research, it will be applied to reasoning about topics such as genes, evolution, and ecology. The investigators will use SBF theory as a pedagogy as a well as an assessment system, in the context of several courses in introductory biology at Michigan State University for both life science majors and non-majors. Students will create, refine, and reason with diagrammatic representations of their own models of the topics they study, and investigators will build software to automate the coding of such representations and the ways they change over the course. The work of approximately 800 students will be analyzed to look for shifts in student reasoning at key points in the instruction, tracking learning trajectories over time. The assessment method will be validated by correlating the scores with those on other forms of parallel assessment, such as multiple-choice, short-answer, and diagrammatic questions. <br/><br/>Overall, the investigators will develop and evaluate a framework for analyzing student understanding, propose strategies for promoting systems thinking and metacognition, and advance research on learning about complex systems. The project is innovative in its application of SBF theory to the pedagogy, assessment, and analysis of introductory biology college courses, and also in its adaptation of software tools to automate the analysis of students models and associated reasoning."
1453721,CAREER: Statistical Information Retrieval Modeling for Complex Search,IIS,INFO INTEGRATION & INFORMATICS,2/1/2015,2/15/2018,Grace Hui Yang,"Yang, GH","Yang, GH",DC,Georgetown University,Continuing grant,James French,1/31/2020,"$552,012.00 ",,huiyang@cs.georgetown.edu,37th & O St N W,Washington,DC,200571789,2026250100,CSE,7364,"1045, 7364",$0.00 ,normalFunding,"With the increasing popularity of Web applications and users' deep involvement in the Web, search engines face great challenges with a new degree of complexity. For instance, location-based services collect more complex contextual information such as geo-locations, season, time and temperature. Users' search activities have become more complex and usually task-based generating a variety of feedback and engagement signals such as clicks, mouse movements, eye tracking results, and query reformulations.??? Moreover, search is not only an individual user's personalized activity, but also activities shared by many users with similar information needs. Search engines are presented with the richest types of information and the largest amount of data ever and the complexity of the available information is tremendous. This demands that search engines be upgraded from retrieval systems that basically look for documents for single queries to decision engines that can pick the best choices for information seeking tasks. Through disseminating research results in papers and tools, the project will make three types of broad impact. First, the techniques developed in this project will benefit a broad population of everyday users and empower them to deal with complex, task-oriented web search. Second, the algorithms and software developed will provide fellow researchers and practitioners a handful of useful tools for solving IR problems incorporating dynamics. Third, the project will reach out to middle school girls and elementary school students. It will be easy for any search engine user to start using the proposed new search engine. However, to be an expert on IR, students need to be good at mathematics, natural language processing, user interface, artificial intelligence, and programming. This will be an excellent project to attract young people and minorities to these STEM disciplines.<br/><br/>This project aims to create the next generation search engines, to be more specific, decision engines. The focus will be on designing, experimenting, and deploying statistical models for modeling the dynamics presented in the search process. The technical challenges are: (1) given the complexity of the available data, integrating a search engine appropriately into the right places in the larger context for the ultimate information seeking tasks; (2) providing theoretical and practical support to formal modeling of user engagement and other dynamics in retrieval models for better retrieval effectiveness; (3) modeling a user's exploration in the information space and optimizing a search engine's actions and algorithms; and (4) modeling interactions between a user and a search engine as well as interactions among multiple users, creating the dynamic environment for them all to interact and to game with each other and achieve a win-win optimization. The success of this project will start a new research field in IR: dynamic IR modeling. The results of this research will be highly influential with great impact on the next generation search engines. The work will build a foundation for future advances in the fields of reinforcement learning in IR and game theory in IR."
1230418,SBIR Phase II: Serious Gaming Platform for Mastering the Physician-Patient Diagnostic Interview,IIP,SMALL BUSINESS PHASE II,9/1/2012,4/23/2014,David Baker,"Baker, D","Baker, D",WV,IntelligentSimulations LLC,Standard Grant,Glenn H. Larsen,2/28/2015,"$551,483.00 ",,vicbaker01@gmail.com,1022 Laurelwood Drive,Morgantown,WV,265088900,3042918977,ENG,5373,"169E, 5373, 8031, 8032, 8042, 9150, 9178",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project will complete development of the Artificial Intelligent (AI) Patient platform. This immersive simulation platform helps medical students hone their listening and rapport-building skills by interacting with ?virtual? patients. The student asks questions and the video clip response from the patient depends on the specific question asked, how that question is asked, and when it is asked in the interview. If the student asks the wrong question, or asks inappropriate questions, then the patient will respond in a way that will prevent a positive doctor-patient relationship from developing. Because it combines video clips and artificial intelligence and is web-based, we anticipate that this training platform will teach a medical school student (and other health professionals) how to really pay attention to their patients, and that it will do so more effectively than other training products already on the market. In Phase II, we will complete the platform build, incorporate additional artificial intelligence and speech recognition capabilities, create versions of the platform that will work on smart phones and tablets, and develop a set of six patient scenarios. This work will result in a platform that closely approximates a natural conversational experience.<br/><br/>The broader impact/commercial potential of this project will be to achieve a significant advancement over currently available computer-based training and other instructional tools. Medical schools are experiencing a transition from passive to active methods of teaching, as professors and students both have the desire to replace passive learning methods of PowerPoint slides, lectures, and instructional videos with more interactive methods of learning. The active experience provided by the AI Patient platform will help students learn to be more effective listeners and better health practitioners, which will result in better patient outcomes. The platform will also allow researchers to track and measure the effectiveness of using this kind of training tool. By working with our medical school teaming partners (West Virginia University School of Medicine and the West Virginia School of Osteopathic Medicine), we will develop a set of scenarios that we can license to other medical schools. Sales to the medical school community will support the development of more medical scenarios and enable us to expand into other sectors?such as law enforcement, HR training, and social work?where trust and rapport-building skills are critical."
1350339,"CAREER: Combining Crowdsourcing and Computational Creativity to Enable Narrative Generation for Education, Training, and Healthcare",IIS,Cyber-Human Systems (CHS),2/15/2014,12/29/2017,Mark Riedl,"Riedl, M","Riedl, M",GA,Georgia Tech Research Corporation,Continuing grant,William Bainbridge,1/31/2019,"$549,998.00 ",,riedl@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"1045, 7367",$0.00 ,normalFunding,"The proposed project explores the problem of automated narrative generation, the creation of narratives by computer systems. The project introduces a transformative new approach to narrative generation that blends human and computational creativity with crowdsourcing. The system addresses fundamental limitations of computer reliance on pre-coded domain knowledge in order to generate a virtually unlimited variety of narratives and make it possible for non-experts and non-programmers to create interactive narratives.  The research has four major components: (1) Develop artificial intelligence algorithms that emulate human ability to create narratives. (2) Design and implement novel models of human-computer creative collaboration. (3) Study fundamental questions pertaining to human narrative learning and cognition. (4) Explore the role of narrative generation in real-world domains: virtual agents that create rapport with humans and intelligent creativity augmentation tools for creating and sharing interactive experiences. The work will be piloted in two healthcare systems: a virtual agent that creates rapport and fosters longitudinal engagement with patients through autobiographical narratives; and intelligent tools that allow caregivers to create social skill scenarios for young adults with autism to practice. <br/><br/>Narratives are important because they are a fundamental means by which humans organize, understand, and explain the world. If computer systems could create effective narratives, they would be better able to interact with people. The research will result in novel algorithms, software, and a body of experimental knowledge that will enable the building of interactive narrative systems that are practical, scalable, usable by non-programmers, and can address societally important problems in education, training, and healthcare interventions. The proposed approach to creativity support will significantly lower the technical, artistic, and skill barriers to creating interactive narrative systems, opening avenues for educators, trainers, caregivers, and hobbyists to create and share interactive experiences.<br/><br/>The project includes an educational plan to develop a sustainable, annual summer hack-a-thon camp wherein high school students work alongside K-12 teachers to create interactive narratives that motivate and guide classroom inquiry based learning. The hack-a-thon aims to provide minority and low socioeconomic high school students with hands-on computing science experience and to produce a library of interactive inquiry-based learning software systems for K-12 teachers."
1350598,CAREER: A Broad Synthesis of Artificial Intelligence and Social Choice,IIS,"ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS",2/15/2014,1/31/2018,Ariel Procaccia,"Procaccia, A","Procaccia, A",PA,Carnegie-Mellon University,Continuing grant,James Donlon,1/31/2019,"$548,308.00 ",,arielpro@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7495, 7796","1045, 7495, 7796, 7932",$0.00 ,normalFunding,"Social choice theory is the field that studies the aggregation of individual preferences toward a collective choice. While the artificial intelligence (AI) community has so far played a dominant role in the study of the computational aspects of social choice, the interaction between core AI paradigms and social choice theory has been surprisingly limited. <br/><br/>This project is enhancing the interaction between the two fields through a synthesis of social choice with the following AI areas: (i) decision making under uncertainty, by building on models studied in AI to create new ways to model, analyze, and make decisions in environments where preferences are dynamically changing; (ii) multiagent systems, by studying settings where agents randomly vote over multiple states, and investigating the connection between normative properties and system performance; and finally (iii) machine learning, by employing insights about strategic behavior under structured preferences, developed in the social choice literature, in order to design regression learning algorithms that discourage strategic manipulation.<br/><br/>An overarching goal of this project is to demonstrate the potential of social choice theory to AI researchers, and ultimately to establish social choice theory as a standard paradigm in AI. Equally importantly, this project is expected to increase the scope of social choice theory. Broader impacts include a new web-based voting system, which has the potential to serve and educate hundreds of thousands of users; dissemination through a new book on computational social choice; and a workshop on computational social choice, which will help set a new agenda for the field."
1423260,CHS: Small: Advanced Design Principles for Computer Simulated Agents,IIS,Cyber-Human Systems (CHS),9/1/2014,5/19/2017,Christine Lisetti,"Lisetti, C","Lisetti, C|Williams, M",FL,Florida International University,Continuing grant,William Bainbridge,8/31/2019,"$545,618.00 ",Mark Williams,lisetti@cis.fiu.edu,11200 SW 8TH ST,Miami,FL,331990001,3053482494,CSE,7367,"7367, 7923, 9251",$0.00 ,normalFunding,"This project will investigate human interaction with simulated agents in situations where humans expect empathic communication, such as healthcare.  In domains such as this, the person interacts with computer-based interventions (CBI) as an education process evolves.  Almost all psychosocial interventions currently available on the web are delivered merely via text.  Research indicates that many users will lose interest and drop out, although completion is critical to achieving desired goals.  Human-computer interaction literature suggests that interacting with simulated agents can increase the user's engagement, but that the user will expect social competence when interacting with them.  This project will answer a set of research questions for the design of simulated characters with some empathic intelligence, to create a new modality for the delivery of CBIs.  The specific health-related application area will facilitate development and evaluation of new techniques and design principles, that will have much wider applicability, potentially whenever people interact with computer-based systems through simulated agents. <br/><br/>This research will advance the ability of computer scientists to create competent simulated agents that can adapt their verbal and non-verbal behavior to the user's affective states, and over time tailor their interaction to the specific user to produce the maximum positive impact in terms of users' engagement and achievement of their goals.  The model of empathy and social competence developed will enable simulated characters to adapt in real time to a user's short-lived emotions over a single interactive session.  Longer-term affective states will be modeled over long-term interaction via follow-up sessions with the same individual.  Thus, development of rapport between a human and an artificial intelligence is a dynamic process over time, and the research is expected to discover new principles that might not be seen in exclusively short-term interactions. The project will provide: (1) a scheme to design tailored interaction by constructing a dynamic user-model with user's demographic information and fluctuating personal characteristics; (2) a model of empathic verbal communication built by combining motivational interviewing techniques with an ontology-based dialog system; (3) a computational model for the integration of verbal and non-verbal communication cues by adapting the character's facial expressions, vocal modulation, and kinesics to its verbal utterances in the context of the session.  In addition, the research will engage scientific questions about diversity in communication style across human groups, facilitated by the fact that the project is housed at the region's principal minority-serving research university.  The fact that the research will involve students in the development of systems that integrate multiple technologies will give them an excellent educational experience, gaining competence that will be valuable for a range of future careers."
9810437,University of Maine Connection to the vBNS,CNS,"NETWORK INFRASTRUCTURE, EPSCoR Co-Funding",9/1/1998,2/5/2003,Gerald Dube,"Dube, G","Dube, G|Markowsky, G|Patton, J",ME,University of Maine,Continuing grant,Gregory E Monaco,2/28/2003,"$545,583.00 ","George Markowsky, James Patton",dube@maine.maine.edu,5717 Corbett Hall,ORONO,ME,44695717,2075811484,CSE,"4091, 9150","0000, 1072, 4091, 9150, 9217, HPCC, OTHR",$0.00 ,normalFunding,"This award is made under the high performance connections portion of ANIR's  ""Connections to the Internet"" announcement, NSF 96-64.  It provides partial  support for two years for a DS-3 connection to the vBNS.  Applications  include projects in artificial intelligence and underwater vehicle  research, wood science anf forest engineering, tribology, ceramic film  characterization, insect population dynamics, digital libraries, conflict  and violence, and oceanography.  Collaborating institutions include the  Naval Postgraduate School; Pennsylvania State University; University of New  Hampshire; Brookhaven, Argonne and Oak Ridge National Labs; Naval Research  Lab; University of Illinois; Naval Undersea Weapons Center; University of  California - Santa Barbara; Woods Hole; Dartmouth; Bedford Institute of  Oceanography; several European institutions;  Oregon State University;  University of Rhode Island; and Goddard Space Flight Center."
624275,Collaborative Research: DHB: Human Dynamics of Robot-Supported Collaborative Work,IIS,"HSD - DYNAMICS OF HUMAN BEHAVI, HSD - GENERAL, Cyber-Human Systems (CHS)",12/15/2006,7/8/2010,Sara Kiesler,"Kiesler, S","Kiesler, S|Hodgins, J|Fussell, S|Forlizzi, J",PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,11/30/2011,"$544,000.00 ","Jessica Hodgins, Susan Fussell, Jodi Forlizzi",kiesler@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7319, 7326, 7367","0000, 7319, 7326, 7367, 9102, 9215, 9218, 9251, HPCC, OTHR",$0.00 ,normalFunding,"This is a project to understand and test theories of how three aspects of human-robot interaction independently and interactively affect collaborative work: robot social behavior, mutual understanding in human-robot communication, and the impact of robotic assistants on group dynamics.  With advances in computing technology and artificial intelligence, autonomous robots are becoming viable in such critical domains as search and rescue, military battle, mine and bomb detection, scientific exploration, law enforcement, and hospital care. Robotic assistants ranging from museum guides to forestry scouts are being developed to interact with people ""in person"" or remotely, as agents that collaborate with the work team. This project is targeted at little understood but critical aspects of robot-supported collaborative work. <br/><br/>The research involves three kinds of studies: (1) fundamental laboratory research on behavioral characteristics of robots performing social tasks, especially as these characteristics reflect lifelikeness, (2) controlled experiments and field studies of interpersonal communication and the development of mutual understanding between robot and human, and (3) studies of robots in work groups. The studies are designed to motivate and test theory, as well as to explore both direct and secondary or indirect social effects of robot-supported collaborative work. The fieldwork will be carried out in hospitals and scientific exploration settings. <br/><br/>This research will advance our understanding of the possibilities and problems of mutual adaptation in human-robot interaction over time, and will help us anticipate changes in the group dynamics of collaborative work. It also will extend our basic knowledge of communication and group dynamics in environments that incorporate robotic technology.  It will improve our ability to make principled design decisions about robots that work with people, and better understand the societal impact of robots. In particular, this research will give us a foundation for understanding and designing collaborative work with robots in critical environments like mines, hospitals, households with elderly or disabled residents, in challenging scientific settings, and in situations in which the robot is remote. The work also will contribute to public and student awareness of the human side of robotics, and help motivate students' interests in science and engineering.<br/>"
226861,CADRE:  A Tool for Transforming WordNet into a Core Knowledge Base,CNS,EXPERIMENTAL SYSTEMS/CADRE,7/1/2001,7/6/2005,Dan Moldovan,"Moldovan, D","Moldovan, D",TX,University of Texas at Dallas,Standard Grant,Stephen Mahaney,6/30/2006,"$540,432.00 ",,moldovan@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,4725,"4725, 9218, HPCC",$0.00 ,normalFunding,"EIA-0078854<br/>Moldovan, Dan I<br/>Southern Methodist University<br/><br/>CADRE: A Tool for Transforming WordNet into a Core Knowledge Base<br/><br/>  This project extends a popular database of English words to make it more useful in such tasks as question answering, information retrieval, and summarization.  Wordnet is a lexical database for English that has been widely adopted in artificial intelligence and computational linguistics for a variety of practical applications.  The basic elements of WordNet are sets of words that are linked according to semantic relations:  synonomy, antonymy, superordination, and so forth.  WordNet is publicly available, widely used, and is currently being into a multilingual database.<br/><br/>This project will develop a set of tools that can be applied to current and future versions of WordNet to extend it for knowledge processing applications.  The extensions are enhancements of the glosses that currently contain definitions, comments, and examples of sets of words that are linked in WordNet.  Enhanced glosses will be syntactically parsed, will have each word tagged with its part of speech, and will themselves be linked with other glosses that describe related concepts.<br/>"
963285,Collaborative Research: Measuring Collective Intelligence,IIS,Cyber-Human Systems (CHS),1/1/2010,1/11/2010,Thomas Malone,"Malone, T","Malone, T",MA,Massachusetts Institute of Technology,Standard Grant,Ephraim P. Glinert,12/31/2014,"$538,213.00 ",,malone@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7367,"9215, HPCC, 7924",$0.00 ,normalFunding,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research. But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence. One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College. The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems. For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups. Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups. Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups. A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems. This research will provide powerful new tools for managing and designing such systems. Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors. Imagine that this test could predict the team's future performance on a wide range of important tasks. And imagine that the test could also help suggest changes to the team that would improve its flexibility. Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks. From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently. This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts: With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it. With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems. The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
1704908,"RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making",IIS,ROBUST INTELLIGENCE,8/1/2017,7/27/2017,Elias Bareinboim,"Bareinboim, E","Bareinboim, E",IN,Purdue University,Standard Grant,Weng-keen Wong,7/31/2020,"$536,513.00 ",,eb@purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,7495,"7495, 7924",$0.00 ,normalFunding,"Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project also helps to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project studies identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project considers the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project further aims to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project considers the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
540549,BPC-DP: Building a Bridge in Brooklyn,CNS,"BROADENING PARTIC IN COMPUTING, ITR-BROADENING PARTICIPATION",3/1/2006,6/19/2009,Lori Scarlatos,"Scarlatos, L","Scarlatos, L|Sklar, E|Rudowsky, I|Parsons, S|Chopra, S",NY,CUNY Brooklyn College,Standard Grant,Janice E. Cuny,5/31/2011,"$536,500.00 ","Elizabeth Sklar, Ira Rudowsky, Simon Parsons, Samir Chopra",Lori.Scarlatos@stonybrook.edu,Office of Research & Sponsored P,Brooklyn,NY,112102889,7189515622,CSE,"7482, 7584","9102, 9178, 9218, 9251, HPCC",$0.00 ,normalFunding,"Brooklyn College (BC) proposes a project that focuses on female minority students, primarily Black and Hispanic, who make up the majority of the population at Brooklyn College. The image for the project is the ""tree that grows in Brookly"", illustrating that students can aim high, reaching to meet personal and professional goals, while at the same time, remaining connected to their past, their families, their culture and their roots. Girls are attracted to professions where they feel that they can make a difference, and through this project, they will see that careers in computing can make a difference - through advances in computing technology, they can help analyze their grandmother's mammography images, organize the inventory in their uncle's deli or search for legal briefs to help their neighbor's deportment case. This Bridging project will implement and test a series of interventions aimed at students across six critical years - from junior year in high school through senior year in college. By focusing on preparation, recruitment and retention, the project will emphasize the importance of computer science (CS) in a larger context and provide peer mentors and role models. A broad range of activities, at both high school and undergraduate levels, will be pursued: a Summer Institute to give high school<br/>students a chance to explore context-based computing concepts informally, a Computing Preparatory Course to provide high school students with background for college CS classes, Interdisciplinary Seminars to afford undergraduates who are undecided about their major an opportunity to examine computing applied to socially relevant areas, Alternate Pathways into CS to provide a sequence of tracked, application-based introductory programming courses to new undergraduate majors, and early involvement in Undergraduate Research and Community Outreach to show students the purpose for the skills they are developing. A strong, multi-faceted Mentoring Program will create a continuous support system for participants at all stages of the project and will include Student Ambassadors to link BC students to high schools. The expected results will be a collection of proven methods that can be exported to other institutions across New York City and beyond. <br/>"
443945,Collaborative Research: I/UCRC: Safety Security Rescue Research Center (SSR-RC),IIP,"CISE RESEARCH RESOURCES, INDUSTRY/UNIV COOP RES CENTERS",8/15/2004,6/12/2013,Nikolaos Papanikolopoulos,"Papanikolopoulos, N","Papanikolopoulos, N|Hadjiyanni, T|Roumeliotis, S|Gini, M|Papanikolopoulos, N",MN,University of Minnesota-Twin Cities,Continuing grant,Lawrence A. Hornak,8/31/2013,"$532,750.00 ","Tasoulla Hadjiyanni, Stergios Roumeliotis, Maria Gini, Nikolaos Papanikolopoulos",npapas@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,ENG,"2890, 5761","0000, 1049, 115E, 116E, 122E, 5761, 7218, 8039, 9177, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"This multi-university Industry/University Cooperative Research Center for Safety, Security and Rescue Research located at the University of South Florida and the University of Minnesota will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, firefighting, transportation safety, and emergency response to mass casuality-related activities. The need for safety, security, and rescue technologies has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics in February 2003. <br/><br/>The Center will be built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at the University of South Florida (the lead institution) and the University of Minnesota."
548754,SBIR Phase II: Developing a Cost-Effective Method for Creating Cognitive Models for Cognitive Tutors,IIP,SMALL BUSINESS PHASE II,1/1/2006,12/4/2007,Stephen Gilbert,"Gilbert, S","Gilbert, S",IA,Clearsighted,Standard Grant,Ian M. Bennett,7/31/2008,"$531,999.00 ",,stephen@clearsighted.net,Suilte 4210,Ames,IA,500104514,5152335137,ENG,5373,"1666, 7218, 9177, 9178, 9251, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project will make the creation of effective intelligent tutoring systems (ITSs) easier, and it will enable the dissemination of that technology to a broader audience than currently realized. ITSs have proven to be highly effective in delivering computer-based instruction, but they have historically been expensive and difficult to build, requiring specialized skill in artificial intelligence and production systems programming. Building upon Clearsighted's Phase I accomplishments, the firm will: (1) finish a fully-functional software development kit (SDK) that will allow non-cognitive scientists to create the cognitive model that powers an ITS; (2) develop technology that will enable an ITS to communicate to the vast majority of third-party software; (3) develop techniques that will allow an ITS to work with an institution's existing on-line learning system; and (4) evaluate the research team's work with respect to both time-savings in building ITSs and customers' return on investment. Two main results are anticipated: (1) a two- to three-fold decrease in the amount of time it takes to author an ITS; and (2) an estimated savings to customers of 30% per hour of the cost of traditional training time.<br/><br/>The success of ITSs is well documented (e.g., Koedinger, Anderson, Hadley, & Mark, 1997; Corbett, 2001; Morgan & Ritter, 2002). However, ITSs have not been broadly deployed, due to the high level of expertise needed and the cost to create. Furthermore, lack of viable options to interface the cognitive model of an ITS with already existing software impairs wider dissemination of that technology. By increasing technological understanding of how to reduce the amount of the expertise needed to create an ITS and how to accomplish interfacing ITSs with existing software, the result of this supported work will be a wider distribution of ITSs. Clearsighted is well poised to become a market leader in on-line technical training by leveraging this technology. Clearsighted has partnered with Carnegie Learning, the ITS leader in K-12 education to assist in these goals, and it has the additional expertise needed to perform the required work. By transitioning ITS technology from its currently very small market to a wider audience that includes not only education, but also corporate and industrial applications, the costs to the many companies and institutions that do on-line training will greatly decrease, and the productivity of their workers will increase."
1319680,SHF: Small: RUI: Generating High Quality Trace Links through Intelligent Composition of Tracing Features,CCF,"SOFTWARE & HARDWARE FOUNDATION, SOFTWARE ENG & FORMAL METHODS",8/1/2013,5/29/2015,Jane Huang,"Huang, J","Huang, J",IL,DePaul University,Standard Grant,Sol J. Greenspan,7/31/2017,"$529,383.00 ",,JaneClelandHuang@nd.edu,1 East Jackson Boulevard,Chicago,IL,606042287,3123627595,CSE,"7798, 7944","7923, 7944, 9229, 9251",$0.00 ,normalFunding,"Software traceability serves a critical role in ensuring that software systems operate correctly. It is used to support a wide variety of software engineering activities such as change management, compliance verification, and safety analysis. Unfortunately current practices fall far short of delivering cost-effective traceability, primarily because creating and managing trace links in large and/or complex systems is time-consuming, arduous, and error-prone. These problems were highlighted in a recent report entitled 'Critical Code: Software Producibility for Defense' commissioned by the Department of Defense. The report stressed the need for the research community to develop cost-effective and accurate traceability solutions.  While state of the art tracing techniques offer significant promise for reducing the cost and effort of tracing, they fall short of meeting industrial needs primarily because the quality of the generated links is imprecise. This work will investigate ways to integrate techniques from feature modeling, product line development, artificial intelligence and machine learning to deliver a dynamically configurable trace infrastructure.  The framework will then be used to investigate and integrate a broad set of novel tracing techniques which are expected to significantly improve the quality of generated trace links.<br/><br/>The results of the project will contribute towards the development of software intensive systems, especially safety-critical ones in which traceability is mandatory. Technology transfer will be facilitated by delivering solutions on the TraceLab platform, disseminated via the Center of Excellence for Software Traceability (CoEST.org) and through training materials targeted at industrial users. Ongoing research opportunities will be provided for a diverse group of undergraduate and graduate students, and pedagogical materials will be developed and made publicly available for use in a variety of courses on requirements engineering, software engineering and software architecture."
534736,UAV-Enabled Wilderness Search and Rescue: A Human-Centered Approach,IIS,"HUMAN COMPUTER INTER PROGRAM, Cyber-Human Systems (CHS), COLLABORATIVE SYSTEMS",11/1/2005,5/22/2007,Michael Goodrich,"Goodrich, M","Goodrich, M|Morse, B|McLain, T",UT,Brigham Young University,Standard Grant,Ephraim P. Glinert,10/31/2009,"$525,426.00 ","Bryan Morse, Timothy McLain",mike@cs.byu.edu,A-285 ASB,Provo,UT,846021231,8014223360,CSE,"6845, 7367, 7496","7496, 9178, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"Wilderness search and rescue (WSAR) is the task of finding and giving assistance to humans who are lost or injured in mountain, desert, lake, river, or other remote settings.  Because of the vast distances involved in wilderness settings, searchers frequently depend on surveillance from helicopters and small airplanes.  Although these resources are very useful for searchers, the have limitations: resources consume considerable cost, there can be delays between when the resources are needed and when they arrive, ground searchers and pilots must overcome communications barriers between them, and the aircraft may not be able to provide low level imagery because of flying restrictions associated with rugged terrain.  The central hypothesis of this project is that mini (3-5 foot wing spans), fixed wing Unmanned Aerial Vehicles (UAVs) can be used by WSAR personnel to efficiently find people in the wilderness.  The human factors issues associated with small UAVs are much different than those associated with large UAVs, mostly because small UAVs for WSAR personnel imply limitations on operator training, sensor capacity, autonomy capability, and flight time.  The PI's plan is to develop operator interfaces and UAV autonomy for WSAR systems that allow people without RC-piloting skills to search an area, using either online or offline approaches.  When working online, the PI will adopt a non-pilot operator perspective and design autonomy to allow operators working in an ""augmented virtuality"" environment to ""guide the camera"" rather than fly the UAV.   In situations where information from a UAV's video is to be recorded and used in offline information retrieval and analysis, the PI will pursue an active mosaic approach in which video images are overlaid on terrain maps.  The PI will employ a strongly human-centered approach in all phases of the project, both for creating the WSAR systems and for evaluating them, in which expertise from researchers in human-robot interaction, computer vision, controls, and artificial intelligence is integrated.  User studies will include field tests with WSAR personnel, investigation of current work practice in WSAR teams, usefulness of active mosaicing for offline and online searches, and so on.<br/><br/>Broader Impacts:  Each year, many people are lost or find themselves in jeopardy while hiking, boating/kayaking, skiing, fishing, etc.  Each year, wilderness search and rescue consumes thousands of person-hours and hundreds of thousands of dollars in Utah alone.  With each hour that passes between the time that a person is lost and WSAR people find the victim, the effective search radius grows by approximately 3km.  Each hour spent in the water or lost in the woods decreases the likelihood of a successful rescue.  A portable UAV with appropriate interfaces, autonomy, and sensor processing at an affordable price should decrease the amount of time required between when searchers arrive at a scene and the time when aerial surveillance is present to support their efforts.  Such a system would increase the probability of successful rescue."
1704938,RI: Medium: Collaborative Research: Incorporating Biologically-Motivated Circuit Motifs into Large-Scale Deep Neural Network Models of the Brain,IIS,ROBUST INTELLIGENCE,10/1/2017,8/16/2017,Kenneth Miller,"Miller, K","Miller, K",NY,Columbia University,Standard Grant,Kenneth C. Whang,9/30/2020,"$525,000.00 ",,kdm2103@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,7495,"7495, 7924, 8089",$0.00 ,normalFunding,"This project studies the effects of incorporating, into deep neural networks for visual processing, several heretofore unincorporated features of biological visual cortical circuits. Deep neural networks are artificial circuits loosely inspired by the brain's cerebral cortex. Their abilities to solve complex problems, such as recognizing objects in visual scenes, have revolutionized artificial intelligence and machine learning in recent years. The hierarchy of layers in a deep network trained for visual object recognition also provides the best existing models of the hierarchy of areas in the visual cortex implicated in object recognition (the ""ventral stream""). This project seeks to understand whether and how incorporating additional features of brain circuits may (1) improve machine learning performance, particularly on tasks that are more challenging than those typically studied; and (2) yield improved models of visual cortex. Improving the performance of deep networks would yield great benefits across wide swaths of society and industry that are impacted by advances in artificial intelligence. Improved models of visual cortex will advance understanding of cortical function, which may lead to significant further benefits for understanding normal mental functioning and perception and their potential enhancement, as well as mental illness and perceptual and cognitive deficits. <br/><br/>Deep networks currently achieve their success using almost purely feedforward processing. Yet the visual cortical ventral stream that helped inspire deep networks also uses massive recurrent processing within each area as well as feedback connections from higher areas to lower areas and ""bypass"" connections from lower areas to areas multiple steps higher in the hierarchy. Deep networks also use ""neurons"" that can either excite or inhibit different neurons that they project to, whereas biological neurons are exclusively excitatory or inhibitory. This project will incorporate feedback and bypass connections into deep networks, as well as local recurrent processing in networks of separate excitatory and inhibitory neurons. Recent work by the investigators has shown how local recurrent processing explains a number of nonlinear visual cortical operations often summarized as ""normalization."" Simple forms of normalization currently used in deep networks maintain activities in an appropriate dynamic range, but the biological forms of normalization involve interactions between different stimulus features and locations in determining neural responses, which may have important computational roles e.g. in parsing visual scenes. The performance of deep networks incorporating these features will be assayed on a variety of visual tasks and as models of ventral stream neural data and human psychophysical data, and compared to performance of existing deep net models."
642906,CAREER:Synthesis of Search Procedures for Constraint Programs,IIS,ROBUST INTELLIGENCE,1/1/2007,1/19/2011,Laurent Michel,"Michel, L","Michel, L",CT,University of Connecticut,Continuing grant,todd leen,12/31/2012,"$525,000.00 ",,ldm@engr.uconn.edu,438 Whitney Road Ext.,Storrs,CT,62691133,8604863622,CSE,7495,"1045, 7495, 9218, HPCC",$0.00 ,normalFunding,"<br/>Proposal 0642906<br/>""CAREER: Synthesis of Search Procedures for Constraint Programs""<br/>PI: Laurent D. Michel<br/>University of Connecticut<br/><br/>Abstract<br/><br/>This research aims at synthesizing constraint programs (CP) from high-level constraint programming models. Constraint programming is a method for solving complex optimization applications, which are ubiquitous in our society, are critical to many industries, and affect almost every aspect of our daily lives. However, current constraint programming methodologies require significant expertise to design and program search procedures, and consequently, are not yet widely used by optimization modelers. This is in contrast with modeling languages for mathematical programming, which are now highly automated.<br/><br/>This project investigates the automatic synthesis of constraint programs from high-level models. Its approach exploits the ability of constraint programs to express combinatorial structures in individual constraints to derive key properties like symmetries or dominance for entire models. From these properties, it can reformulate and synthesize search procedures adapted to the underlying solver technology, such as constraint programming, local search, integer programming, or even hybrids. To educate the next generation of engineers, the PI is developing material targeting high school math and science teachers and will disseminate these efforts via the DaVinci initiative at the University of Connecticut. The Broader Impacts of this project include the development of a new generation of modeling languages and systems based on recent advances in programming languages, compilers and artificial intelligence; these will be able to serve a wider audience of optimization modelers.<br/><br/>"
9720341,Learning and Intelligent Systems: Modeling Learning to      Reason with Cases in Engineering Ethics: A Test Domain for  Intelligent Assistance,DRL,"KDI-COMPETITION, LEARNING & INTELLIGENT SYSTEMS",10/1/1997,3/28/2002,Kevin Ashley,"Ashley, K","Ashley, K|Moore, J|Pinkus, RL|Chi, M",PA,University of Pittsburgh,Standard Grant,Elizabeth VanderPutten,9/30/2002,"$524,916.00 ","Johanna Moore, Rosa Lynn Pinkus, Michelene Chi",ashley@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,EHR,"8877, 8888","0000, OTHR",$0.00 ,normalFunding,"9720341  Ashley                 A clinical ethicist, cognitive psychologist, law professor/computer scientist, and computer  scientist/linguist team up to examine how students reason with and learn from case-based texts in  the context of a two-term required graduate engineering ethics course. Taught by the clinical  ethicist, the course is structured so that students regularly discuss and resolve cases as they are  introduced to ethical reasoning and a set of methodological tools developed to aid in the resolution  of ethical dilemmas.               The overall goal of this research is to help students learn to identify ethical components in  practical engineering problems and to enhance their ability to apply the methodological tools and  justifications as they resolve the dilemmas. More specifically, the project goals are to (1) examine  how engineering students adapt conceptual tools for ethical reasoning as they are introduced to,  discuss, and resolve dilemmas presented in the case-based texts; (2) descriptively model this  process using a Web-browser-compatible automated drafting environment (ADE) as a data  gathering tool; (3) examine how ADE's on-line data base of case-based texts, conveniently  accessible in ADE's Web-browser-like drafting environment, can assist this process; (4) explore  how to use computational models of the underlying case-based reasoning to enable ADE to  provide intelligent assistance in aspects of the process; and (S) evaluate how having access to ADE  compliments or interferes with students' developing ability to identify, articulate, analyze and  resolve ethical problems.               The resulting methodological tool, ADE provides convenient access, for both teacher and  student, to an on-line database of textual materials such as methodologies and cases outlined in the  required course texts, mid-level principles, professional codes of engineering ethics, decisions of a  professional association ethics review board and an existing on-line repository of engi neering  ethics cases and commentary. ADE acts like an intelligent assistant engaging students in a  dialectical process. It provides an ""argument worksheet"", a checklist to help the student analyze  an ethical problem, case-based access to information for constructing the arguments, and feedback.  ADE is evaluated empirically in terms of a cognitive model to be developed in an empirical  investigation of case-based learning to solve ill-defined problems. Building ADE also contributes  to three main research areas in Artificial Intelligence, Case-Based Reasoning, and Intelligent  Tutoring: 1. Case representation and relevance assessment, 2. Planning ethical arguments and  explaining those plans, and 3. Recognizing students' solution plans."
1703161,RI: Medium: Collaborative Research: Incorporating Biological-Motivated Circuit Motifs into Large-Scale Deep Neural Network Models of the Brain,IIS,ROBUST INTELLIGENCE,10/1/2017,8/16/2017,Daniel Yamins,"Yamins, D","Yamins, D",CA,Stanford University,Standard Grant,Kenneth C. Whang,9/30/2020,"$524,779.00 ",,yamins@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7495,"7495, 7924, 8089",$0.00 ,normalFunding,"This project studies the effects of incorporating, into deep neural networks for visual processing, several heretofore unincorporated features of biological visual cortical circuits. Deep neural networks are artificial circuits loosely inspired by the brain's cerebral cortex. Their abilities to solve complex problems, such as recognizing objects in visual scenes, have revolutionized artificial intelligence and machine learning in recent years. The hierarchy of layers in a deep network trained for visual object recognition also provides the best existing models of the hierarchy of areas in the visual cortex implicated in object recognition (the ""ventral stream""). This project seeks to understand whether and how incorporating additional features of brain circuits may (1) improve machine learning performance, particularly on tasks that are more challenging than those typically studied; and (2) yield improved models of visual cortex. Improving the performance of deep networks would yield great benefits across wide swaths of society and industry that are impacted by advances in artificial intelligence. Improved models of visual cortex will advance understanding of cortical function, which may lead to significant further benefits for understanding normal mental functioning and perception and their potential enhancement, as well as mental illness and perceptual and cognitive deficits. <br/><br/>Deep networks currently achieve their success using almost purely feedforward processing. Yet the visual cortical ventral stream that helped inspire deep networks also uses massive recurrent processing within each area as well as feedback connections from higher areas to lower areas and ""bypass"" connections from lower areas to areas multiple steps higher in the hierarchy. Deep networks also use ""neurons"" that can either excite or inhibit different neurons that they project to, whereas biological neurons are exclusively excitatory or inhibitory. This project will incorporate feedback and bypass connections into deep networks, as well as local recurrent processing in networks of separate excitatory and inhibitory neurons. Recent work by the investigators has shown how local recurrent processing explains a number of nonlinear visual cortical operations often summarized as ""normalization."" Simple forms of normalization currently used in deep networks maintain activities in an appropriate dynamic range, but the biological forms of normalization involve interactions between different stimulus features and locations in determining neural responses, which may have important computational roles e.g. in parsing visual scenes. The performance of deep networks incorporating these features will be assayed on a variety of visual tasks and as models of ventral stream neural data and human psychophysical data, and compared to performance of existing deep net models."
1725456,SPX: Collaborative Research: Ula! - An Integrated Deep Neural Network (DNN) Acceleration Framework with Enhanced Unsupervised Learning Capability,CCF,SPX: Scalable Parallelism in t,9/1/2017,7/22/2017,Yiran Chen,"Chen, Y","Chen, Y|Li, H",NC,Duke University,Standard Grant,Yuanyuan Yang,8/31/2021,"$520,000.00 ",Hai Li,yiran.chen@duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,042Y,026Z,$0.00 ,normalFunding,"In light of very recent revolutions of unsupervised learning algorithms (e.g., generative adversarial networks and dual-learning) and the emergence of their applications, three PIs/co-PI from Duke and UCSB form a team to design Ula! - an integrated DNN acceleration framework with enhanced unsupervised learning capability. The project revolutionizes the DNN research by introducing an integrated unsupervised learning computation framework with three vertically-integrated components from the aspects of software (algorithm), hardware (computing), and application (realization). The project echoes the call from the BRAIN Initiative (2013) and the Nanotechnology-Inspired Grand Challenge for Future Computing (2015) from the White House. The research outcomes will benefit both Computational Intelligence (CI) and Computer Architecture (CA) industries at large by introducing a synergy between computing paradigm and artificial intelligence (AI). The corresponding education components??? enhance existing curricula and pedagogy by introducing interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices, and give special attentions to women and underrepresented minority groups.<br/><br/>The project performs three tasks: (1) At the software level, a generalized hierarchical decision-making (GHDM) system is designed to efficiently execute the state-of-the-art unsupervised learning and reinforcement learning processes with substantially reduced computation cost; (2) At the hardware level, a novel DNN computing paradigm is designed with enhanced unsupervised learning supports, based on the novelties in near data computing, GPU architecture, and FGPA + heterogeneous platforms; (3) At the application level, the usage of Ula! is exploited in scenarios that can greatly benefit from unsupervised learning and reinforcement learning. The developed techniques are also demonstrated and evaluated on three representative computing platforms: GPU, FPGA, and emerging nanoscale computing systems, respectively."
1654187,CAREER: Instrumental divergence and goal-directed choice,BCS,COGNEURO,2/15/2017,8/25/2017,Mimi Liljeholm,"Liljeholm, M","Liljeholm, M",CA,University of California-Irvine,Continuing grant,Uri Hasson,1/31/2022,"$519,821.00 ",,m.liljeholm@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,SBE,1699,"1045, 1699",$0.00 ,normalFunding,"Theories of instrumental behavior distinguish between goal-directed decisions, motivated by a deliberate consideration of the probability and current utility of their consequences, and habits, which are rigidly and automatically elicited by the stimulus environment based on reinforcement history.  In spite of the far-reaching implications of this distinction, ranging from the structuring of economic policies to the diagnosis and treatment of behavioral pathology, much is still unknown about what factors shape goal-directed decisions and what conditions prompt a transition from goal-directed to habitual action selection.  Generally, while computationally expensive, a goal-directed strategy offers greater levels of flexible instrumental control.  Since subjective utilities often change from one moment to the next, such flexibility is essential for reward maximization and thus may have intrinsic value, potentially serving to motivate and reinforce specific decisions, as well as to justify the general processing cost of goal-directed computations.  A critical requirement for flexible instrumental control, however, is that available action alternatives yield distinct outcome states.  With the support of this NSF Career award, Dr. Mimi Liljeholm is investigating the novel hypotheses that instrumental divergence? the difference between outcome probability distributions associated with alternative actions? can shape choice preferences, induce conditioned reinforcement, and arbitrate between goal-directed and habitual decision strategies.  The objective of this research is to address important gaps in current knowledge about the nature and limits of goal-directed behavior, using a combination of innovative experimental designs, computational modeling and functional magnetic resonance imaging (fMRI).  The educational component of the award provides hands-on training in neuroimaging methods, and in the computational and neural bases of learning and decision-making, at undergraduate and graduate levels.  <br/><br/>All studies use a simple gambling task in which alternative actions yield different colored tokens, each worth a particular amount of money, with various probabilities.  In studies assessing a preference for flexible instrumental control, the relevant choice is between pairs of actions with different levels of instrumental divergence.  Expected monetary pay-offs vary independently of instrumental divergence across options, dissociating the relative contribution of each factor to behavioral choice performance.  Studies investigating the capacity of high instrumental divergence to induce conditioned reinforcement measure changes in the affective valence of visual stimuli based on their association with high versus low instrumental divergence.  Finally, following extended exposure to high versus low instrumental divergence, the degree to which behavior is goal-directed or habitual is assessed using a standardly employed outcome devaluation procedure, in which the monetary amount associated with a particular token color is altered: Goal-directed, but not habitual, decisions are modulated by such changes in the utility of sensory-specific outcomes states.  Neuroimaging data is acquired by scanning participants with fMRI as they perform the task, and a reinforcement learning framework is used to model the intrinsic value of flexible instrumental control (by treating instrumental divergence as a surrogate reward) at behavioral and neural levels. Since many psychiatric disorders are characterized by an abnormal sense of agency, and addiction associated with a rapid transition from goal-directed to habitual action-selection, broader impacts of this project include the potential development of pre-clinical diagnostic assays for early detection of cognitive, affective and behavioral pathology.  The concepts advanced under this project may also help improve the performance of reinforcement learning algorithms, for example by using instrumental divergence to specify new optimization criteria, potentially benefiting medical, industrial and commercial applications of artificial intelligence."
747522,CAREER: Automated Support for Novice Authorning of Interactive Drama,IIS,Cyber-Human Systems (CHS),4/15/2008,4/18/2011,Michael Mateas,"Mateas, M","Mateas, M",CA,University of California-Santa Cruz,Standard Grant,William Bainbridge,3/31/2015,"$516,000.00 ",,michaelm@soe.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7367,"1045, 1187, 7367, 9215, 9251, HPCC",$0.00 ,normalFunding,"The goal of this project is to enable novices (non-programmers and non-expert storytellers) to create interactive dramas (IDs), artificial intelligence (AI) based interactive story experiences with autonomous characters and dynamic plot progression. Accomplishing this goal requires answering the following research question: how can one incorporate storytelling and character creation theories from the theory of dramatic writing, as well as theories of storyboard layout from comics, into an AI model of story generation and character creation that collaborates with a human author to create an ID. Most research work in ID has focused on individual components, such as autonomous character architectures or story managers/generators, not on fully integrated systems with engaging content. This is primarily due to the difficulty of authoring; creating IDs currently requires large, interdisciplinary teams of AI researchers, story authors and domain experts. This project will address the authoring problem by combining novel work in story generation, novel work in visual interfaces for programming, and authoring insights from the only publicly fielded, complete ID (Facade).<br/><br/>Enabling novice authoring of ID will have significant impact: as a new and powerful mode of personal expression, in applications of ID technology to education and training, and for engaging middle school and high-school students in computational expression. Unlike traditional videogames, ID focuses on interpersonal interaction, enabling rich and powerful game-like experiences that focus on meaningful social interaction with autonomous characters within a dynamically generated, changing story. Such technology is essential for serious games (games for education and training) that focus on people-to-people interaction, such as management training, and public service games that tackle complex topics such as racism. Currently, the construction of IDs requires teams of experts, putting them out of reach of individuals and organizations who are not technology and game design experts, but who wish to harness this powerful new medium. The goal of the project is to take the construction of ID out of the hands of experts, and make it available to everyone.<br/>"
742304,"Safety, Security, Rescue, and First Response",IIP,"INDUSTRY/UNIV COOP RES CENTERS, , , ",9/1/2007,9/14/2012,R. Vijay Kumar,"Kumar, RV","Kumar, RV|Taylor, C|Yim, M|Daniilidis, K|Pappas, G",PA,University of Pennsylvania,Continuing grant,Shashank Priya,8/31/2014,"$515,263.00 ","Camillo Taylor, Mark Yim, Kostas Daniilidis, George Pappas",Kumar@seas.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,ENG,"5761, J418, K611, K650","0000, 1049, 122E, 170E, 5761, OTHR",$0.00 ,normalFunding,"The University of Pennsylvania has joined the multi-university Industry/University Cooperative Research Center for Safety, Security and Rescue Research located at the University of South Florida and the University of Minnesota.  The I/UCRC  will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, firefighting, transportation safety, and emergency response to mass casualty-related activities. <br/><br/>The need for safety, security, and rescue technologies has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics.   The Center is built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at member institutions.<br/>"
1659628,REU: From the intertidal to the deep ocean: Monterey Bay Regional Ocean Science REU Program,OCE,"EDUCATION/HUMAN RESOURCES,OCE",5/1/2017,8/3/2018,Corey Garza,"Garza, C","Garza, C",CA,University Corporation at Monterey Bay,Continuing grant,Elizabeth Rom,4/30/2020,"$514,985.00 ",,cogarza@csumb.edu,100 Campus Center,seaside,CA,939558001,8315823089,GEO,1690,9250,$0.00 ,normalFunding,"A Research Experience for Undergraduates (REU) program at the California State University, Monterey Bay (CSUMB) campus will bring eleven undergraduates to CSUMB each summer for three years. This program includes a partnership with five other organizations, including the Naval Postgraduate School, Hopkins Marine Station of Stanford University, Moss Landing Marine Laboratory, Monterey Bay Aquarium Research Institute, and Elkhorn Slough National Estuarine Research Reserve, which are all within a short distance of CSUMB. Students will live at CSUMB, but they will conduct research and be mentored by CSUMB faculty and researchers at partner organizations. Research themes include Oceanography, Marine Biology and Ecology, Ocean Engineering, and Marine Geology, with a wide range of topics in each of these themes. Students receive a stipend, housing and travel expenses. Professional development activities include workshops on scientific ethics and Responsible Conduct in Research (RCR), scientific boating, Geographical Information Systems (GIS), graduate school admissions and fellowships, and scientific communication. Many students will be able to present their research results at a conference or a professional meeting following the program. This program will provide unique research and professional development opportunities to a diverse group of thirty-three students and thus supports the national goal of creating a well-trained scientific workforce.<br/><br/>Students who participate in the this program have the opportunity to work with researchers at a variety of marine science research institutions. Potential research topics include, but are not limited to: Trace Metal Analysis; Internal Wave Dynamics; Ocean Analysis and Prediction; Ocean Modeling; Nearshore Processes; Coastal Circulation; Marine Microbiology; Fish Ecology; Population Genetics; Invasion Ecology; Biomechanics; Remotely Operated Vehicles (ROVs); Autonomous Underwater Vehicles (AUVs); Artificial Intelligence; Coastal Erosion; Seafloor Mapping, and Biogeochemical Analysis."
1000845,CAREER: Telling the Story of a Visual World: Event Classification and Integrated Image Understanding,IIS,ROBUST INTELLIGENCE,9/1/2009,5/4/2012,Fei-Fei Li,"Li, FF","Li, FF",CA,Stanford University,Continuing grant,Jie Yang,6/30/2014,"$514,615.00 ",,feifeili@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7495,"1045, 1187, 9102, 9215, HPCC, 9251",$0.00 ,normalFunding,"The ability to make meaning out of a visual world, such as recognizing objects, scenes and semantically meaningful activities and events, is a cornerstone of artificial intelligence. In computer vision, very important progress has been made recently in object and scene level recognition. But such tasks are often performed without an integrated and coherent description of the scene. Moreover, very few current algorithms are capable of further interpreting higher level semantic meanings of an image such as an event or activity. The goal of this project is to achieve event classification via an integrated image understanding given a single unknown image.<br/>This project aims to push the frontier of integrated and descriptive understanding of images through the development of sophisticated learning frameworks suitable for training algorithms by using a large amount of real-world data such as the ones from the Internet. High accuracy performance, minimal human supervision, flexibility and scalable learning will be the focus of this endeavor. This project?s theoretical framework ties together several areas of computer vision, offers interesting model representations for the machine learning field, and connects more semantically driven visual recognition problem with the natural language processing field. <br/>The results are vital for image understanding technology for the visually- impaired; automatic annotation of images for large digital library as well as the next generation of image retrieval engines; and translation, education and rehabilitation technology for language students and medical patients (such as aphasia, stroke, etc.). <br/>The project?s long-term educational plan focuses on bringing the latest visual computation and cognition research directly into the classroom and the community at large, with an emphasis on reaching the underrepresented groups of students."
916708,Theoretical Foundations of Evolving Knowledge Bases,CCF,"INFORMATION TECHNOLOGY RESEARC, ALGORITHMS",9/15/2009,7/7/2010,Gyorgy Turan,"Turan, G","Turan, G|Sloan, R",IL,University of Illinois at Chicago,Standard Grant,Balasubramanian Kalyanasundaram,8/31/2014,"$514,589.00 ",Robert Sloan,gyt@uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,"1640, 7926","9218, 9251, HPCC",$0.00 ,normalFunding,"This project studies evolving knowledge bases, using tools from theoretical computer science.  As opposed to a database containing facts that can be queried, a knowledge base contains general statements that can be used to derive further implications. Developing a knowledge base, in particular, a knowledge base containing commonsense knowledge that can be used for commonsense reasoning, is a fundamental task of artificial intelligence (AI). This task is taking on a somewhat different focus nowadays, as even partial solutions would have important applications in intelligent agent technology.  One common feature of current approaches to the development of commonsense knowledge bases is the interactive acquisition of web-based user input of knowledge.<br/><br/>Algorithms for developing commonsense knowledge bases have to perform several different tasks, such as reasoning, revising (i.e., updating the current knowledge in the presence of new, potentially conflicting information), and learning (i.e., improving the quality of the knowledge base over the long run). This research addresses all three of these areas.<br/><br/>The bulk of the research uses Horn formulas as the formalism for knowledge representation. Horn formulas are an important class of logical expressions that have been studied for decades in complexity theory, logic programming, databases, and AI, with efficient algorithms for basic reasoning tasks.  Evolving knowledge bases present many new problems for Horn knowledge bases. Particular problems addressed by this research, based on the challenges referred to above, include: Horn-to-Horn belief revision, learning Horn formulas in the model of learning from entailment, approximate minimization of Horn formulas, probabilistic analysis of the set of consequences of random Horn formulas and related combinatorial problems, Horn approximation of knowledge bases and complexity problems for non-classical generalizations of Horn formulas. The latter point towards extending the knowledge representation formalism to handle different aspects of commonsense reasoning.<br/><br/>In more general terms, the objective of the research is to develop algorithms for building knowledge bases that can evolve over time. This task is relevant for both short and long term applications. The research contains a comprehensive approach to several important areas which so far have been mostly been studied separately. In the long term, research in this area will contribute to the development of tools for building better intelligent agents possessing commonsense knowledge and capable of commonsense reasoning. Such agents will expand the scope of and improve the quality of automated services.<br/>"
545726,CAREER: Organizational Adaptation in Artificial Agent Societies,IIS,"Cyber-Human Systems (CHS), COLLABORATIVE SYSTEMS",5/15/2006,6/2/2010,Marie desJardins,"desJardins, M","desJardins, M",MD,University of Maryland Baltimore County,Continuing grant,William Bainbridge,4/30/2013,"$513,640.00 ",,mariedj@cs.umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,CSE,"7367, 7496","1045, 1187, 7367, 9102, 9216, 9251, HPCC",$0.00 ,normalFunding,"The overall goal of this research is to develop methods for organizational adaptation in artificial agent societies, resulting in short-term and long-term changes to the society's structure that lead to demonstrable performance improvements. Specifically, the project will develop techniques to locally adjust connections between agents and to form long-term stable teams, resulting in responsive, effective agent societies. A closely related educational objective is to develop course materials centered around the organizational learning software to be developed. <br/><br/>The organizational structure of a multi-agent system refers to the nature of the physical or virtual connections among agents, including their communication, familiarity, and trust and reputation relationships. Agents can adapt this organization by modifying connections, by changing their patterns of interaction with other agents, and by establishing authority relationships and subcontracts. Effective organizational adaptation requires the agents to maintain knowledge of the other agents to whom they are connected, including their capabilities, competence, resource capacities, reliability, and trustworthiness. From the system designer's perspective, developing protocols and methods by which agents can adapt their own organization requires an understanding of how organizational change affects the system dynamics at an individual and at a global level. This project will develop a theoretical framework for organizational adaptation in a simulated multi-agent society, implement this framework within an experimental testbed, and use the framework to develop techniques for two forms of organizational learning: local adaptation of network structure and contract-based approaches for forming stable teams and coalitions.  These techniques will be applied to several multi-agent applications: multi-robot exploration, distributed vehicle monitoring and tracking, and supply chain management. <br/><br/>Software agents with varying degrees of autonomy are the focus of many current research projects. They are currently used for information gathering, e commerce, virtual entertainment, and mobile robot applications. As intelligent agents become more ubiquitous, it will be of great benefit if the resulting ""agent societies"" can work effectively to provide value to their users. This research will result in fundamental advances in representations, modeling, and self-organizing environments and protocols for agent societies. A primary educational objective of the work is to distribute software and benchmarks to facilitate education and research on multi-agent organizational adaptation. This distribution will include a suite of ""mini-projects"" suitable for classroom assignments or independent study research projects. The other educational objectives include outreach to underrepresented students at primarily undergraduate institutions and involvement in mentoring programs for doctoral students in the artificial intelligence community. <br/>"
1157105,REU-RET Site: Willamette Valley Mathematics Research Consortium for Undergraduates and Teachers,DMS,WORKFORCE IN THE MATHEMAT SCI,3/1/2012,2/24/2012,Inga Johnson,"Johnson, I","Johnson, I|Starr, C",OR,Willamette University,Standard Grant,Jennifer Slimowitz Pearl,2/28/2015,"$513,069.00 ",Colin Starr,ijohnson@willamette.edu,900 State Street,Salem,OR,973013930,5033706617,MPS,7335,"1359, 9250",$0.00 ,normalFunding,"The Willamette Valley Mathematics Research Consortium for Undergraduates and Teachers is a summer REU-RET program at Willamette University, Linfield College, Lewis & Clark College, and the University of Portland. Our program consists of four research teams, one per partner institution, each with four students, one teacher, and two faculty mentors for an eight-week REU and seven-week RET. Each team will focus on one of four challenging research projects from a faculty mentors? area of expertise, such as matroid theory, graph theory, combinatorial game theory, stochastic modeling, artificial intelligence, tiling theory, complex algebraic geometry, computational biology, knot theory or digital sensor networks. Consortium meetings will bring together the four research groups regularly to speak about their projects, learn about the progress of their peers, listen to presentations by invited speakers from academia and industry, and network with other students and faculty. Recruitment for student applicants is nationwide and includes targeted recruitment from underrepresented groups in consultation with the Pacific Northwest Louis Stokes Alliance for Minority Participation. Teacher applicants are recruited regionally in Oregon and southwest Washington.<br/><br/>The primary goal of the Willamette Valley Mathematics Research Consortium for Undergraduates and Teachers is to immerse undergraduates and teachers in a challenging, transformative research experience that will reveal the nature of mathematics research. Throughout the summer undergraduates and teachers will develop new content knowledge, research skills, and an increased understanding of the process of mathematical discovery and research. Within their research teams and at Consortium meetings, participants will improve their ability to communicate current mathematical research in an effective and engaging manner. All participants will develop a greater awareness of career opportunities in STEM fields. As in previous years, REU research results will be disseminated through student co-authored publications, through public presentations, and online. Teachers will create materials to be used in the classroom and disseminated at professional meetings; the REU-RET provides partial funding for students and teachers to present at conferences. Through these program activities our broader goals are to increase the number of students who pursue advanced study and careers in STEM fields, increase the number of teachers with an understanding of mathematical discovery and research, and increase the effective communication of mathematical research."
349663,SBIR Phase II:  Mobility Agents for Persons with Cognitive Disabilities,IIP,SMALL BUSINESS PHASE II,3/1/2004,4/29/2005,Alexander Repenning,"Repenning, A","Repenning, A",CO,AGENTSHEETS INC,Standard Grant,Ian M. Bennett,2/28/2006,"$512,000.00 ",,ralex@cs.colorado.edu,4595 Carter Trail,BOULDER,CO,803013809,3035301773,ENG,5373,"0000, 1545, 9139, 9178, 9251, HPCC, OTHR",$0.00 ,normalFunding,"This Smal Business Innovation Research (SBIR) Phase II project will develop Mobility Agents that help persons with cognitive disabilities use public transportation systems.  The realization of an operational system that wirelessly connects users to real-time bus information through Mobility Agents depends on the fact that public transportation systems are increasingly equipped with GPS (Global Positioning System) systems connected to control centers through dedicated wireless networks.  Controllers use this infrastructure to schedule and optimize operations and avoid organizational problems such as bunching.  Agentsheets proposes to use this existing infrastructure to compute highly personalized information and deliver it on PDAs or cell phones to persons with cognitive disabilities.  Wireless devices with location aware Mobility Agent services that help travelers use public transportation systems, permit caregivers to customize these agents, and monitor the progress of travelers by means of utilizing The Pragmatic Web, a framework for highly customizable Web information; and Deductive Tracking, a combination of sensor fusion and minimalist common sense AI that creates more reliable tracking information.  Agentsheets will explore design and implementation issues for agent-based real-time user interfaces on handheld devices; build the system, and test it in a real-world setting using the Boulder bus system as a public transportation test bed.<br/><br/>The Mobility Agents technology turns general GPS-based information into personalized, practical information.  Customization mechanisms range from simple preferences to rule definition, and are relevant to the fields of End-User Development/Programming, Visual Languages, and Human Computer Interaction.  Deductive Tracking contributes to Sensor Fusion and Artificial Intelligence.  Parts of a Phase I 3D engine, used in the real-time transportation visualization, have been made available to other research organizations and are already in use.  This technology proffers assistance to persons with cognitive disabilities.  The elderly and other groups will also benefit from the same technological developments.  This technology creates new service organizations.  It reduces the need for human escorts, increases the autonomy of persons with cognitive disabilities, and decreases the need for federal support. <br/>..."
224363,CISE Research Resources: Teams of Miniature Mobile Robots,CNS,"CISE RESEARCH RESOURCES, COMPUTING RES INFRASTRUCTURE",11/1/2002,5/16/2007,Nikolaos Papanikolopoulos,"Papanikolopoulos, N","Papanikolopoulos, N|Nelson, B|Gini, M|Boley, D|Durfee, W",MN,University of Minnesota-Twin Cities,Continuing grant,C.S. George Lee,10/31/2007,"$509,452.00 ","Bradley Nelson, Maria Gini, Daniel Boley, William Durfee",npapas@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,"2890, 7359","2890, 9152, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"EIA-0224363<br/>Nikolaos Papanikolopoulos<br/>Daniel L. Boley; William K. Durfeet; Maria L. Gini; Bradley J. Nelson<br/>University of Minnesota-Twin Cities<br/><br/>CISE RR (Collaborative): Teams of Miniature Mobile Robots<br/><br/>This project, redesigning and manufacturing a team of Scout-Ranger robots, improvises on the current scout design through novel design schemes, software development, sensory fabrication, and processing sensory data in real time. The research extends work based on a previous generation of Scouts. The institution developed a heterogeneous robotic team emphasizing the ""Scout"" robot, launched and controlled by a larger platform, the ""Ranger."" After deployment, Scouts have a unique combination of mobility modes including rolling and hopping, multiple sensing capabilities for navigation (e.g., cameras, microphones), full communications for data and instructions (controlled by cellular phones), and onboard computational resources. Their functionality is increased by actuated wheels and miniature grappling hooks and can serve applications such as reconnaissance, earthquake rescue operations, homeland security space exploration, fire rescue missions, hostage release operations, etc. Their design requires a compromise in power, sensor types, locomotion, and size. However, rather than concentrating on size, this work focuses primarily on communications, sensor fabrication, and sensor placement. Solutions to research problems are sought in areas of miniature-robot design, communication for distributed robotics (especially in low-bandwidth situations), and resource allocation for distributed robotics. Specifically:<br/>1. Designs of miniature robots: modifying original scout design, giving special care to image-processing<br/>2. Software support for Robot Teams: sharing resources leading to decision making and planning<br/>3. Tradeoffs between sharing communication channels and performance in motion detection<br/>4. Sensor fabrication in the micro fabrication lab<br/>5. Analysis of sensory data (images) of the team of robots; seeking optical positioning of the sensor to maximize coverage/redundancy<br/>6. Analysis of traffic patterns (of humans) in a building<br/>7. Detection of anomalies on those patterns, or detection of unusual situations (i.e. smoke): using method of Principal Direction Divisive Partitioning<br/>8. Innovative uses of Scouts: tele-rehabilitation, dynamic hopping devices, etc.<br/>The educational plan includes the incorporation and mentoring of women and minority students. The robots will be used not only in Computer Vision and Robotics classes, also, in Algorithms, Data Structures, Operating Systems, and Artificial Intelligence. Outreach activities, proposed for K-12, along with public outreach complement the research agendas."
307906,Representation and Reasoning about Adaptive Interfaces,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/15/2003,5/25/2005,Daniel Weld,"Weld, D","Weld, D",WA,University of Washington,Continuing grant,Douglas H. Fisher,6/30/2007,"$506,951.00 ",,weld@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6856,"9218, HPCC",$0.00 ,normalFunding,"Previous work on adaptive websites, wearable computing and intelligent user interfaces has shown that these tasks present significant challenges to the fields of machine learning, knowledge representation, and reasoning under uncertainty. This project will address the following core artificial intelligence problems using adaptive interfaces as inspiration and an experimental testbed.<br/><br/>1) Given a database of behavioral data for one or more users, what is the best representation for encoding a predictive model of user behavior? What are the best algorithms for learning such a model? This project will generalize Markov models and Dynamic Bayes Nets to create Relational Markov Models (RMMs) and Dynamic Probabilistic Relational Models (DPRMs) respectively. Effective inference and learning algorithms will be developed and evaluated against traditional propositional methods.<br/><br/>2) Representing user interfaces is a major challenge. This project will extend the work on task-centered user-interface design with ideas from the planning literature (sensory actions, exogenous events) to develop an expressive task formalism with clear semantics.<br/><br/>3) Adapting an interface, which is represented as an augmented plan schema, requires new methods for reasoning about actions. In addition to analyzing causal dependency structures, restructuring operations akin to partial evaluation will be necessary. Fast inference is an essential component of this project. A satisficing plan is not good enough, so the work will use a utility model combining plan length with a cognitive dissonance factor. <br/><br/>Methodologically, the project is composed of six coupled activities: (1) Formalize the RMM and DPRM representations; (2) Devise efficient particle-filtering inference methods; (3) Develop learning algorithms based on shrinkage; (4) Formalize a declarative, plan-based interface representation, and evaluate expressiveness on a corpus of adaptation examples; (5) Devise a comprehensive set of adaptation transformations and a utility metric; (6) Implement the methods, incorporate in a user interface platform, and perform extensive experiments. <br/><br/>The research will have broad impact, because progress in user interfaces has been dwarfed by the simultaneous enormous increase in the speed of computers. Artificial intelligence techniques are perhaps the most promising avenue for harnessing processing power to increase user productivity. This project will contribute to improved user interfaces not only in desktop software but also in personalized information systems for wearable computers.<br/>"
643752,CAREER: Making music documents accessible in musical terms,IIS,INFO INTEGRATION & INFORMATICS,1/1/2007,5/24/2011,Bryan Pardo,"Pardo, B","Pardo, B",IL,Northwestern University,Continuing grant,Maria Zemankova,12/31/2012,"$506,669.00 ",,pardo@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7364,"1045, 1187, 7364, 9216, 9251, HPCC",$0.00 ,normalFunding,"Making Music Documents Accessible in Musical Terms<br/>One of the key problems facing us in the 21st century is information retrieval and management. Finding ways to automatically index, label, and access multimedia content (such as music documents) in meaningful ways is an open research question that increases in importance as multimedia databases proliferate and grow. Music collections, such as the 3.5 million recordings in Apple Computer's iTunes repository, comprise one of the most popular categories of on-line multimedia content.<br/>For scholars, musicians and even casual listeners, the music document is only the beginning, a tool to initiate the task at hand. Musicians may be interested in remixing a musical recording even though all they have available is the final mix. Scholars may wish to analyze the harmonies in a piece. Others may want karaoke that follows the singer's expressive timing, or a way to remove the sound of an unwanted cell phone ring from a recording of their daughter's flute recital.<br/>The objective of this research is to develop two key facilitating technologies to enable these kinds of interactions: score alignment and source separation. Score alignment, involves aligning an audio performance and to the events in a machine-readable music score. When aligned to a score, a performance can be addressed by melodic and harmonic content. We propose to advance the state-of-the-art by enabling a machine to follow partially specified scores (such as Jazz lead sheets). This alignment require significant inference about likely surface structures (the note sequence in an improvised solo) from deeper structural descriptions in the score (the chords in a lead sheet). This will enable alignment of entire classes of music, such as much Jazz, Pop and Rock, that cannot currently be aligned to scores.<br/>The second technology, source separation, is the process of isolating individual source signals, given mixtures of the source signals. With source separation, individual instruments and sounds can be accessed, identified and manipulated in ways beyond the power of commercial audio search and editing software. We will advance the field through score-informed separation, as well as new iterative methods for approximating source models from acoustic mixtures.<br/>The idea is to develop a synergistic system for music-information-retrieval and interaction that uses multiple document modalities (written scores, audio files, MIDI) to infer more about the music structure than is possible using a single modality.<br/>This research will impact the signal-processing community (source separation), the music information retrieval community (music indexing and search) and the artificial intelligence community (tools for intelligent abstraction of real-world data). To broadly disseminate the work, demonstration tools will be made available over the internet and results will be published in relevant journals and conferences. The PI is committed to involving undergraduates and members of historically underrepresented groups in research, working with the SROP and UROP programs to make this happen. The PI also teaches the course ""Machine Perception of Music"" where research results will be disseminated to a wide variety of students."
433653,Intentional Vision in Humans and Robots,IIS,"HSD - DEC, RISK & UNCERTAINTY, EPSCoR Co-Funding",9/15/2004,8/18/2007,Daniel Levin,"Levin, D","Levin, D|Kawamura, K|Wilkes, DM|Saylor, M",TN,Vanderbilt University,Standard Grant,William Bainbridge,8/31/2008,"$503,958.00 ","Kazuhiko Kawamura, D. Mitchell Wilkes, Megan Saylor",daniel.t.levin@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,"7322, 9150","0000, 9150, 9152, 9178, OTHR, SMET",$0.00 ,normalFunding,"This project will explore how people construe the representational states of robots, and the cognitive and perceptual basis for this construal, particularly with respect to vision. Specifically, a series of experimental studies will explore people's beliefs about a highly anthropomorphic humanoid robot named ISAC. The most basic experiments will ask whether subjects overestimate ISAC's ability to see visual changes. Follow-ups will explore the degree to which these misunderstandings affect assumptions that might underlie on-line human-robot interactions, and this research will explore the perceptual basis for invoking an anthropomorphic model. <br/><br/>People make systematic mispredictions about visual experience, vastly overestimating their own and others' ability to see visual changes, and further, these overestimates also apply to mechanical representational systems such as computers when they are described as having anthropomorphic beliefs, goals, and intentions. Research has also begun to identify specific perceptual cues that may serve to bootstrap knowledge about representations. The focus of this project is both to understand intentional vision in the human users of robotic systems, and ultimately to use this understanding as the basis for improving the artificial intelligence (AI) underlying the robots' processing of human users' intentions.<br/><br/> The research represents a novel application of insights gained from cognitive development to understanding how adults construe mechanical representational systems. As such, it not only has the potential to advance our understanding of adults' models of representation and the perceptual basis of these models, but it also has the potential to guide the development of the AI underlying human-robot interaction. In particular, this research will isolate situations in which user models of humanoid robots may diverge from reality, and specify an ecologically valid basis for AI programming that can structure the coding of intentional human action. <br/><br/> This research will not only enrich the existing collaborations between the cognitive science and engineering communities at Vanderbilt University, but it will also have a broader educational impact. Testing these ideas in the context of a humanoid robot will also provide a compelling context for both graduate and undergraduate students to consider basic questions of representation and mind, and it is expected that Vanderbilt undergraduates will play a crucial role in assisting with this research. <br/><br/>Humanoid robots are currently being developed to fill real-world functions ranging from household chores to elder-care. Among the challenges these devices pose, perhaps the most difficult is the need for a two-way understanding between the robots and their human users. Not only do humans need to understand robot capabilities and representational states, but robots require the same understanding of humans. This is particularly true if robots are to have productive and flexible interactions with humans, a process that requires a careful alignment of understanding that is dynamic enough to coordinate a complex flow of changing circumstances, beliefs, desires, and intentions.  This research will strengthen the scientific basis for efforts to improve human-robot interaction.<br/>"
915071,RI: Small: Foundations and Applications of Generalized Planning,IIS,ROBUST INTELLIGENCE,9/1/2009,9/13/2010,Shlomo Zilberstein,"Zilberstein, S","Zilberstein, S|Immerman, N",MA,University of Massachusetts Amherst,Standard Grant,James Donlon,8/31/2013,"$503,519.00 ",Neil Immerman,shlomo@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,"7495, 7923, 9215, HPCC",$0.00 ,normalFunding,"This project is developing automated methods of artificial intelligence (AI) for creating generalized plans that include loops and branches, can handle unknown quantities of objects, and work for large classes of problem instances. One of the key challenges is to reason about plans with loops and to do so without using automated theorem proving, which tends to be intractable. In particular, research is accomplishing the following goals: (1) develop new theoretical foundations for generalized planning; (2) develop effective abstraction mechanisms and new plan representations to support these new capabilities; (3) develop effective algorithms for plan synthesis as well as generalization of sample plans; (4) develop analysis tools to reason about the applicability, correctness and efficiency of generalized plans; (5) extend the framework to include sensing actions, conditional plans, and domain-specific knowledge in the form of partially specified plans; (6) create a new set of challenging benchmark problems and perform a rigorous evaluation of the approach; and (7) increase the interaction between the AI community and other communities, particularly model checking, that study the abstraction mechanisms and theoretical foundations necessary for generalized planning. This new framework may significantly improve the scope and applicability of automated planning systems."
9873491,KDI: Learning Through Writing Using Adaptive Tutoring Systems: Modeling Knowledge Representations from Open-Ended Questions,DRL,"HUMAN COGNITION & PERCEPTION, SOFTWARE ENGINEERING AND LANGU, LEARNING & INTELLIGENT SYSTEMS",10/1/1998,8/5/2003,Adrienne Lee,"Lee, A","Lee, A|Cowie, J|Foltz, P",NM,New Mexico State University,Standard Grant,John Cherniavsky,9/30/2003,"$501,468.00 ","Jim Cowie, Peter Foltz",alee@crl.nmsu.edu,Corner of Espina St. & Stewart,Las Cruces,NM,880038002,5756461590,EHR,"1180, 2880, 8888","1337, 8888, OTHR, 0000",$0.00 ,normalFunding,"This project combines relevant, recent findings from psychology, education, artificial intelligence, and computational linguistics in learning and knowledge representation and applies them to the development of intelligent tutoring systems (ITSs). Learning theory can be extended through the study of the evolution of different types of knowledge representations together with procedural representations. Thus, this research will examine learning, the change in students' knowledge representations, as they integrate multiple sources of information.<br/><br/>Although ITSs have been developed to examine learning for well-defined problems requiring a limited set of possi-ble responses, ITSs have had problems evaluating open-ended questions that require the student to provide natural language responses. However, asking students to provide written answers to essay questions can provide a much richer representation of student knowledge and also improving students' writing abilities. Thus, this research will demonstrate that ITSs can be developed which extend beyond simple responses and that these ITSs can adapt more readily to provide individualized instruction to students. In order to develop these ITSs, this research uses the computational linguistic technique Latent Semantic Analysis (LSA) to model student knowledge representations from essay-based answers within tutoring systems.<br/><br/>As students' knowledge representations change, so too should their essay responses, including more knowledge and improving in quality. Therefore such an ITS can provide the necessary feedback for student improvement (both in domain knowledge and in writing skill). In addition, the ITS can initially assess the students' ability and provide extra help to the students with help gradually fading as the student gains more knowledge (e.g., scaffold-ing). Thus, by incorporating LSA into an ITS, individualized instruction is possible for adjusting both the level of feedback provided and the content presented. The goal of this research is thus to study the acquisition of complex skills through incorporating LSA, a method for representing students' knowledge representations through their essays, into intelligent tutoring systems.<br/><br/>Because this research focuses on complex skills from knowledge-rich domains, results from this project extend theories of learning in psychology by providing information about how multiple sources of knowledge are integrated into students' knowledge representations as they are learning . The research also has theoretical implications for educational psychology including the systematic examination of scaffolding for two content areas. In addition, because LSA is an automatic method for deriving knowledge representations, this research has broad implications for developing systems for training in any area of content knowledge."
953756,CAREER: New Directions in Computing Game-Theoretic Solutions: Commitment and Related Topics,IIS,"ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS, COMPUT GAME THEORY & ECON",3/1/2010,2/19/2014,Vincent Conitzer,"Conitzer, V","Conitzer, V",NC,Duke University,Continuing grant,Hector Munoz-Avila,2/28/2015,"$500,002.00 ",,conitzer@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,"7495, 7796, 7932",1045,$0.00 ,normalFunding,"Game Theory occupies an important place in the foundations of multi-agent systems in artificial intelligence. Research under this award focuses on settings where one agent can commit to her (possibly randomized) strategy before the other agent moves. We consider how to compute optimal strategies to commit to in games with a combinatorial structure, extensive-form games, and repeated/stochastic games. Among other topics are connections to learning in games and mechanism/environment design, and the implications of commitment for the efficiency of computing game-theoretic solutions more generally.<br/><br/>The main objective of the research is to make scientific contributions to artificial intelligence, multi-agent systems, and computational game theory, but to also advance real-world applications. For example, other researchers have expanded on the PI's prior theoretical research (with his PhD advisor) to apply the commitment framework to security applications, such as the placement of checkpoints and canine units at Los Angeles International Airport and the scheduling of Federal Air Marshals. The research performed under this award aims to provide a solid scientific foundation for improving and expanding this and related applications. The award also helps to build connections between computer science and economics, the traditional home of Game Theory. This interdisciplinary link can help diversify the computer science community, intellectually and demographically. Research is tightly integrated with the PI's educational efforts, which include the development of courses in Computational Microeconomics and Game Theory and an approved Computational Economics minor."
822696,SBIR Phase II: Artificial Intelligence Tutoring and Assessment for Teacher Development,IIP,SMALL BUSINESS PHASE II,7/15/2008,7/15/2008,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Glenn H. Larsen,6/30/2010,"$500,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,5373,"1653, 9216, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II research project focuses on bringing the power and benefits of artificial intelligence tutoring technology to the arena of teacher professional development (PD). The proposed innovation is a teacher professional development system built on the principles of artificial intelligence, and delivered via the Internet. Similar to a flight simulator, this technology will offer a realistic but benign opportunity to test and expand a teacher's preparedness through practice with realistic classroom situations. A key objective is the creation of a classroom simulator which incorporates a virtual master teacher, to help teachers deepen their content understanding, learn to respond to student questions more effectively, practice proven pedagogical techniques for improving student understanding and conduct self-monitoring and assessment before getting in front of a live class. <br/><br/>An increasing number of schools are forced to rely on new or out-of-field teachers to fill the gap for teaching science and mathematics, often resulting in a substantial decline in quality, depth and individual attention students receive. Because of the well-documented problems of teachers teaching out of their content areas, and low-performing schools having greater percentages of lesser-qualified teachers, states have established stronger criteria for in-service teachers and newly qualifying pre-service teachers. Middle and high school science and mathematics are the areas where most out-of-area teaching is occurring. In the National Center for Education Statistics (NCES) report, 'The Condition of Education', a key finding is that high school students in high-poverty, high-minority schools were more often taught science, mathematics and English courses by out-of-field teachers than their peers in low-poverty, low-minority schools. This research is expected to impact these issues and in addition address the goals of the American Competitiveness Initiative and the requirements for highly qualified teachers identified in the 'No Child Left Behind' initiative."
1554626,CAREER: Smart Protection for DC Power Systems: Distributed and Proactive Approach,ECCS,"ENERGY,POWER,ADAPTIVE SYS",3/1/2016,1/19/2016,Jae-Do Park,"Park, JD","Park, JD",CO,University of Colorado at Denver,Standard Grant,Anil Pahwa,2/28/2021,"$500,000.00 ",,jaedo.park@ucdenver.edu,"MS F428, AMC Bldg 500",Aurora,CO,800452570,3037240090,ENG,7607,"1045, 155E",$0.00 ,normalFunding,"The goal of this CAREER project is to provide intelligent solutions for the protection of DC power systems, which is one of the major barriers that prevent the wide usage of DC power systems. DC power systems have received renewed attention due to a number of advantages they offer such as easy renewable energy resource integration, high-efficiency long distance transmission, and simpler interface with power electronics converters. Applications including microgrids with distributed generators, bulk power transmission, and low-voltage distribution systems have been investigated. Compared to the control aspects of DC systems that have made sizable progress, system protection has always been a challenge. The research in this project will address protection issues for DC power systems, which will contribute to strengthen this important aspect of DC power systems and can have impact in various applications. The outcomes of this research will be disseminated through presentations and publications and can be readily utilized in conjunction with other aspects of distributed and/or sustainable energy applications using DC power to generate synergistic effects on overall system reliability improvement. Furthermore, this CAREER project will academically and financially support graduate students and nurture them to prepare them as part of the next generation of multidisciplinary researchers and engineers. The project will also provide ample research opportunities to undergraduate students.<br/><br/>While the advantages of DC power systems are great, the protection aspects of these systems have posed many challenges such as effectively breaking a DC arc, autonomously locating a fault within a microgrid, DC protective equipment, and certainly the lack of standards, guidelines and experience. Although protection technology for AC systems has a long history and maturity, it is difficult to directly apply these to DC systems because of the non-alternating nature and fast dynamics of DC power. Hence, the protection of DC power systems needs to take a fundamentally different approach than that of existing AC technologies. Furthermore, complex modern power systems need more intelligence for their operation. In this CAREER project, a distributed and proactive approach will be taken as the project aims to provide a protection framework with swift fault current interruption, accurate fault location, and distributed decision-making based on various system parameters. The protection framework development will contain integrated components for fast responses and compound decisions based on multi-dimensional intelligence. The successful execution of this CAREER project will contribute to the implementation of modern power systems that take advantage of DC power. The activities will result in multidisciplinary research as well as educational impacts, and will provide interesting and useful applications of advanced artificial intelligence, control and communication technologies to the power and energy system area."
1651538,CAREER: Evaluating the Process-Structure-Property Relationships of Carbon Nanotube Forests with In-Situ Synthesis Observation and Dynamic Simulations,CMMI,"CAREER: FACULTY EARLY CAR DEV, Materials Eng. & Processing",7/15/2017,3/10/2017,Matthew Maschmann,"Maschmann, M","Maschmann, M",MO,University of Missouri-Columbia,Standard Grant,Thomas F. Kuech,6/30/2022,"$500,000.00 ",,MaschmannM@missouri.edu,115 Business Loop 70 W,COLUMBIA,MO,652110001,5738827560,ENG,"1045, 8092","1045, 8021, 8025, 9150",$0.00 ,normalFunding,"This Faculty Early Career Development (CAREER) Program research project investigates how carbon nanotubes interact with one another during collective growth by using direct observation and complimentary numerical simulation. Nanoscale materials such as carbon nanotubes offer superior mechanical, electrical, and thermal properties relative to many other conventional engineering materials. When vast arrays of carbon nanotubes are synthesized together they form interconnected and self-organized populations known as carbon nanotube forests. The interactions between growing nanotubes lead to the structures bending and kinking which detract from their mechanical properties.  Numerical simulations employing artificial intelligence and machine learning will facilitate the rapid exploration of high-dimensional processing space associated with nanotube formation and will guide the experimental aspects of this project. The results of this work and the understanding of the synthesis process will help control the mechanisms of carbon nanotube interactions during their synthesis, leading to enhanced and engineered carbon nanotube forest properties. Middle school students will be engaged with the research through a one-week summer camp in which hands-on nanoscale materials engineering will be merged with artistic expression through collaboration with the University of Missouri Museum of Art and Archeology. The results of these investigations will enable the use of the art and observation at the nanoscale to engage and inspire grade school children in STEM-based learning in cooperation with the university art museum.<br/><br/>The forces and mechanisms that drive carbon nanotube forest self-assembly are currently poorly understood, in part because in-situ diagnostic techniques with sufficient resolution to interrogate the evolving mechanical interactions are lagging. This project will implement direct visualization of carbon nanotube forest growth and assembly using in-situ synthesis methods within scanning and transmission electron microscopes. A variety of synthesis conditions will be investigated to link the role of important processing factors to the observed behaviors. Transmission electron microscope techniques will facilitate not only time-resolved visual inspection of individual nanotubes and their host catalyst nanoparticles but also compositional analyses at or near atomic resolution. Scanning electron microscope techniques will examine coordinated assembly of carbon nanotubes within the larger population at length scale ranging from tens of nanometers of tens of microns. Experimental observations will be input into a time-resolved finite element simulation to interrogate the forces generated during nanotube forest assembly. After synthesis, the mechanical properties of carbon nanotube forests will be measured using in-situ scanning electron microscope compression and simulated with the finite element model for validation. The validated model will serve as a vehicle for rapid assessment of process-structure-property relationships using an artificial intelligence algorithm to autonomously search for appropriate synthesis conditions that satisfy user-defined forest property sets. A carbon nanotube forest synthesis simulation tool will be made publically available at nanohub.org to facilitate broader impact of the simulations developed in this project."
643742,"CAREER: Discriminative, Syntactic Machine Translation",IIS,ROBUST INTELLIGENCE,12/15/2006,6/29/2011,Dan Klein,"Klein, D","Klein, D",CA,University of California-Berkeley,Continuing grant,Tatiana D. Korelsky,11/30/2012,"$500,000.00 ",,klein@cs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,7495,"1045, 1187, 7495, 9218, HPCC",$0.00 ,normalFunding,"Statistical machine translation systems have seen increasing success in recent years, due to improved statistical methods and larger quantities of training data. However, their ability to generalize has been limited by overly simplistic representations, which are not sensitive to linguistic structure. This project investigates techniques for syntax-aware machine translation in three directions: (1) extending monolingual grammar induction models to the multilingual case, (2) designing discriminative tree-to-tree models which account for structural divergences between languages, and (3) building efficient inference systems for such models.<br/><br/>This project aims to develop general models and algorithms for syntactic translation, as well as building end-to-end translation systems. A particular focus is on language pairs for which monolingual resources do exist, but for which large bilingual training texts are unavailable. Another focus is exploring the way in which monolingual algorithms can be extended or applied to the multilingual case. In addition to the production of new translation systems and algorithms, a central goal is to develop and make available educational materials suitable for use in training undergraduate and graduate students in the areas of machine translation specifically and artificial intelligence more broadly."
447685,CAREER: Integrating denotational meaning into probabilistic language models,IIS,"HUMAN LANGUAGE & COMMUNICATION, ROBUST INTELLIGENCE",5/15/2005,3/20/2009,William Schuler,"Schuler, W","Schuler, W",MN,University of Minnesota-Twin Cities,Continuing grant,Tatiana D. Korelsky,4/30/2011,"$500,000.00 ",,schuler.77@osu.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,"7274, 7495","1045, 1187, 9218, HPCC",$0.00 ,normalFunding,"The purpose of this project is to develop probabilistic language models that efficiently integrate denotational semantic information into syntactic and phonological stages of recognition for use in spoken language interfaces to sensor or robotic agents.  This integration is intended to allow information about the meanings or denotations of words in the agent's current environmental context to influence the probability estimates it assigns to hypothesized analyses of its input, before any recognition decisions have been made, so that the interfaced agent can favor in its search those analyses that ""make sense"" in its representation of the current state of the world.  Since these models can be trained on the same kinds of examples that may be used to establish word meanings in the agent's lexicon, it is expected that they will be easier to adapt to changing domains than those relying exclusively on word co-occurrence statistics in fixed corpora.<br/><br/>A recognizer based on this model will eventually serve as a testbed for evaluating spoken language interfaces to networked scout robots in search and rescue applications and mobile manipulation robots in home care tasks or materials handling applications in joint projects with other members of the Artificial Intelligence Robotics and Vision Lab, as well as in applications that require navigating digital road maps or other geographic data in joint projects with members of the Spatial Databases group at the University of Minnesota.  This model will also be adapted as a framework for teaching natural language processing concepts, providing students with a broader context in which various processing components may fit together, and inviting students to consider innovative solutions to natural language processing problems that cross the boundaries among traditional components."
1216045,RI: Small: Efficient Bayesian Learning from Stochastic Gradients,IIS,ROBUST INTELLIGENCE,9/1/2012,8/30/2012,Max Welling,"Welling, M","Welling, M|Shahbaba, B",CA,University of California-Irvine,Standard Grant,Jie Yang,8/31/2016,"$500,000.00 ",Babak Shahbaba,welling@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,7923,$0.00 ,normalFunding,"The total volume of data was estimated to be 0.8 Zettabytes in 2009 (1 Zettabyte = 1 trillion gigabytes) and predicted to grow to a staggering 35 Zettabytes in 2020, doubling every two years. Therefore, one of the primary challenges for machine learning is to develop statistically principled methods that will scale up to very large datasets. Moreover, we would like to (efficiently) learn highly complex models without the worry of overfitting and with confidence levels on our predictions. While Bayesian methods satisfy these latter desiderata, the current state-of-the-art inference procedures based on Markov Chain Monte Carlo (MCMC) posterior sampling do not meet the ""big-data"" challenge.<br/><br/>We propose a new family of MCMC procedures that typically requires only a few hundred data-cases per update. These ""stochastic gradient MCMC samplers"" inherit the efficiencies of stochastic approximation methods, but will asymptotically sample from the correct posterior distribution. This endows this family of methods with an ""anytime"" property, namely that one can sample cheaply from a rough approximation of the posterior but can obtain more accurate samples in exchange for more computation.<br/><br/>We believe this new class of methods will for the first time unlock the full strength of Bayesian methods for very large datasets. Due to their highly practical nature, the techniques developed under this grant are likely to gain widespread acceptance across a broad spectrum of academic disciplines as well as in industry. To expedite the transfer process we will publish open source software on our webpages and collaborate with a company (ID Analytics) to work on realistic, large scale inference problems. Two students at the University of California, Irvine (UCI) will be employed on this grant who will collaborate with a number of students and postdocs in the UK (University of Oxford and University of Bristol). UCI and UK students will also be exchanged for a few weeks a year to cross-fertilize research and to gain international experience. Research results from this grant will be integrated into artificial intelligence and machine learning courses at UCI through class projects."
709338,CRI: CRD - Developing a Dark Web Collection and Infrastructure for Computational and Social Sciences,CNS,"COMPUTING RES INFRASTRUCTURE, INFO INTEGRATION & INFORMATICS",9/1/2007,7/20/2008,Hsinchun Chen,"Chen, H","Chen, H",AZ,University of Arizona,Continuing grant,Maria Zemankova,8/31/2012,"$500,000.00 ",,hchen@eller.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,"7359, 7364","7364, 9216, HPCC",$0.00 ,normalFunding,"Researchers all over the world in a variety of disciplines are working on developing the means for understanding extremist groups, terrorism and terrorists: their effects on the world; how they communicate, organize and propagate themselves; how they are funded; and who they connect with and why.  This project is intended to create a large archive, known as the ?Dark Web Archive,? and a research infrastructure for use by computer and information scientists as well as social scientists studying a wide range of computational problems and social and organizational phenomena. The archive will ultimately comprise testbed data containing thousands of multilingual websites and multimedia files by U.S. domestic, Middle Eastern, and Latin American terrorist and extremist groups.<br/><br/>The intent is to support computer and information science (CIS) researchers in using the Dark Web archive for a wide range of exercises:  to develop video and voice recognition technologies, advance information retrieval techniques whether in English or other languages, and improve methodologies in data and text mining as well as machine learning and artificial intelligence.  Social scientists will also be able to use the archive, for example,  to study dynamic ?dark? networks and the linkages or relationships between organizations, examine use of the web by extremist/terrorist groups, and study the inter-relationship of culture, religion and politics.  The Dark Web archive will support the comparison of current and historical data, minimize manual analysis by researchers in the social sciences; and enable the replication of experiments by researchers.  In addition to supporting researchers in information, computer and social sciences, this project will also have some utility for the national security sector, including law enforcement and the intelligence community.<br/><br/>The project Web site (http://ai.arizona.edu/research/terror/CRDabstract.htm) provides access to the Dark Web archive, research infrastructure, and additional information. <br/><br/>"
347631,"CAREER: Statistical Learning Theory for Natural Language Processing: Theory, Algorithms and Representations",IIS,"HUMAN LANGUAGE & COMMUNICATION, ROBUST INTELLIGENCE",6/1/2004,7/24/2008,Michael Collins,"Collins, M","Collins, M",MA,Massachusetts Institute of Technology,Continuing grant,Tatiana D. Korelsky,5/31/2010,"$500,000.00 ",,mcollins@cs.columbia.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,"7274, 7495","1045, 9216, HPCC",$0.00 ,normalFunding,"The focus of this project is the further development of statistical methods in the context of natural language processing (NLP).  The project involves research in three core theoretical or algorithmic areas, and in three application areas within NLP.  The core areas are supervised learning for natural language tasks; a study of the issues of efficient search and parameter estimation, particularly by exploring connections between NLP models such as weighted context-free grammars and work on search and estimation in graphical models; and finally, a study of unsupervised or partially supervised learning.  The three application areas are syntactic analysis; learning in natural language interfaces; and learning approaches to information extraction.<br/><br/>A first aim is to further develop a theoretical understanding, and new algorithms, for machine learning approaches to natural language. A second aim is to apply these algorithms to natural language problems, and in particular to develop an understanding of the representations which lead to good performance on these tasks. <br/><br/>Improvements in core technologies for machine learning in natural language processing domains could have impact on a wide range of NLP applications. Our aim is to make it relatively simple to build a natural language interface, or information extraction system, in a new domain.  Advances in our theoretical understanding of learning in language problems could also have an impact in linguistics, in studies of learnability or language acquisition.  Finally, an important goal of the research and educational plan is to build connections between computational linguistics and other fields, particularly machine learning, and probabilistic representation and reasoning in artificial intelligence.<br/>"
1117801,HCC: Small: Manipulating Perceptions of Robot Agency,IIS,Cyber-Human Systems (CHS),9/1/2011,8/5/2011,Brian Scassellati,"Scassellati, B","Scassellati, B",CT,Yale University,Standard Grant,Ephraim P. Glinert,8/31/2014,"$500,000.00 ",,brian.scassellati@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,7367,"7367, 7923",$0.00 ,normalFunding,"Robots are increasingly becoming a part of daily human interactions: They vacuum floors, deliver medicine in hospitals, and provide company for elderly and disabled individuals. This project examines one aspect of people's interactions with these robots: how intentional and self-reflective the robot seems to be. Because the perceived agency of a robot affects many dimensions of people's interactions with that robot, it is important to understand how features of robot design, such as its behavior and cognitive abilities, affect perceptions of agency.  This question is addressed through a series of laboratory experiments that manipulate behavior and cognitive abilities and measure the degree of agency attributed to socially interactive robots.<br/><br/>Intellectual merit: The project will lead to new measures of perceived robot agency and new knowledge about how people collaborate with robots. The results will inform how engineers construct robots, how artificial intelligence researchers conceptualize behavioral architectures, and how designers craft interactions to produce robots that engage people in simple ways.<br/><br/>Broader impacts: The project will provide a new quantitative measurement of agency that can be used in human-robot interaction and related disciplines and new information that can inform how agency is modeled in the design of human-robot interactions, especially in situations where recognition of agency is a primary factor.  The outcomes will be used to improve socially assistive robotics for children with social deficits. The project will also enhance interdisciplinary research offerings for graduate and undergraduate students at the investigators' institution."
1652735,CAREER: Urban Transport Network Design with Privacy-Aware Agent Learning,CMMI,"CAREER: FACULTY EARLY CAR DEV, CIVIL INFRASTRUCTURE SYSTEMS",3/15/2017,3/14/2017,Joseph Chow,"Chow, J","Chow, J",NY,New York University,Standard Grant,Cynthia Chen,2/28/2022,"$500,000.00 ",,joseph.chow@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,ENG,"1045, 1631","029E, 036E, 039E, 1045",$0.00 ,normalFunding,"Technological advances for transportation systems are quickly evolving from their roots in highway materials and traffic control 70 years ago to technologies that support ""smart cities"": autonomous vehicles, on-demand mobility services, and traffic control with machine learning, among others. In 2016, the U.S. Department of Transportation proposed spending $4 billion on autonomous vehicles, and pledged $40 million in tackling smart cities as a grand challenge. However, successful operation of these technologies in a large scale, highly congested city remains prone to operational pitfalls and obstacles. For example, how should a service operator best deploy their vehicles or inform their travelers in real time to optimize service and learning potential simultaneously, while acknowledging their privacy? Some high profile failures include the on-demand transit service Kutsuplus in Helsinki and the Car2Go car share service in San Diego. These systems are highly dynamic, but methods in machine learning and dynamic optimization are not designed for the unique intricacies of urban transport networks. This Faculty Early Career Development (CAREER) Program project is for integrated research and advanced education to create new technologies for these dynamic systems, train students and professionals in these technologies, and engage with private operators and incubators in New York City to operationalize them. The project will use real data from industry partners in ridesharing and autonomous vehicle systems operations, and drive innovation and entrepreneurship by defining new functional roles that mix transportation, computer science, and economics. This will culminate in a test bed in New York City that is expected to shape a next-generation national interdisciplinary research center on ""smart transit"" over the next decade. The PI will recruit local high school students to work with his PhD students each summer; the high school students will be identified through the university's ARISE (Applied Research Innovations in Science and Engineering) program which creates STEM education experiences for women, minorities, and students from low-income backgrounds.  <br/><br/>The research marries three theories together in order to address these new mobility problems in smart cities: dynamic resource allocation under uncertainty, agent-based machine learning, and privacy optimization in a network context. All three are necessary because transportation systems need to be optimized holistically, but data is typically obtained from multiple travelers or vehicles in operation. As such, agent learning and minimization of privacy concerns in the system optimization is needed. The methodology expands the science of inverse optimization by integrating it with dynamic network optimization with privacy control as constraints on the estimated parameters. The research benefits all types of dynamic mobility systems: it will make shared autonomous vehicle fleet operations viable and on-demand service fleets more sustainable and resilient. Data privacy and security in a transport system design context will also be advanced, allowing data from travelers to be more accessible. This research will benefit smart cities, sensor deployment, artificial intelligence, collective behavior, differential privacy, service systems, public policy, and network economics."
720773,CSR---SMA: Computer Architecture Optimization: A Machine Learning Approach,CNS,Computer Systems Research (CSR,9/1/2007,7/30/2009,Jose Martinez,"Martinez, J","Martinez, J|Caruana, R",NY,Cornell University,Continuing grant,M. Mimi McClure,8/31/2012,"$500,000.00 ",Rich Caruana,martinez@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7354,"7354, 9218, HPCC",$0.00 ,normalFunding,"Exponential increases in transistor densities at each new technology generation have allowed us to build chips with greatly enhanced capabilities and functionality. The last twenty years have witnessed the introduction and adoption of numerous architectural advances at the processor level, as computer architects have successfully translated increases in transistor budgets to performance. Unfortunately, effective hardware policies for managing and controlling these complex artifacts have not advanced commensurately. Most policies are ad hoc at best, and generally incapable of providing important functionalities like anticipating the long-term consequences of  decisions (planning), or generalizing from experience obtained through decisions executed in the past to act successfully in new situations (learning).<br/><br/>At the same time, the artificial intelligence and machine learning communities have made tremendous strides in designing computer programs and algorithms that learn about their environment and improve automatically with experience. The proposed inter-disciplinary work will develop methodologies based on such a technology to design efficient, adaptable, and self-optimizing on-chip hardware policies. The project will concentrate on chip multiprocessors, in which opportunities for hardware management promise to be numerous and challenging. If successful, this approach may set off a change in the way computer architects think about and conduct research on computer architecture design.<br/><br/>The project will apply machine learning technology in two ways: (1) tools for the systematic design of optimized management policies that can then be installed in hardware (e.g., ROM-based circuits); and (2) self-optimizing hardware agents that implement efficient policies, can learn from their environment, and improve automatically with experience.<br/><br/>"
548723,SBIR Phase II: Artificial Intelligence and Character Animation,IIP,SMALL BUSINESS PHASE II,2/1/2006,2/8/2008,Michal Hlavac,"Hlavac, M","Hlavac, M",MA,"Ingeeni Studios, Inc.",Standard Grant,Errol Arkilic,4/30/2008,"$499,996.00 ",,michal@ingeeni.com,271 Windsor Street,Cambridge,MA,21390000,6178187547,ENG,5373,"1087, 9139, 9216, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project is to build and launch simple and intuitive software tools that allow for the creation of interactive 3D graphics within Macromedia Flash (a 2D vector graphics package). Combined with the existing technology, this collection of technologies will provide the first version of the revolutionary Artificial Intelligence Platform for the creation and delivering of interactive animated characters with emotional intelligence. The systems provide the characters with autonomous behavior selection (what should I do?), emotion (how do I feel?) and learning (have I seen this before?). Such a unique blend of technologies opens opportunities for the study of the theories of the human mind and creates an entirely new class of interactive media.<br/><br/>The broader impacts of this work are scientific, educational, and economic. The technologies advance discovery and understanding of the workings of the human mind by giving a rapid prototyping environment for computational theories of the mind. Scientists and non-scientists alike can create AI networks and see the resulting characters ""twitch"" on screen in real time. This work promotes teaching, training and learning as Ingeeni will work with UC Irvine and MIT Media Lab to develop curriculums for Synthetic Characters classes that use the platform. Massive adoption of Ingeeni's technologies is the company's main goal, and it is developing libraries of detailed step-by-step tutorials freely available online."
1152898,Analysis of causal cognition in rats,BCS,"PERCEPTION, ACTION & COGNITION",6/1/2012,7/30/2013,Aaron Blaisdell,"Blaisdell, A","Blaisdell, A",CA,University of California-Los Angeles,Continuing grant,Betty H. Tuller,5/31/2015,"$499,996.00 ",,blaisdell@psych.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,SBE,7252,"1045, 7252",$0.00 ,normalFunding,"Humans learn about their world through both personal experience and social communication but complete information is rarely available. In fact, we are remarkably adept at drawing conclusions from only partial information (for example, a doctor diagnosing a disease or a detective solving a crime) and imagining alternate scenarios (an especially useful enterprise for scientists). Like humans, many animals are able to learn about the world through personal experience, as Pavlov showed in dogs and Skinner showed in rats and pigeons. In previous NSF-funded research, the principal investigator showed that rats have the capacity to go beyond direct experience and training and make causal inferences, that is, inferences about a cause-effect relationship they had never previously observed. Causal inferences were much like those of a scientist or a human child in that they originated from the rat's interactions with the world. Rats also act as if they expect a cause to be present even if it is not directly observable. Thus, rats exhibit at least some of the hallmarks of human reasoning. The current research project builds on these results by exploring other ways in which animals are able to reason about their world. Can a rat, like a doctor or detective, determine a cause-effect relationship from only partial and incomplete information? If so, what are the psychological mechanisms that support these causal inferences? To what extent can a rat reason about hidden events in order to solve ambiguous problems? <br/><br/>Answers to these questions can determine aspects of cognition that are uniquely human and aspects that humans share with other animals. Such knowledge may impact the development of artificial intelligence systems designed to make adaptive decisions and inferences based on limited prior knowledge.  The principal investigator also serves as faculty mentor in two programs for high-school students in the greater Los Angeles area (drawn from diverse backgrounds) and will involve the students in this research."
634044,Collaborative Research: Assisting and Assessing Middle School Science Learning in Formal and Informal Settings,DRL,REAL,1/1/2007,8/22/2007,Daniel Schwartz,"Schwartz, D","Schwartz, D",CA,Stanford University,Continuing grant,Elizabeth VanderPutten,12/31/2010,"$499,992.00 ",,daniel.schwartz@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,EHR,7625,"9177, SMET",$0.00 ,normalFunding,"An important goal of formal education is to prepare students for future learning when there is no longer classroom supervision. To continue learning, people need to learn to self-assess their own progress and understanding. We are investigating the social basis of self-assessment for learning. Specifically, we hypothesize that, under identifiable conditions, assessing others can support self-assessments that promote content learning plus the ability to develop self-assessment strategies that can be applied in the future. In this project, we take advantage of Teachable Agent technologies where students learn by teaching computer agents through the use of well-formed visual representations. Teachable Agents, using simple artificial intelligence techniques, can then reason based on what they have been taught. This creates optimal conditions for self-assessment, because students' assessments of their agents' performance is also an assessment of their own knowledge. The work occurs in the context of teaching the key ecosystem concepts of interdependence and balance to middle school students. Students will first create Teachable Agents that are linked to their curriculum on pond and river ecosystems, and use this learning experience to create a new Teachable Agent that can sustain multiple fish in a home aquarium system. Students will also use the Teachable Agents in a new homework model that leverages current trends in home computer use and connects learning in formal and informal settings; students log on, chat with one another, and their agents interact with another in an on-line virtual environment. Overall, the proposed project joins three important strands of research assisted by advanced technology tools: The learning of dynamic processes in science; the social basis of self-assessments for learning; and, the improvement of connections between formal and informal learning settings."
522634,GSE/RES Learning Companions as Change Agents: Improving Girls' Self-efficacy Beliefs in Learning Math,HRD,RES ON GENDER IN SCI & ENGINE,9/1/2005,6/5/2007,Yanghee Kim,"Kim, Y","Kim, Y|Hailey, C",UT,Utah State University,Continuing grant,Jolene K. Jesse,8/31/2009,"$499,991.00 ",Christine Hailey,ykim9@niu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,EHR,1544,"9178, SMET",$0.00 ,normalFunding,"Utah State University is investigating the educational potential of virtual peers to change girls' negative self-images and attitudes toward science, technology, engineering and mathematics (STEM), moving them in a desirable direction. The virtual peers, called pedagogical agents as learning companions (PALs), may encourage and persuade girls to increase their belief of self-efficacy in learning math and to build more positive attitudes toward pursuing careers in STEM.<br/><br/>Research indicates that girls' negative views of the fields of STEM are often due to social and cultural influences. Family, schools, and media are likely to impose stereotypic role expectations on girls and infuse girls with ideal ""Barbie doll"" images of girls. As a result, many girls tend to identify STEM as masculine and doubt their ability to compete. Girls need to be exposed to social environments that will encourage them to overcome ungrounded social stereotypes and build constructive views of their competency in STEM. Although the stereotypic views of family, teachers, or friends cannot be immediately changed or influenced, girl-friendly virtual social environments can be created to help girls build positive attitudes toward STEM. <br/><br/>The project will 1) investigate the effectiveness of PALs in facilitating girls' self-confidence and efficacy in learning math and 2) investigate the characteristics of PALs critical to that end. To reach the goals, a three-year research agenda is planned. In the first year, the project will focus on the effects of the gender and age of PALs. The research will investigate whether gender (male vs. female) and age (adult vs. peer) are related to girls' choices of PALs as their learning partners and, subsequently, girls' self-efficacy and attitude change. In the second year, the project will focus on the effects of the competency and ethnicity of PALs. The research will be an investigation of whether PALs' competency (strong vs. weak) and ethnicity (Caucasian vs. Hispanic) have an impact on Caucasian and Hispanic girls' choices of PALs as their learning partners and, subsequently, girls' self-efficacy and attitude change. In the third year, the project will concentrate on the effects of the feedback type and emotion of PALs. The research will be an investigation of whether PALs' feedback type (harsh vs. nice) and emotion (empathetic vs. non-empathetic) will have an impact on girls' attribution of their success and failure, their self-efficacy, and their feelings of affability with PALs. The research questions will be answered using a quasi-experimental design and both quantitative and qualitative data. The sample will include approximately 200 9th-grade girls in required algebra I classes in public high schools in large and mid-size cities in a mountain-west state of the USA.<br/><br/>Intellectual Merit<br/>First, unlike most technology-based interventions that have been focused on the cognitive aspect of learning, this project is geared toward the affective aspect of girls' math learning. This project will identify how PALs can be used to effect girls' math self-efficacy and positive attitude toward learning math. Second, PALs are a special subset of pedagogical agents and are grounded on findings from human-peer interaction research. This project will identify the specific characteristics of PALs that might affect girls' math self-efficacy and attitudes. Third, PAL-based interventions will be implemented in ordinary classrooms regularly throughout the semester. This project will provide classroom-based evidence on the educational value of PALs in K-12 settings and implications for long-term use.<br/><br/>Broader Impacts<br/>The project is conducted through the collaborative efforts of a multidisciplinary team and so will yield implications for multiple communities, such as researchers in women/gender education, STEM education in general, educational technology, human/computer interaction, and artificial intelligence in education.<br/><br/>If found to be effective, PALs are potentially an efficient and cost-effective intervention to re-shape girls' STEM beliefs and attitudes, compared to human-mentoring programs. Through classroom implementation, the project has implications for PALs' role for improving Caucasian and minority girls' math self-efficacy and attitudes. The influential characteristics of PALs for PAL/learner relations identified in the project will provide implications for research on human relations as well as on human/computer interactions. <br/>"
1117684,III:  Small:  Compression-Aware Algorithms for Massive Datasets,IIS,INFO INTEGRATION & INFORMATICS,7/1/2011,7/17/2012,Gabriel Robins,"Robins, G","Robins, G|Shelat, A",VA,University of Virginia Main Campus,Continuing grant,Sylvia J. Spengler,6/30/2016,"$499,984.00 ",Abhi Shelat,robins@cs.virginia.edu,P.O.  BOX 400195,CHARLOTTESVILLE,VA,229044195,4349244270,CSE,7364,7923,$0.00 ,normalFunding,"As many application domains continue to generate data at exponentially increasing rates, much of the data that is gathered is stored in a compressed format. However, very few classic data processing algorithms have been updated to handle compressed data. This project aims to address this gap by developing (i) algorithms for massive data sets that can directly operate on compressed data; and (ii) compression schemes that are aware of the algorithms that would  operate on the data. <br/><br/>In many settings, algorithms that manipulate very large composite objects while interacting only with their succinct descriptions can substantially reduce the time and memory requirements relative to their counterparts that have to work with uncompressed representations of the same data. These performance gains are realized by leveraging highly repetitive or parametrically specified input structures, to enable algorithms to manipulate very large composite objects while interacting only with their compressed descriptions. Anticipated results of the project include new geometric algorithms that solve problems such as convex hull, Voronoi diagrams, nearest points and earth-mover distances when the inputs are in compressed format; new graph algorithms that compute minimum spanning trees, shortest paths, and network flows on compressed input graphs; and new compression-aware data structures that support efficient storing, querying and processing of compressed data. All the algorithmic contributions will be validated with experiments on real and synthetic massive data sets. The resulting algorithms are likely to find application in many different domains including networks, genomics, databases, computer graphics, artificial intelligence, geographic information systems, integrated circuit design, and computer-aided engineering. <br/><br/>Broader Impacts: Compression-aware data processing algorithms and algorithm-aware data compression schemes have applications across a wide range of tasks that involve processing of massive data sets consisting of large data objects (e.g., images, sequences, graphs). The formulations, algorithms, codes, and theories <br/>that will be developed and disseminated by this project are likely to contribute to the development of efficient and practical algorithms and data structures that could impact the way in which organizations collect, store, process, such data. The project offers enhanced research based training opportunities for students in an area of considerable theoretical as well as practical significance. Additional information about the project can be found at: http://www.cs.virginia.edu/robins"
9872500,Improving Electric Power Industry Competitiveness Through the Application of Artificial Intelligence,EEC,ENGINEERING EDUCATION,9/1/1998,6/20/2001,Daniel Tylavsky,"Tylavsky, D","Tylavsky, D|Heydt, G|Karady, G|Holbert, K",AZ,Arizona State University,Standard Grant,Mary Poats,8/31/2002,"$499,976.00 ","Gerald Heydt, George Karady, Keith Holbert",tylavsky@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,ENG,1340,"9299, OTHR, 0000",$0.00 ,normalFunding,"Deregulation of the electric industry is forcing most utilites to be more competitive. To be competitive, utilities need people at all levels that are trained to deliver a better product, at a lower cost, with more reliability. The goal of this CRCD project entitled, ""Improving Electric Power Industry Competitiveness Through the Application of Artificial Intelligence,"" is to help improve electric power utility competitiveness by incorporating, into the upper division undergraduate and graduate curriculum, instructional modules that can be used to train people in these critical areas. The instructional modules to be developed will focus in the area of the application of artificial intelligence to operation, control and simulation of electric power systems. These modules are based on already completed research at the University of Washington and Arizona State University. <br/><br/>These modules will be completed with a team of technical researchers, instructional methodology experts and computer-based media specialists. All modules will be computer based and disseminated in multiple ways including via the Internet. Formative assessment will be ongoing throughout the life of the project. <br/><br/>Instructional design will center around active learning strategies such as cooperative learning with emphasis on team methods; however, instructional design will also include components to appeal to the reflective learner as well as students with other learning styles.<br/><br/>The results of this work is expected to enhance the ability of new graduates as well as electric power engineers perform in the rapidly changing, highly competitive world brought on by deregulation of the electric power industry."
1527434,RI: Small: New Directions in Computational Social Choice and Mechanism Design,IIS,ROBUST INTELLIGENCE,9/1/2015,8/3/2015,Vincent Conitzer,"Conitzer, V","Conitzer, V",NC,Duke University,Standard Grant,James Donlon,8/31/2019,"$499,972.00 ",,conitzer@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"We often need to make collective decisions: who will represent us as president, where will we all go out for dinner tonight, who will receive the award, and so on. Similar problems are faced in multiagent systems in artificial intelligence. What are the best procedures for reaching such decisions? The agents could vote over the outcome, but what should the exact procedure be? This is studied in the theories of social choice and mechanism design, with the latter focusing particularly on agents that act strategically in their own self-interest. However, an ever-increasing amount of activity is moving online, and collective decision making is no exception. For example, we rate or vote on content, products, and people online. Key aspects of these novel applications are not present in the traditional models of social choice and mechanism design. For example, in an Internet-based mechanism, who gets to and who will participate? How can we know that a single agent is not participating multiple times? How can we allow agents to meaningfully participate when the number of voting events is potentially overwhelming? The proposed research aims to extend the traditional models to incorporate these aspects and to develop new algorithmic and other techniques to ensure outcomes are meaningful and increase economic efficiency and human welfare.<br/><br/>In many domains, multiple self-interested agents need to make a collective decision. The theory of social choice concerns how such collective decisions should be made. Closely related, the theory of mechanism design concerns how to design mechanisms for such problems that result in good outcomes even when agents behave strategically. In recent years, major progress has been made on understanding the computational aspects of both social choice and mechanism design. In the proposed research, the PI and his team set out to adapt these techniques to novel domains such as those enabled by the Internet or the availability of new data. For example, one key issue is the identity of the participating agents. In an Internet-based mechanism, who gets to and who will participate? How can we know that a single agent is not participating multiple times? The PI and his team aim to address such issues with techniques based on social network structure, as well as on the effort that agents expend participating. Another key issue is the possibility of agents strategically providing inaccurate data. Again, explicit modeling of the agents' effort costs in doing so will play a key role."
1734304,"CompCog: Computational, distributed accounts of human memory: improving cognitive models",BCS,"PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",8/1/2017,7/19/2017,David Reitter,"Reitter, D","Reitter, D",PA,Pennsylvania State Univ University Park,Standard Grant,Lawrence Gottlob,7/31/2020,"$499,969.00 ",,reitter@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,SBE,"7252, 7495","7252, 7495",$0.00 ,normalFunding,"Memory is among the most impressive aspects of human cognition, allowing us to learn new words or new ideas from just a few examples.  However, the scientific understanding of how this learning occurs is limited.  This research project focuses on how learning occurs in the context of memory for language. Within the human mind, there is something like a dictionary that tells people what words mean (semantics) and how words are combined to make grammatical sentences (syntax). How does the mind learn this dictionary from experience with a language? Computer simulations can help science better understand this learning process. This scientific understanding can, in turn, help teach languages in the classroom and aid in the early detection of language deficits, whether it be developmental deficits in children, or age-related deficits in adults. Furthermore, improving the ability of computers to simulate language learning processes can also lead to the development of better technology such as machine translation, web search, and virtual assistants.  This project considers how a better understanding of language learning can help us avoid common pitfalls of memory connected to the use of language.  For example, humans easily over-generalize and judge a ""book by its cover"", associating certain occupations or personality traits with a gender.  If we know how people come up with associations between words and concepts, we can also detect and prevent prejudices in language to help ensure that artificial intelligence applications, such as web search, do not produce prejudiced results.  The project supports an interdisciplinary and diverse team of researchers and students at Penn State, attracting college students to engage with research in cognitive science and artificial intelligence.<br/><br/>In this project, the researchers are designing a new model of human memory, the Hierarchical Holographic Model.   This computational model helps explain certain aspects of how words and languages are learned.  The model draws on the successes of artificial intelligence and deep neural networks, and applies these insights to psychology.   With this model, the researchers investigate the question of whether human memory has the ability to detect arbitrarily indirect associations between concepts.  The model uses a recursive learning process, building on previously learned knowledge to acquire new knowledge, which allows the model to learn arbitrarily indirect and abstract relationships between words. The researchers consider evidence that sensitivity to abstract relations between words improves the ability of the computer model to learn syntax, such as parts-of-speech, and to use words appropriately to construct grammatical sentences. This work will be assessed against human language data and competing computational models. The success of the computational model should provide evidence that (1) language acquisition depends on indirect associations, and (2) human memory must be able to form indirect associations to facilitate it."
1526723,RI: Small: Bayesian Modeling of Situated Communicative Goals,IIS,"PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",9/1/2015,6/10/2016,Matthew Stone,"Stone, M","Stone, M|Hemmer, P",NJ,Rutgers University New Brunswick,Continuing grant,Tatiana D. Korelsky,8/31/2019,"$499,945.00 ",Pernille Hemmer,matthew.stone@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,"7252, 7495","7252, 7495, 7923",$0.00 ,normalFunding,"This multidisciplinary project undertakes a program of research in natural language generation (NLG), the subfield of artificial intelligence that aims to construct intuitive, accessible utterances to communicate the data, knowledge and reasoning of computational systems.  NLG capabilities have an important role in facilitating new, more natural interaction with computers, both in current applications such as mobile information access and in emerging ones such as personal assistants and human-robot interaction.  NLG systems remain inflexible and difficult to build, however.  This research aims to addresses this problem by developing techniques to train NLG systems to match human language use.  The project is a close collaboration that links psychological experiments, designed to uncover the strategies human speakers use, to computational experiments, which apply these strategies in NLG systems using machine learning.<br/><br/>The theoretical framework at the center of this project is Bayesian cognitive modeling, a probabilistic approach that explains human information processing in terms of decision making under uncertainty.  Applied to language use, Bayesian cognitive modeling involves estimating the communicative goals speakers adopt, the knowledge and meanings available to speakers, and the choices speakers make to express needed information in suitable linguistic terms.  Such knowledge and strategies can then be used to drive NLG systems.  The specific research of the project investigates three key domains for applying NLG to construct messages to describe real-world situations: making lexical choices, constructing complex linguistic structures compositionally, and fulfilling multiple overlapping communicative goals.  The project explores each domain through interrelated activities carried out by an interdisciplinary team of computer scientists and psychologists: to formalize speaker choices using a range of Bayesian cognitive models; to fit the models to visually-grounded language corpora using machine learning; to evaluate the empirical scope of goal-directed reasoning by comparing the learned models both to attested human choices and to baseline learned models; and to assess how well the models match human comprehension of linguistic meaning.  The intellectual merits of the project lie in bridging the gap between traditional goal-directed rational models of human behavior and state-of-the-art computational methods that instantiate templates or reproduce likely patterns.  In addition to the societal impacts of the technology, the broader impacts of the project include the construction of data resources, models and modeling tools that will be distributed to facilitate further research, and contributions to ongoing initiatives for education in cognitive science at Rutgers."
644204,CAREER: Art and Vision: Scene Layout from Pictorial Cues,IIS,ROBUST INTELLIGENCE,1/15/2007,1/14/2011,Stella Yu,"Yu, S","Yu, S",MA,Boston College,Continuing grant,Jie Yang,10/31/2012,"$499,933.00 ",,stellayu@berkeley.edu,140 Commonwealth Avenue,Chestnut Hill,MA,24673800,6175528000,CSE,7495,"1045, 1187, 7495, 9218, HPCC",$0.00 ,normalFunding,"<br/><br/>CAREER: Art and Vision: Scene Layout from Pictorial Cues<br/><br/>PI:  Stella (XingXing) Yu     <br/><br/>Institution: Boston College<br/>Artists are the masters of visual perception. Studying art and vision together can provide new solutions to fundamental problems in computer vision. We focus on inferring scene layout from a single image. This problem has been studied since the earliest days of Artificial Intelligence research, resulting in a host of so-called Shape-from-X methods, where X could be shading, perspective, etc.<br/>Unfortunately, each of these methods works under its own assumptions which often do not hold in real images. How these cues interact and integrate remains elusive. Painters constantly use a combination of four techniques: occlusion, perspective, shading, and form to effectively evoke a 3D percept from a 2D picture. Studying their techniques can lend insights into the computation of recovering scene layout from pixel values. The PI proposes to bring artists and vision scientists together to solve the computational problem of scene layout from pictorial cues. This project realizes it in three areas:<br/>education, experiments and computational modeling.<br/><br/>A new interdisciplinary course, Art and Visual Perception, has been developed at Boston College to give a comprehensive cross-examination of how art contributes to the understanding of vision, and how vision contributes to the generation and viewing of art. Students are actively engaged in both art practice and vision experiments.<br/>Learning art and vision together results in a deeper understanding than studying each discipline separately. Students' assignments also result in valuable datasets for vision research.<br/><br/>The computational approach to scene layout from pictorial cues in this project is to group pixels into spatially organized surfaces from a global integration of multiple pictorial cues in a spectral graph-theoretic framework. The goal is to turn artistic rendering knowledge on how these cues interact into a computational reality.<br/>The PI will study geometry (occlusion and perspective), appearance (brightness and color), and form using eye tracking and psychophysics experiments and computational models. These efforts are organized into two phases that progress from inferring the spatial layout from scenes made of planar surfaces (rooms and streets) to scenes made of curved surfaces (landscape and generic scenes).<br/><br/>Intellectual Merit<br/><br/>What is most remarkable about vision is its ability to perceive 3D spatial layout from a single 2D image. The proposed research replicates this ability in computation from a grouping perspective.<br/>Compared to statistical learning approaches, the grouping method is not only generic and thus scales well with the number of scenes, but can also produce a precise organization of surfaces in the scene.<br/>Compared to traditional Shape-from-X approaches, the grouping method examines each pictorial cue in conjunction with others. The integration of these multiple pictorial cues allows them for the first time to become applicable to real images. The PI has developed the essential grouping machinery in spectral graph theory for depth segregation. Compared to most existing formulations on this topic, it has unparalleled conceptual simplicity, computational efficiency, and guaranteed near-global optimality. The proposed research on brightness and color perception, in connection with Shape-from- Shading and surface organization, will help clarify the role of low- level and high-level mechanisms in the long-standing scientific debate between Hering and Helmholtz on color perception.<br/><br/>Broader Impact<br/><br/>This project bridges the gap between art and science not only in research but also in education by developing a new curriculum that traverses the areas of neuroscience, psychology, computer science, and visual arts, by involving students in art practice and scientific experiments, and by providing a forum for artists and scientists to exchange ideas on visual perception. These interdisciplinary efforts befit the liberal arts education tradition at Boston College. This project will not only benefit from the strong Fine Arts department on campus, but also cultivate computer science awareness and outreach to non-technical people, and promote the growth of the young Computer Science department at Boston College.<br/><br/>URL:  http://www.cs.bc.edu/~syu/artvis/<br/>"
1016509,"AF:  Small:  Beyond Worst-Case Analysis in Approximation Algorithms, Algorithmic Mechanism Design and Online Algorithms",CCF,"ALGORITHMS, COMPUT GAME THEORY & ECON",8/1/2010,7/23/2010,Anna Karlin,"Karlin, A","Karlin, A",WA,University of Washington,Standard Grant,Balasubramanian Kalyanasundaram,7/31/2014,"$499,847.00 ",,karlin@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7926, 7932","9218, HPCC",$0.00 ,normalFunding,"In theoretical computer science, algorithms are usually evaluated with respect to their worst-case performance, whereas in other areas, average-case analysis is often used. Both of these approaches have drawbacks: worst-case analysis is overly pessimistic and average-case analysis often rests on unrealistic assumptions. To address these issues, a number of other analysis frameworks have been proposed including self-improving algorithms, smoothed analysis, instance-optimality, and algorithmic design based on a variety of data models. The objective of the project is to continue this line of research and develop techniques that go beyond worst-case analysis in the areas of approximation algorithms, algorithmic mechanism design and online algorithms.  In the area of approximation algorithms for NP-hard problems, the project focuses on the development of approximation algorithms that achieve a kind of instance optimality. In the area of algorithmic mechanism design, the PI will continue to study the design and analysis of profit maximizing auctions in single-parameter environments and beyond. In the area of online algorithms, the PI will work to develop effective online algorithms for a fundamental and practical self-organizing data structure problem.<br/><br/>Through the development of more effective and practical algorithms and a deeper understanding of the performance of these algorithms in practice, this research has the potential to impact a variety of subfields of computer science including artificial intelligence, systems and networking, data mining, and electronic commerce."
1116384,HCC: Small: Building Audio Interfaces with Crowdsourced Concept Maps and Active Transfer Learning,IIS,Cyber-Human Systems (CHS),9/1/2011,8/16/2011,Bryan Pardo,"Pardo, B","Pardo, B|Gergle, D",IL,Northwestern University,Standard Grant,Ephraim P. Glinert,8/31/2016,"$499,804.00 ",Darren Gergle,pardo@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7367,"7367, 7923",$0.00 ,normalFunding,"The United States is a world-leader in software and in multimedia content (e.g. music, film). To remain so, we must continually raise the bar in both software and media production. Software tools for media production (e.g. the audio production suite Protools) often have complex interfaces, conceptualized in ways that makes it difficult for any but the most expert to realize the power of these tools. Complex interfaces and steep learning curves can discourage creative people from doing their best work with such tools. Here, we focus on audio production tools. We propose a user-centered approach to remove the great disconnect between existing audio production tools and the conceptual frameworks within which many people work, both expert musicians and the broader public. The tools we develop will automatically adapt to the user's conceptual framework, rather than forcing the user to adapt to the tools. Where appropriate, the tools will speed and enhance their adaptation using active learning informed by interaction with previous users (transfer learning). The tools will also automatically build a crowdsourced audio concept map. This will help provide facilities for computer-aided, directed learning, so that tool users can expand their conceptual frameworks and abilities. By letting people manipulate audio on their own terms and enhancing their knowledge of such tools with directed learning, we expect to transform the interaction experience, making the computer a device that supports and enhances creativity, rather than an obstacle.<br/><br/>This work will have a number of broader impacts. The tools developed will be directly usable by practicing musicians and will also facilitate learning and creativity for the general public. These techniques will also be applicable to personalization of hearing aids and new diagnostic systems for audiologists. Our approach to tool personalization is core work in human-computer interaction and should generalize to other creative activities (e.g. image manipulation). Resulting advances in active and transfer learning will be of great value to machine learning researchers. Finding the relationships between quantifiable parameters of audio and the language and metaphors used by practicing musicians to describe sound is central to this work. This is of great interest to cognitive scientists, linguists, artificial intelligence researchers, and engineers. Concept maps for audio terms should also prove useful for machine translation. Broad application of techniques to map human descriptive terms on to machine-manipulable parameters will change expectations for both artists and scientists. Artists will be able to explore new lines of creativity that currently require significant investments of time in vastly disparate fields (e.g. signal processing and painting). This has the potential to transform information science and lead to new cognitive models of creativity, forming the basis for new approaches to education and research in both technology and in art."
349604,SBIR Phase II: Evolving Object Neural Networks,IIP,SMALL BUSINESS PHASE II,2/1/2004,2/2/2004,David Fogel,"Fogel, D","Fogel, D",CA,"NATURAL SELECTION, INCORPORATED",Standard Grant,Errol Arkilic,1/31/2006,"$499,642.00 ",,dfogel@natural-selection.com,"5910 Pacific Center Blvd., Suite",San Diego,CA,921217710,8584556449,ENG,5373,"9139, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research Phase II research project will investigate the problem of generating evolutionary object neural networks for controlling characters in classes of entertainment software, with consideration given to genres of massively multiplayer online games. The objective of the research is to identify and develop general self-adaptive routines and software tools that can be incorporated in a software developer's kit (SDK) that is suitable for licensing to third-party developers. A series of experiments conducted within a statistical framework will identify first- and second-order effects of parameter choices for the evolutionary control of game characters, which will be incorporated into the SDK. R&D will be aimed at generating the most rapid evolutionary learning for game characters while having the smallest code ""footprint."" Additional research will facilitate automatic play testing and optimization of artificial intelligence in games. The scientific and technical understanding of hybridizing evolutionary computation and neural networks will be enhanced by the careful study of the nonlinear effects of parameter choices in the studied settings<br/><br/>If successful this product will ease the transition of video games from development to products. The development of an SDK that will help reduce the time and cost of segments of video game production by 50-80%. The software developed may serve as educational classroom aids in university courses. Furthermore, the strong correlation between video games and military simulations suggests important contributions to dynamic planning in combat simulations, as well as extensions to optimizing courses of action in business operations, such as supply-chain management."
1316223,RCN Proposal: Macroecology of Infectious Disease,DEB,ECOLOGY OF INFECTIOUS DISEASES,9/1/2013,6/5/2017,Patrick Stephens,"Stephens, P","Stephens, P|Poulin, R|Altizer, S|Smith, K|Aguirre, A",GA,University of Georgia Research Foundation Inc,Continuing grant,Samuel M. Scheiner,8/31/2019,"$499,451.00 ","Robert Poulin, Sonia Altizer, Katherine Smith, Alonso Aguirre",prsteph@uga.edu,310 East Campus Rd,ATHENS,GA,306021589,7065425939,BIO,7242,"7242, EGCH",$0.00 ,normalFunding,"Scientists from multiple disciplines, including wildlife biology, public health, veterinary parasitology and biomedical sciences, have compiled a wealth of data on the distribution and impacts of infectious diseases, with most studies focused on particular locations or single host-pathogen interactions. This wealth of data creates the opportunity to address a pressing need, namely to explore the patterns and drivers of infectious disease emergence in humans and natural ecosystems at global scales. This project will create a Research Coordination Network to bring together internationally recognized experts from ecology, conservation medicine, parasitology and computational sciences to quantify and explore the drivers of global scale patterns of pathogen biodiversity. Participants will work together to assemble data sets of unprecedented size, including information about disease occurrence in host species ranging from insects to humans. With help from experts in machine learning (artificial intelligence) and geographic information systems (GIS), they will work to build predictive models that can be used to understand the changing distributions of infectious diseases and identify future hotspots of novel disease emergence in humans and wildlife.<br/><br/>Emerging infectious diseases, especially those that jump from wildlife to livestock and humans, threaten public health around the world. Using state of the art computational methods, the RCN will be able to answer critical questions such as: How and why do certain pathogens successfully move from one host species to another? Are hotspots of pathogen biodiversity in wildlife the same areas as hotspots of disease emergence in humans and livestock? To share its findings, the RCN will develop educational products such as webcasts and workshops aimed at educational levels from high school to post graduate, and will train students from under-represented groups through a summer research program. The RCN will also develop and maintain databases of global infectious disease biodiversity and make these data freely available to the academic community and the general public."
120309,QSB: Phenotyping Single Nucleotide Polymorphisms using Bayesian Networks,ECCS,"CONTROL, NETWORKS, & COMP INTE",10/1/2001,12/23/2003,Marco Ramoni,"Ramoni, M","Ramoni, M|Sebastiani, P",MA,Children's Hospital Corporation,Standard Grant,Paul Werbos,9/30/2004,"$498,849.00 ",Paola Sebastiani,marco_ramoni@harvard.edu,300 LONGWOOD AVENUE,Boston,MA,21155737,6179192729,ENG,1518,"0000, 1757, OTHR",$0.00 ,normalFunding,"The recent completion of a draft of the human genome leaves us with a staggering number of sequences, an impressive number of surprising statistics, and the task of making sense of it, by linking the genetic code to observable characters (phenotypes). And one of the surprising statistics emerged from this first draft can hold the key to unlock the code. On average, the genomes of any two human individuals are identical at 99.9% of all nucleotides. While this extremely high degree of identity is striking, the enormous size of the genome (over 3 x 109 base pairs) means that a 0.1% rate of divergence is still equivalent to over 3 million differences between any two people, which translates, on the average, into one difference every 1000 bases. These subtle variations, called polymorphisms, have been proven to be invaluable tools to relate genetic code<br/>to phenotypes. By far the most common type of polymorphism is the alteration of a single base (A, C, G or T), known as a Single Nucleotide Polymorphism (SNP). Although only a small fraction of these variations resides in coding parts of the genome (i.e. segments that actually affect the expression of the genetic code), SNPs act as unique markers on the genetic code and allow to follow along families (pedigrees) the simultaneous inheritance of code segments and phenotypic characters. This phenomenon allows us to assess the relationship between characters and some areas of the genetic code. The signal of these variations is so strong that simple Mendelian in-heritance was able to reveal the genetic basis of important diseases, such as Huntington's disease or cystic fibrosis. These phenotypes, however, are easy to discover because they follow a simple<br/>pattern of inheritance of a single gene. The next challenge is to discover the genetic bases of complex traits caused by more than one coding region or by the interplay between genetic predisposition and environmental conditions.<br/><br/>This project seeks a solutions to this problem by mean of an unsupervised machine learning technology known as Bayesian networks (BBNs), born at the confluence between Statistics and Artificial Intelligence. A BBN is a direct acyclic graph in which nodes represent stochastic variables and links represent dependencies among variables. Recent developments of the technology have made possible learning these networks from databases comprising values of several variables and, in so doing, discovering the most probable model of dependence among these variables. BBNs are not restricted to pairwise models of interactions but they can describe and therefore help to assess models where more than one variable is responsible for changes in others. SNPs, environmental conditions and observable characters are represented as stochastic variables, thus allowing a seamless integration of the information. The first technological chal-lenge of the project is the integration of the hierarchical structure of pedigree information (i.e. the information about family inheritance) in the flat structure of the BBNs, where all variables are equally interacting. The second issue tackled by the project will be understanding of the stochastic nature of the mechanism causing missing data (such as failed enotyping, missing phenotypes on ancestors), the development of appropriate treatment for the incomplete databases, and the assessment of the reliability of the resulting models. The third aspect of the project is the integration with existing SNPs databases to provide fast access to the available SNPs information."
412000,"Knowledge Representation, Reasoning, and Problem Solving in a Cellular Domain",IIS,"WORKFORCE, ARTIFICIAL INTELL & COGNIT SCI",8/1/2004,6/26/2006,Chitta Baral,"Baral, C","Baral, C",AZ,Arizona State University,Continuing grant,Edwina L. Rissland,7/31/2010,"$496,465.00 ",,chitta@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,"1713, 6856","0000, 9215, 9216, 9218, 9251, HPCC, OTHR",$0.00 ,normalFunding,"The aim of the proposed research is to develop new and adapt existing knowledge representation and reasoning schemes to represent and perform various kinds of reasoning and problem solving tasks, such as prediction, explanation, diagnosis and planning about the activities inside a cell. This project aims to focus on happenings and mechanisms such as signal transduction, protein-protein interactions and other biochemical reactions. The project's preliminary results suggest that the knowledge representation, reasoning, and problem solving approaches of Artificial Intelligence are well suited for this task. In a cell when a ligand binds to an appropriate receptor it activates the receptor which in turn triggers a series of events. In the terminology of planning and reasoning about actions, the binding of a ligand to the receptor can be thought of as an action; the conditions under which a ligand can bind to a receptor, as the executability conditions of an action in a planning domain; Similarly, the direct effects of the ligand binding to a receptor can be expressed using planning terminologies. Planning is just one of the problem solving and reasoning tasks in the context of reasoning about actions in ther cellular domain. Others include prediction (hypothetical reasoning), explanation, and diagnosis. In the context of a cell, representing the cell behavior using actions and determining the effects and side effects of a drug (that manifests as a ligand) would correspond to prediction. Similarly, figuring out what interventions will change the cell behavior in a particular way corresponds to planning; determining the cause behind some unexpected observations about the cell corresponds to diagnosis. Since research on cell decoding is ongoing this project will have only partial information about the happenings inside a cell, and its reasoning schemes will need to be able to deal with incomplete information. In this way, this project ties into important goals in AI research on knowledge representation and reasoning. Although the existing research in knowledge representation and reasoning provides a good foundation for representing and reasoning about cell behavior, there are several new features in this domain that pose new research challenges. Tackling them is the main goal of this project. Challenges to be addressed include modeling triggering activity, notions of sensitization of receptors, and protein 'recruiting' proteins."
1216977,EXP: Building a Learning Analytics System to Improve Student Learning and Promote Adaptive Teaching Across Multiple Domains,IIS,"TUES-Type 2 Project, REAL, Cyberlearn & Future Learn Tech",9/1/2012,9/5/2012,Marsha Lovett,"Lovett, M","Lovett, M|Genovese, C",PA,Carnegie-Mellon University,Standard Grant,Maria Zemankova,8/31/2016,"$496,315.00 ",Christopher Genovese,lovett@cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7511, 7625, 8020","8045, 8841, 9178, SMET",$0.00 ,normalFunding,"This PI team aims to use artificial intelligence to exploit data collected from intelligent tutoring systems to provide feedback both to students and to teachers effectively and at the right times. The team is using a new analytic approach, which introduces hierarchical modeling to learning analytics, to investigate how to better understand students' learning states. Algorithms make valid interpretable and actionable inferences from student-learning data, drawing on cognitive theories and statistics to make it work. As in tutoring systems, analysis is at the level of component skills rather than looking at end performance on a task as a whole. Research is around construction of the algorithms for deducing student learning and student learning states and around learning ways of signaling both to learners and to their teachers what concepts and skills learners understand and are capable of and which they are having trouble with. A learning dashboard will allow teachers to visualize the learning needs of a whole class and adapt activities to student needs. Feedback aimed at learners themselves will help learners recognize activities they need to engage in next to better their skills or understanding. Evaluation will include the degree to which learners development of metacognitive skills when such tools are available. <br/><br/><br/>The proposed work will contribute towards the next generation of intelligent tutoring systems as well as contribute to the data analytics needed to make use of large-scale educational data repositories. Because the Learning Dashboard will be independent of any particular domain, and because metacognition and self-assessment are foregrounded, the Learning Dashboard and what is learned about designing an effective learning dashboard should be applicable across disciplines and classes. The proposal brings together what is known about learning, metacognition, and intelligent tutoring systems to address timely learning analytics issues."
546663,CAREER:  Scaling Up First-Order Logical Reasoning with Graphical Structure,IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",12/15/2005,11/30/2009,Eyal Amir,"Amir, E","Amir, E",IL,University of Illinois at Urbana-Champaign,Continuing grant,Sven G. Koenig,11/30/2010,"$496,038.00 ",,eyal@cs.uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,"1640, 7495","1045, 1187, 6856, 7495, 9218, HPCC",$0.00 ,normalFunding,"Proposal 0546663<br/>""CAREER: Scaling Up First-Order Logical reasoning with Graphical Structure""<br/>PI: Eyal Amir<br/>University of Illinois at Urbana-Champaign<br/><br/>The ability to reason automatically about the world is central to Artificial Intelligence (AI).  In recent years the number of objects and relations that applications must consider has increased dramatically, and current real-world applications require reasoning mechanisms that can scale to thousands and millions of objects and relations. This research focuses on scaling up logical inference to many objects using graph-based structures that are available in real-world domains. The key idea is a methodology for fast and correct inference in first-order logic (FOL) that can ignore most interactions between objects, functions, and predicates. The method works by partitioning the input FOL theory into a tree of sub-theories, identifying (seemingly essential) ignorable interactions, and creating a compact propositional encoding of the original theory.  It reasons with that new encoding or uses the tree to guide reasoning in FOL directly.<br/>This project has the potential for wide Broader Impact through possible applications including object detection and complex queries on natural language texts.  This project will integrate research and educational activities by involving students in the research and by integrating the research into both undergraduate and graduate classes.<br/>"
953495,CAREER: Evolutionary Computation and Bioinformatics,IIS,"INFO INTEGRATION & INFORMATICS, EPSCoR Co-Funding",6/1/2010,7/18/2014,Clare Congdon,"Congdon, C","Congdon, C",ME,University of Southern Maine,Continuing grant,Sylvia J. Spengler,5/31/2016,"$496,000.00 ",,congdon@gmail.com,96 Falmouth St,Portland,ME,41049300,2072288536,CSE,"7364, 9150","1045, 1187, 7364, 9102, 9150, 9215, 9251, HPCC",$0.00 ,normalFunding,"The research focus of this project is to develop a novel evolutionary computation-based approach for identifying candidate modules in non-coding DNA that respond to environmental toxins (such as arsenic) and that alter gene expression. These modules are composed of short pieces of DNA that are binding sites for proteins; the cooperative and combinatorial interactions are believed to contribute to the inducibility and specificity of environmentally responsive genes. Since each gene has an enormous number of possible modules, searching for them in the laboratory is untenable; even an exhaustive computational search for candidate modules is impractical, given the large space. Thus, the development of artificial intelligence techniques is called for.<br/><br/>This is an interdisciplinary proposal that makes contributions in both computer science and biology. The computational contributions include designing an effective search through the large and complex space of possible modules. While a few existing tools have been designed to search the thousand base pair region immediately upstream of the gene, the work here is designed to search significantly longer sections, 1 million base pairs and longer in length. The existing approaches cannot be expected to scale to the larger search, requiring the development of a novel approach.<br/><br/>The PI has plans for introducing undergraduates to research, both through coursework and in supervised research projects. This proposal will support and encourage the creation of a new upper-level course in informatics as well as the development of informatics-themed exercises to be incorporated at the introductory level. The project will further directly support undergraduate researchers who will contribute to the core research project.<br/>This project will result in a well integrated program of research and teaching for the PI, contribute to the available tools and our understanding of evolutionary computation approaches for informatics work, and introduce scores of students to this work."
1423419,RI: Small: Design and Implementation of Goal-directed Solvers for Answer Set Programming,IIS,ROBUST INTELLIGENCE,7/1/2014,6/24/2014,Gopal Gupta,"Gupta, G","Gupta, G",TX,University of Texas at Dallas,Standard Grant,James Donlon,6/30/2018,"$495,109.00 ",,gupta@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"This project is focused on the development of an efficient Answer Set Programming (ASP) solver, advancing the state-of-the-art in logic based knowledge representation, logic programming and artificial intelligence.  ASP is an elegant way to represent knowledge and perform advanced reasoning (common sense reasoning, non-monotonic reasoning, planning, constraint satisfaction, etc.). ASP is based on the stable model semantics proposed by Gelfond and Lifschitz. It has gained wide acceptance in the last fifteen years in the knowledge representation (KR) and artificial intelligence (AI) research communities due to its incorporation of negation, its expressiveness and simple, intuitive syntax. Considerable past research has been done in developing the ASP paradigm as well as its implementations and applications.  Implementation techniques for realizing answer set solvers range from simple guess-and-check based methods to those based on SAT solvers and complex heuristics. Applicability of current ASP systems is limited due to (i) the current implementation methods not being goal-directed (i.e., not being query-driven), (ii) need for grounding the answer set program if predicates are present, (iii) being forced to find the model of the entire program (even though to answer a given query only a small subset of the model needs to be computed), and (iv) no answer being produced even if a minor inconsistency (unrelated to the query) is present in the knowledge base. This project addresses these problems by developing a query-driven implementation of answer set programs containing predicates.  Current systems have to process the entire knowledge base (expressed as an answer set program) to compute an answer. In contrast, the query-driven method developed in this project only accesses and processes parts of the knowledge base that are involved in answering the query. Query-driven execution allows predicates to be directly included in answer set programs. It also leads to efficiency in execution.  <br/><br/>The query-driven method is based on PI's group's recent discovery of coinductive logic programming. Coinductive logic programming imparts operational semantics to greatest fixed point-based computations. Given a query and an answer set program, this coinduction-based operational semantics is used to compute (partial) answer sets that contain the query goal(s). With query-driven execution, predicates can be supported directly, i.e., answer set programs containing predicates no longer have to be grounded first. The main tasks of this project are the following: (i) develop an efficient query-driven, top-down execution strategy for propositional answer set programs; (ii) extend this query-driven execution strategy to handle Datalog ASP (without grounding the program first); (iii) further extend this query-driven execution strategy to handle Predicate ASP (without grounding the program first); (iv) develop coinductive extension of ASP and its implementation; (v) develop a query-driven abductive reasoning engine based on ASP; and, (vi) further extend the engine to incorporate constraints over reals.  The key intellectual contributions of the research is the investigation of techniques for query-driven execution of answer set programs and advanced reasoning systems that employ negation.  The research tests the claim that a query-driven implementation can more elegantly (and efficiently) support constraints and abduction in ASP. The broader impacts of this work include the availability of more powerful applications of knowledge representation; mechanisms for common sense reasoning; integration of advanced ASP systems into education and research venues; and the development of the research careers of graduate and undergraduate students, including those from under-represented groups."
821766,MRI: Acquisition of Robotic Hardware for Humanoid Research  in Cognitive Science and Engineering,BCS,"MAJOR RESEARCH INSTRUMENTATION, ROBUST INTELLIGENCE",9/1/2008,6/3/2009,Stefano Carpin,"Carpin, S","Carpin, S|Newsam, S|Kallmann, M|Noelle, D|Matlock, T",CA,University of California - Merced,Standard Grant,John E. Yellen,8/31/2011,"$492,500.00 ","Shawn Newsam, Marcelo Kallmann, David Noelle, Teenie Matlock",scarpin@ucmerced.edu,5200 North Lake Road,Merced,CA,953435001,2097566405,SBE,"1189, 7495","0000, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"This award establishes a humanoid robotics facility at the University of California, Merced to be used by cognitive scientists and engineers to investigate (1) how embodiment constrains models of human cognition, (2) how people naturally interact with humanoid robots, and (3) how the design of robotic control systems can best address the cognitive issues surrounding human-robot interaction.  The centerpieces of this facility will be a fully mobile humanoid robot and a humanoid torso equipped with two human-like dexterous arms and a vision system mounted on a fully actuated head. Though much work on humanoid robots has focused on solving fundamental engineering problems associated with robust operation in real world environments, the proposed facility will support research that uses the robot as an instrument to test hypotheses of human cognition or that augments robotic capabilities in a manner sensitive to the cognitive limitations of human-robot coordination.  As a scientific instrument, a humanoid robot can be used to present precise, controlled motions and patterns of interaction to human experimental participants, offering new methods for probing human responding in interactive contexts.  The embodied perceptual and motor capabilities of such a robot also make it a challenging testbed for computational models of human cognitive processes.  Developing cognitive systems that appropriately support human-robot interaction will reify and test our understanding of embodied perception, humanoid motor coordination, and cooperative interaction.<br/><br/>The proposed facility is also intended to support interdisciplinary research at the boundary between cognitive science and engineering. Emerging cognitive research on human-robot interaction has the potential to transform robotics research and result in practical innovations in the design of humanoid robot control systems.  These additional engineering contributions will be extremely valuable, as robots will be equipped with physical and cognitive abilities that are appropriate for human environments, and with communication and coordination skills that are appropriate for human-robot collaboration.  Indeed, robotic assistants have already demonstrated potential in numerous application areas, including physical therapy, care for the elderly and disabled, collaborative work, and astronaut support during space exploration.  Though recent technological innovations have allowed for the development of reliable and affordable robotic mechanisms that mimic human bodies, many questions related to the intelligent control of these bodies remain.  By supporting the exploration of models of human cognition within a robotic framework, and by generally applying insights from cognitive science to the problems of embodied perception and motor control, practical progress is expected in domains such as locomotion in cluttered environments, spatial awareness and spatial reasoning, dexterous object manipulation, task-oriented attention and perception, imitation and learning, life long adaptation, and multi-modal social interaction and coordination with humans, including the use of natural gestures.<br/><br/>This facility will advance the development of integrated research and teaching programs at UC Merced, a new campus located in an economically challenged region with low educational levels.  The availability of this equipment will grant students access to unique training opportunities in Cognitive Science, Artificial Intelligence, Motion Planning, Computer Graphics, Computer Animation, Computer Vision, Machine Learning, Robot Algorithms, and Humanoid Robotics.<br/>"
1717062,SaTC: CORE: Small: Scalable and Meaningful Threat Intelligence Generation,CNS,Secure &Trustworthy Cyberspace,8/15/2017,8/7/2017,Damon McCoy,"McCoy, D","McCoy, D",NY,New York University,Standard Grant,Dan Cosley,7/31/2020,"$492,064.00 ",,dm181@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,CSE,8060,"025Z, 7434, 7923, 9102",$0.00 ,normalFunding,"Threat intelligence is used by organizations to protect systems and end-users by detecting and blocking communications with known attackers' systems. Quality threat intelligence can also provide methods of detecting attackers' tools, which are often less ephemeral than their attack infrastructure.???Unfortunately, producing quality threat intelligence is often a highly manual and inefficient process.???This has resulted in???limited???amounts of useful threat intelligence which is available???only to???those companies that can afford it. This research develops new data-analytics methods to identify???an attacker's infrastructure and attack tools. Our methods leverage the ability to???efficiently collect???large amounts???of raw attacker data, process it, and build artificial intelligence techniques to discover attack patterns. This project improves the efficiency of generating high quality threat intelligence data, and makes it more affordable to a large range of companies.<br/>???<br/>Achieving this goal of improving the efficiency of generating useful threat intelligence requires progress on several key challenges. The project (i) investigates supervised machine learning based methods for efficiently collected large-scale amounts of data from attackers, (ii)???improves???methods for storing this data and other freely available raw threat intelligence data such that it can be easily joined, (iii) identifies robust features that can be extracted from this raw data???which???can be used for training supervised machine learning detection techniques,???and???(iv) enables high performance and efficient generation of large-scale useful threat intelligence data.???Consequently, this research has the potential to transform the way in which threat intelligence data is produced and improve the security of organizations by making threat intelligence more accessible. This work also creates many educational opportunities for undergraduate and graduate students to gain experience using data-analytics techniques to efficiently detect emerging threats and improve the security of organizations."
535284,"Unsupervised, Non-stop Extraction of Information from the World Wide Web",IIS,"INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE, COLLABORATIVE SYSTEMS",3/1/2006,6/3/2008,Oren Etzioni,"Etzioni, O","Etzioni, O|Soderland, S",WA,University of Washington,Continuing grant,Maria Zemankova,2/28/2009,"$492,000.00 ",Stephen Soderland,etzioni@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7364, 7495, 7496","7495, 9215, 9218, 9251, HPCC",$0.00 ,normalFunding,"A long standing dream of Artificial Intelligence has been to create an<br/>autonomous learner that continuously increases its knowledge by<br/>reading a wide variety of texts.  To date, this kind of knowledge<br/>acquisition has been attempted only rarely, and typically at small<br/>scale.  Yet the Web has made a vast library of online text readily<br/>accessible.  <br/><br/>In response, this project investigates a family of unsupervised,<br/>domain-independent, scalable systems that learn from the Web in an<br/>open-ended fashion.  Such systems not only extract information but<br/>also extend their ontology, incorporating new classes and relations.<br/>Furthermore, the systems' learning is recursive -- once new relations<br/>are learned, the system builds on these to learn new relations,<br/>relations between relations, and so on.  The project investigates the<br/>automatic control of this process, and analyzes both the power and<br/>limitations of this form of learning.<br/><br/>The project will impact both the natural language processing (NLP) and machine learning (ML) communities<br/>by investigating fundamental issues in learning from text.  In<br/>addition, the systems developed could lead to a new generation of Web<br/>search engines that improve information access, achieving a broad<br/>societal and economic impact. <br/>"
328849,Deriving General World Knowledge from Texts by Abstraction of Logical Forms,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/1/2003,6/22/2004,Lenhart Schubert,"Schubert, L","Schubert, L|Kyburg, H|Carlson, G",NY,University of Rochester,Standard Grant,Douglas H. Fisher,8/31/2007,"$491,491.00 ","Henry Kyburg, Gregory Carlson",schubert@cs.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,6856,"9178, 9216, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"The goal of this project is to break through the knowledge acquisition bottleneck in the effort to endow artificial intelligence (AI) systems with common sense.  The novel idea is to abstract general propositions about what is possible in the world from the specific assertions made in miscellaneous texts (including fiction).  This will be accomplished by compositional interpretation of parse trees, with heuristics to decide on verb argument structure and with concomitant simplification and abstraction of logical forms.<br/><br/>The research will employ state-of-the-art parsers to derive general knowledge from unannotated texts.  Semantic classifications of words will strengthen and disambiguate the knowledge derived from text.  There will be an emphasis on the extraction of causal knowledge, since this is so central to commonsense understanding of the world.  This will be made possible by the use of event variables in logical forms and fuller interpretation of adverbial modification.  Research will also investigate the representation of general (and often uncertain or even inconsistent) knowledge and methods of using such knowledge for inference.  One result will be a demonstration system that is able to answer simple questions eliciting general knowledge.<br/><br/>The broader impact of this work includes enhanced learning and active research participation by doctoral candidates as well as undergraduates.  By helping to break through the knowledge acquisition bottleneck, this research will pave the way for building more user-friendly AI systems for a broad range of potential applications, such as personal agents that mediate between a user and more specialized software, medical advice systems, tutoring systems, and computer games.  It could also serve to bootstrap natural language understanding systems towards more human-like understanding."
9722614,RUI: Quantum Interferometry,PHY,"OPTICAL PHYSICS, WESTERN EUROPE PROGRAM",8/1/1997,6/14/2002,Herbert Bernstein,"Bernstein, H","Bernstein, H|Greenberger, D|Shull, C|Horne, M|Zeilinger, A",MA,Hampshire College,Continuing grant,C. Denise Caldwell,9/30/2002,"$491,450.00 ","Daniel Greenberger, Clifford Shull, Michael Horne, Anton Zeilinger",hbernstein@hampshire.edu,893 West Street,Amherst,MA,10023372,4135595378,MPS,"1290, 5980","0000, 1290, 5946, 5955, 9178, 9229, 9251, OTHR, SMET",$0.00 ,normalFunding,"This research project in the general area of quantum interferometry will investigate interference phenomena at both the single and multiparticle levels. A varied set of experiments will be conducted, all of which have as their focus some property of entangled states or quantum measurement and communication. Atoms, neutrons, and photons will be used as the interfering elements. The experimental component will be accompanied by theoretical development in the general area of quantum interference."
1527668,III: Small: Sampling Techniques in Computational Logic,IIS,"INFO INTEGRATION & INFORMATICS, ",9/1/2015,6/28/2018,Moshe Vardi,"Vardi, M","Vardi, M",TX,William Marsh Rice University,Standard Grant,Aidong Zhang,8/31/2019,"$488,286.00 ",,vardi@rice.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,CSE,"7364, R217","7364, 7923, 8237",$0.00 ,normalFunding,"Constrained sampling and counting are two fundamental problems in data analysis. In constrained sampling the task is to sample randomly from among possible solutions to a Boolean formula. A related problem is that of constrained counting, determining the number of possible solutions to a Boolean formula.  These problems have applications in machine learning, probabilistic reasoning, and planning, among other areas  In particular, te project looks at the electronic-design-automation industry to determine what practical solutions to the problems require. Both problems can be viewed as aspects of one of the most fundamental problems in artificial intelligence, which is to understand the structure of the solution space of a given set of constraints.<br/><br/>This project focuses on the development of new algorithmic techniques for constrained sampling and counting, based on a universal hashing - a classical algorithmic technique in theoretical computer science. Many of the ideas underlying the proposed approach go back to the 1980s, but they have never been reduced to practice. This project builds on recent progress in Boolean reasoning to develop methods to reduce these algorithmic ideas to practice. Methods for approximations with formal guarantees provide opportunities to scale what is fundamentally a computationally intractable problem. Pruning techniques can also reduce ""waste"" in hashed solutions, but introduce challenges in ensuring samples are independently distributed. This work has potential for breakthrough results in constrained sampling and counting, providing a new algorithmic toolbox in machine learning, probabilistic reasoning, and the like."
1619344,RI: Small: Harnessing the Power of Constraint Propagation by Controlling Consistency Levels and Synthesizing Constraints,IIS,ROBUST INTELLIGENCE,7/1/2016,4/13/2018,Berthe Choueiry,"Choueiry, B","Choueiry, B",NE,University of Nebraska-Lincoln,Standard Grant,James Donlon,6/30/2019,"$486,000.00 ",,choueiry@cse.unl.edu,151 Prem S. Paul Research Center,Lincoln,NE,685031435,4024723171,CSE,7495,"7495, 7923, 9150, 9251",$0.00 ,normalFunding,"Decision and optimization problems raise many challenges in daily life as well as in business, engineering, and science.  Solving them ""well"" and ""quickly"" directly benefits our life-styles and economy, and allows us to effectively manage our resources.   Many scientific disciplines have focused on formalizing and solving such difficult combinatorial problems.   Constraint Processing (CP), a subfield of Artificial Intelligence, has focused on the transparent modeling of the restrictions (i.e., constraints) that govern those problems and create their complexity.  By examining how constraints interact among themselves and how interactions propagate along the constraints, CP has developed generic mechanisms to solve a problem by ruling out forbidden decisions and combinations of decisions, gradually eliciting the acceptable solutions and the optimal choices.  To this end, CP has formalized in terms of consistency properties how constraints interact among themselves and with the possible options.   Thus, the identification of such properties and the design of algorithms for enforcing them are at the heart of CP, and constitute perhaps what best distinguishes this area from other scientific disciplines concerned with the same computational problems.  The goal of this project is to understand the tradeoffs between the effectiveness and the cost of a variety of consistency algorithms, and to control how to interleave them dynamically during problem solving to solve difficult problems and reduce computational cost.<br/><br/>In particular, the research will garner the most computational benefits from consistency-based techniques by dynamically (a) selecting the right level of consistency to enforce at any point during search, and (b) synthesizing new constraints over opportunistically chosen variables.  The proposed activities extend on recent practical algorithms for higher-levels consistency, and contribute to the progress of the research in fundamental aspects of CP.  The developed methods will benefit other types of graphical models such as games as well as the next generation of commercial and public-domain constraint solvers. The insight gained from this research will improve the scope and content of the introductory and advanced courses on CP both at the undergraduate and graduate levels.   The various research tasks will allow the mentoring and training of young engineers and scientists to understand the roots of complexity in problem solving and to learn how to overcome it in practice."
953667,Career: An Adaptive Compiler for Multi-core Environments,CCF,"COLLABORATIVE RESEARCH, COMPILERS, SOFTWARE & HARDWARE FOUNDATION, EPSCoR Co-Funding",3/1/2010,7/16/2014,John Cavazos,"Cavazos, J","Cavazos, J",DE,University of Delaware,Continuing grant,Almadena Y. Chtchelkanova,2/28/2015,"$484,909.00 ",,cavazos@cis.udel.edu,210 Hullihen Hall,Newark,DE,197162553,3028312136,CSE,"7298, 7329, 7798, 9150","1045, 1187, 5918, 5980, 7329, 7942, 9150, 9151, 9218, 9251, HPCC",$0.00 ,normalFunding,"Compilers are a critical component between the software developer and the computer. They translate application written by software developers into machine code that is processed by the computer. An important task of a compiler is to optimize applications so that they run efficiently.  Traditional methods to develop optimizing compilers are ad-hoc, labor-intensive, and ineffective.  As a consequence, optimizing compilers for a new processor often produces code that achieves only a fraction of the machine?s available performance. This is especially true for today's multi-core architectures, which are parallel processors on a single chip.  This research will involve investigating techniques from the artificial intelligence community that will allow a compiler to automatically adapt and tune to new architectures.  In effect, this research will replace hand-tuning with self-tuning compilers that adapt software automatically to match the performance characteristics of each target architecture.<br/><br/>In this project, the PI proposes to explore the viability of developing adaptive compilers for multi-core environments (ACME) to allow application portability while still achieving high performance.  The PI will create a statistical auto-tuning framework to support the probabilistic representation of the following features: the benefit analysis of optimizations, the identification and prediction of the appropriate runtime environment for different optimizations, and the generation of executables that efficiently combine several optimized code versions. He will invent components to measure accurately the characteristics of applications and targeted computing systems. The PI hopes to discover techniques to replace ?traditional? optimization benefit analysis with powerful machine learning models. These models will address the broad spectrum of parallel applications and multi-core environments, and they will be able to analyze and predict benefit under different dynamic contexts."
1317815,NRI: Small: Collaborative Planning for Human-robot Science Teams,IIS,National Robotics Initiative,10/1/2013,9/18/2013,Gaurav Sukhatme,"Sukhatme, G","Sukhatme, G",CA,University of Southern California,Standard Grant,Reid Simmons,9/30/2017,"$482,252.00 ",,gaurav@cs.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,8013,"7923, 8086",$0.00 ,normalFunding,"This project envisions the future of scientific exploration as a collaborative endeavor between human scientists and autonomous robotic systems. The key challenge to materializing this vision lies in combining the expert knowledge of the scientist with the optimization capabilities of the autonomous system. The scientist brings specialized knowledge and experience to the table, while the autonomous system is capable of processing and evaluating large quantities of data. This research leverages these complementary strengths to develop a collaborative system capable of guiding scientific exploration and data collection by integrating input from scientists into an autonomous learning and planning framework. This is achieved by combining probabilistic planning with inverse reinforcement learning to integrate human input and prior knowledge into a unified optimization framework in the context of scientific exploration. The project team is validating the approach in the challenging domain of autonomous underwater ocean monitoring. This domain is particularly well suited for the testing of human-robot collaboration due to the limited communication available underwater and the necessary supervised autonomy capabilities. By integrating feedback from the human user into an algorithmic planning framework, the goal is to improve the efficiency of scientific data collection and gather data about phenomena that were previously outside the reach of scientific investigation. The use of autonomous vehicles for scientific data collection is becoming increasingly prominent; however, the research community lacks a foundational understanding of the interactions between scientists and autonomous vehicles. This work focuses on principled methods for integrating human input into algorithmic optimization techniques moving towards the goal of supervised autonomy for robots.<br/><br/>This project has the potential to change the way scientific data are collected through the development of a foundational framework for human-robot scientific collaboration. Such a framework is expected to have broad implications throughout the fields of human-robot interaction and artificial intelligence. The proposed research is being integrated into the robotics and computer science curriculum at both the graduate and undergraduate levels. It is also being utilized for K-12 robotics outreach programs in Los Angeles. The algorithms created in this research are transitioned to field tests and operations via ongoing collaborations with the Monterey Bay Aquarium Research Institute (MBARI) and the Southern California Coastal Ocean Observing System (SCCOOS)."
1054630,CAREER: Online Education as a Vehicle for Human Computation,IIS,Cyber-Human Systems (CHS),3/15/2011,3/16/2011,Luis von Ahn,"Ahn, Lv","Ahn, Lv",PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,2/29/2016,"$482,052.00 ",,biglou@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,7367,"1045, 1187, 7367",$0.00 ,normalFunding,"Human computation is a growing research area that studies how to harness the combined power of humans and computers to solve problems that would be impossible for either to solve alone. The goal of this project is to introduce online education as a new vehicle and incentive mechanism for human computation. The central hypothesis is that problems that are difficult for computers can be transformed into tasks that are also educational, so that students solve the problems at the same time as they learn. With millions of people learning online, education could provide a powerful motivator for participation in distributed human computation. This project will demonstrate that education allows significantly more complex problems to be attacked with human computation than has been possible with previous paradigms for human computation. The project will also explore whether human computation can be a motivator for education. <br/><br/>The hypothesis will be tested on a new large-scale system called Duolingo, a free language-learning site in which students will solve problems that computers cannot yet solve. The site will present students with many types of activities, each exercising a different aspect of the foreign language while simultaneously channeling the students to perform a different task that artificial intelligence cannot yet accomplish. Some of the tasks that students will perform include: language translation, audio transcription, and image tagging. <br/><br/>Broader impacts.  The project will provide a free language-learning site expected to help millions of users learn a foreign language.  It will also provide large quantities of useful data in many languages to train more accurate machine learning algorithms for language translation, voice recognition, and computer vision.  Duolingo will also serve as a platform for performing large-scale experiments on how people learn languages online. In addition, undergraduate and graduate classes will be improved and developed using this research."
535100,Intransitive Classification and Choice,IIS,"ARTIFICIAL INTELL & COGNIT SCI, ROBUST INTELLIGENCE",12/1/2005,11/30/2010,Jeffrey Bilmes,"Bilmes, J","Bilmes, J|Meila, M",WA,University of Washington,Continuing grant,todd leen,11/30/2011,"$480,245.00 ",Marina Meila,bilmes@ee.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"6856, 7495","7495, 9218, HPCC",$0.00 ,normalFunding,"The goal of this project is to develop a framework for intransitive pattern classification and models of intransitive choice. Intransitivity can arise from various forms of classifiers. This includes the augmenting of log-likelihood ratios with correction terms and collections of binary classifiers (SVMs/kernel machines, binary neural networks, etc.) when used for multi-class classifiers. Intransitivity can also arise in individual and group choice (e.g., elections, tournament-style competitions). The project is developing methods to better explain intransitivity in these classifiers and to model preference relationships in social choice. Questions being investigated by this project include: (1) why/when intransitivity occurs; (2) why/how it helps classification; (3) how to introduce intransitivity in classifier systems; (4) whether intransitivity should itself be a goal, or rather whether to treat it as an artifact of imperfection and an indication of incertitude; (5) methods to detect intransitivity; (6) how intransitivity can be used to reduce errors; (7) how to model intransitivity; (8) the relationship between intransitivity in machine learning and in sociology, psychology, voting theory, political science, operations research, mathematics, economics, and philosophy; and (9) if transitive explanations can better explain natural organisms. In addition to establishing new cross-field scientific connections, this project has a broader impact through integration of its results into new seminars, tutorial articles on intransitive decision making, and new freely-available software."
519483,Multisensory convergence and mushroom body control pathways in bumblebees,IOS,"BEHAVIORAL NEUROSCIENCE, BEHAVIORAL SYSTEMS CLUSTER, MODULATION",7/15/2005,4/17/2008,Wulfila Gronenberg,"Gronenberg, W","Gronenberg, W",AZ,University of Arizona,Continuing grant,Cedric L. Williams,9/30/2010,"$480,015.00 ",,wulfi@neurobio.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,BIO,"1191, 7472, 7714","1096, 9183, BIOT",$0.00 ,normalFunding,"Bees and other social insects show very complex behaviors that include learning of color, odors and landmarks, navigation and communication. A certain component of the insect's brain, the mushroom body, is known to be involved in learning and memory and to control complex behavior. The mushroom body is particularly large and elaborate in bees. The aim of the project is to determine how the mushroom body processes sensory input such as color, movement, odor, etc. This information is distributed to different layers of the mushroom body. Does each layer represent a particular aspect of the world the bee perceives? Do nerve cells combine specific stimulus combinations relevant for learning or navigation? Can electrical brain stimulation change how the nerve cells process sensory information? The electrical signals and responses of individual nerve cells will be recorded while the bee watches relevant stimuli on a video screen. Afterwards, the nerve cells will be injected with a tracer and the cell's structure and branching pattern in the brain will be three-dimensionally reconstructed and compared to its response properties. This study will help to understand general mechanisms of sensory processing by nerve cells that are involved in learning, memory and cognition. The project makes use of a relatively simple nervous system that is much easier to approach experimentally than vertebrate animals, yet through evolutionary relationship individual nerve cells in the bee brain perform the same operations as nerve cells in the human brain. The project will help minority undergaduate students and students from community colleges to get involved in scientific research and will train graduate students in techniques and approaches relevant in biology and computer science (artificial intelligence).<br/>"
1149882,CAREER: New Directions for Metric Learning,IIS,ROBUST INTELLIGENCE,3/1/2012,3/2/2015,Kilian Weinberger,"Weinberger, K","Weinberger, K",MO,Washington University,Continuing grant,todd leen,10/31/2015,"$478,280.00 ",,kilianweinberger@cornell.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,CSE,7495,"1045, 7495, 9251",$0.00 ,normalFunding,"Quantifying similarity is a fundamental challenge in artificial intelligence and machine learning which - if performed perfectly - would reduce many tasks to a trivial nearest neighbor search. For example, determining whether an email were spam would be as simple as searching a labeled database of emails and assigning it the same label (spam or not) as the email considered most similar to it. But how can one measure the similarity of two email messages? Does the same measurement still apply when comparing medical images? How does our understanding of similarity depend on the problem specification? Metric learning optimizes distance functions specifically for a given task, taking into account both the learning problem and the data. Initial successes with linear metrics show great improvements on many ""k-nearest neighbors""-based learning tasks. <br/><br/>This project pursues four research directions that strengthen the theoretical understanding of metric learning within the research community, broaden its impact and significantly improve the current state-of-the-art: <br/><br/>1. Are there non-linear transformations that lead to equally elegant and efficient optimization problems as existing linear metrics? As data sets grow and become increasingly complex, linear metrics are no longer sufficient to capture similarity relations. By exploring the use of non-linear metrics, this research can substantially improve the impact of metric learning and the accuracy of similarity relations. <br/><br/>2. Can the impact of metric learning be extended to machine learning frameworks beyond nearest neighbors? Designing new metric learning algorithms that explicitly optimize distances for a broad variety of machine learning algorithms will significantly increase the number of applications and learning methods that can directly benefit from metric learning. <br/><br/>3. Can metrics be learned from weak supervision? Removing the dependency on labeled data will reduce the cost of metric learning and increase its applicability. <br/><br/>4. Can one develop a solid theoretical framework to explain preliminary empirical successes and to direct future research? This will strengthen the theoretical understanding of metric learning within the research community. <br/><br/>Successful resolution of the proposed problems will lead to novel learning methods which will be immediately applicable to ongoing high-impact medical research collaborations of the principal investigator. In conjunction with these research directions, the principal investigator will also pursue educational goals, including the co-development of a K-12 curriculum module estimated to impact 2,500 high-school students. Many topics in the proposed research plan have components ideal for introducing the research process to undergraduate and graduate students, and the principal investigator plans to use his research as a vehicle to instruct and inspire future computer scientists and next-generation researchers."
308139,"Scalable Multi-Objective Planning for Metric Temporal Domains:     Heuristics, Algorithms and Tradeoffs",IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2003,4/7/2005,Subbarao Kambhampati,"Kambhampati, S","Kambhampati, S",AZ,Arizona State University,Continuing grant,Edwina L. Rissland,10/31/2006,"$472,642.00 ",,rao@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,6856,"9178, 9216, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"This project will develop effective algorithms for metric temporal domains.  In many real world domains, planning involves handling actions with durations that produce and consume discrete as well as continuous resources, and goals with deadlines. The plans themselves may differ in multiple quality dimensions, including completion time, cost and execution flexibility. Previous approaches for synthesizing plans in such ""metric temporal"" domains have been plagued by poor scale-up potential, which inhibited the adaptation of the automated planning technology to such domains.  In metric temporal domains, goals have deadlines, actions have temporal durations, and their preconditions and effects occur over arbitrary intervals during action durations, and actions can produce as well as consume discrete or continuous resources. Planning in many real-world situations, including logistics, supply chain as well as space autonomy, has these characteristics.  Despite its potential applicability, adaptation of planning technology in these domains has been inhibited by the poor performance of the previous metric temporal planners.<br/><br/>The overall aim of this proposed research is to build on the advances in our understanding of the classical plan synthesis to develop scalable approaches to metric temporal planning domains.  The contributions of the project will include: (1) development of domain-independent heuristics based on planning graphs that are sensitive to multiple quality metrics of metric temporal plans (2) a suite of techniques based on constraint satisfaction problem encodings for improving the temporal quality of a given plan and (3) development of two planning algorithms with complementary tradeoffs, one searching in the space of position constrained plans, and the other searching in the space of order (precedence) constrained plans, and (4) a comprehensive investigation of the tradeoffs offered by position constrained and order constrained planners. The contributions of this research will be evaluated using the benchmark domains being developed in the planning community. <br/><br/>The results of this work will improve the suitability of computerized planning systems for a number of practical application areas.  They will also be incorporated into a textbook on foundations of automated planning and scheduling and into an undergraduate level course on automated planning and scheduling. <br/>"
1421925,RI: Small: Neuroevolution of Brain-Inspired Computational Models Over Vast Timescales,IIS,ROBUST INTELLIGENCE,7/1/2014,6/24/2014,Kenneth Stanley,"Stanley, K","Stanley, K",FL,University of Central Florida,Standard Grant,James Donlon,8/31/2018,"$472,542.00 ",,kstanley@cs.ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"For many years researchers inspired by the idea of natural selection have experimented with computer programs called evolutionary algorithms.  These algorithms simulate a kind of artificial breeding process in which a set of candidates generated by the computer are evaluated for their ability to perform a desired task.  The best performers are then allowed to reproduce with slight variation to form a new and hopefully improved generation.  In recent years evolutionary algorithms have exhibited the ability to evolve brain-like structures called artificial neural networks in an approach called neuroevolution.  These evolved networks perform tasks often critical to technological progress and artificial intelligence like controlling robots or recognizing images.    However, unlike evolution in nature, which yields dramatic changes over hundreds of thousands of generations, evolutionary algorithms have rarely been run for more than a few thousand.   This project for the first time is applying new evolutionary techniques that reward continual novelty and diversification to experiments evolving over hundreds of thousands of generations, on the scale of nature.  The driving hypothesis is that modern evolutionary algorithms run on this scale can yield robotic behaviors, agent morphologies, and decision-making capabilities significantly beyond the current state of the art.<br/><br/>To investigate long-term evolution in practice, artificial neural networks are being evolved in a variety of domains through new kinds of novelty-driven neuroevolution algorithms designed to avoid the convergence seen in typical evolutionary experiments.  Because this new class of algorithms tends to avoid convergence, the long-term dynamics and ultimate potential for discovery of such algorithms over vast time scales (i.e. hundreds of thousands of generations) is almost entirely unknown.  The idea of running neuroevolution at unprecedented timescales mirrors recent results in related areas like deep learning where massive computation has proven capable of fundamentally altering the kinds of problems that can be solved.  Because evolutionary runs over hundreds of thousands of generations yield enormous troves of evolutionary data, an important component of the project is the development visualization techniques for exploring and characterizing the results of such runs.   The project overall is producing a new set of tools, a new set of evolved capabilities for autonomous control and decision-making, and an increased understanding of the implications of big data and big computation for simulated evolution in computers."
1658380,Collaborative research: Combining models and observations to constrain the marine iron cycle,OCE,CHEMICAL OCEANOGRAPHY,7/1/2017,3/3/2017,Jefferson Moore,"Moore, J","Moore, J|Primeau, F",CA,University of California-Irvine,Standard Grant,Simone Metz,6/30/2020,"$470,704.00 ",Francois Primeau,jkmoore@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,GEO,1670,,$0.00 ,normalFunding,"Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
633856,Collaborative Research: REESE- Assisting and Assessing Middle School Science Learning in Formal and Informal Settings,DRL,REAL,1/1/2007,8/24/2007,Gautam Biswas,"Biswas, G","Biswas, G",TN,Vanderbilt University,Continuing grant,Elizabeth VanderPutten,12/31/2010,"$467,355.00 ",,gautam.biswas@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,EHR,7625,"9150, 9177, SMET",$0.00 ,normalFunding,"An important goal of formal education is to prepare students for future learning when there is no longer classroom supervision. To continue learning, people need to learn to self-assess their own progress and understanding. We are investigating the social basis of self-assessment for learning. Specifically, we hypothesize that, under identifiable conditions, assessing others can support self-assessments that promote content learning plus the ability to develop self-assessment strategies that can be applied in the future. In this project, we take advantage of Teachable Agent technologies where students learn by teaching computer agents through the use of well-formed visual representations. Teachable Agents, using simple artificial intelligence techniques, can then reason based on what they have been taught. This creates optimal conditions for self-assessment, because students' assessments of their agents' performance is also an assessment of their own knowledge. The work occurs in the context of teaching the key ecosystem concepts of interdependence and balance to middle school students. Students will first create Teachable Agents that are linked to their curriculum on pond and river ecosystems, and use this learning experience to create a new Teachable Agent that can sustain multiple fish in a home aquarium system. Students will also use the Teachable Agents in a new homework model that leverages current trends in home computer use and connects learning in formal and informal settings; students log on, chat with one another, and their agents interact with another in an on-line virtual environment. Overall, the proposed project joins three important strands of research assisted by advanced technology tools: The learning of dynamic processes in science; the social basis of self-assessments for learning; and, the improvement of connections between formal and informal learning settings."
527252,Collaborative Research Traffic Congestion: Actions and Reactions,BCS,HSD - DYNAMICS OF HUMAN BEHAVI,9/1/2005,7/22/2010,Konstantinos Triantis,"Triantis, K","Triantis, K|Teodorovic, D",VA,Virginia Polytechnic Institute and State University,Standard Grant,Amber L. Story,2/28/2011,"$467,044.00 ",Dusan Teodorovic,triantis@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,SBE,7319,"0000, 7319, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"This interdisciplinary research focuses on the effects of traffic congestion, and on evaluating alternative investments to manage the demand for transport services, as well as the social and behavioral impact of these investments. Today traffic flows continue to rapidly outpace resources available to society for improving the transportation infrastructure, and better management of existing facilities would be a cost effective way for resolving the problem. Since congestion depends on the policies chosen by the traffic authorities, and on the social interaction of individuals as drivers and passengers, analyzing congestion requires an integrated approach that allows for different viewpoints: the transportation agencies', the consumers', as well as the perspective of society as a whole. The primary objective of this research is to find an optimal mix of strategies that will spread traffic congestion over geographical space and time by better utilization of current resources, thereby reducing its costs. These strategies, such as dynamic pricing or highway reservation methods, have either been implemented in few selected areas in the United States, or have been discussed conceptually; however, their effects on travel and the urban infrastructure are not well understood. We propose to bring together tools from economics, systems engineering, and transportation engineering for a comprehensive analysis of the congestion problem. A number of concurrent objectives will be pursued in this research, which involves artificial intelligence models of users' transportation services, a set of economic experiments to evaluate different transportation policies, a model of the interaction of social networks and transportation choices, and a system dynamics analysis of transportation and social networks and their dynamic evolution. The successful completion of this research will have the potential to lead to new paradigms of traffic analysis and to a new understanding of the linkages between transportation, the urban infrastructure and ultimately the regional economy."
1016465,RI: Small: Integrating Paradigms for Approximate Stochastic Planning,IIS,ROBUST INTELLIGENCE,8/15/2010,9/9/2013,Mausam Mausam,"Mausam, M","Mausam, M",WA,University of Washington,Standard Grant,todd leen,7/31/2014,"$466,508.00 ",,mausam@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7495,"7923, 9251",$0.00 ,normalFunding,"A fundamental challenge for Artificial Intelligence is sequential decision making under uncertainty, a task where automated algorithms lag far behind human-level intelligence. The primary reason for the disparity is curse of dimensionality - the number of states is exponential in the problem features. Recent advances that restrict decision-theoretic computation to a reachable subset of state space have scaled to moderately-sized problems, but proven ineffective in scaling to real problems. On the other hand, probabilistic planners based on deterministic planning might scale up, but with a massive loss in solution quality.<br/><br/>This project is investigating several methods to scale probabilistic planning to real-sized problems. We combine decision-theoretic analysis, basis function approximation and the classical AI planning techniques, to develop a series of highly scalable planners. A common theme in our techniques is the use of deterministic plans to automatically obtain domain abstractions in the form of 'good' or 'bad' properties, or intermediate subgoals. The project introduces and exploits a principled collaboration between decision theory and classical planning techniques, thus retaining the benefits of both - high quality as well as high performance. Experiments show that our new planner solves difficult planning competition problems using orders of magnitude less memory outputting high quality policies.<br/><br/>Our research also proposes effective solutions to long-standing problems of generating a set of basis functions and computing a hierarchical problem decomposition. Both basis function approximation and hierarchical decomposition are popular in existing literature for speeding up planning, but they are not fully automated - a human is required to specify the basis functions and the hierarchy. We provide novel, domain-independent solutions that remove this additional human effort.  <br/><br/>Our research addresses several long standing challenges in AI, like scaling stochastic planning, and automatically generating basis functions and subgoal hierarchies. We expect to produce state-of-the-art planners that will be effective in large and complex real world scenarios, e.g., planetary exploration, military operations planning, and robotic decision making."
613550,SoD-TEAM:  Problem-Solving Methodology in Collaborative Design,CCF,"ITR-SCIENCE OF DESIGN, SOFTWARE ENG & FORMAL METHODS",8/15/2006,7/6/2010,Steven Tanimoto,"Tanimoto, S","Tanimoto, S|Winn, W",WA,University of Washington,Standard Grant,Sol J. Greenspan,7/31/2011,"$465,642.00 ",William Winn,tanimoto@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7372, 7944","7372, 9216, 9218, 9251, HPCC",$0.00 ,normalFunding,"Directorate for Computer and Information Science and Engineering (CISE)<br/>Division Computer and Network Systems (CNS)<br/>Science of Design (SoD) Program<br/><br/>Proposal Number: 0613550 <br/>P/I:   Steven Tanimoto <br/>PI's Department: Computer Science and Engineering <br/>Institution:  University of Washington<br/>Award:   $ 449,642<br/><br/>Title:    ""SoD-TEAM: Problem-Solving Methodology in Collaborative Design""<br/><br/>This project focuses on software tools that facilitate collaboration among members of a design team. The project permits a design team to manage the explored portions of a space of alternative designs. In addition, it supports evaluation and communication among team members about design alternatives. One goal of the project is to develop a methodology and a framework for software-designers that is based on studies that will lead to understanding how to support end-user exploration of solution-spaces. In addition the project facilitates collaboration among designers with different interests, expertise and the need to have both private as well as share common group-based designs. The theory of problem solving that forms the basis of the project involves ""state-space search."" The state-space search methodology applies to both formal problem solving (where automation without human intervention is possible) and to complex design problems in which some aspects can be ""fuzzy"". However, the approach proposed with this project is to merge the two genres of software and create a new one: software that allows a collaboration among automatic design processes and human designers, and one that makes visible not only the details of particular designs but also a substantial piece of the space of possible designs. In support of this project, the proposers developed the core of an initial research prototype software system to support design with transparent display of design spaces. This system, T-Star, implements a human interface that supports problem-solving using an approach from artificial intelligence that includes a view of the portion of the solution space that has been explored so far. Having a visual rendition of the spatial context of exploration helps ground design team collaboration.<br/><br/>Program Manager: Anita J. La Salle<br/>Date: June 26, 2006<br/>"
1018954,"RI: Small: A Human-Level, Real-Time, Integrated Agent",IIS,ROBUST INTELLIGENCE,9/1/2010,4/19/2011,Arnav Jhala,"Jhala, A","Jhala, A|Mateas, M",CA,University of California-Santa Cruz,Standard Grant,Weng-keen Wong,1/31/2015,"$464,090.00 ",Michael Mateas,ahjhala@ncsu.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7495,"7495, 7923, 9251",$0.00 ,normalFunding,"This project is developing and integrating statistical and symbolic methods of Artificial Intelligence in an agent architecture and evaluating the agent in a competitive domain, notably the real-time strategy game StarCraft. Real-time strategy (RTS) games provide several interesting research challenges including real-time decision making, enormous state spaces and imperfect information. StarCraft is a popular commercial RTS game that has several professional gaming leagues, and therefore ideal for evaluating the performance of AI agents. Professional StarCraft players reason about and react to strategic decisions at multiple levels of abstraction, sometimes executing over 300 game actions per minute, so developing competition-level StarCraft agents presents extraordinary challenges.  <br/><br/>More specifically, the project is using novel supervised and unsupervised learning algorithms to automatically learn domain knowledge from collections of professional gameplay traces; the agent is being implemented within the reactive planning architecture ABL (A Behavior Language). The ABL reactive planner provides the glue for integrating multiple, heterogeneous reasoners within a real-time execution environment. <br/><br/>This work is expected to make significant contributions to the understanding of decision making processes  in a complex, real-time domain. This understanding will contribute to the development of robust, intelligent systems that can be deployed within real-world environments. This work will motivate AI researchers to build integrated agent architectures. As a well-known game with very high-level professional play, research in StarCraft AI has the potential to attract significant attention to AI research. The StarCraft competition being hosted by our lab  has attracted significant interest both within and outside academia, and at the high-school, undergraduate and graduate level. Thus, this work has the potential to raise general public awareness in research in human-level AI, and will encourage high-school students to pursue careers in computer science and game design."
812653,Supporting Wilderness Search and Rescue Personnel: Acquiring and Visualizing Aerial Imagery,IIS,"Cyber-Human Systems (CHS), GRAPHICS & VISUALIZATION",11/1/2008,4/13/2011,Bryan Morse,"Morse, B","Morse, B|Goodrich, M",UT,Brigham Young University,Continuing grant,Ephraim P. Glinert,10/31/2012,"$462,784.00 ",Michael Goodrich,morse@byu.edu,A-285 ASB,Provo,UT,846021231,8014223360,CSE,"7367, 7453","7367, 7453, 9150, 9215, 9251, HPCC",$0.00 ,normalFunding,"Wilderness search and rescue (WiSAR) is the task of finding and giving assistance to humans who are lost or injured in mountain, desert, lake, river, or other remote settings.  Rapid coverage of large search areas and difficult terrain is critical; as the search radius increases, the probability of finding and successfully aiding the missing person decreases.  Prior NSF-sponsored research established the hypothesis that mini (2-8 foot wing span), fixed-wing Unmanned Aerial Vehicles (UAVs) equipped with video cameras can support WiSAR personnel.  In this project the PIs plan to extend that work, by addressing key human factors and technology obstacles that must be overcome to make such support practical and efficient.  Through enhanced WiSAR-oriented UAV operator interfaces and visualization, the PIs will improve both the UAV's coverage of the search area by people without piloting skills and the searcher's detection of the missing person or other signs in the video.  The design of these WiSAR systems will integrate the PIs' expertise in human-robot interaction, computer vision, visualization, and artificial intelligence.  The project adopts a human-centered evaluation approach that uses both laboratory and field tests.  Innovative aspects of the work include integration of video mapping, missing-person modeling, and human interaction to create prioritized search maps that are dynamically updated as information is acquired, and which can then be used to perform search planning based on this dynamic information, requiring real-time planning algorithms that can adapt to uncertainty and new information.  The prioritized search maps and resulting plans can be used directly by WiSAR personnel, or integrated into the UAV operator?s interface, or allow WiSAR personnel to outline a plan and grant the UAV sufficient autonomy to optimize coverage subject to this outline.   The PIs will also integrate multiple video sources (including infrared imaging), anomaly detection and tracking, and geo-registered video annotation in order to further assist WiSAR personnel in detecting, identifying, and communicating information about objects of potential interest in the video sources.  These will be presented to WiSAR personnel in the form of interfaces designed for their separate roles: UAV operator, video searcher, incident commander, and field searcher, as well as integrated interfaces for individuals acting in multiple roles simultaneously.  Finally, the PIs will extend this work to support video-equipped manned aircraft and ground search teams.<br/><br/>Broader Impacts:  Each year, many people are lost or find themselves in jeopardy while hiking, boating/kayaking, skiing, fishing, etc.  WiSAR consumes thousands of man-hours and hundreds of thousands of dollars each year in Utah alone.  Creating appropriate visualization algorithms and user interfaces to support planning, visualization, and UAV control should decrease the amount of time required to locate and offer assistance to missing persons, increasing the likelihood of successful rescue.  The PIs plan to include in this project undergraduate students from nearby Utah Valley State College (UVSC), a school that does not yet have a graduate program and consequently has few opportunities for socially relevant, interdisciplinary undergraduate research."
1650961,Individuating and comparing objects and events,BCS,LINGUISTICS,7/15/2017,7/13/2017,Alexis Wellwood,"Wellwood, A","Wellwood, A",IL,Northwestern University,Standard Grant,William J. Badecker,4/30/2018,"$462,064.00 ",,wellwood@usc.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,SBE,1311,"1311, 9178, 9179, 9251",$0.00 ,normalFunding,"The primary mode by which we communicate our ideas about the world and about each other is through language. However, languages aren't merely passive vehicles for the transmission of information. Rather, our sentences carry along with them evidence of the fundamental concepts and categories that we use to understand the world and each other. At one level, this fact about language might seem obvious: a person on one side of an argument might choose to use words that a person on a different side might not, and attending to these different choices tells us something about the people speaking. Such observations about language and language users are studied in fields like sociolinguistics. Yet, our language also reveals more basic truths about us which are not as easily accessible to consciousness, and which are more tied to elements of our common experience. For example, people talk as if there are objects that can be counted (""four spoons"") and substances that cannot (e.g., ""four muds"" is odd), even if arranged in discrete piles. Investigating language at this deeper level can thus reveal basic structures of thought, informing theories of cognition and its development, as well as applications in artificial intelligence.<br/><br/>This project studies parallels in the conceptualization of the basic categories 'object' and 'event' as they are encoded in language and understood by both adults and 4 year olds. Previous research in linguistics and the philosophy of language has uncovered striking formal parallels in the encoding of these categories across nominal and verbal language. The project links this research to what is known about object representation in cognitive science, and uses this link to extend what is known about event representation. Specifically, the project (i) tests whether the observed linguistic parallels correspond to parallels in how adults and children conceptualize minimally-different static and dynamic scenes, (ii) investigates the extent to which representational biases for simple dynamic scenes predicts how adults and children understand quantificational language involving words like ""more"", and (iii) probes the hypothetical universality of the language-cognition linkages by teaching English-speaking adults and children attested, but non-English patterns of event encoding. The results of this project will demonstrate the fruitfulness of connecting formal semantics, philosophy of language, and cognitive science to illuminate the interface between linguistic and non-linguistic perception and cognition."
1149803,CAREER: A New Neat Framework for Statistical Machine Learning,IIS,ROBUST INTELLIGENCE,3/1/2012,3/2/2015,Pradeep Ravikumar,"Ravikumar, P","Ravikumar, P",TX,University of Texas at Austin,Continuing grant,Weng-keen Wong,2/28/2017,"$458,368.00 ",,pradeepr@cs.cmu.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7495,1045,$0.00 ,normalFunding,"The pendulum in Artificial Intelligence (AI) research has periodically swung from so called ""neat"" or mathematically rigorous approaches, and ""scruffy"" or more adhoc approaches. In recent years, real-world data across varied fields of science and engineering are increasingly complex, and involve a large number of variables, which has resulted in a surge of scruffier methods. This proposal develops a general ""neat"" framework for such modern settings by leveraging state of the art developments in two of the most popular subfields of machine learning methods: graphical models and high-dimensional statistical methods. These developments have in common that a complex model parameter is expressed as a superposition of simple components, which is then leveraged for tractable inference and learning.<br/><br/>Our unified framework results not only in a unified picture of these developments but also provides newer methods to work with such high-dimensional data. The research thus impacts problems across science and engineering wherever statistical machine learning approaches are being used (such as genomics, natural language processing and image analysis, to name a few). The work on a unified framework for statistical machine learning problems is highly coupled with a push for imparting training to students on what we call ""comptastical"" thinking. This combines both computational and statistical thinking required for addressing the problems of limited computation and limited data inherent in modern statistical AI application domains. The proposal also develops an infrastructure for component-based courses with relationally organized lecture module components."
1321053,"RI: Small: Deep Learning: Theory, Algorithms, and Applications",IIS,ROBUST INTELLIGENCE,8/15/2013,6/16/2014,Pierre Baldi,"Baldi, P","Baldi, P",CA,University of California-Irvine,Continuing grant,Weng-keen Wong,7/31/2016,"$457,999.00 ",,pfbaldi@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,"7495, 7923, 9251",$0.00 ,normalFunding,"The ability to learn is essential to the survival and robustness of biological systems. There is also growing evidence that learning is essential to build robust artificial intelligent systems and solve complex problems in many application domains. However, solutions to complex problems ranging from recognizing faces to understanding speech, cannot be implemented in a single step. Instead they require multiple processing stages, for instance to extract increasingly more abstract and refined features from an input image. <br/><br/>Thus computers and brains are both faced with the problem of deep learning --- how to simultaneously optimize the parameters of a hierarchy of processing stages in order to solve complex tasks and display intelligent behavior. In the past few years there has been remarkable progress in computer science to address the deep learning problem, and deep learning methods now claim state-of-the-art performance in several application areas. The next generation of machine learning methods holds the promise to not only approach human performance in tasks previously impossible for computers, but also to exceed it. However, our theoretical understanding of deep learning remains limited and there are several important areas where deep learning has not yet been applied systematically. This project addresses these challenges and opportunities by furthering formal understanding of the theory and algorithms behind deep learning, and by applying deep learning methods to new problems in the life sciences. Because deep learning can be used in almost any domain, the results have the potential for broadly impacting science, engineering, and technology across multiple areas. <br/><br/>The project has educational and outreach components, ranging from courses to virtual 3D world interactions, for undergraduate and graduate students at UCI, as well as talented students from local high schools, and underrepresented minority students from local colleges. Scientific results, data, and software resulting from the project will be disseminated in scientific journals and over the web.<br/><br/>The project has three main thrusts: theory, algorithms, and applications. From a theoretical standpoint, the project develops better mathematical understanding of deep architectures, including stacks of autoencoder networks, and their properties. These theoretical results will inform the design of deep-learning architectures. From an algorithmic standpoint, the project investigates, formally and through simulations, several deep learning algorithms, including the dropout algorithm and the PI's deep targets algorithm. From an application standpoint, the project uses the new theoretical and algorithmic knowledge in application to the life sciences, for instance for protein structure prediction, and in predicting chemical reactions. Advancing the state-of-the-art for any one of these thrusts will have a significant impact in computer science, artificial intelligence, statistical machine learning, and the corresponding application field."
1423276,RI: Small: CompCog: Modeling Latent Discrete Knowledge Across Utterances,IIS,ROBUST INTELLIGENCE,8/1/2014,6/10/2016,Jason Eisner,"Eisner, J","Eisner, J",MD,Johns Hopkins University,Continuing grant,Tatiana D. Korelsky,7/31/2018,"$457,999.00 ",,jason@cs.jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,7495,"7495, 7923, 9251",$0.00 ,normalFunding,"Each human language is a system of conventions for communicating information.  Yet how does everyone know this complex system?  Describing it is difficult even for linguists.  Yet young children somehow figure out the rules and vocabulary of their native language.  Adults continue to learn when confronted with unfamiliar words, with new conventions associated with social media, or with the layout conventions of a new website. <br/> <br/>This project develops new artificial intelligence methods for tasks of this kind.  These methods will enable computers to deal with a wider variety of human language data, thus improving information access and global communication.  They will also provide insight as to why human intelligence is able to succeed at these problems.<br/><br/>The methods will seek to discern the systematic structure that explains the patterns in naturally occurring linguistic data.  Specifically, our computers will analyze naturally occurring data in order to learn:<br/><br/>* How to break down words into meaningful parts and reassemble those parts into new words.  This is a subject that linguists call morphophonology.  It is practically important in automated analysis and translation of speech and text.<br/><br/>* How to break down sentences into meaningful phrases.  This requires determining the basic word order facts of the language -- the problem of grammar induction, considered to be a central mystery of human language learning.<br/><br/>* How to extract machine-readable data from large websites that present databases in human-readable form.  This involves automatically figuring out the database structure and layout conventions of a website.<br/><br/>* How to track names across large quantities of informal text.  By discovering the principles that govern how people use and modify names, a computer can recognize that the nickname ""Vlad P."" or the misspelled patronymic ""Vladimir Vladimirovich"" might be variant ways of referring to ""Vladimir Putin,"" especially in a political comment.  <br/><br/>The project will address each of these domains in a principled way.  Our strategy in each domain is to develop a novel Bayesian generative model along with efficient, principled machine learning algorithms for approximate inference.  We expect to expand the range of modeling and inference techniques that are available to the natural language processing community.  <br/><br/>Innovative technical directions include the automatic reconstruction of phonological underlying forms, a novel treatment of grammar induction as structured prediction, a nonparametric model of databases and database-backed websites, and a phylogenetic model of name variation."
1618783,"RI: Small: Effective Preference Reasoning over Combinatorial Domains: Principles, Problems, Algorithms, and Implementations",IIS,ROBUST INTELLIGENCE,7/1/2016,12/22/2017,Miroslaw Truszczynski,"Truszczynski, M","Truszczynski, M",KY,University of Kentucky Research Foundation,Standard Grant,Weng-keen Wong,6/30/2019,"$457,594.00 ",,mirek@cs.uky.edu,109 Kinkead Hall,Lexington,KY,405260001,8592579420,CSE,7495,"7495, 7923, 9150, 9251",$0.00 ,normalFunding,"Preferences are fundamental attributes of human reasoning and decision making. They appear whenever a choice between alternatives is to be made. Understanding and automating preference reasoning is a major problem of artificial intelligence, especially important for the design of autonomous intelligent decision support systems. If there are few alternatives, preferences between them can be represented explicitly and preference reasoning is typically easy. However, in practice the number of alternatives facing the decision maker can be daunting in many cases.  In such cases, modeling and representing preferences of the decision maker, and automating preference reasoning based on the model are challenging. To respond to the challenge, the project will study principles and properties of preference aggregation and optimization over large domains of alternatives, and algorithms to support preference reasoning tasks; will develop methods for preference learning and approximation in support of building preference models; and will implement software for effective preference modeling and reasoning. Areas such as knowledge representation, computational social choice, and constraint solving embodied by answer-set programming and satisfiability testing will inform these studies. The project will result in a theoretical and algorithmic framework for preference reasoning over combinatorial domains, in software tools for effective preference reasoning, and in methods to integrate them into artificial intelligence decision support systems that are becoming pervasive in industrial, scientific and governmental applications. <br/><br/>The project will assume that the space of alternatives is modeled by a combinatorial domain, where alternatives are represented in terms of values of attributes relevant to decision making. While combinatorial domains are exponentially large in the number of attributes, the sets of values of individual attributes are typically small. This opens a possibility of expressing preferences over elements in a combinatorial domain in terms of preferences on attribute values and relations between the attributes. This is the setting for the project, with preference trees, CP-nets and answer set optimization programs as formal representations of preferences over combinatorial domains. The project will focus on preference aggregation and preference optimization. Finding optimal and near-optimal alternatives, finding collections of optimal or near-optimal alternatives that are in some sense diverse (or similar), and aggregating preferences that are only partially known are some examples of specific problems we will consider. As building manually preference models over large domains is infeasible, the project will study methods to learn preference models (for instance, preference trees), and develop methods for model approximation (different models have varying computational properties, and close approximations of ``hard'' models with ``easy'' ones may prove effective for reasoning with the former).  Finally, the project will develop a software suite for several key preference reasoning tasks. The implementation will exploit advances in answer-set programming and satisfiability. The resulting software will be systematically evaluated on benchmarks coming from or motivated by practical applications."
954138,CAREER: Reasoning under Uncertainty in Cybersecurity,CNS,"TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace, EPSCoR Co-Funding",3/1/2010,3/10/2014,Xinming Ou,"Ou, X","Ou, X",KS,Kansas State University,Continuing grant,Sylvia J. Spengler,3/31/2016,"$457,373.00 ",,xou@usf.edu,2 FAIRCHILD HALL,Manhattan,KS,665061100,7855326804,CSE,"7795, 8060, 9150","1045, 7434, 7923, 9150, 9168, 9178, 9251",$0.00 ,normalFunding,"Cyber security, like security in the physical world, relies upon investigation methodologies that piece together dispersed evidence spread across multiple places, and come to a conclusion on what security breaches have happened and how they happened. While effective evidential reasoning based on manual analysis are used in the physical world by law-enforcement agencies, in the cyber world we need automated reasoning methodologies to handle the automated cyber attacks against our nation's information infrastructures every day. This research aims at discovering and developing such automated reasoning methodologies. The problem is  difficult due to the uncertain nature of such reasoning, which is compounded by the characteristics of cyber attacks.<br/><br/>The uncertainty in cyber security comes from two sources. The first is the uncertainty from not knowing the attacker's actions and choices. Since hackers are essentially invisible in the cyberworld, we have to rely upon various types of sensors that report symptoms of potential attacks. The second source of uncertainty comes from these sensors. Since in most cases the symptoms of cyber<br/>attacks significantly overlap with symptoms from benign network activities, it is not possible to rely on a single sensor to give an absolutely correct judgment on whether an attack has happened and succeeded. A key question is how to use these imperfect sensors to conduct reasoning so that one can come up with almost certain conclusions regarding a system's security status. <br/><br/>This challenge of reasoning under uncertainty is not new. In the past four decades computer science researchers have developed an array of reasoning models and methods for uncertainty, especially in the area of artificial intelligence. However, the emergence of cyber threats poses a new<br/>challenge to this problem. The existing methodologies typically require a knowledge-engineering process to build a knowledge model for the problem domain. This has worked reasonably well with the more static and well-behaved problem domains such as disease diagnosis. A key difference between these problem domains and cyber security is that the latter has to deal with an active<br/>malicious attacker who will try to break whatever assumptions made in the reasoning model. For this reason, the knowledge model for cyber security cannot be static because then they can be easily evaded. What will be an effective and practical knowledge engineering approach to handle the uncertainty in cyber security is the biggest open problem that needs to be answered from the<br/>research.<br/><br/>This research adopts an empirical, bottom-up approach to tackle the above challenges. Instead of starting from the existing theories, the PI will start from empirical study on how a human security analysts would reason about cyber events and try to capture the essence of the reasoning in the process. Then, the PI will carry out this empirical study by running intrusion detection sensors on production networks and work with system administrators to understand and reason about the alerts. The next step is to develop a reasoning model that simulates the human reasoning process, and apply the automated reasoning engine on fresh new data to see how it fares. In this spiral theory development process the PI can always make sure that the methodologies are applicable to real cyber-security analysis and constantly find gaps in the model that reveal what will be the most appropriate theories and how to apply them in this problem. The eventual goal is to find the right theoretical framework for reasoning under uncertainty in cyber-security, and validate such theories through repeatable experiments on data from production systems.<br/><br/>This research is tightly integrated into the PI?s education efforts both for students and targeted at the society at large. The empirical nature of the research provides a valuable venue for dialogue between security practitioners and researchers, which will result in a two-way education process: students working on the project can acquire the essential skills of applying advanced knowledge to a practical problem; and security practitioners like system administrators can learn the state-of-the art in cyber security technology through collaborative work with the research team. The empirical study carried out from the research will provide endless data and examples to refresh the materials of the cyber-security courses taught by the PI. New courses with a focus on uncertainty in cyber security defense will be developed. There will be a number of undergraduate students who take part in the research efforts, which will provide a unique education experience for them. Moreover, the test-bed infrastructure produced from the research will also be used as an education platform for the general public about cyber-security problems, with the help of the out-reach programs already established at Kansas State University."
1441009,Project Engage: Training Secondary Teachers to Deliver Computer Science and Engineering Instruction,DRL,"STEM - Computing Partnerships, Computing Ed for 21st Century",9/1/2014,7/22/2015,David Allen,"Allen, D","Allen, D|Dow, P|Lin, C",TX,University of Texas at Austin,Standard Grant,Julio E. Lopez-Ferrao,8/31/2017,"$457,287.00 ","Pauline Dow, Calvin Lin",allen@che.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,EHR,"1996, 7382","7578, 8244, 9177, SMET",$0.00 ,normalFunding,"Developing computer science teachers who can support high school students in being successful in rigorous, academic computer science courses is a national need.  Project Engage: Training Secondary Teachers to Deliver Computer Science and Engineering Instruction will support the implementation of an emerging Computer Science Principles course called Thriving in Our Digital World (TODW) in forty-five urban, suburban, and rural schools, including public, private, magnet, and charter schools, in Texas.   The TODW course will be offered in a unique dual enrollment mode (concurrent high school and college credit).  This project will test two innovative professional development techniques for expanding the reach to more schools: flipped classroom techniques, in which teachers receive recorded video-based professional development, and then use face-to-face time for more hands-on activities; and an automated system which will use artificial intelligence technology to support negotiation of common grades for student work between high school teachers and college faculty.  This project's research agenda will address the following core challenge: In a field such as computer science where there is limited expertise, how can we most efficiently scale professional development so as many schoolteachers as possible can provide high quality instruction?  <br/><br/>The STEM-C (Science, Technology, Engineering, and Mathematics, including Computing) Partnerships program supports research-driven partnerships between STEM experts and K-12 school systems to bring about institutional change for better STEM education at the K-12 level. This STEM-C Partnerships' Computer Science Education Expansion project builds on prior funding of the UTeachEngineering: Training Secondary Teachers to Deliver Design-Based Engineering Instruction Partnerships through the National Science Foundation's Math and Science Partnership program. This project will produce the scientific foundation and the concrete artifacts needed to deliver a highly scalable curriculum for TODW. The artifacts will include a differentiated curriculum, scalable professional development, and scalable assessment tools and processes. The differentiated curriculum will include formative assessments which can be used by teachers to architect novel pathways through the curriculum for individual students or whole classes. Assessments will be created that can be delivered through a double-blind collaborative review (DBCR) rubric scoring tool, which will include machine learning algorithms that help detect consistent discrepancies between scores of individual (novice) computer science teachers and (expert) college-level computer science professors. The DBCR tool will use machine learning techniques such as basic text features (Bag of Words), syntactic and semantic modeling (n-grams and Latent Dirichlet Allocation), and cluster analysis against existing artifact corpora. Since the assessments of student artifacts are explicitly tied to rubrics, human evaluators may also use the DBCR tool to specify specific features that support line item rubric scores. The available features will vary from project to project but will leverage a variety of tools available in the DBCR user interface: (1) selectable categorical classifications, (2) the highlighting of relevant text features, and (3) annotations to mark document structures, such as cross references and supporting evidence.  Project evaluation will focus on both implementation fidelity of the TODW course and student-level outcomes in classes that implement TODW. If successful, the professional development could serve as a model for more scalable teacher professional development in many domains."
1406049,II-EN: Software Tools for Monte-Carlo Optimization,CNS,"COMPUTING RES INFRASTRUCTURE, ROBUST INTELLIGENCE",10/1/2014,6/20/2016,Alan Fern,"Fern, A","Fern, A|Dietterich, T|Tadepalli, P|Todorovic, S|Groce, A",OR,Oregon State University,Standard Grant,Reid Simmons,9/30/2019,"$456,286.00 ","Thomas Dietterich, Prasad Tadepalli, Sinisa Todorovic, Alex Groce",afern@eecs.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,"7359, 7495","7359, 7495, 9251",$0.00 ,normalFunding,"The Computing Research Infrastructure project supports the development of an open-source software library for Monte Carlo methods in artificial intelligence on a cloud-based platform.  Monte Carlo methods are randomized numerical algorithms used in AI, machine learning, data mining, and the physical sciences.  As data size and model complexity continue to grow, advanced large-scale Monte-Carlo techniques (including parallel implementation) has become ubiquitous.  However software tools to easily implement advanced techniques for large-scale Monte Carlo are not established or broadly available.<br/><br/>The software library developed in this project will help bridge this gap, and lower the barrier to adoption of advanced Monte Carlo techniques by a broad research community.  The library will include a variety of existing state-of-the-art algorithms, as well as novel software components. The algorithms and tools have many important applications, including: <br/>(a) optimization of ecological management problems, including endangered species conservation, forest fire management, and invasive species management (b) automated software testing, (c) optimization for experimental design in science and engineering, (d) tracking of multiple objects from noisy visual evidence, and (e) activity and object recognition in computer vision. These problems have significant societal and economic importance and the research has the potential to significantly extend current capabilities.<br/><br/>The algorithms and tools will be implemented using a common interface supporting a cloud-based platform, which will allow other researchers to extend and apply the library to important applications. The software library will be integrated into the<br/>undergraduate and graduate curriculum at Oregon State University.  In addition, an online course centered around the theory and application of the library components will be developed, facilitating use by a wide audience.<br/><br/>The developed library will include components based on the investigators' research that realize a number of technical<br/>innovations for Monte-Carlo Optimization (MCO), including: a) Exploiting multi-fidelity simulators in MCO for offline and online planning, (b) Developing MCO techniques for item discovery problems, (c) Developing MCO techniques for online policy improvement in sequential decision making, (d) Learning to reduce branching factors for more efficient online MCO, and (e) Integrating symbolic reasoning and MCO for scalable sequential decision making. These new capabilities will advance the state-of-the-art in artificial intelligence and enable new applications to be addressed that are beyond the scope of prior MCO methods."
1056046,CAREER: Oxidative Stress - Responsive Shape Memory Vascular Patch,CBET,Engineering of Biomed Systems,9/1/2011,4/11/2012,Hak-Joon Sung,"Sung, HJ","Sung, HJ",TN,Vanderbilt University,Standard Grant,Michele Grimm,8/31/2016,"$455,999.00 ",,hj72sung@gmail.com,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,ENG,5345,"004E, 1045, 1187, 137E, 7218, 7237, 9102, 9150",$0.00 ,normalFunding,"Sung<br/>1056046<br/><br/>The PI will program two ""smart"" functions (i.e., oxidative stress-responsive and shape memory functions) into biomaterials by employing shape memory polymers crosslinked with peptide sequences that degrade in response to injury-mediated overproduction of reactive oxygen species. The ""smart"" functions of these biomaterials will be evaluated as a form of an injectable vascular patch whose shape, size, and thickness can be tuned to custom-fit even small blood vessels. Stimuli-sensitive materials change their structure and shape in response to changes in environment, such as heat, light, moisture or magnetic field. In the proposed project, oxidative stress is selected as an external stimulus because overproduction of reactive oxygen species is a universal mark of damaged organs, tissues, and cells. Reactive oxygen species-degradable peptides that can crosslink polymers when making patch scaffolds will be used to generate the oxidative stress-responsive function. Shape memory polymers in a combinatorial format, x% crosslinkable unit -co-y%non-crosslinkable unit, where x and y% indicate the molar ratio, will be used to tune the ability to memorize  temporary shapes and regain their original shape after exposure to body temperature (37 ???C).  The basic polymer type proposed for this study has shown excellent vascular compatibility in previous studies. Furthermore, the polymer-peptide complex will be fabricated asvascular patch scaffolds aimed at repairing small blood vessels (e.g., cerebral hemorrhage and stroke). The patch scaffold surface will be coated with antibodies against vascular cell adhesion molecule-1 to generate a ""suture-free sealing effect"" by mimicking inflammatory cell adhesion onto injured endothelium.  The ""smart"" functions and their subsequent effects on vascular healing will be evaluated in a bioreactor system that mimics the vascular environment. This is a very challenging research task due to the interdisciplinary nature of the conceptual and technical approaches. <br/><br/>Intellectual Merit: The proposed research will advance the state of the art in methods and techniques for applications of ""smart"" biomaterials to develop therapeutic inventions. Some of the innovative expected results include: 1) providing a stepping stone to develop the next generation of biomaterials that enable  artificial intelligence-like work flow (i.e., navigating, sensing, and fixing); 2) incorporating biological molecules into a shape memory material function; 3) advancing ""smart"" material functions to cope with complex biological signaling; 4) a new therapeutic approach to regeneration of injured small blood vessels and a therapy of further pathogenesis, such as cerebral hemorrhage and stroke; and 5) generating a new tool box for minimally-invasive surgery and for design of scaffolds with customizable  size, shape, and thickness. The proposed research will have a far reaching impact in terms of real applications of the research developed, as well as the broad spectrum of research areas. Achieving the goals of this project requires a deep understanding of material design and fabrication, as well as biomedical applications. <br/><br/>Broader Impact: Direct outcomes of this research will influence a large cross-section of the engineering and biomedical community and will stimulate education towards multidisciplinary subjects. Successful translation of the research to real world applications has the potential to revolutionize biomaterials and the regenerative medicine industry. Broader impacts also result from a range of education and dissemination activities, including 1) integrating research projects with coursework, outreach, and training through the existing courses and programs; 2) teaching abroad to expand outreach; and 3) creating a web-based vibrant youth community comprised of students in the  US and S. Korea. Though the focus is biomaterials and tissue engineering, the basic elements will appeal to students from all areas of science and engineering. The PI will use established assessment tools to evaluate and adjust his pedagogical methods in these various integrative learning environments. He will also disseminate his new pedagogical methods for use by other instructors."
534999,Proto-Value Functions: A Unified Framework for Learning Task-Specific Behaviors and Task-Independent Representations,IIS,ROBUST INTELLIGENCE,1/1/2006,12/19/2007,Sridhar Mahadevan,"Mahadevan, S","Mahadevan, S",MA,University of Massachusetts Amherst,Continuing grant,Douglas H. Fisher,12/31/2009,"$455,686.00 ",,mahadeva@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,"7495, 9218, HPCC, 9178, 9251, SMET",$0.00 ,normalFunding,"This project addresses a longstanding puzzle in artificial intelligence (AI): how can agents transform their temporal experience into multiscale task-independent representations that can effectively guide long-term task-specific behavior? The project will investigate a nonparametric framework combining task-independent learning with task-specific learning. Algorithmically, the framework comprises of four phases. Initially, agents learn a discrete manifold representation of a given environment, which can be viewed as a topological graph representing the states reachable through single or multi-step actions. Next, the graph is analyzed using spectral clustering techniques to reveal ""bottlenecks,"" symmetries, and other geometric invariants. In the third phase, an orthonormal set of task-independent basis functions called proto-value functions are extracted from the environment's topology: These basis functions capture large-scale geometric invariants that all value functions on the state space must adhere to. In the final phase, proto-value functions are combined with rewards to approximate task-specific value functions.<br/><br/>The proposed framework unifies two previously disparate lines of research in AI: learning of behavior using value functions, pioneered by Arthur Samuel, and the learning of representations based on global state space analysis, pioneered by Saul Amarel. The theoretical basis for the framework draws upon links between discrete and continuous mathematics: Riemannian manifolds and the spectral theory of graphs; elliptic differential equations and abstract harmonic analysis on graphs. Specifically, the Hilbert space of smooth functions on a Riemannian manifold has a discrete spectrum based on the eigenfunctions of the Laplace-Beltrami operator. The applications of this theory to Markov decision processes will be explored, in particular the ability of Laplacian eigenfunctions or proto-value functions to both capture large-scale geometric structure and as well as approximate task-specific value functions. A novel class of algorithms termed Representation Policy Iteration (RPI) will be investigated, which interleave representation learning and behavior learning. The research thus also addresses a longstanding question not resolved in much previous work on approximation methods for solving large Markov decision processes: how can basis functions be generated automatically? The research will investigate the scalability of the proposed framework to larger problems, including both discrete factored state spaces as well as continuous state spaces. The testbeds include simulated discrete and continuous benchmark problems, simulated and real robot testbeds, and an information extraction task of maintaining the Reinforcement Learning Repository (RLR), the world's largest collection of documents and data relating to reinforcement learning.<br/><br/>Broader impacts of this project include algorithmic and theoretical insights leading to a unified approach to learning behavior and representation, as well as applications to real-world problems such as humanoid robotics and web repository maintenance. Additionally, this project will give valuable research experience to women graduate students and to undergraduate students from local four year colleges."
1319966,RI: Small: Any-Angle Search,IIS,ROBUST INTELLIGENCE,8/1/2013,7/20/2018,Sven Koenig,"Koenig, S","Koenig, S",CA,University of Southern California,Standard Grant,James Donlon,7/31/2019,"$452,979.00 ",,skoenig@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,"7495, 7923, 9251",$0.00 ,normalFunding,"In this project, the PI studies any-angle search methods. Any-angle search methods are variants of the heuristic search method A* that interleave the search with path optimizations by propagating information only along grid edges (to achieve small runtimes) but without constraining the paths to grid edges (to find short ""any-angle"" paths, namely paths whose headings can change by any angle). The objective of this project is to broaden any-angle search from a few isolated search methods to a well-understood framework and to extend its applicability. To this end, the PI is developing new any-angle search methods and analyzing their properties, which is complicated by the fact that even base properties often do not transfer from A* to them. The team will also evaluate all new and existing any-angle search methods against each other and against alternative search methods, for example, to understand how they trade off among runtime, path length and memory consumption.<br/><br/>Any-angle search is a recent search paradigm that promises to result in a new class of powerful path-planning methods for mobile robots, including underwater and aerial vehicles. The project includes dissemination activities to raise awareness of any-angle search in artificial intelligence and robotics (such as via tutorials, open-source code and web applets) and offers research opportunities to both graduate and undergraduate students."
924248,The Sensorimotor Dynamics of Naturalistic Child-Parent Interaction and Word Learning,BCS,DS - Developmental Sciences,9/1/2009,8/19/2009,Chen Yu,"Yu, C","Yu, C|Smith, L",IN,Indiana University,Standard Grant,Betty H. Tuller,8/31/2013,"$452,151.00 ",Linda Smith,chenyu@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,SBE,1698,"0000, 6868, 7956, OTHR, 6890","$452,151.00 ",normalFunding,"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>Children begin to comprehend words at 9 months. They say their first word at around 12 months. The pace of vocabulary learning then accelerates so that by 24 to 30 months, children add words at the staggering rate of 5 to 9 new words per day. There have been many studies focusing on documenting developmental progress in early language acquisition, and most theories of learning derived from those studies have focused on macro level descriptions that sound like explanations, such as ""the mother tried to elicit the child's attention by waving the toy."" These descriptions may capture higher-level human behaviors, but they fall short of a mechanistic account of how word learning works in real time. Toddlers learn words through millisecond by millisecond, second by second, and minute by minute events that are generated by actively engaging in the world, with objects, and with their social partners. But very little is known about how any of this works in real time and in the cluttered context of the real world interactions of toddlers and parents, contexts typically characterized by many interesting objects, shifts in attention by each participant, and goals (beyond teaching and learning words). In light of this, the series of experiments in this project will provide a systematic study of child-parent interaction and learning as coupled complex systems. The child's actions (head and eye movements, hand movements, picking up objects) create within the child dynamic dependencies of looking, seeing, touching and feeling. Each moment of perceptual and motor activity by the learner determines the next -- a head turn determines what is seen next, which may determine what is reached for and brought close to the eyes, which selects and generates the next view. Thus, the learner is a dynamic complex system. But the toddler is not alone when learning new words. Instead, a mature partner -- who is also a complex multimodal system -- offers words, gestures and actions. Critically, the streams of touches, sights and sounds from two participants are closely coupled, with one agent shaping the experiences and behaviors of the other. The study will measure the dynamic multimodal behavioral patterns within and across social partners as children and parents actively engage with and talk about objects in everyday contexts. The project will collect multiple streams of high-resolution, high-quality video and speech data from both participants. The dense and rich streams of multimodal data are useful only to the degree that one can find meaningful patterns in those dynamic streams that bring new insights into real-time learning events. To this end, the project will develop new methods of data analysis, visualization and data mining to quantify fine-grained behavioral patterns within an individual's cognitive, perceptual and motor systems and across social partners. This constitutes a significant advance in theoretical approaches to early word learning and one that also has broad applications. Measuring interaction patterns within and between complex systems is a critical problem across science -- from cells, to brains, to coupled physical systems, to human-computer interaction, to groups of animals, to teams of people. Thus, this research will bring new methods and analytic tools for measuring the information in coupled interactive systems.<br/><br/>Understanding learning mechanisms in the context of a dynamic, everyday learning environment is essential to understanding typical development, individual differences, and atypical development. Designing effective procedures to benefit children with developmental delays requires a principled understanding of that dynamic environment as it relates to the cognitive learning system. Thus, the work will provide scientists, educators, and parents with an understanding of children's early cognitive processes and general principles to facilitate child-parent social interaction and early language learning. Moreover, building anthropomorphic machines that can acquire language automatically may be best accomplished by emulating how toddlers learn language. Artificial intelligence systems with human-like language skills have important utilities in real-world applications. Finally, this approach is methodologically novel. Not only will it provide new findings, but the research will be a proving ground for the development and invention of these new techniques -- techniques that may be applied in many different domains of social and behavioral studies, such as typical and atypical cognitive development, collaboration and joint problem solving, and adult social interactions."
1350671,"CAREER: Problem Solving in Dynamic, Distributed Environments",IIS,"ROBUST INTELLIGENCE, EPSCoR Co-Funding",1/15/2014,1/23/2014,Roger Mailler,"Mailler, R","Mailler, R",OK,University of Tulsa,Standard Grant,James Donlon,12/31/2018,"$450,793.00 ",,roger-mailler@utulsa.edu,800 S. Tucker Drive,Tulsa,OK,741049700,9186312192,CSE,"7495, 9150","1045, 7495, 9150",$0.00 ,normalFunding,"Computers are increasingly used to monitor and manage many aspects of our daily lives.  These systems are often required to work together to solve complex problems that are rapidly changing.  Current approaches to addressing these situations develop tailored distributed protocols that are verified through empirical testing.  This project increases the practical applicability of distributed problem solving techniques by developing a theoretical model of these problems based on thermodynamic theory.  Using this model, a protocol's performance can, for the first time ever, be predicted under previously untested conditions.<br/><br/>This theoretical model is validated through extensive empirical evaluation and this project develops a new protocol that alters its problem solving strategy to maximize the trade-off between deliberate and reactive decision making based on environmental dynamics.  This protocol is applied to address a pressing practical problem: allocating telescopes for tracking objects in Low Earth Orbit (LEO). With nearly all of our manned space missions and satellites in LEO, effectively monitoring space debris has broad implications to society at large and scientific progress along numerous directions.<br/><br/>This transformative research combines cross-disciplinary ideas from artificial intelligence, distributed systems, and statistical physics.   The educational initiatives in this project directly address the recruitment and retention of students, especially focusing on women and minorities, into Computer Science by generating excitement through the Heartland Gaming Expo and by utilizing a new peer outreach program, called Engineering Ambassadors."
713178,RI: Large-Scale Dynamic Programming,IIS,INFO INTEGRATION & INFORMATICS,8/15/2007,8/12/2008,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Continuing grant,Sylvia J. Spengler,8/31/2011,"$450,000.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7364,"7495, 9216, HPCC",$0.00 ,normalFunding,"Dynamic programming is a very general, powerful, and robust problem solving paradigm in artificial intelligence and computer science.  Dynamic programming is an algorithm schema that includes a number of well-known systematic search algorithms in Artifical Intelligence, including breadth-first search, Dijkstra''s algorithm, A*, value iteration and policy iteration for Markov decision processes, as well as many polynomial-time algorithms for combinatorial problems, and pseudo-polynomial-time algorithms for numeric NP-complete problems.  These algorithms are extremely robust, in that they are guaranteed to find a solution to a problem if one exists, and often an optimal solution.<br/><br/>Most dynamic programming algorithms are limited in the size of problems they can solve by the amount of storage available.  While semiconductor memory costs about $100 per gigabyte, magnetic disk storage costs less than 40 cents per gigabyte, and single disks with one terabyte of storage are now available.  In practice, the available storage on a modern workstation can be increased by three orders of magnitude with multiple disks, at moderate cost. Unfortunately, you can''t simply replace memory with disk storage in a dynamic programming algorithm.  The reason is that it takes about ten milliseconds to access a single byte on disk, compared to about 100 nanoseconds for main memory.<br/>However, large blocks of data on disk can be read or written sequentially at high speed. This work will develop, implement, and experiment with dynamic programming algorithms that store their data on magnetic disk.  The main research challenge is to design these algorithms so that all data access is sequential.  By shifting the resource bottleneck from space to time, parallelizing these algorithms to run on multiple processors or multiple cores becomes an additional research challenge.  The PI has had some success with this paradigm, implementing large-scale breadth-first and heuristic searches that run for months at a time. The techniques will be broadened to cover other classes of dynamic programming algorithms.  The proposed challenge problems include numeric NP-complete problems, finding the radius and diameter of various problem spaces, and amino acid and DNA sequence alignment in computational biology.  If successful, in addition to engaging students at UCLA, the work can have impact throughout computer science.  The idea of extending memory with disk storage is potentially applicable to any memory-intensive algorithm and can be used to speed up computations that reside entirely in memory by improving cache performance."
1319365,RI: Small: Reinforcement Learning with Predictive State Representations,IIS,ROBUST INTELLIGENCE,8/1/2013,7/24/2014,Satinder Baveja,"Baveja, S","Baveja, S",MI,University of Michigan Ann Arbor,Continuing grant,Weng-keen Wong,7/31/2018,"$450,000.00 ",,baveja@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Like animals and humans, artificial autonomous agents that are able to predict short-term and long-term consequences of their actions can then plan their behavior, act more intelligently, and achieve greater reward. Agents that can learn such predictive models from experience can be more robust in their intelligence than agents that rely on pre-built models. The PI and graduate students are focused on the particularly challenging but natural case where observations from the agent's sensors far in the past can continue to influence the predictions of consequences of actions long into the future. (For example, the observation of where you park the car in the morning will help predict where you will see the car later in the day.) There are two broad classes of approaches to learning predictive models in such 'partially observable' settings. Finite-history models use short-term history of observations to predict future observations conditioned on actions; these are fast to learn but are limited because they cannot capture the effects of long-term history. Latent-variable models can capture the effects of long-term history by positing hidden or latent variables that capture the true state of the environment (e.g., the location of the car), but such models are difficult to learn because the latent variables have to be inferred from data. <br/><br/>This project builds on previous work by the PI and others on a third approach, called Predictive State Representations (or PSRs), in which the agent maintains predictions of future observations conditioned on future actions as a summary-representation of history; these models can both be fast to learn and capture the effect of long-term history. This project develops new PSR-based methods and algorithms for hierarchical models, rich-feature-based models, and local and modular models.  The project applies the new methods to challenging applications from active perception and robotics. In addition, theoretical understanding of these richer and newer methods will be developed. Altogether the project significantly expands the applicability of PSR-methods as well as their theoretical foundations and algorithms. <br/><br/>Broader Impacts: New methods that allow artificial agents to robustly build predictive models would advance the state of knowledge across the fields of artificial intelligence, reinforcement learning, control, operations research, psychology, and neuroscience. The PI is co-leading an effort to create a new undergraduate degree in Data Sciences at the University of Michigan to be jointly managed by Computer Science & Engineering and Statistics. This future degree as well as other current undergraduate research programs will be targeted to recruit, mentor, and train students for this project."
1116541,RI: Small: Addressing Visual Analogy Problems on the Raven's Intelligence Test,IIS,ROBUST INTELLIGENCE,8/1/2011,7/30/2012,Ashok Goel,"Goel, A","Goel, A",GA,Georgia Tech Research Corporation,Continuing grant,Hector Munoz-Avila,7/31/2015,"$450,000.00 ",,ashok.goel@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7495,7923,$0.00 ,normalFunding,"This proposal aims to create purely image-based reasoning methods for solving visual analogy problems, particularly so-called Raven's Progressive Matrices (RPM) problems. The project draws on recent results from the study of human cognition as well computer science and mathematics. Raven's Progressive Matrices consist wholly of visual analogy problems in which a matrix of geometric figures is presented with one entry missing, and the correct missing entry must be selected from a set of answer choices. Recent analysis of RPM data suggests that although in general the performance of individuals with autism on most intelligence tests is significantly inferior to that of typically developing individuals, on the Raven's test the performance of the two groups is comparable. This data is consistent with the ""Thinking in Pictures"" hypothesis that has been proposed as a potential, partial cognitive explanation of autism. In both artificial intelligence and psychology, current theories of solving RPM problems first convert the visual inputs into verbal representations and then process the verbal representations. In contrast, this project explores the hypothesis that many RPM problems can be solved using only visual representations, without extracting any verbal representations from the input images. This project will develop and analyze computational techniques for addressing RPM problems with only visual representations. <br/><br/>In particular, this project will develop a novel algorithm based on affine transformations for addressing RPM problems as well as a second algorithm that makes use of fractal encodings. With both approaches -- affine and fractal -- the project seeks to achieve human-level performance on RPM in terms of percentages of problems solved correctly. The two algorithms will also be tested on the ""odd-man-out"" corpus that contains thousands of visual analogy problems. The project will formally characterize the set of visual analogy problems for which the affine and fractal algorithms are applicable, analyze the computational properties of the algorithms, construct proofs of their correctness for specific classes of problems, and compare the errors made by the two algorithms with those made by two groups of humans -- typically developing individuals and individuals with autism. The project will parameterize the visual algorithms to detect the settings under which the patterns of errors made by an algorithm on RPM problems most closely match the error patterns of the two human groupings. <br/><br/>Autism is an important problem of growing social concern. While the thinking-in-pictures hypothesis has long been a significant insight into cognition in autism, and empirical evidence -- both behavioral and neuroimaging -- in its favor is increasing, there have been no computational models for it. The proposed research would help provide a computational form to this hypothesis and may help establish a disposition towards visual thinking with autism. RPM is considered one of the core tests of intelligence, and although there have been several suggestions about the visuospatial nature of RPM problems, all current computational models addressing such visual analogy problems use sequential processing on propositional representations of the input images. The algorithms from this project that rely on visual representations for RPM could provide new insights into intelligence testing. Lastly, while fractal encodings have been used in computer graphics for generating images and in computer vision for texture analysis in image processing, this project's use of fractal encodings for visual analogies on intelligence tests will contribute to knowledge of fractal computing."
447903,CAREER:    Undirected Bipartite Graphical Models,IIS,"INFORMATION & KNOWLEDGE MANAGE, INFO INTEGRATION & INFORMATICS",3/15/2005,2/12/2009,Max Welling,"Welling, M","Welling, M",CA,University of California-Irvine,Continuing grant,Maria Zemankova,2/29/2012,"$450,000.00 ",,welling@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,"6855, 7364","1045, 9218, HPCC",$0.00 ,normalFunding,"Modern society increasingly relies on processing, storing and communicating large amounts of information. The exponential growth of databases necessitates the development of algorithms that structure, compress and query them efficiently. The goal of this research is to develop new tools based on probabilistic models to achieve these objectives.<br/><br/>A new class of ""undirected bipartite graphical models"" is studied that embeds documents into a low dimensional ""topic-space"". These representations are efficient and capture semantic relationships. Training of the underlying probabilistic model is achieved through a technique called ""contrastive divergence learning"" which is particularly well adapted to the UBG model. The main contributions of this research are the development of a new class of probabilistic graphical model, the development of improved learning algorithms that scale up to large data-sets and the application of these novel techniques to two real world applications: image restoration and information retrieval.<br/><br/>Research is integrated with teaching through the development of new classes in machine learning both at the undergraduate and the graduate level, where students will be engaged in research in the above application areas.<br/><br/>The proposed research makes important contributions that can have a broad impact on security, web-technologies, commerce, multi-media, medical expert systems etc. In particular, the proposed projects in image restoration and information retrieval have the potential to make an impact on tomorrow's technologies.  An open-source, web-based repository with freely available software will be developed to help achieve that goal.<br/><br/>http://www.ics.uci.edu/~welling/NSFcareer/NSFcareer.html"
1420316,RI: Small: A Systematic Approach to Robot Task and Motion Planning in Belief Space,IIS,ROBUST INTELLIGENCE,8/15/2014,8/13/2014,Tomas Lozano-Perez,"Lozano-Perez, T","Lozano-Perez, T|Kaelbling, L",MA,Massachusetts Institute of Technology,Standard Grant,Reid Simmons,7/31/2018,"$450,000.00 ",Leslie Kaelbling,tlp@csail.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Non-technical Abstract:<br/>Robots have the potential for wide-ranging positive impacts on society in complex or dangerous applications such as disaster relief, elder care and the reshoring of manufacturing jobs.  However, existing robots have had limited success is these domains, mainly because the planning and control algorithms are not robust to misconceptions in the robot's ""understanding"" of its environment nor to small imperfections in the robot's ability to execute the required actions.  The overall goal of this project is to develop the sensing, planning, and control algorithms necessary to overcome these problems, and hence necessary to allow robots to work productively in complex domains shared with humans.<br/><br/>The key activities of this project are the development of new ways of representing uncertainty in the state of the world that support efficient planning for robots. These new representations and algorithms provide principled and practical methods of integrating perception and action in complex domains. The resulting algorithms are tested in the context of a real robot performing household tasks in a kitchen environment.<br/><br/>The project also involves a thorough integration of research and education. Graduate and undergraduate students are involved in all aspects of the research. Furthermore, the research in this project forms the basis of an undergraduate subject on robot planning algorithms under development at MIT.<br/><br/>Technical Abstract:<br/>The overall goal of this project is to develop the estimation, planning, and control techniques necessary to enable robots to perform robustly and intelligently in complex uncertain domains. Robots operating in complex, unknown environments have to deal explicitly with uncertainty. Sensing is increasingly reliable, but still inescapably local: robots cannot see, immediately, inside cupboards, under collapsed walls, or into nuclear containment vessels. Planning, whether in household and disaster-relief domains, requires explicit consideration of uncertainty and the selection of actions at both the task and motion levels to support gathering information.<br/><br/>In order to explicitly consider the effects of uncertainty and to generate actions that gain information, it is necessary to plan in belief space: that is, the space of the robot's beliefs about the state of its environment, which we will represent as probability distributions over states of the environment. For planning purposes, the initial state is a belief state and the goal is a set of belief states: for example, a goal might be for the robot to believe with probability greater than 0.99 that all of the groceries are put away in acceptable locations, or that there are no survivors remaining in the rubble.<br/><br/>This project is developing a systematic, integrated approach to finding plans efficiently in high-dimensional uncertain domains. By factoring the belief space and exploiting a decoupling between geometric and probabilistic reasoning, this approach can employ constraint satisfaction methods to generate good solutions relatively efficiently. This program of basic research provides conceptual, formal, algorithmic, and software results that are of use in mobile manipulation robotics, as well as artificial intelligence more generally, including applications from medical diagnosis and treatment to electronic commerce to managing energy production and distribution systems."
1402004,Environmentally Responsive Supramolecular Constructs and Models for Chemical Communication,CHE,Macromolec/Supramolec/Nano,8/1/2014,6/2/2017,Jonathan Sessler,"Sessler, J","Sessler, J",TX,University of Texas at Austin,Standard Grant,George Janini,7/31/2018,"$450,000.00 ",,sessler@mail.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,MPS,6885,7234,$0.00 ,normalFunding,"With this award from the Macromolecular, Supramolecular and Nanochemistry Program, Jonathan L. Sessler of The University of Texas is carrying out research aimed at creating new systems that can communicate chemically. Living systems are unique in their ability to communicate by purely chemical means and a wide array of new technologies could become possible if we were able to mimic this behavior. Chemical communication in living systems can occur over short distances, which is what happens when brain cells communicate by the release and capture of neurotransmitter molecules. Or, the communication can take place over large distances, such as when insects, or even some mammals, communicate by releasing pheromones. Although these processes are well known in the world of biology, it has not yet been possible to reproduce this type of communication in an artificial system. In this work, the investigators are doing just that, using sophisticated laboratory methods they have developed to accomplish molecular design and construction in a controlled fashion. This work will likely impact the development of possible new information systems. New approaches to artificial intelligence and wireless communication may become possible as a result of this fundamental research. The work is having a further broad impact through the training of the next generation of scientists in cutting-edge laboratory techniques that will prepare the students involved in this research for work in a wide variety of technologically challenging areas.<br/><br/>This project focuses on the use of electron rich and electron poor receptors whose features can be modulated via changes in pH, redox potential, and substrate binding. Particular emphasis is being placed on tetrathiafulvalene calixpyrrole receptors and various electron deficient substrates, including fullerene derivatives. Conformational switching, as engendered by anion binding to a calixpyrrole, for instance, is used to induce changes in equilibrium. These perturbations, in turn, serve to release small chemical species that can act as triggers for the modulation of other receptor systems, such as those built from oligopyrroles. A range of techniques, including standard spectroscopies, photochemistry, color-based reactions, and solid state crystallography is being used to characterize the systems involved in this project and the changes in their features due to induced perturbations in equilibrium behavior."
1018152,RI:  Small:  Understanding Value-based Multiagent Learning and Its Applications,IIS,ROBUST INTELLIGENCE,8/15/2010,8/1/2010,Michael Littman,"Littman, M","Littman, M",NJ,Rutgers University New Brunswick,Standard Grant,James Donlon,3/31/2014,"$450,000.00 ",,mlittman@cs.brown.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7495,"7923, 9150",$0.00 ,normalFunding,"This project explores the behavior of value-based learning methods in multi-agent environments. Value-based methods make decisions by using experience to estimate the utility impact of alternatives and choosing those with high predicted value. Because they evaluate components of behavior instead of treating behaviors as atomic units, they are computationally and statistically efficient. While these methods have been used in computational experiments for many years, only recently have researchers begun to formally characterize their behavior. Our own preliminary work is finding that some value-based methods exhibit super-Nash behavior, making them particularly worthy of study.<br/><br/>More specifically, we are analyzing, mathematically and experimentally, how value-based algorithms perform in several classes of simulated games of varying complexity from the artificial intelligence community, multi-agent engineering applications drawn from the wireless networking area, and as models of human and animal decision making in collaboration with cognitive neuroscientists. Where possible, we are refining existing value-based algorithms to work more efficiently, robustly, and generally than existing algorithms. We are also designing educational outreach activities, including creating entertaining instructional videos on how to promote cooperative behavior in real-life social dilemmas."
713541,Decision-Theoretic Planning in Multi-Agent Environments,IIS,Cyber-Human Systems (CHS),7/15/2007,5/9/2012,Piotr Gmytrasiewicz,"Gmytrasiewicz, P","Gmytrasiewicz, P",IL,University of Illinois at Chicago,Continuing grant,Ephraim P. Glinert,6/30/2013,"$450,000.00 ",,piotr@cs.uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,7367,"7367, 9215, HPCC",$0.00 ,normalFunding,"This work will develop interactive partially observable Markov decision processes (IPOMDPs), which provide a framework for optimal planning that agents can use while interacting with other agents. I-POMDPs unify decision-theoretic approach to planning with elements of games with incomplete information. Decision-theoretic planning, formalized as traditional POMDPs, has had a wide impact in control theory, artificial intelligence, and cognitive science. However, POMDPs by themselves are not suitable in interactive settings because they would force the assumption that other agents are random and static. Game theory, on the other hand, is centered on interaction among rational agents. However, the game-theoretic solution concept of Nash equilibria and their variations result in solutions that are non-unique and incomplete. I-POMDPs address the above disconnect between decision and game theories. They include Bayesian update over models of other agents during interactions, result in policies that are best responses to the others' expected actions, and reduce to classical POMDPs if the agent is acting alone."
1714779,"AF: Small: Lower Bounds for Computational Models, and Relations to Other Topics in Computational Complexity",CCF,ALGORITHMIC FOUNDATIONS,9/1/2017,7/10/2017,Ran Raz,"Raz, R","Raz, R",NJ,Princeton University,Standard Grant,Tracy J. Kimbrel,8/31/2020,"$450,000.00 ",,ranr@princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,7796,"7923, 7927",$0.00 ,normalFunding,"Computational complexity theory is a mathematical field that studies the limits of computers and the resources needed to perform computational tasks. A mathematical theory of computation is crucial in our information age, where computers are involved in essentially every part of our life. Computational complexity is also essential in designing efficient communication protocols, secure cryptographic protocols and in understanding human and machine learning. Studying the limits of computational models is among the most exciting, most challenging, and most important topics in theoretical computer science and is essential for understanding the power of computation and for the development of a theory of computation.<br/><br/>The project will study lower bounds for the resources required by different computational models, as well as related topics in computational complexity. The project will focus on three main research directions:<br/><br/>Time-Space lower bounds for learning: In a sequence of recent works, the PI and his coauthors proved that some of the most extensively studied learning problems require either a super-linear memory size or a super-polynomial number of samples. The project will further study memory/samples lower bounds for learning and their relations to other topics in complexity theory. Lower bounds for learning under memory constraints demonstrate the importance of memory in learning and cognitive processes. They may be relevant to understanding human learning and may have impact on machine learning, artificial intelligence and optimization. They also have applications in cryptography.<br/><br/>Lower bounds for arithmetic circuits: The project will study lower bounds for arithmetic circuits and formulas, as well as for subclasses of arithmetic circuits and formulas. Lower bounds for arithmetic circuits may have a broader impact within theoretical computer science, because of the centrality of polynomials in theoretical computer science.<br/><br/>Lower bounds for communication complexity: In a sequence of recent works, the PI and his coauthors proved the first gaps between information complexity and communication complexity. These results show that compression of interactive communication protocols to their information content is not possible, and hence show that interactive analogs to Shannon's source coding theorem and Huffman coding are not possible. Separation results of communication complexity and information complexity may be relevant to electrical engineering and in particular to the design of efficient communication protocols. The project will further study these topics, and more generally, lower bounds for communication complexity and their relations to other topics in computational complexity."
1528179,CSR: Small: Automatic Storage and Network Contention Management for Large-scale High-performance Computing Systems,CNS,Computer Systems Research (CSR,9/1/2015,8/12/2015,Darrell Long,"Long, D","Long, D",CA,University of California-Santa Cruz,Standard Grant,M. Mimi McClure,8/31/2019,"$450,000.00 ",,darrell@cs.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7354,"7354, 7923",$0.00 ,normalFunding,"High performance computing is essential to science, industry, and the environment, from resource exploration to the design of the next generation of consumer electronics. These high performance computer systems are among the most complex and expensive computer systems and require that their resources be used in the most efficient manner. Many of the applications that utilize high performance computing are data-intensive, and storage system performance is a crucial aspect of system performance. However, storage systems are notoriously sensitive to contention caused by competition among storage clients for limited bandwidth and disk access. This is a significant problem for shared storage systems. <br/><br/>This project provides an automatic storage contention alleviation and reduction system (ASCAR) for large-scale high-performance storage to increase bandwidth utilization and fairness of resource allocation. ASCAR uses machine learning methods combined with several heuristics to discover the fittest control strategy. It is a highly scalable and fully automatic storage contention and congestion management system, which can improve the efficiency of both legacy and new systems, with no need to change either server hardware/software or existing applications. ASCAR regulates I/O traffic from the client side using a rule based algorithm. It employs a shared-nothing design and requires no runtime coordination between clients or with a central coordinator whatsoever, because runtime coordination is slow and unscalable. The effectiveness of ASCAR relies on the quality of traffic control. The research team has designed a prototype algorithm, the SHAred-nothing Rule Producer (SHARP), which produces rules in an unsupervised manner by systematically exploring the solution space of possible designs. Starting from one initial rule, SHARP uses heuristics similar to random-restart hill climbing to find the optimal parameters without the need for an exhaustive search. ASCAR monitors the workloads running on the system and uses several heuristics to pick up the fittest rules. <br/><br/>It is clear that computer systems are getting ever more sophisticated, and human-lead empirical-based approach towards system optimization is not the most efficient way to realize the full potential of these modern, complex, high performance computing systems. This research brings machine learning, artificial intelligence, and big data methods to systems research and could lead to a very low cost I/O performance increase for a wide range of systems."
546590,"CAREER: Implementable Network Algorithms via Randomization, Belief Propagation and Heavy Traffic",CNS,"INFORMATION TECHNOLOGY RESEARC, ADVANCED NET INFRA & RSCH, Networking Technology and Syst",2/15/2006,8/18/2009,Devavrat Shah,"Shah, D","Shah, D",MA,Massachusetts Institute of Technology,Continuing grant,Joseph Lyles,1/31/2012,"$450,000.00 ",,devavrat@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,"1640, 4090, 7363","1045, 1187, 7363, 7388, 9218, HPCC",$0.00 ,normalFunding,"Communication networks are becoming irreplaceable components of any large engineering system.  The performance of such networks is determined by the algorithms implemented within them. This proposal aims at developing novel design and analysis methods for implementable network algorithms. Designing high-performance implementable network algorithms is an extremely challenging task. For example, a typical network algorithm operating in the core of the Internet needs to make complicated decisions roughly every 50ns while utilizing limited resources. Similarly, in the context of wireless networks, algorithms have access to limited computation and energy resources for performing desired tasks.  Consequently, only the simplest algorithms are implementable in such networks.  But a simple algorithm may perform rather poorly if it is not well-designed. <br/><br/>Addressing this tension between simplicity and high-performance is the focal point of this proposal. The algorithm designer experiences this tension in the context of scheduling and routing algorithms, which are critical for the operation of Internet and wireless mesh networks. The established theoretical solutions for these tasks require solving complicated optimization problems. The known algorithmic solutions to these optimization problems are un-implementable. Hence ad-hoc solutions are implemented in the current networks which are poor in performance. For example, in many cases current solutions utilize no more than 30% of  the network capacity ! I intend to bridge the gap between theory and practice by designing implementable good approximations of appropriate optimization problems using two simple yet powerful ideas: (1) Belief propagation (BP) and (2) Randomization. In operational terms, BP is an iterative, distributed, simple message-passing style heuristic for optimization problems. BP is based on deep insights of Statistical Physics and Artificial Intelligence. Algorithms based on BP have been very successful in solving notoriously hard problems in areas such as Turbo Decoding, Image Reconstruction, and Constraint Satisfiability. The method of randomization has been extremely successful in simplifying implementation of complex algorithms. The idea behind randomization is very simple: base decision on a few randomly chosen samples instead of the whole state. The clever choice of random samples result in excellent performance wherein the state of system has a lot of redundant information.  Such is the case in many networking application, which makes randomization well-suited. The design approach based on BP and randomization for scheduling and routing may lead to more than 90% utilization of network capacity.  <br/><br/>An important counterpart of algorithm design is the analysis method that is useful to quantify the performance of algorithm. The so-called ""curse of dimensionality"" of large networks makes performance analysis of algorithms mathematically intractable. The principal investigator (PI) plans to develop analysis method by reducing the ""effective dimension of algorithm"" and thus making it tractable for analysis using effective framework of heavy traffic theory from stochastic networks. <br/><br/>Intellectual merit. This proposal will primarily advance the understanding of design and analysis of implementable network algorithms. Further, it will advance the understanding of BP, which is one of the central (and rather mysterious) topics of current research in AI and Statistical Physics community. The heavy traffic based analysis method will be helpful in advancing the application and development of theory in stochastic networks. <br/><br/>Broad impact. The scheduling and routing algorithms that will be developed as a part of the proposed research may help in designing high-performance LAN switches and efficient wireless mesh network architecture. This may lead to a cost-effective architectural solution for broad-band access networks. The proposed research will be disseminated to the community via publications in journals, conferences and workshops. Further, the PI plans to interact and collaborate closely with networking industry. In particular, Cisco systems Inc. is supportive of this research.<br/>"
1337198,XPS: DSD: Collaborative Research: NeoNexus: The Next-generation Information Processing System across Digital and Neuromorphic Computing Domains,CCF,Exploiting Parallel&Scalabilty,9/15/2013,9/6/2013,Hai Li,"Li, H","Li, H|Chen, Y",PA,University of Pittsburgh,Standard Grant,tao li,6/30/2017,"$450,000.00 ",Yiran Chen,hai.li@duke.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,8283,,$0.00 ,normalFunding,"The explosion of ""big data"" applications imposes severe challenges of data processing speed and scalability on traditional computer systems. The performance of traditional Von Neumann machines is greatly hindered by the increasing performance gap between CPU and memory, motivating the active research on new or alternative computing architectures. By imitating brain's naturally massive parallel architecture with closely coupled memory and computing as well as the unique analog domain operations, neuromorphic computing systems are anticipated to deliver superior speed for applications in image recognition and natural language understanding.<br/><br/>The objective of this research is to establish the fundamental framework and design methodology for NeoNexus -- the next-generation information processing system inspired by human neocortex. It integrates neuromorphic computing accelerators with conventional computing resources by leveraging large scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays. The computation and data exchange will be carefully coordinated and supported by the innovative interconnect architecture, i.e., a hierarchical network-on-chip (NoC). The software-hardware co-design platform will be developed to address the various design challenges. The project will help computer architecture and high-performance computing communities to overcome the ever-increasing technical challenges of traditional architectures and accelerate the fusion between conventional computing technology and cognitive computing model. It will also promote the applications of artificial intelligence technology advances in modern computer architectures and motivate the inventions at both software and hardware levels. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce."
1201790,Super-Turing Computation and Brain-Like Intelligence,ECCS,"ENERGY,POWER,ADAPTIVE SYS",7/1/2012,4/30/2014,A. Steven Younger,"Younger, AS","Younger, AS|Siegelmann, H|Redd, E",MO,Missouri State University,Continuing grant,Radhakisan S. Baheti,6/30/2016,"$449,999.00 ","Hava Siegelmann, Emmett Redd",SteveYounger@missouristate.edu,901 South National,Springfield,MO,658970027,4178365972,ENG,7607,1653,$0.00 ,normalFunding,"The objective of this research is to advance significantly Artificial Intelligence by developing the first ever, brain-like Super-Turing system. <br/>The approach is to build a computational system that is much more powerful (Super) than digital computation.  Alan Turing, a WWII code breaker, developed a conceptual (Turing) machine that has been basic to the digital computation revolution of the last 70 years.  This project will develop a Super-Turing mathematical model and implement it on an Optical Analog Neural Network Computer.  The project will focus on understanding system abilities and differences between Super-Turing and Turing systems.  Natural and artificial time-series will be compared to those of Super-Turing models and modeled Super-Turing processes will be compared with those of the brain. <br/>Intellectual Merit <br/>Super-Turing Computation is a novel, transformative technology that will rewrite computational limits and lay a new foundation for Artificial Intelligence.<br/>Broader Impact<br/>Increasing the capabilities of machine intelligence will profoundly influence society; Intelligent Super-Turing systems are expected to be capable of improving quality of life, e.g. providing intelligent robotic assistants, improving individualized education, creating new industries and medical technologies producing great economic benefit.  Further, a deepened understanding of Super-Turing computation as it relates to living systems is likely to bring new insights into brain function - fundamentally impacting neuroscience and brain-related medical technologies. Graduate and undergraduates will be trained in the interdisciplinary areas of advanced mathematics, physics, and computer science."
1618477,RI: Small: Unraveling and Building Top-Down Generators in Deep Convolutional Neural Networks,IIS,ROBUST INTELLIGENCE,7/1/2016,6/28/2016,Zhuowen Tu,"Tu, Z","Tu, Z",CA,University of California-San Diego,Standard Grant,Kenneth C. Whang,6/30/2019,"$449,999.00 ",,zhuowen.tu@gmail.com,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,7495,"7495, 7923, 8089",$0.00 ,normalFunding,"Deep learning has recently significantly advanced research fields that are closely related to artificial intelligence. The fundamental problem of knowledge representation however remains open and the role of top-down process in deep learning is yet not very clear. For example, to train a deep learning algorithm to detect simply the translation of a dog in an image, a data-driven way of training deep learning would require generating thousands of samples by moving the dog around in the image. However, a top-down model, if available, can directly detect translation using two variables along the axes. The main goal of this project is to explore a path to discover, learn, and build embedded deep learning models, accounting for a rich family of top-down spatial transformation and geometric composition in convolutional neural networks. The resulting models provide a transparent way of understanding the embedded top-down transformation process through neural network layers. The learned neurally-inspired top-down knowledge representation will benefit studies across multiple disciplines, including visual perception, brain sciences, cognitive modeling, and decision making. <br/><br/>The current practice in deep learning, for example convolutional neural networks (CNN), is largely dominated by data-driven bottom-up approaches. While the performances of various applications using convolutional neural networks (CNN) are impressive, there nevertheless exists a big gap between what bottom CNN can offer and what comprehensive intelligence requires. These strongly bottom-up CNN characteristics leave a big room for one to provide deep learning with the ability to also incorporate top-down information for effective knowledge representation, network learning, cognitive modeling, and visual inference. This project is about building a roadmap towards developing top-down generators. This is done by unraveling the role of explicit top-down knowledge representation and propagation, by studying the feature flows produced inside the convolutional neural networks, by building robust analysis-by-synthesis methods that combine top-down and bottom-up processes, and by creating explicit generative models to assist a wide range of applications. The benefit of studying the top-down generators to a broad family of applications is greatly intriguing, including but not limited to: creating network internal data augmentation, building object detection, developing scene understanding systems; modeling compositional and contextual object configurations; and performing zero-shot learning."
1216467,RI: Small: Reinforcement Learning by Mirror Descent,IIS,ROBUST INTELLIGENCE,8/1/2012,7/16/2012,Sridhar Mahadevan,"Mahadevan, S","Mahadevan, S",MA,University of Massachusetts Amherst,Standard Grant,Weng-keen Wong,7/31/2016,"$449,991.00 ",,mahadeva@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,7923,$0.00 ,normalFunding,"A fundamental challenge in machine learning is the design of computational agents that, rather than being explicitly programmed, autonomously learn complex tasks in stochastic real-world environments. Past approaches, such as reinforcement learning algorithms for solving Markov decision processes, scale poorly to large state spaces. The proposed research addresses this curse of dimensionality by investigating a novel framework combining reinforcement learning and online convex optimization, in particular mirror descent and related algorithms. Mirror descent scales significantly better than classical first-order gradient descent in high-dimensional state spaces, by using a distance-generating function specific to a particular state space geometry.<br/><br/>The proposed framework enables several significant algorithmic advances in the design of autonomous machine learning agents: a new class of first-order mirror-descent based methods for learning sparse solutions to Markov decision processes will be developed that scale significantly significantly better than previous second-order methods; novel hierarchical methods for solving semi-Markov decision processes will be investigated; and finally, applications to a variety of high-dimensional Markov decision processes will be explored.<br/><br/>The anticipated outcomes of the proposed work include foundational advances in designing autonomous agents that learn to solve sequential decision-making problems, which will impact a large number of target applications from manufacturing to robotics and scheduling. The educational goal includes the development of a graduate-level course in online convex optimization for sequential decision-making, as well as interdisciplinary tutorials to enhance the cross-fertilization of ideas from applied mathematics and optimization to machine learning and artificial intelligence."
1717896,AF: Small: Efficiently Learning Neural Network Architectures with Applications,CCF,ALGORITHMIC FOUNDATIONS,9/1/2017,6/26/2017,Adam Klivans,"Klivans, A","Klivans, A",TX,University of Texas at Austin,Standard Grant,Tracy J. Kimbrel,8/31/2020,"$449,920.00 ",,klivans@cs.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7796,"7923, 7926",$0.00 ,normalFunding,"In the last few years there have been several breakthroughs in machine learning and artificial intelligence due to the success of tools for learning ""deep neural networks"" including the best computer program for playing Go, the best programs for automatically playing Atari games, and the best tools for several fundamental object-recognition tasks.  These are considered some of the most exciting new results in all of computer science.<br/><br/>From a theoretical perspective, however, the mathematics underlying these neural networks is not as satisfying.  We have few rigorous results that explain how and why heuristics for learning deep neural networks perform so well in practice. The primary research goal of this proposal is to develop provably efficient algorithms for learning neural networks that have rigorous performance guarantees and give applications to related problems from machine learning.  Given the ubiquity of machine learning algorithms, this research will have direct impact on data science problems from a diverse set of fields including biology (protein interaction networks) and security (differential privacy).  The PI is also developing a new data mining course at UT-Austin that will incorporate the latest research from these areas.<br/><br/>A central technical question of this work is that of the most expressive class of neural networks that can be provably learned in polynomial time.  Furthermore, the algorithm should be robust to noisy data.  A neural network can be thought of as a type of directed circuit where the internal nodes compute some activation function of a linear combination of the inputs.  The classical example of an activation function is a sigmoid, but the ReLU (rectified linear unit) has become very popular.  In a recent work, the PI showed that a neural network consisting of a sum of one layer of sigmoids is learnable in fully-polynomial time, even in the presence of noise.  This is the most expressive class known to be efficiently learnable.  Can this result be extended to more sophisticated networks?  This question has interesting tie-ins to kernel methods and kernel approximations.<br/><br/>For the ReLU activiation, the PI has shown that this problem is most likely computationally intractable in the worst case.  The intriguing question then becomes that of the minimal assumptions needed to show that these networks are computationally tractable.  In a recent work, the PI has shown that there are distributional assumptions that imply fully-polynomial-time algorithms for learning sophisticated networks of ReLUs.  Can these assumptions be weakened?  This work has to do with proving that certain algorithms do not overfit by using compression schemes.  Another type of assumption that the weights of the unknown network are chosen in some random way (as opposed to succeeding in the worst-case).  This corresponds to the notion of random initialization from machine learning.  Can we prove a type of smoothed analysis for learning neural networks, where we can give fully-polynomial-time learning algorithms for almost all networks?<br/><br/>Finally, in this proposal we will explore what other tasks can be reduced to various types of simple neural network learning.  For example, the problem of one-bit compressed sensing can be viewed as learning a threshold activation using as few samples as possible.  Still, we lack a one-bit compressed sensing algorithm that has optimal tolerance for noise.  Another canonical example is matrix or tensor completion, where it is possible to reduce these challenges to learning with respect to polynomial activations.  Finding the proper regularization to ensure low sample complexity is an exciting area of research."
713118,RI: High Performance Algorithms for Probabilistic and Deterministic Graphical Models,IIS,ROBUST INTELLIGENCE,8/15/2007,7/6/2008,Rina Dechter,"Dechter, R","Dechter, R",CA,University of California-Irvine,Continuing grant,todd leen,7/31/2012,"$449,713.00 ",,dechter@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,"7495, 9218, HPCC",$0.00 ,normalFunding,"<br/>Proposal 0713118<br/>""RI: High Performance Algorithms for Probablistic and Deterministic graphical Models<br/>PI: Rina Dechter<br/>University of California--Irvine<br/><br/>ABSTRACT<br/><br/>The goal of this project is to develop powerful algorithms that can help computer programs make sophisticated decisions when faced with real-life problems. The project's novelty is its specific focus on automated reasoning where the relevant information is a combination of certain (deterministic) and uncertain (probabilistic) information. The need to accommodate both types of information is motivated by many real world problems such as scheduling of operating rooms and the diagnosing the nature of a disease, where situation assessment, planning or decision-making often involve taking into consideration both hard constraints and probabilistic information. A unique aspect of the project is that its algorithms will be founded upon a single theoretical framework--AND/OR search, developed by the investigator--which is driven by the graphical representation of the problems and often results in exponentially reduced complexities. The guiding principle behind the algorithms is the exploitation of useful structural features of a given problem instance, such as decomposability, sub-problem equivalence, and sub-problem irrelevance. The work proposed here promises to enhance problem-solving knowledge not just in the field of artificial intelligence, but also in the scientific community in general. As they are completed, the new algorithms will be posted on a publicly available Web site.<br/><br/>"
219875,ITR:  Beyond the Talking Head and Animated Icon: Behaviorally Situated Avatars for Tutoring,IIS,ITR SMALL GRANTS,9/15/2002,7/26/2005,Francis Quek,"Quek, F","Quek, F|McNeill, D",OH,Wright State University,Continuing grant,Karen Kukich,2/28/2006,"$449,662.00 ",David McNeill,quek@tamu.edu,3640 Colonel Glenn Highway,Dayton,OH,454350001,9377752425,CSE,1686,"1654, 9216, HPCC",$0.00 ,normalFunding,"Behaviorally Situated Avatars for Tutoring: Beyond the Talking Head and Animated Icon<br/>Abstract<br/><br/>One-on-one tutoring is a critical component of teaching and learning. This project investigates technology to deploy an anywhere-tutor anywhere-student system that permits a tutor to provide instruction via an animated avatar. Exploiting psycholinguistic information, the system translates time-situated pointing and communicative gestures performed on a LCD tablet in conjunction with speech into a stream of behaviorally correct, spatially situated 3D gestures performed by the avatar tutor.  A camera tracks the student, facilitating socially aware behavior by the avatar.  The system exploits the student's ability to use body motion cues in the embodied avatar to direct her attention to appropriate locations of projected graphics that serve as artifacts of instruction.  The technology will potentially facilitate a tutoring program in which students may connect to a pool of tutors for help with a variety of topics.  The approach essentially implements tutoring 'telephone handsets' at both ends of the interaction.  Tutors may be distributed across multiple sites at their convenience and take calls as they are needed. Widespread access to such tutoring will facilitate the vision of universally available educational opportunities.  The project will investigate the necessary artificial intelligence and interaction technologies and evaluate the efficacy of this tutoring methodology.<br/><br/><br/>"
1718550,RI: Small: CompCog: Leveraging Deep Neural Networks for Understanding Human Cognition,IIS,"PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",8/15/2017,8/4/2017,Thomas Griffiths,"Griffiths, T","Griffiths, T",CA,University of California-Berkeley,Standard Grant,Kenneth C. Whang,7/31/2020,"$448,284.00 ",,tomg@princeton.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,"7252, 7495","7495, 7923, 8089",$0.00 ,normalFunding,"The last few years have seen significant breakthroughs in artificial intelligence and machine learning, resulting in systems that approach or even exceed human performance in interpreting pictures and words. This project explores the implications of these breakthroughs for understanding how the human mind works. Focusing on artificial neural networks, a key technology behind many recent breakthroughs that is capable of discovering novel representations for complex stimuli, the project has two goals. First, assessing the degree of correspondence between human and machine learning by examining whether the pictures or words that are similar in the representations discovered by neural network models are also judged to be similar by people. Second, developing methods for increasing this correspondence, with the goal of being able to use neural network representations to generate good predictions about how people learn and form categories using real images or text.<br/><br/>This research project will answer basic scientific questions about how the representations discovered by contemporary neural networks relate to human cognition. It will then explore what architectures and training regimes produce representations with these properties. In addition, the project will address the methodological question of how one can modify these representations to produce better alignment with human cognition. Answering this question will lead to powerful new tools for making models of human behavior in naturalistic contexts, leveraging the latest results in machine learning to broaden the scope of experimental research in cognitive science. By building stronger links between human and machine learning, this project will have implications for both fields. Even if current neural network systems turn out to differ significantly from human learning, they provide state-of-the-art representations for images and text that can be used as a starting point for developing better accounts of human representations. By discovering the ways in which the representations learned by artificial neural networks differ from those of humans, one can identify new algorithms and training methods that will result in a closer alignment. Since human beings remain the best examples available of systems that can solve certain problems, such an alignment offers a path toward expanding the capacities of current artificial intelligence systems and making them more interpretable by people, which is critical in settings that require human-machine interaction."
1717705,"CHS:Small: A Kinder, Gentler Technology: Enhancing Human-Machine Symbiosis Using Adaptive, Personalized Affect-Aware Systems",IIS,Cyber-Human Systems (CHS),8/15/2017,8/4/2017,Domen Novak,"Novak, D","Novak, D|McCrea, S",WY,University of Wyoming,Standard Grant,Dan Cosley,7/31/2020,"$447,889.00 ",Sean McCrea,dnovak1@uwyo.edu,1000 E. University Avenue,Laramie,WY,820712000,3077665320,CSE,7367,"7367, 7923, 9150",$0.00 ,normalFunding,"A longstanding goal in artificial intelligence is to develop smart systems that interact well with humans.  Advances in sensing and machine learning are increasingly allowing computers to infer mental states, raising questions about how agents might use those inferences to adapt to human partners.  This project will systematically address how to design and evaluate ""affect-aware"" systems that adapt their behavior based on estimates of their users' emotional experiences.  The team will first look at the effectiveness of current strategies that vary the difficulty of educational tasks and games based on inferred affect.  They will then develop new strategies that take into account both individual personality and dynamic characteristics of the physical environment.  Finally, they will evaluate these strategies, paying particular attention to what happens when systems act on incorrect inferences about affect.  These studies will help pave the way toward self-driving cars, conversational assistants, and virtual reality characters that consider affect when interacting with people, ideally leading to better experiences and outcomes.  The team will also develop new interdisciplinary courses in human factors and human-computer interaction, connecting with industrial partners to help train students in both the practice and research of these kinds of adaptive systems.  Further, they will do public outreach about these systems and use them to provide summer research experiences for K-12 and community college students, focusing on those from groups traditionally underrepresented in computing.<br/><br/>The project will be structured as a series of lab studies, using spatial cognition games and robot-assisted motor rehabilitation tasks as testbeds that allow the team to directly manipulate task difficulty and measure enjoyment/engagement and performance/learning outcomes.  The team will first collect training data with people using the testbeds at randomly selected difficulty levels and reporting the perceived level of difficulty as too easy (bored), too hard (frustrated), or about right, while capturing heart rate signals, skin conductance and temperature, electroencephalogram (EEG) data, and environmental factors including light, time of day, and room temperature.  These will be used to train affect recognizers using a variety of machine learning methods: linear discriminant analysis (including a Kalman adaptive version), support vector machines, neural and Bayesian networks, and random forests.  Using a common adaptation strategy that adjusts difficulty up or down one step, the team will measure the enjoyment and performance outcomes that affect-aware recognizers achieve both with and without considering environmental factors, comparing those to a baseline strategy that adapts difficulty based only on task performance.  During these experiments, the team will also collect data about users' personality characteristics and use those to develop individualized recognition models and adaptation strategies for different personality types. These individualized models and strategies will be evaluated by comparing them to the baseline data from the first experiment.  Finally, they will compare the outcomes of these systems with those from a ""best-case"" system controlled by humans and a ""worst-case"" error-prone system that chooses adaptation strategies randomly, looking at those induced error rates along with the natural error rates captured during the other experiments to determine the effect of recognition and adaptation error on satisfaction and task outcomes."
1219114,RI: Small: A New Approach to Influence Diagram Evaluation,IIS,ROBUST INTELLIGENCE,9/1/2012,7/24/2012,Eric Hansen,"Hansen, E","Hansen, E",MS,Mississippi State University,Standard Grant,Weng-keen Wong,8/31/2016,"$445,000.00 ",,hansen@cse.msstate.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,CSE,7495,"7923, 9150",$0.00 ,normalFunding,"A central goal of research in artificial intelligence, operations research, and related fields is the development of algorithmic approaches to decision making under uncertainty. This project considers influence diagrams, a widely-used graphical model for representing and solving problems of sequential decision-making under imperfect information. Influence diagrams were originally developed to provide a more compact representation of a decision problem than is provided by a decision tree, which suffers from an exponential explosion in the number of its branches as a function of the number of variables in the model. Although influence diagrams provide a compact problem representation, standard algorithms for solving influence diagrams do not represent the solution to a decision problem in a similarly compact form. This project addresses this limitation by introducing a more compact graphical representation of decision strategies that improves the scalability of algorithms for solving influence diagrams, makes it easier for a human user to understand the recommended decision strategy, and allows a principled approach to approximation. In addition, the project develops a new approach to solving influence diagrams based on branch-and-bound search, including an incremental approach to probabilistic inference.<br/><br/>The algorithms and software tools developed from this project will improve the scalability and utility of influence diagrams as an approach to automated decision making under uncertainty. These contributions will have a broad impact in the many disciplines in which influence diagrams are applied, including medical decision analysis and support, therapy plan selection, user modeling, information retrieval, climate change analysis, and many others."
966086,Attracting and Retaining Promising Transfer Students into STEM Fields,DUE,S-STEM:SCHLR SCI TECH ENG&MATH,7/1/2010,6/17/2011,Jaime Davila,"Davila, J","Davila, J|Jarvis, C",MA,Hampshire College,Continuing grant,Elizabeth Teles,6/30/2017,"$441,550.00 ",Christopher Jarvis,jdavila@hampshire.edu,893 West Street,Amherst,MA,10023372,4135595378,EHR,1536,"9178, SMET",$0.00 ,normalFunding,"The effort of the college to open access to transfer students comes at a time when increasingly sophisticated methodological methods are being developed to forge connections across science, technology, engineering, and mathematics (STEM) fields. This project acts as a catalyst for these developments and offers up to 20 transfer students a pathway to achieve bachelor degrees. This project is motivated by the institutional objective to better attract and retain science concentrators in STEM fields. Additionally, a core team of faculty, whose work investigates questions in computational science, artificial intelligence, and the biological sciences, are interested in building structural and cultural cohesion around concentrators who may already be motivated by work and life experiences to excel in STEM fields. <br/><br/>Intellectual Merit: While the college has done well attracting underrepresented students in STEM fields, the overall attrition rate for underrepresented groups is somewhat high. The college has begun to take deliberate and careful measures to address these attrition rates. This project allows the college to offer a more robust financial aid package to help to attract and retain transfer students. These transfer students provide diversification, which strengthens the overall demographic makeup of the college and offers a more diverse range of perspectives in the classroom.<br/><br/>Broader Impact: The inquiry-driven, cross-disciplinary approach to teaching science at the college has demonstrated success in attracting students from diverse backgrounds to STEM fields. According to recent admissions data, the college graduates more science concentrators (15%) than it initially attracts (10%). Moreover, from 2005-08, women and students from underrepresented groups comprised 70% of science concentrators. Many of these students enter a range of scientific and medical careers, or pursue graduate study upon matriculating. This project allows faculty to work with a greater number of students and is expected to result in higher numbers of talented graduates prepared to make meaningful contributions to national and international scientific challenges."
203446,CRCD: Machine Learning Advances for Engineering Education,CNS,CISE EDUCAT RES & CURRIC DEVEL,8/15/2002,5/9/2007,Michael Georgiopoulos,"Georgiopoulos, M","Georgiopoulos, M|Gelenbe, E",FL,University of Central Florida,Continuing grant,Anita J. LaSalle,7/31/2007,"$440,851.00 ",Erol Gelenbe,michaelg@ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,1709,"9218, 9299, HPCC, 9251",$0.00 ,normalFunding,"0203446<br/>Michael Georgiopoulos<br/>University of Central Florida<br/>Orlando, FL<br/>""Machine Learning Advances for Engineering Education""<br/><br/>This project, at the University of Central Florida (UCF), integrates research results from the theory and applications of Machine Learning into the Engineering/Computer Science curricula. Two new courses and several revised courses include material from Adaptive Reasoning Theory, Genetic Algorithms, Human Behavior Representation, and Simulation Meta-modeling. The objectives of this CRCD project include: 1. Incorporating current state-of-the-art Machine Learning research results into the undergraduate and first year graduate curriculum to enhance students' critical thinking, intellectual growth and communication skills, 2. Offering a unique curriculum, by traditional undergraduate standards, where the PIs integrate their current research results into the curriculum. This curriculum is timely and dynamic, reflecting the PIs' and the machine learning community's research interest changes with time, 3. Offering the opportunity to a multi-disciplinary group of students (spanning the spectrum of electrical, computer, industrial, civil, mechanical, and computer science students) to benefit from research and its transfer into curricula, 4. Assessing and evaluating the educational impact of the project through a sequence of carefully chosen evaluation instruments developed by an educational consultant, and 5. Disseminating the curriculum development efforts to a number of affiliate Universities."
1202141,CAREER: Enabling Community-Scale Modeling of Human Behavior and its Application to Healthcare,IIS,ROBUST INTELLIGENCE,10/1/2011,6/13/2014,Tanzeem Choudhury,"Choudhury, T","Choudhury, T",NY,Cornell University,Continuing grant,Hector Munoz-Avila,2/29/2016,"$440,125.00 ",,tanzeem.choudhury@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7495,"1045, 1187, 7495, 9102, 9150, 9215, 9251, HPCC",$0.00 ,normalFunding,"Research supported by this award is developing community-based methods for sensing, recognizing, and interpreting human activities from body-worn sensors. Specifically, this research is<br/><br/>1) developing systems that learn new classes of activity with minimal human supervision, where the system queries a human user for additional information on an activity being learned, but only when such queries are informationally necessary and behaviorally unobtrusive,<br/><br/>2) developing the paradigm of community-guided learning, which leverages people's social ties and behavioral similarities, in order to define an efficient scheme for sharing various aspects of the underlying activity classes across many individuals, and<br/><br/>3) evaluating the new community-guided learning methods by using them to learn about (a) social isolation and functional independence among elderly persons, and (b) social interaction among high-functioning autistic children.<br/><br/>Speaking generally, the research is advancing machine learning and artificial intelligence, especially in the areas of semi-supervised, active, and relational learning. Beyond these basic scientific contributions, the resulting research has the potential to transform community health assessment by collecting fine-grained clinically-relevant information continuously, cheaply, and unobtrusively, over long periods of time. This research also opens up many opportunities for education and outreach, in part because it is pushing machine learning and artificial intelligence into social and societally-important realms, promising to attract groups, notably women, who are under-represented in computer science.<br/>"
1733884,AitF: Collaborative Research: Efficient High-Dimensional Integration using Error-Correcting Codes,CCF,Algorithms in the Field,9/1/2017,8/11/2017,Dimitris Achlioptas,"Achlioptas, D","Achlioptas, D",CA,University of California-Santa Cruz,Standard Grant,Tracy J. Kimbrel,8/31/2021,"$438,177.00 ",,optas@cs.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7239,,$0.00 ,normalFunding,"Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br/><br/>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory."
812113,(RI+hcc)-Small: Computational Social Choice: Aggregating Preferences in Combinatorial Domains,IIS,ROBUST INTELLIGENCE,9/1/2008,7/28/2010,Vincent Conitzer,"Conitzer, V","Conitzer, V",NC,Duke University,Continuing grant,todd leen,8/31/2012,"$437,212.00 ",,conitzer@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7495,"0000, 7495, 9215, 9251, HPCC, OTHR",$0.00 ,normalFunding,"In traditional social choice, it is assumed that each agent explicitly ranks all of the alternatives. In Artificial Intelligence applications this is generally impractical: for example, there are exponentially many joint plans<br/>or allocations of tasks/resources. Nevertheless, even the computational social choice community has so<br/>far focused primarily on the explicit-ranking model. While this was a necessary phase to establish a solid<br/>foundation for this line of research, it is now time to move on and consider the combinatorial domains with<br/>exponentially many alternatives that motivated computational social choice in the first place. This is what<br/>the proposed research will do.<br/>The PI proposes the following 5-part research plan. First, he plans to study how agents? votes should<br/>be represented, that is, what language the agents should use to express their preferences in a combinatorial<br/>domain. Once the language has been determined, he plans to study what rule should be used to make a<br/>decision based on the votes. Such a rule would be useless without a good algorithm for executing it, that<br/>is, for solving the winner determination problem. Even with a good language, it may be overwhelming<br/>for an agent to report its complete preferences, so the PI plans to study how to elicit the (relevant parts of)<br/>agents? preferences by asking the agents simple queries. Finally, he plans to address the problem of agents<br/>voting insincerely to manipulate the decision, in part by investigating whether such manipulation can be<br/>made computationally infeasible.<br/>Broader Impacts<br/>The proposed research will allow agents to coordinate when solving a complex problem, even if they have<br/>been created by different designers with different objectives. For example, robots in search-and-rescue or<br/>other exploration settings can vote over how they will divide the exploration. This allows a much greater<br/>diversity of agents to participate in such a task, undoubtedly leading to better results. Also, some of the<br/>research is likely to be applicable to human decision making.<br/>Europe is starting to take the lead in computational social choice; if funded, this proposal will ensure that<br/>the U.S. retains expertise in and continues to shape this burgeoning research area. Of course, research is not<br/>a zero-sum game, and the PI plans to collaborate closely with the other researchers in the area. In fact, this<br/>proposal corresponds to the PI?s part of a 12-investigator proposal that was just recommended for funding<br/>by the European Science Foundation (ESF). This (NSF) proposal would also support the PI?s collaboration<br/>with Jeff Rosenschein (Hebrew University); for this collaboration, Jeff and the PI already received a small<br/>US-Israel Binational Science Foundation grant that serves to support the Israeli side as well as travel.<br/>The proposal also includes plans to develop a new graduate course on computational social choice,<br/>mentor graduate and undergraduate students, build connections to economics and political science, and<br/>attract more women to computer science (as well as participate in other outreach activities)."
1117956,RI: Small: Towards Practical Tractability in Constraint Processing,IIS,ROBUST INTELLIGENCE,8/1/2011,1/23/2015,Berthe Choueiry,"Choueiry, B","Choueiry, B",NE,University of Nebraska-Lincoln,Standard Grant,Hector Munoz-Avila,7/31/2015,"$435,564.00 ",,choueiry@cse.unl.edu,151 Prem S. Paul Research Center,Lincoln,NE,685031435,4024723171,CSE,7495,"7495, 7923, 9150, 9251",$0.00 ,normalFunding,"Many problems in artificial intelligence, engineering, and management can be advantageously modeled and solved as Constraint Satisfaction Problems, but scalability remains in practice a major obstacle to the successful deployment of Constraint Solvers. The goal of this project is to design algorithms and strategies that enable computers to overcome, in practice, the scalability barrier. To this end, the proposed research targets the two fundamental mechanisms in Constraint Processing that are the most promising for breaking the complexity barrier, namely, enforcing consistency and detecting and breaking symmetry. This project aims to design new algorithms for those two mechanisms and develop strategies for intertwining them. <br/><br/>The tractability of a problem is guaranteed by a relationship between a structural parameter of the problem and its level of consistency. This project aims to design algorithms that enforce the needed level of consistency without adversely modifying the structure of the problem. Symmetries can be detected and exploited to dramatically reduce the cost of problem solving. This project aims to (1) design algorithms for detecting symmetries, and (2) develop approximation strategies for exploiting them without sacrificing the soundness and completeness of problem solving. A key observation is that algorithms for enforcing consistency and those for locally detecting symmetry are based on the same atomic operations. Furthermore, they seem to be effective under complementary operating conditions. This project further aims to design strategies for intertwining the operation of the two types of algorithms so that the application of the one type enables and facilitates that of the other type, in order to yield new opportunities to control the combinatorial explosion. The approach will be validated on applications of practical importance and extended to address similar combinatorial problems in other areas of Computer Science such as Databases and Software Engineering.<br/><br/>The proposed activities contribute to the progress of the research on two fundamental aspects of Constraint Processing. From a practical perspective, this research directly benefits many combinatorial problems of practical importance. From a scientific standpoint, this project will identify connections and build new bridges with other areas of Computer Science, such as Databases and Software Engineering. The insight gained from these investigations will be used to improve the scope and content of introductory and advanced courses on Constraint Processing. The opportunities and research avenues will be heavily exploited to involve undergraduate students in research and to give them experience in using the project's insights on problems that they find engaging (e.g., Sudoku) and for understanding the operation of algorithms in Computer Science courses; the goal is to motivate students to conduct research in Constraint Processing and to transfer results from this field to other students and researchers in Computer Science, Mathematics, Engineering, to entice high-school students to study Computer Science, and in addition, to explain to the general public some of the fundamental mechanisms at the heart of complex problem solving."
1441331,"EXP: Collaborative Research: PerSketchTivity- Empowering and Inspiring Creative, Competent, Communicative, and Effective Engineers through Perspective Sketching",IIS,"S-STEM:SCHLR SCI TECH ENG&MATH, Cyberlearn & Future Learn Tech",9/1/2014,6/14/2016,Tracy Hammond,"Hammond, T","Hammond, T|Liew, J|McTigue, E",TX,Texas A&M Engineering Experiment Station,Standard Grant,Elliot Douglas,8/31/2018,"$433,056.00 ","Jeffery Liew, Erin McTigue",hammond@tamu.edu,TEES State Headquarters Bldg.,College Station,TX,778454645,9798477635,CSE,"1536, 8020","7218, 8045, 8244, 8841, 9251",$0.00 ,normalFunding,"The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by building examples and studying their possibilities for fostering learning as well as challenges to using them well. This project examines whether technology can support learning to freehand sketch. Sketching has been demonstrated to play an important role in a number of domains, including engineering, and the ability to quickly sketch has been shown to improve creativity by making it easier for engineers to generate ideas and communicate them. This project will modify artificial intelligence tools that support recognizing sketches to directly help teach undergraduate engineers how to sketch well. Research studies will examine whether the tool helps students learn sketching skills, and importantly how it influences their spatial reasoning ability. Thus, if successful this research will not only create tools to allow people to learn to sketch better, but also will advance our understanding of how spatial reasoning and sketching are linked, and could eventually lead to more effective engineering education.<br/><br/>The project proposes two interconnected strands of work: developing the software tool and conducting research studies in the context of undergraduate engineering courses. The software tool will use a heterogenous set of classifiers to help provide feedback to learners as they perform a sequence of sketching exercises on tablets. The design process will iterate on the tool to explore what types of feedback are most helpful and how different classifiers can be used to detect different levels of sketching skill. The program of research will include studying whether sketching training leads to advances in spatial reasoning skills, whether it affects design self-efficacy and attitudes towards sketching, transfer of spatial skillsets to design activities in other courses, and how sketching skills correlate to success on spatial reasoning tasks.  In addition, through iterative development including user-centered design processes, design principles for sketching based tools will be derived. Data sources will include both qualitative and quantitative data such as pre- and post-test spatial reasoning tasks, structured interviews, surveys, and artifact analysis. Additionally, students (N=approximately 30-40) using the new tool in class will be compared to control cohorts of approximately 30 students who either use traditional engineering curricula (little free-hand sketching and some isometric drawing) and a sketching curriculum without the AI tool."
1633857,BIGDATA: F: Open-World Foundations for Big Uncertain Data,IIS,Big Data Science &Engineering,9/1/2016,9/6/2016,Guy Van den Broeck,"Broeck, GVd","Broeck, GVd",CA,University of California-Los Angeles,Standard Grant,Sylvia J. Spengler,8/31/2019,"$432,202.00 ",,guyvdb@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,8083,"7433, 8083",$0.00 ,normalFunding,"Driven by the need to learn from vast amounts of text data, efforts throughout natural language processing, information extraction, databases, and AI are coming together to build large-scale knowledge bases. These systems continuously crawl the web to extract relational data from text, and have already populated their databases with millions of entities and billions of tuples. Large-scale probabilistic knowledge bases are revolutionizing the way we access data. They are now routinely used by scientists to build knowledge bases of publications, by law enforcement to extract information from the dark web, and by regular search engine users who find their results augmented with structured information. Such knowledge bases are inherently probabilistic: to go from raw text to structured data, a sequence of statistical machine learning techniques associate probabilities with database tuples. This project revisits the semantics underlying such systems, and provide a more adequate foundational framework. In particular, the closed-world assumption of probabilistic databases, that facts not in the database have probability zero, clearly conflicts with their everyday use, and obstructs the progress in this area.<br/><br/>More specifically, this project develops a new semantic foundation based on the open-world assumption, that facts not in the database are possible, but have unknown probability. It designs the basic algorithms for query answering in this setting, both exact and approximate. Moreover, in a deep theoretical component, this project studies fundamental questions of data and domain complexity that are unique to open-world reasoning about big uncertain data. Finally it develops proof-of-concept applications in machine learning and data mining, and additional knowledge-representation layers that strengthen open-world reasoning. The developed semantics provide meaningful answers when some tuple probabilities are not precisely known. The developed algorithms allow for efficient query answering, even when reasoning about the open world, in time linear in the database size for tractable queries. This project provides a scientific leap at the fundamental, semantic level. It also provides a context for training undergraduate and graduate students in subjects spanning databases, artificial intelligence, theory, and machine learning, and will target the integration of probabilistic knowledge bases into computer science curricula."
849453,SHINE: Digitization of 27 Years of Big Bear Solar Observatory (BBSO) Films and Application in Statistical Study of Filaments and Flares,AGS,SOLAR-TERRESTRIAL,3/1/2009,12/22/2011,Haimin Wang,"Wang, H","Wang, H",NJ,New Jersey Institute of Technology,Continuing grant,Ilia I. Roussev,2/28/2014,"$431,262.00 ",,haimin.wang@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,1523,"001P, 1323, EGCH",$0.00 ,normalFunding,"From 1969 to 1995, Big Bear Solar Observatory (BBSO) staff recorded all of their observations on 35 mm film before switching to digital imaging after 1995. These film data include full-disk observations from BBSO's 8 inch telescope and high resolution observations from the 10 and 26 inch telescopes, with the cadence of observations ranging from 10 seconds to 1 minute. These film data cover two and one-half solar cycles, include thousands of flares, and span the entire operational service of several space missions, including SMM, CGRO, and Yohkoh. Wide public access to these BBSO data films is impractical and their scientific capability has never been fully explored. <br/><br/>The requested funding will support the purchase of specialized commercial digitizing equipment, as well as the employment of a postdoctoral researcher and undergraduate students to digitize these films and archive them in the public domain. The BBSO data to be digitized includes full-disk and high resolution H-alpha images, as well as He I images. The entire set of full-disk data will be converted to create a synoptic data base. High resolution film data will be digitized according to events selected by the full-disk data. All observed solar flares and filament eruptions will be automatically detected and cataloged using artificial intelligence methods that have been developed and implemented at BBSO. <br/><br/>Despite some limitations of the film data format, the PI notes that the long-term coverage and high quality of the BBSO data will have very broad applications for many statistical studies. The PI's team will carry out targeted research on the filaments and flares with the digitized data. They plan to perform statistical analysis of solar filaments, including their motions and eruptions. They will study filament oscillations to verify whether they are precursors to, or the result of, solar flares. The PI and postdoc will investigate the rate of magnetic reconnection at the Sun and the relationship of filament acceleration to hard X-ray (HXR) emission. This new study will complement the ongoing comparison of existing BBSO digital data and HXR data from the RHESSI spacecraft.<br/><br/>This research addresses the SHINE goal of understanding the initiation of CMEs and electron acceleration in flares. The study of a large number of archived events will improve the forecasting of future solar eruptive events, and thus assist operational space weather prediction. Funding is not requested for the PI, but it will instead support the postdoc and undergraduate students. At least three undergraduate students will participate in the film digitization and research, and the postdoc will gain management training by assisting the PI in supervising these students."
1725423,Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students,DUE,IUSE,9/1/2017,7/21/2017,Julie Linsey,"Linsey, J","Linsey, J",GA,Georgia Tech Research Corporation,Standard Grant,Heather Watson,8/31/2022,"$429,108.00 ",,julie.linsey@me.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,EHR,1998,"8209, 8244, 9178",$0.00 ,normalFunding,"Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
1717324,RI: Small: General Intelligence through Algorithm Invention and Selection,IIS,ROBUST INTELLIGENCE,9/1/2017,7/25/2017,Julian Togelius,"Togelius, J","Togelius, J|Nealen, A",NY,New York University,Standard Grant,James Donlon,8/31/2020,"$427,000.00 ",Andrew Nealen,julian.togelius@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Creating better artificial intelligence has plenty of applications in different areas of society, from self-driving cars and aircraft to production planning, control of machines and music composition. Most current artificial intelligence research focuses on creating algorithms that can only do a single thing, or solve a single problem.  To achieve artificial general intelligence we must learn how to create algorithms that can solve many different problems, without a human having to adjust the algorithm for every problem. The research in this project aims to understand how such artificial general intelligence can be created. The basic idea is to build algorithms that can create their own more specific algorithms, and learn to automatically select the right algorithm for the right problem. In order to develop these algorithms, we need a large set of good problems to test them on. Games are widely used to test AI algorithms, because they model real-world problems but are fast and easy to execute. The general algorithms developed in this project will be tested on a set of classic games, and a real-time strategy game.<br/><br/>This research project aims to investigate how we can create more general artificial intelligence through online stochastic search for algorithms, combined with and informed by online selection among discovered algorithms. In other words, the project will investigate the combination of genetic programming in the space of tree search algorithms with algorithm selection, also called hyper-heuristics, for creating more general problem-solving abilities. These capabilities will be evaluated through a sequence of experiments on two different test beds.  Successful completion of the research will clarify the potential of search in algorithm space as a method for creating more general artificial intelligence, and produce a number of algorithms. This includes both the algorithms that will be designed for searching for algorithms and searching among algorithms, as well as the new algorithms that will be discovered by the search in algorithm space. The methods produced are expected to ultimately be generally applicable to a large number of problems."
1718384,RI: Small: A New Approach to Integrating Graphical Models in Decision-Theoretic Planning,IIS,ROBUST INTELLIGENCE,8/15/2017,7/25/2017,Eric Hansen,"Hansen, E","Hansen, E",MS,Mississippi State University,Standard Grant,James Donlon,7/31/2020,"$427,000.00 ",,hansen@cse.msstate.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,CSE,7495,"7495, 7923, 9150",$0.00 ,normalFunding,"This project addresses one of the central problems of research in Artificial Intelligence: the problem of planning, or sequential decision making, under uncertainty and imperfect information. Planning algorithms are widely-used for control and decision-making problems in engineering and business, with many practical applications in robotics, process control, logistics, user-adaptive systems, resource management, and related problems where automation of decision making is useful. This project considers two widely-used decision-theoretic frameworks for planning under uncertainty and imperfect information, which are partially observable Markov decision processes and influence diagrams, and integrates these two frameworks in a novel way that leverages their complementary advantages. <br/><br/>The project integrates these two frameworks by showing how to generalize algorithms for solving influence diagrams, especially classic variable elimination algorithms, so that they use algorithmic techniques for solving partially observable Markov decision processes (POMDPs) to improve scalability, as well as to represent plans and strategies more compactly. The generalized variable elimination algorithms developed in this project can behave like traditional algorithms for solving influence diagrams, or like traditional algorithms for solving POMDPs, depending on the order in which variables are eliminated. From this perspective, algorithms for influence diagrams and POMDPs that once appeared dissimilar can be viewed as special cases of the same, more general algorithm. More importantly, this perspective allows these complementary algorithmic techniques to be combined in new ways, leading to planning algorithms with improved performance, wider applicability, and easier-to-interpret results.  The project focuses on several related research problems that will extend this approach and make it more useful in practice, including the development of new heuristics for variable elimination ordering, the development of approaches to improving planner performance by leveraging problem structure, including context-specific independence, and the development of an integrated approach to bounded-error approximation that will allow tradeoffs between plan quality and computation time. Although the project focuses on finite-horizon planning problems, the integrated approach may also be used in solving infinite-horizon planning problems with non-Markovian structure. In addition to the intellectual impact of this research, the project will contribute to education, student mentoring, and outreach."
115885,MRI:  Instrumentation for Intelligent Agent and Wireless Computing Research,CNS,MAJOR RESEARCH INSTRUMENTATION,9/1/2001,6/26/2001,Diane Cook,"Cook, D","Cook, D|Das, S|Holder, L|Yerraballi, R|Huber, M",TX,University of Texas at Arlington,Standard Grant,Rita V. Rodriguez,8/31/2005,"$426,284.00 ","Sajal Das, Lawrence Holder, Ramesh Yerraballi, Manfred Huber",cook@eecs.wsu.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,CSE,1189,"1189, 9218, HPCC",$0.00 ,normalFunding,"EIA-0115885<br/>Diane J. Cook<br/>University of Texas at Arlington<br/><br/>MRI:  Instrumentation for Intelligent Agent and Wireless Computing Research <br/><br/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training on intelligent agents in a mobile environment.  The Wireless Intelligent Simulator Environment being established will integrate software agents, human agents, and robot agents, so that physically distributed interacting agents can perform a variety of tasks cooperatively or competitively.  <br/>"
9453422,Presidential Faculty Fellows,ECCS,"CONTROL, NETWORKS, & COMP INTE, PROF OPPOR FOR WOMEN IN RSCH",10/1/1994,2/29/2000,Yilu Liu,"Liu, Y","Liu, Y",VA,Virginia Polytechnic Institute and State University,Continuing grant,Radhakisan S. Baheti,9/30/2000,"$424,681.00 ",,liu@utk.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,ENG,"1518, 1592","0000, 1592, 9296, OTHR",$0.00 ,normalFunding,"9453422  Liu  Develop intelligent diagnostic methodologies to detect incipient  failures in power system equipment using adaptive recognition  techniques and artificial neural networks.  We will continue the  work of power system equipment diagnosis using artificial neural  networks.  The previously developed methods and experiences will  be widely tested.  An important task for failure diagnosis is to  determine the most representative parameters of equipment status,  and the most likely cause of a particular failure or performance  deterioration.  These will be achieved through sensitivity tests  of individual or a group of parameters in ANNs.  Although ANN-  based diagnosis systems are problem-dependent, some general rules  on input feature selection, ANN architecture, and training  algorithms will be developed for use as guidelines in similar  applications.      Develop dynamic contingency analysis and control algorithms using  Satellite-Based Phasor Measurement Technology.  Develop real-time  dynamic models in order to investigate the possibility of  tracking power system dynamics in real-time.    Establish research programs in characterizing harmonic noise in  power systems by developing an integrated probabilistic harmonic  flow algorithm that considers the nonlinear dependence of  harmonic voltages and currents, and random variations of  operation modes and switching status of harmonic sources.  More  effort will be devoted to develop algorithms for identifying  harmonic sources based on limited measurements for multiple  circuit nodes.    The computer animation packages for teaching difficult concepts  will be expanded and more complex field problems and concepts  will be illustrated with animation.  Multimedia tools will be  gradually added to the conventional classroom teaching.    The power engineering core course materials will be updated and  revised in order to establish an ideal knowledge mix for today's  Electrical Engineering graduates.  The Power Quality Teaching and  Research  Lab are being planned and lab equipment are being  researched.  It is planned that new lab equipment will be added  for harmonic measurements.  This will allow us to begin data  gathering and analysis.  Also, lab experiments will be developed  for students to use in the new power quality course.       ***"
329880,SENSORS: Collaborative Research: MEMS for Multi-Mode Civil Infrastructure Monitoring,CMMI,"APPLIED MATHEMATICS, GRANT OPP FOR ACAD LIA W/INDUS, SENSORS AND SENSING SYSTEMS",9/1/2003,1/28/2009,Irving Oppenheim,"Oppenheim, I","Oppenheim, I|Pessiki, S|Greve, D",PA,Carnegie-Mellon University,Standard Grant,Shih-Chi Liu,8/31/2009,"$423,953.00 ","Stephen Pessiki, David Greve",ijo@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,ENG,"1266, 1504, 1639","032E, 1039, 1057, 1059, 1504, 7224, 7234, CVIS",$0.00 ,normalFunding,"The overall research objective of this project, a collaboration between CMU and Lehigh, is to develop, study, and test new MEMS sensor system regarding its capabilities for structural monitoring. The proposed research embraces new MEMS transducers development, combined experimental and mathematical investigation of the devices' multi-mode sensing performance, structural testing for determination of condition characterization, and methods to power and communicate with devices. Included is also an integral component of mathematical investigation of non-linear effects of sensors performance and their electromechanical functions.<br/><br/>The project will significantly promote teaching and training of students of all levels and diverse backgrounds by sharing experience on non-traditional mode on the basis of multidisciplinary education. The technical outcome is expected to enhance the management, safety and security of the public infrastructures through smart sensing and monitoring."
1031505,A Hybrid Electronic Tongue for Geoenvironmental Site Characterization,CMMI,"Geotechnical Engineering and M, ENG DIVERSITY ACTIVITIES",9/1/2010,3/5/2012,Pradeep Kurup,"Kurup, P","Kurup, P|Nagarajan, R",MA,University of Massachusetts Lowell,Standard Grant,Richard J. Fragaszy,8/31/2014,"$421,859.00 ",Ramaswamy Nagarajan,Pradeep_Kurup@uml.edu,600 Suffolk Street,Lowell,MA,18543643,9789344170,ENG,"1636, 7680","015E, 036E, 037E, 038E, 043E, 1057, 116E, 1636, 7680, 7974, 9178, 9179, 9231, 9251, CVIS",$0.00 ,normalFunding,"This project will support the development of a novel ?electronic tongue cone penetrometer? for on-site characterization of heavy metals such as Arsenic, Cadmium, Copper, Chromium, Lead, Manganese, Mercury, Nickel, Selenium, Thallium and Zinc in soils and groundwater. The electronic tongue is a device that mimics the human gustatory system using microelectrode sensor arrays coupled with artificial intelligence for pattern recognition. The project will involve fundamental research to design and assemble materials for highly sensitive and broadly-selective microelectrode sensors. This will be followed by the development of conductometric and voltammetric techniques for the hybrid electronic tongue. In addition, intelligent machine learning models for multivariate data processing and interpretation will be developed for classification and quantification of heavy metals. Calibration chamber studies will be conducted to develop methods for analysis of heavy metals in aqueous soil samples. Finally, the microelectrode sensor arrays will be deployed in a field-rugged cone penetrometer to facilitate real-time geoenvironmental site characterization.<br/><br/> <br/><br/>The successful completion of this project would result in the development of a novel in situ tool and method, for rapid, safe, and cost effective characterization of heavy metal contaminated sites. This minimally invasive technology will limit potential personnel exposure to contaminated media, and reduce the amount of investigation-derived waste normally generated during conventional borehole drilling and sampling activities. It will also reduce the time-consuming laboratory analysis during initial site investigations, and will provide regulatory agencies with critical information that is necessary for taking appropriate steps such as communicating drinking water advisories in a timely manner. This technology can also be expanded further to detect other types of toxins, making this approach applicable to diverse fields such as biotechnology, pharmaceuticals and medical diagnostics, food industry, environmental monitoring, law enforcement and homeland security."
1718945,RI: SMALL: Efficient Implementations of Goal-Directed Solvers for Answer Set Programming,IIS,ROBUST INTELLIGENCE,9/1/2017,8/4/2017,Gopal Gupta,"Gupta, G","Gupta, G",TX,University of Texas at Dallas,Standard Grant,James Donlon,8/31/2020,"$420,000.00 ",,gupta@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"The goal of this project is to develop efficient implementation techniques for realizing automated reasoning systems that emulate human-style common sense reasoning. Automating common sense reasoning is important for developing advanced applications of artificial intelligence (AI), particularly, in areas where the thought process of an expert needs to be automated, e.g., reasoning performed by a medical doctor during diagnosis and prescribing a treatment. Human reasoning is difficult to emulate on a computer, as humans simplify reasoning by using default conclusions (e.g., if Tweety is a bird, it must fly) coupled with raising exceptions (if Tweety turns out to be a penguin later, retract the conclusion about Tweety's flying abilities). Because of this peculiar nature of human reasoning, approaches based on standard logic do not work very well: one has to resort to a non-monotonic logic, i.e., a logic in which conclusions reached now may be withdrawn later as new information becomes available. Research conducted in this project will result in efficient, query-driven implementations of these non-monotonic logics. Successful completion of this project will result in advanced applications such as an automated system that can advise a physician on how to treat a particular disease, or a self-driving car's decision-making system that can emulate a human's driving expertise.<br/><br/>The project will rely on the paradigm of answer set programming (ASP) to represent common sense knowledge. An answer set program consists of rules containing (possibly negated) predicates. Current ASP systems rely on first grounding the answer set program to obtain an equivalent propositional program, and then using a Boolean satisfiability (SAT) solver to find models of this propositional program that contain the answer that is sought by the user. The grounding requirement restricts the range of programs that can be executed. This project builds upon earlier research on directly executing predicate answer set programs, i.e., without grounding them first. It aims to realize faster implementations of such systems by designing a virtual machine to which an answer set programs will be compiled to and executed."
9720170,Acquisition of a Symmetric Multiprocessor Scientific Computer System,EIA,MAJOR RESEARCH INSTRUMENTATION,9/1/1997,9/4/1997,David Landau,"Landau, D","Landau, D|McRae, W",GA,University of Georgia Research Foundation Inc,Standard Grant,Stephen Mahaney,8/31/1999,"$420,000.00 ",Walter McRae,dlandau@physast.uga.edu,310 East Campus Rd,ATHENS,GA,306021589,7065425939,CSE,1189,"1189, 9218, HPCC",$0.00 ,normalFunding,"9720170 Landau, David P. University of Georgia Acquisition of a Symmetric Multiprocessor Scientific Computer System The University of Georgia is upgrading its parallel scientific computing facility to a 24-node Silicon Graphics Origin 2000 High Performance Computer System to advance a multidisciplinary activity in intelligent multiscale scientific simulations. This platform has the flexibility to run several jobs at once in mixed configurations and will allow a user to run programs requiring distributed memory processing. Research areas to be supported range from parallel computing, artificial intelligence, optimization and interoperability issues, scalable parallel algorithm design for nuclear physics, fluid flow modeling, materials simulation, molecular modeling, quantum chemistry, polymer modeling, and geological modeling. The proposed computing facility will allow the University to continue and expand its educational programs in computational sciences. In addition to graduate students participating in the research projects described in the proposal, existing undergraduate and graduate courses in computational physics, biology, simulation methods, and business process modeling will utilize the proposed facility."
412812,Pushing the Boundaries of AI Planning,IIS,ARTIFICIAL INTELL & COGNIT SCI,6/1/2004,4/24/2008,Dana Nau,"Nau, D","Nau, D",MD,University of Maryland College Park,Continuing grant,Douglas H. Fisher,5/31/2009,"$420,000.00 ",,nau@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,6856,"9218, HPCC",$0.00 ,normalFunding,"This project has the goal of developing planner-generalization techniques that can be used to modify AI planning algorithms to remove some of the restrictive assumptions found in classical approaches to AI planning, such as: perfect knowledge about actions and objects and history of the planning environment, static planning environment, instantaneous actions, discrete time, determinism, black-and-white solution criteria. A starting point for the project will be the PI's preliminary results on a method to ""non-determinize"" forward-chaining planners. Using both theoretical and empirical techniques, the project will explore ways to systematically generalize planning algorithms to deal with nondeterminism, actions with probabilistic effects, and temporal issues. Results of the project will provide theoretical and experimental underpinnings necessary to enable AI planning to better address the needs of real-world planning applications such as manufacturing planning and ship movement planning. It is intended that implementations of algorithms developed in this project will be made available as open-source software."
1629564,XPS: FULL: Collaborative Research: Parallel and Distributed Circuit Programming for Structured Prediction,CCF,Exploiting Parallel&Scalabilty,8/15/2016,8/11/2016,Jason Eisner,"Eisner, J","Eisner, J",MD,Johns Hopkins University,Standard Grant,Anindya Banerjee,7/31/2019,"$415,000.00 ",,jason@cs.jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,8283,,$0.00 ,normalFunding,"This project develops a system for ""circuit programming,"" which allows a programmer to focus on the high-level solution to a problem rather than on the details of how the computation is organized. Circuit programming consists of writing rules that describe how data items depend on one another. The intellectual merits lie in the design of a new programming language for specifying these rules, along with the algorithms whereby the computer automatically finds efficient strategies for managing the necessary computations on available parallel hardware.  The project's broader significance and importance lie in its potential to streamline work in areas such as artificial intelligence and machine learning.  With the growing complexity of systems in these areas and their need to process big data in depth, research and teaching typically get bogged down in programming details, especially for parallel platforms; this project aims to delegate those details to automatic methods.<br/><br/>The research develops a programming system for Dyna, a circuit programming language that enables concise specification of large function graphs that may be cyclic and/or infinite. Dyna employs (1) a pattern-matching notation that augments pure Prolog with evaluation and aggregation and (2) an object-like mechanism for dynamically defining new sub-circuits as modifications of old ones.  This project is building an adaptive system that can mix forward and backward chaining to seek a fixpoint of the circuit and to update this fixpoint as the inputs change.  The system will perform compile-time and runtime analysis of the Dyna program and will map it to Habanero, a system for scheduling parallel computations on multicore processors, with extensions for task priorities, task cancellation, GPU execution, and distributed execution."
9802773,Combinatorial Optimization and Integer Programming: Polyhedral Analysis and Algorithms,CMMI,"COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT, OPERATIONS RESEARCH",7/15/1998,7/7/2000,Egon Balas,"Balas, E","Balas, E|Cornuejols, G",PA,Carnegie-Mellon University,Continuing grant,Ronald L. Rardin,6/30/2001,"$413,619.00 ",Gerard Cornuejols,eb17@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,ENG,"1271, 2865, 5514","9147, MANU",$0.00 ,normalFunding,"9802773 Balas The research funded by this grant addresses some basic theoretical and methodological aspects of integer and combinatorial optimization. Over the last few years the principal investigators have developed a technique called lift-and-project for solving mixed integer programs. When embedded in an enumerative framework, called branch-and-cut, this approach has shown itself to be highly robust and competitive with the best available alternatives. A major goal of the research is to consolidate these results and develop the approach in new directions, by solving several open problems concerning the properties of the cutting planes used; the way of generating and handling them; and, the interplay between cutting and branching. Part of this research will combine polyhedral methods with some tools borrowed from artificial intelligence. A closely related research topic is focussed on a heuristic procedure called OCTANE, which uses a neighborhood search defined by a construction based on polarity. Another topic involves ideal 0-1 matrices, which make certain integer programs defined by them solvable as linear programs. Finally, a substantial part of the research will focus on the traveling salesman problem, and some of its generalizations, focusing on a dynamic programming approach that can efficiently solve large classes of problems in this area. The research envisaged here is expected to substantially enhance the state of the art in solving integer and combinatorial optimization problems in general, traveling salesman-type problems in particular. Some of the investigations are aimed at gaining new theoretical insights and a deeper understanding of the structures involved, but most of the research is methodological in nature and is therefore expected to result in more efficient algorithms and computer codes. The problems to which such algorithms may be applicable range from investment decisions, capacity expansion models, location and distribution problems, to industrial scheduling and sequencing."
448806,CAREER:  A Generic Scheme for Graph Topology Optimization,CMMI,ENGINEERING DESIGN AND INNOVAT,3/1/2005,5/24/2010,Matthew Campbell,"Campbell, M","Campbell, M",TX,University of Texas at Austin,Standard Grant,Christina L. Bloebaum,2/28/2011,"$412,000.00 ",,matt.campbell@oregonstate.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,ENG,1464,"067E, 068E, 1045, 116E, 1187, 9148, 9178, 9231, 9251, MANU",$0.00 ,normalFunding,"This career-development project will investigate the first generalized scheme for solving topological design problems. This approach combines aspects of optimization, graph theory, mathematical programming, artificial intelligence, and shape and graph grammars. While traditional optimization is typically used to find the best values for dimensions and parameters within an already detailed design, topology optimization can be used earlier in the design process to determine a configuration of constitutive elements. Configuring components can be tedious given the abundance and variety of component types and the pressures imposed by shorter design cycles. Such topological problems are prevalent in engineering design. Examples include the design of sheet metal components, the location and connection of roadways, and the choice and connection of processors in a chemical plant. Thus, a design synthesis method is proposed to automatically choose and configure elements.<br/><br/>The research activities will be integrated with an educational plan that includes a project-intensive approach to teaching machine elements, a web-based portfolio tool geared towards high-school students interested in engineering and undergraduate students, and the development of two interdisciplinary graduate courses in design. <br/>It is expected that the broader impacts of the research will become significant when the new method is used to solve real engineering design problems. Since the method proposes to increase the representation abilities and improve the efficiency of the search process, more ambitious design problems can be addressed computationally. By developing and implementing generalized modules for solving search problems such as these, researchers will be able to implement their specific representation and evaluation code to work within the proposed framework. <br/>.<br/>"
238442,CAREER:  Adaptive Control in Biological and Man-made Systems,CBET,"Disability & Rehab Engineering, Engineering of Biomed Systems",7/1/2003,7/6/2007,Robert Scheidt,"Scheidt, R","Scheidt, R",WI,Marquette University,Continuing grant,Semahat S. Demir,6/30/2009,"$411,996.00 ",,Robert.Scheidt@marquette.edu,P.O. Box 1881,Milwaukee,WI,532011881,4142887200,ENG,"5342, 5345","0000, 003E, 1045, 1187, 9178, 9231, 9251, OTHR, SMET",$0.00 ,normalFunding,"0238442<br/>Scheidt<br/>Engineers have long drawn inspiration and insight from the study of biological systems. Some of the most intriguing parallels between biological and man-made systems have arisen in the study of information processing and control within biological nervous systems.  Early explorations into control and communication in animals and machines have influenced the development of diverse engineering disciplines such as artificial intelligence, computational neuroscience and the mathematical modeling of logic and the mind. Particularly intriguing are studies of learning and adaptation in nervous systems; such studies have influenced the development and analysis of artificial neural networks and have in turn been influenced by advances in adaptive control theory. <br/><br/>The goals of the proposed research are to identify the neural mechanisms mediating adaptive improvements in motor performance, and to test the hypothesis that abnormal sensory feedback gain degrades motor coordination in a relatively common clinical population. The PI will develop a novel, single-degree-of-freedom, robotic manipulandum for use with both event-related functional magnetic resonance imaging (ER-fMRI) and systems identification techniques to characterize, model and locate within the brain the adaptive mechanisms mediating an important form of motor learning known as motor adaptation. Neurologically unimpaired subjects and autistic children will make goal-directed hand movements while holding the handle of a novel robot. ER-fMRI techniques will be used to quantify brain activity while the robot perturbs the moving hand.  Linear (and if needed, nonlinear) systems identification techniques will be used to identify which brain region(s) are most likely involved in the adaptive neural representation of the hand's mechanical environment. <br/><br/>The proposal outlines the PI's role in developing Marquette University's new Biocomputer Engineering curriculum. The PI will train up to 40 engineers per year in the processes, methodologies, technologies and physiological aspects of engineering microcontroller-based systems in the regulated medical electronics industry. The PI will integrate state-of-the-art knowledge of adaptive algorithms and their validation into the new undergraduate curriculum. The PI will also integrate the proposed research and device development activities into his existing Neuromotor Control course.  Finally, the proposal describes an engineering curriculum development process that draws from industrial best practices in product design and quality control. Curriculum development will incorporate industrial advisory feedback from periodic curriculum design reviews to ensure that state-of-the-art design processes, methodologies and technologies are instructed. <br/>"
711887,RI: Text-to-Picture Synthesis,IIS,ROBUST INTELLIGENCE,8/15/2007,1/28/2009,Xiaojin Zhu,"Zhu, X","Zhu, X|Dyer, C",WI,University of Wisconsin-Madison,Continuing grant,Jie Yang,7/31/2012,"$411,956.00 ",Charles Dyer,jerryzhu@cs.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,CSE,7495,"7495, 9216, HPCC, 9215, 9251",$0.00 ,normalFunding,"Title: Text-to-Picture Synthesis<br/><br/>PIs: Xiaojin (Jerry) Zhu and Charles Dyer<br/>Institution: University of Wisconsin-Madison<br/><br/>Abstract<br/><br/>One challenge in artificial intelligence is to enable natural <br/>interactions between people and computers via multiple modalities. <br/>It is often desirable to convert information between modalities. One example is the conversion between text and speech using speech synthesis and speech recognition. However, such conversion is rare between other modalities. In particular, relatively little research has considered the transformation from general text to pictorial representations. This project will develop general-purpose Text-to- Picture synthesis algorithms that automatically generate pictures from natural language sentences so that the picture conveys the main meaning of the text. Unlike prior systems that require hand-crafted narrative descriptions of a scene, algorithms will generate static or animated pictures that represent important objects, spatial relations, and actions for general text. Key components include extracting important information from text, generating corresponding images for each piece of information, composing the images into a coherent picture, and evaluation. The proposed approach uses statistical machine learning and draws ideas from automatic machine translation, text summarization, text-to-speech synthesis, computer vision, and graphics. This research will produce computational methods as well as working systems.<br/><br/>Text-to-picture synthesis is likely to have a number of important broad impacts. First, it has the potential for improving literacy across a range of groups including children who need additional support in learning to read, and adults who are learning a second language. Second, it may be used as an assistive communication tool for people with disabilities such as dyslexia and brain damage, and as a universal language when communication is needed simultaneously to many people who speak different languages. Third, it can be a summarization tool for rapidly browsing long text documents. This research will foster collaboration between researchers in computer <br/>science and other disciplines, including psychology and education. <br/>Results of the project will be disseminated through technical publications, public web pages and software, seminars and talks, and classroom education.<br/><br/>URL: http://www.cs.wisc.edu/~jerryzhu/ttp/"
99025,Research on Bounded Rationality,SES,"ECONOMICS, DECISION RISK & MANAGEMENT SCI",6/1/2001,5/29/2003,David Laibson,"Laibson, D","Laibson, D|Gabaix, X",MA,National Bureau of Economic Research Inc,Continuing grant,Kaye Husbands Fealing,5/31/2005,"$410,476.00 ",Xavier Gabaix,dlaibson@harvard.edu,1050 Massachusetts Avenue,Cambridge,MA,21385398,6178683900,SBE,"1320, 1321","0000, OTHR",$0.00 ,normalFunding,"This research develops intelligent algorithms that mimic the cognitive processes of human decision-makers. Such algorithms allocate cognitive resources like other scarce resources. Attention is only allocated to tasks in which it will do the most good. The algorithms settle for approximate solutions and ""educated guesses"" when solving highly complex problems. The research develops models that predict the form of such educated guesses, providing an implementable model of artificial intelligence. To succeed such models must find a sensible middle ground between the extreme rationality of omniscience and the extreme myopia of mechanistic strategies. An intelligent machine that tried to think of everything (omniscience) would run out of time when making a decision. By contrast, a machine that acted myopically would quickly blunder into obvious mistakes that humans would never make. Finding a middle ground between the extremes of omniscience and myopia will require answers to numerous questions about cognition. What information do people use? How is that information manipulated? How do individuals decide when to stop working on a complex problem and act on their best guess?<br/><br/>The ""directed cognition model"" that addresses these questions is expressed as a three-step algorithm. First, the algorithm evaluates the expected benefit of various cognitive operations. The expected benefit is related to the predicted likelihood that a cognitive operation will reveal useful information about an upcoming decision. Second, the algorithm executes the cognitive operation with the greatest expected benefit. Third, the algorithm repeatedly cycles through these first two steps, stopping when the cognitive costs of analysis outweigh the expected benefits.<br/><br/>The directed cognition model realizes three goals. First, the model is psychologically plausible, predicting numerous observed psychological phenomena (e.g., salience, myopia, and anchoring) and matching the cognitive strategies that experimental subjects claim to use. Second the model generates precise quantitative predictions that can be empirically tested. Initial experimental data overwhelmingly rejects the perfectly rational model in favor of the directed cognition model. Third, because the model is general it can be applied to a wide class of problems.<br/><br/>By extending the directed cognition model and integrating it with other models of cost-effective cognition, the research develops a general bounded rationality approach to optimization, including boundedly rational dynamic programming. At the core of this approach is a theory of endogenous approximation.<br/><br/>Current applications include contract theory and consumption. Contract theory applications explain both the presence and form of contract incompleteness, including boilerplate contracts. Boundedly rational consumption models explain why households adjust too slowly to changes in their economic environment and why households simultaneously exhibit excessive sensitivity to salient variables like current income.<br/><br/>The directed cognition model makes sharp predictions about how much time experimental subjects will choose to spend on each problem in a multi-part quiz. The model also predicts how the quality of respondents' answers will vary when the amount of time allowed for a given problem is fixed by the experimenter and varied across subjects. If the directed cognition model continues to be empirically validated, it will represent one of the first economic models that can formally predict the difficulty of a decision problem --- i.e., the model predicts the quantitative relationship between time spent analyzing a problem and optimality/accuracy of the resulting decision. Ultimately, a relatively general model of artificially intelligent decision-making may be developed, which can be applied and tested in a wide range of choice problems."
9874391,CAREER: Reducing Drought Hazards by Improving Drought Plans,CMMI,"NAT & MAN-MADE HAZARD MITIGATI, STRUCTURES II, Geotechnical Engineering and M",4/15/1999,12/3/2002,Anne Steinemann,"Steinemann, A","Steinemann, A",GA,Georgia Tech Research Corporation,Continuing grant,Richard J. Fragaszy,11/30/2005,"$410,000.00 ",,acstein@u.washington.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,ENG,"1474, 1498, 1636","1039, 1045, 1057, 1187, 1576, 9102, CVIS",$0.00 ,normalFunding,"This career project deals with drought, one of the most complex and costly of all natural disasters. However, recent research found that drought plans often suffer from deficiencies that limit their value in actual droughts. Drought plans may fail to incorporate valuable expertise and experience from previous droughts. In addition, agencies lack readily accessible methods to test and improve their plans. Because agencies' plans may be inadequate, metropolitan regions may unwittingly be susceptible to disasters.<br/><br/>This research project addresses two key needs for development of drought plans: to improve drought plans before a drought occurs, and to tap existing expertise on drought water management. The research will generate new knowledge and methods for the development and evaluation of drought plans, using a knowledge-based engineering approach. This approach applies artificial intelligence techniques to acquire, formalize, and disseminate expert heuristics within an integrated decision-support system.<br/><br/>The research objectives are to: (1) investigate the factors that reduce drought hazards; (2) design a framework for developing and evaluating drought contingency plans, using knowledge-based engineering methods; (3) test drought plans, using expert heuristics and drought scenarios; and (4) develop an integrated knowledge-based system to help agencies prepare and improve their drought plans. <br/><br/>This integrated CAREER plan will also address deficiencies in water resources education.<br/><br/>The educational objectives are to: (1) provide students experience with real-world water resources problems in which they work directly with agencies and stakeholders; (2) develop and implement problem-based learning exercises that enable students to develop reasoning skills for active, lifelong learning; (3) use information technologies, including knowledge-based systems, in educational and professional settings; and (4) provide students opportunities to contribute both to the advancement of research and to the solution of problems in their community. An interdisciplinary degree program will be developed to establish internships with industries and agencies, and engage students in research and K-12 outreach programs that link scientists and educators from over 5,000 schools in 65 countries. This educational plan will help to meet the growing need for engineers and water resources professionals who can work and communicate effectively when faced with complex, multidisciplinary problems that affect both the public and private sectors."
1629459,XPS: FULL: Collaborative Research: Parallel and Distributed Circuit Programming for Structured Prediction,CCF,Exploiting Parallel&Scalabilty,8/15/2016,8/11/2016,Vivek Sarkar,"Sarkar, V","Sarkar, V",TX,William Marsh Rice University,Standard Grant,Anindya Banerjee,7/31/2018,"$410,000.00 ",,vsarkar@rice.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,CSE,8283,,$0.00 ,normalFunding,"This project develops a system for ""circuit programming,"" which allows a programmer to focus on the high-level solution to a problem rather than on the details of how the computation is organized. Circuit programming consists of writing rules that describe how data items depend on one another. The intellectual merits lie in the design of a new programming language for specifying these rules, along with the algorithms whereby the computer automatically finds efficient strategies for managing the necessary computations on available parallel hardware.  The project's broader significance and importance lie in its potential to streamline work in areas such as artificial intelligence and machine learning.  With the growing complexity of systems in these areas and their need to process big data in depth, research and teaching typically get bogged down in programming details, especially for parallel platforms; this project aims to delegate those details to automatic methods.<br/><br/>The research develops a programming system for Dyna, a circuit programming language that enables concise specification of large function graphs that may be cyclic and/or infinite. Dyna employs (1) a pattern-matching notation that augments pure Prolog with evaluation and aggregation and (2) an object-like mechanism for dynamically defining new sub-circuits as modifications of old ones.  This project is building an adaptive system that can mix forward and backward chaining to seek a fixpoint of the circuit and to update this fixpoint as the inputs change.  The system will perform compile-time and runtime analysis of the Dyna program and will map it to Habanero, a system for scheduling parallel computations on multicore processors, with extensions for task priorities, task cancellation, GPU execution, and distributed execution."
1618193,RI: Small: Linguistic Semantics and Discourse from Leaky Distant Supervision,IIS,ROBUST INTELLIGENCE,8/1/2016,8/11/2017,Hal Daume,"Daume, H","Daume, H",MD,University of Maryland College Park,Continuing grant,Tatiana D. Korelsky,7/31/2019,"$406,792.00 ",,hal@umiacs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"This project studies novel algorithms for building artificial intelligence (AI) systems that can learn to improve their performance with a human in the loop. Many recent AI successes are driven by large, expensive and difficult-to-collect datasets. This yields systems that are deep, but narrow. The goal of this project is to build technology that will allow AI systems to learn from their interactions with people. The project focuses on key applications related to natural language understanding: building technology to understand the meanings of individual sentences, and integrate those meanings into the meaning of a discourse or dialog.  One specific application pursued herein relates to extracting biomedical knowledge from text, which will pave the way to helping biomedical researchers develop novel hypotheses.  The work will fund students from underrepresented groups in STEM, and encourage cross-disciplinary education at the graduate and undergraduate levels. Finally, the work will be communicated to the public not just with scientific papers, but internationally through social media and locally through visits to middle schools and high schools.<br/><br/>Natural language processing (and other fields of artificial intelligence) have had enormous success by training supervised  learning systems on large labeled datasets (""corpora"").  Unfortunately, curating such corpora is infeasible except for very specific problems. This happens either because it is too expensive, or it is too difficult to get human labelers to agree on an annotation standard.  Instead of relying solely on human labeled data, this project develops algorithms that can learn from human interaction.  These systems can continually improve their performance based on downstream performance supervision, often with a human in the loop. This work leverages recent developments on the structured contextual bandits learning framework which provides a theoretically grounded and computationally efficient way in which to develop novel approaches to distant supervision. This resulting learning techniques will push advances in natural language understanding: semantic parsing and discourse interpretation. Furthermore, the underlying imitation learning technology is broadly applicable, including novel applications to recurrent neural network models.  To aid adoption by the research community, code and data from this project will be released open source."
329014,Decision Theoretic Approaches to Human-Robot Social Interaction,IIS,"ROBOTICS, ROBUST INTELLIGENCE",9/1/2003,4/17/2006,Illah Reza Nourbakhsh,"Nourbakhsh, IR","Nourbakhsh, IR|Simmons, R",PA,Carnegie-Mellon University,Continuing grant,C.S. George Lee,8/31/2006,"$405,882.00 ",Reid Simmons,illah@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"6840, 7495","9139, 9178, 9251, HPCC, SMET",$0.00 ,normalFunding,"Robotics and Computer Vision Program<br/><br/>ABSTRACT<br/><br/><br/>Proposal #: 0329014<br/>Title: Decision Theoretic Approaches to Human-Robot Social Interaction<br/>PI: Nourbakhsh, Illah Reza<br/>Carnegie Mellon University<br/><br/>Social rules govern patterns of movement and allow individuals to share a space without interfering with each other's goals.  These social rules of movement are rich and complicated, being highly dependent on context and governing both spatial and temporal relationships.  The research question at the heart of this project is: can robots utilize cues based on human behavior in deciding when and how to apply the correct rules for social interaction?  There are two main components to this question: how to acquire or design the representations of these rules and cues, and how to use this information in a robot's decision-making process.  We approach this as a planning problem because a social interaction requires a sequence of actions rather than a one-time, reactive choice.  We intend to extend existing decision-theoretic planning methods to semi-Markov models, which can represent more complex relationships between time and state than first order Markov models.<br/><br/>This project has potential impact in the research fields of Artificial Intelligence and Robotics as well as impact on numerous modern applications.  It can result in making robots more likely to be deployed in environments where their capacity to be embodied information providers is most useful (museum guides, receptionists, helpmates for the elderly, etc.).  This project is also promoting education for underrepresented groups like women and minorities.<br/>"
1717530,CIF: Small: Foundations of Belief Sharing in Human-Machine Systems,CCF,COMM & INFORMATION FOUNDATIONS,7/1/2017,6/28/2017,Lav Varshney,"Varshney, L","Varshney, L",IL,University of Illinois at Urbana-Champaign,Standard Grant,Phillip Regalia,6/30/2020,"$405,455.00 ",,Varshney@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,7797,"7923, 7936",$0.00 ,normalFunding,"This work aims to develop mathematical laws and foundational principles for belief sharing in systems with human and machine intelligence working together to make robust decisions. Prior work in statistical signal processing and in psychology has only considered technological limitations or human limitations independently, but jointly considering informational limitations of both humans and machines is critical in engineering future sociotechnical systems, especially when people are overwhelmed by too much information. A theory for fundamental limits and optimal designs for such systems is lacking.<br/><br/>Rather than systems with agents sharing either raw data or local decisions, we develop intermediate designs based on sharing beliefs. Belief sharing increases modularity among networked units compared to central analysis of raw data, yet also strengthens coordination compared to decentralized local decisions. We build on our prior bounded rationality models of people and stochastic models of artificial intelligence to determine optimal mixed human-machine architectures. First, we find fundamental information-theoretic limits of belief-sharing under Bayes risk and discrete choice models, new kinds of CEO problems. As a key substep, this involves determining fundamental Ziv-Zakai bounds on Bayesian estimation under non-quadratic criteria. We then use quantization and decision theory to develop optimal architectures that have cognitively- and algorithmically-limited agents, including optimal categorization of beliefs and judgment pooling rules taking human behavior into account. Finally, we consider the language needed to communicate beliefs in complicated network structures to achieve collective intelligence, studying Nash equilibria balancing focal and shared concerns."
1523982,Comp Cog:  Collaborative Research on the Development of Visual Object Recognition,BCS,"DS - Developmental Sciences, PERCEPTION, ACTION & COGNITION",8/1/2015,9/2/2016,Linda Smith,"Smith, L","Smith, L|Yu, C",IN,Indiana University,Continuing grant,Chalandra Bryant,7/31/2018,"$405,158.00 ",Chen Yu,smith4@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,SBE,"1698, 7252","1698, 7252, 7298, 9178",$0.00 ,normalFunding,"Human visual object recognition is fast and robust.  People can recognize a large number of visual objects in complex scenes, from varied views, and in less than optimal circumstances.  This ability underlies many advanced human skills, including tool use, reading, and navigation.  Artificial intelligence devices do not yet approach the level of skill of everyday human object recognition. This project will address one gap in current knowledge, an understanding of the visual experiences that allow skilled object recognition to develop, by capturing and analyzing the visual experiences of 1- to 2-year-old toddlers.  This is a key period for understanding human visual object recognition because it is the time when toddlers learn a large number of object categories, when they learn the names for those objects, and when they instrumentally act on and use objects as tools.  Two-year-old children, unlike computer vision systems, rapidly learn to recognize many visual objects.  This project seeks to understand how the training experiences (everyday object viewing) of toddlers may be optimal for building robust visual object recognition. The project aims to (1) understand the visual and statistical regularities in 1- to 2-year-old children's experiences of common objects (e.g., cups, chairs, trucks, dogs) and (2) determine whether a training regimen like that experienced by human toddlers supports visual object recognition by state-of-the art machine vision. <br/><br/>Considerable progress in understanding adult vision has been made by studying the visual statistics of ""natural scenes."" However, there is concern about possible artifacts in these scenes because they typically photographs taken by adults and thus potentially biased by the already developed mature visual system that holds the camera and frames the pictures. Also, photographed scenes differ systematically from the scenes sampled by people as they move about and act in the world.  Accordingly, there is increased interest in egocentric views collected from body-worn cameras, the method used in the present work.  Toddlers will wear lightweight head cameras as they go about their daily activities, allowing the investigators to capture the objects the toddlers see and the perspectives and contexts in which they see them.  The research will analyze the frequency, views, visual properties, and range of seen objects for the first 100 object names normatively learned by young children, providing a first description of the early learning environment for human visual object recognition.  These toddler-perspective scenes  will be used as inputs to machine learning models to better understand how the visual information in the scenes supports and constrains the development of visual object recognition. Machine-learning experiments will determine which properties and statistical regularities are most critical for learning to recognize common object categories in multiple scene contexts.  Data collected will be shared through Databrary, an open data library for developmental science."
713499,"RI: Extending the Reach of SAT Technology - Quantification, Counting, and Sampling",IIS,ROBUST INTELLIGENCE,8/15/2007,8/29/2008,Bart Selman,"Selman, B","Selman, B|Gomes, C",NY,Cornell University,Continuing grant,Edwina L. Rissland,7/31/2010,"$405,000.00 ",Carla Gomes,selman@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7495,"7495, 9218, HPCC",$0.00 ,normalFunding,"Proposal 0713499<br/>""RI: Extending the Reach of SAT Technology - Quantification, Counting, and Sampling""<br/>PI: Bart Selman<br/>Cornell Univsersity<br/><br/><br/>ABSTRACT<br/><br/>Many real-world computational problems require a search through an exponentially large space of potential solutions. Examples of such problems can be found in a diverse range of areas, for example, in hardware and software design and verification, planning and scheduling, and artificial intelligence (AI). Many such problems can be translated into a common representation, called the Boolean Satisfiability (SAT) formulation. This formulation consists of a set of Boolean (True/False) variables and logical constraints among these variables. The challenge is to find an assignment to the variables such that all constraints are satisfied. In recent years, we have seen tremendous progress in the development of SAT solvers, which search for satisfying assignments. Current SAT solvers handle problem instances with over one million variables and several millions of constraints. An intriguing research question is whether the advances in SAT technology can be exploited for other key reasoning tasks central to AI. <br/><br/>This project considers three such tasks: (1) quantified Boolean reasoning, key in multi-agent reasoning and reasoning in adversarial settings, (2) counting of the number of satisfying assignments, which has many applications in probabilistic inference, and (3) sampling from the set of satisfying assignments, which is closely related to model counting. The broader impact of the proposal will be the design and development of efficient solvers for quantified Boolean formulas (QBF) and algorithms for model counting and sampling applicable to a wide range of users working in areas as diverse as verification, planning, adversarial reasoning, and probabilistic reasoning.<br/>"
851368,REU Site: Rice University Summer Institute of Statistics (RUSIS),DMS,WORKFORCE IN THE MATHEMAT SCI,5/15/2009,4/4/2009,Javier Rojo,"Rojo, J","Rojo, J",TX,William Marsh Rice University,Standard Grant,Noel Brady,10/31/2012,"$404,999.00 ",,javier.rojo@oregonstate.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,MPS,7335,"0000, 9178, 9250, OTHR",$0.00 ,normalFunding,"This award provides continued support for a successful 10-week summer REU site within the Statistics Department at Rice University for the study of Statistics and its applications. As the number of domestic graduate students in the Mathematical Sciences continues to decline, there is a critical need to develop human resources to continue supporting the United States' advantage in the world of science and technology. The Rice University Summer Institute of Statistics (RUSIS) has been successful in encouraging students to pursue graduate degrees in Mathematics and Statistics. Roughly 85% of the students who have attended RUSIS and have graduated, are now doctoral students in Ph.D. programs around the country, and roughly 61% of them are members of underrepresented populations in Mathematics. RUSIS has accomplished this through intensive courses, close supervision of research projects, and visits to various research institutes and agencies in Houston. Specifically, the program <br/><br/><br/> Trains and mentors 17 (12 NSF- and 5 NSA-supported) selected underrepresented minority students and students with no easy access to a career experience at their institution, including community college students, through intensive core courses in probability, stochastic processes, and statistical inference, with special emphasis on areas of current interest. (e.g.  multiple comparisons, extreme value theory, multivariate survival analysis, risk-reliability-sustainability of complex infrastructure systems, artificial intelligence, statistical learning, statistical genetics, and general biostatistics). <br/><br/> Engages the students in research projects under close collaboration with faculty mentors, and with the objective of producing joint publications. Students present their results at national meetings and they are mentored in the preparation and presentation of their talks. In addition, students meet with an advisory committee composed of top scientists and present their work to them. <br/><br/> Teaches short courses on the use of Unix platforms, LaTeX, and software to be utilized for research purposes such as Mathematica, Splus and/or R, and Matlab;<br/><br/> Organizes student and faculty visits to scientific facilities (e.g., Biomathematics and Biostatistics at MD Anderson Cancer Center, NASA) and a series of lectures, by distinguished scientists, is scheduled. These lectures cover a variety of topics ranging from applying to Graduate School to career experiences by outstanding scientists, and discussion of cutting-edge topics in Statistics.<br/><br/> Evaluates and monitors the progress of students for seven years (expected time for them to finish graduate school) after their participation; annual evaluation of the program by the participating students and an external advisory committee is an integral and valuable part of the program."
812149,RI-Small: Decision-Theoretic Planning for Multi-Agent Systems,IIS,ROBUST INTELLIGENCE,9/1/2008,7/23/2008,Shlomo Zilberstein,"Zilberstein, S","Zilberstein, S",MA,University of Massachusetts Amherst,Standard Grant,Jie Yang,8/31/2012,"$404,708.00 ",,shlomo@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,"7495, 9215, HPCC",$0.00 ,normalFunding,"A fundamental challenge in artificial intelligence is to achieve intelligent coordination of a group of decision makers in spite of uncertainty and limited information. Decision theory offers a normative framework for optimizing decisions under uncertainty, but due to computational barriers, developing decision-theoretic reasoning algorithms for multi-agent systems is a serious challenge. This project will advance foundational contributions to the understanding of decision-theoretic planning in stochastic multi-agent domains as well as the development of efficient new algorithms that provide exponential savings in memory requirements and computation time. Moving beyond toy problems is a hard computational challenge that has been broadly recognized by the multiagent systems community. Research under this project will transform the ability of researcher and practitioners to apply decision-theoretic planing to a new range of domains."
524239,CT-ISG/RUI: Ensuring Computation Integrity in Distributed Volunteer Computing Platforms,IIS,ITR-CYBERTRUST,9/1/2005,8/9/2005,Douglas Szajda,"Szajda, D","Szajda, D|Owen, W|Lawson, B",VA,University of Richmond,Standard Grant,Xiaoyang Wang,8/31/2009,"$401,193.00 ","William Owen, Barry Lawson",dszajda@richmond.edu,202 MARYLAND HALL,RICHMOND,VA,231730001,8042898100,CSE,7456,"7254, 9218, HPCC",$0.00 ,normalFunding,"This research investigates the protection of computation integrity and enhancement of data privacy for applications executed on distributed computing platforms that utilize the spare processor cycles of computers connected to the Internet. The goal of the project is to provide computation supervisors with quantifiable protection and privacy mechanisms tailored to application and platform specific constraints. The project considers existing platforms, which prohibit participating computers (""participants"") from communicating with other participants, as well as potential future hierarchical platforms that permit communication among participants and allow dynamic variation of platform topology. The approach to the problem of computation integrity consists of probabilistic verification and novel application of artificial intelligence mechanisms for detecting anomalous behavior. The approach to data privacy is based on obscuring data values while maintaining sufficient output information for identifying specific important data from among a vast data set. The experimental research links to education at the University of Richmond through development of special topics courses and enhancement of existing courses, and by engaging undergraduates in relevant research via funding of research fellowships, equipment, and travel to project related conferences and workshops. The results of the project will provide access to more secure computing platforms, fostering inter-disciplinary research among scientists and practitioners. Specific fields benefiting from results of this research include biology, chemistry, math, finance, medicine, and evolutionary theory. Project implementations will modify existing open source distributed computing code and will be disseminated via the project Web site (http://dvc.richmond.edu/). <br/>"
1533569,Targeted Infusion Project: Development of a Knowledge-Based System for Integrating Artificial Intelligence into the Undergraduate Engineering Curriculum,HRD,HIST BLACK COLLEGES AND UNIV,8/1/2015,7/24/2015,Yachi Wanyan,"Wanyan, Y","Wanyan, Y|Olowokere, D",TX,Texas Southern University,Standard Grant,Claudia M. Rankins,7/31/2019,"$400,000.00 ",David Olowokere,wanyany@tsu.edu,3100 Cleburne Street,Houston,TX,770044501,7133137457,EHR,1594,9178,$0.00 ,normalFunding,"The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue STEM graduate programs and/or careers. The project at Texas Southern University seeks to infuse innovative electrical and computer engineering specialized artificial intelligence (AI) tools into traditional engineering problem-solving routines with a problem-based learning approach to bridge current curricula gaps, enhance engineering students' problem-solving and critical thinking skills, expose them to new technology, prepare them for diverse and multidisciplinary workforce requirements, and attract and encourage students to pursue professional engineering licensure or post-graduate studies in engineering field. The activities and strategies are evidence-based and a strong plan for formative and summative evaluation is part of the project.<br/><br/>There are five key objectives: 1) to develop an interactive and comprehensive intelligent database to document, compare, and analyze cutting-edge AI applications in the civil engineering field and use it as the platform and educational media for curricula development and implementation; 2) to develop one new interdisciplinary course  ""AI Tools for Engineering Problem Solving"" for senior engineering students; 3) to enrich current curricula by integrating innovative AI application case studies into twelve existing civil engineering junior and senior level courses; 4) to foster an interdisciplinary academic setting by hosting a server-based intelligent database; and 5) to support undergraduate students' early involvement in research. The project activities can serve as a model for other institutions that desire to strengthen undergraduate education in their engineering and technology programs."
812671,RI-Small: Statistical Relational Models for Semantic Robot Mapping,IIS,ROBUST INTELLIGENCE,8/1/2008,8/12/2010,Dieter Fox,"Fox, D","Fox, D",WA,University of Washington,Continuing grant,Richard Voyles,7/31/2012,"$400,000.00 ",,fox@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7495,"7495, 9215, HPCC",$0.00 ,normalFunding,"How can we build robots that are able to distinguish and handle the many objects located in our everyday environments?  And how can we endow these robots with the ability to reason about spatial concepts such as rooms, hallways, streets, and intersections?  Even though the robotics community has made tremendous progress in the development of efficient techniques for representing and dealing with noisy sensor information, current techniques do not have the expressive power to address these questions. In this project, we will develop statistical relational machine learning techniques that are able to extract high-level concepts from robotic sensor data.  By transferring knowledge learned in other environments, our techniques will enable robots to recognize objects and places in previously unseen environments.  Ultimately, this research will bring us closer to the dream of truly autonomous robots; robots that can interact with people and operate successfully in the complex environments we live in.<br/><br/>This project also includes teaching efforts and the involvement of undergraduate students in research.  Furthermore, it contains collaboration with an existing NSF project to expose young African-American students to the educational and career opportunities available in computer science, robotics and artificial intelligence."
845643,CAREER: Architecting A Database Management System for Semantic Web Data,IIS,INFO INTEGRATION & INFORMATICS,2/15/2009,1/30/2013,Daniel Abadi,"Abadi, D","Abadi, D",CT,Yale University,Continuing grant,frank olken,8/31/2014,"$400,000.00 ",,abadi@umd.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,7364,"1045, 1187, 7364, 9216, HPCC",$0.00 ,normalFunding,"<br/>The goal of the Semantic Web is to free Web data from the applications that control them, so that data can be easily described and exchanged. <br/>This is accomplished by supplementing natural language and other data found on the Web with machine readable metadata in statement form (e.g., X is-a person, X has-name Joe, X has-age 35) and enabling descriptions of data ontologies so that data from different applications can be integrated through ontology mapping. One element of this vision is to turn the Web into a giant database, against which one can issue structured queries and receive structured answers in response.<br/><br/>The SW-Store project is undertaking the clean-slate design of a DBMS specifically architected for this type of Web metadata and the prevalent Semantic Web data model, the Resource Description Framework, or RDF. The management of Semantic Web data presents many difficult challenges. The size of the data is growing rapidly, and in theory could reach the scale of the Web. The types of queries vary greatly in complexity, ranging from keyword search to complicated parameterized subgraph matching. Data integration, inference, and reasoning must be primitive operations that can operate at scale without human intervention. A data management system must not only be a place where data is stored and from which data is accessed; it must use the machine-readable semantics of the data to develop higher level models and help guide a user through the mass of information. In sum, a data management system for the Semantic Web will look very different from a standard, transactional, relational database system.<br/><br/>The SW-store project researches the architecture of such a system. This research is inherently interdisciplinary, bringing in ideas from the data management, Semantic Web, and artificial intelligence communities. The project involves experimenting with partitioning schemes, where data is allocated to different nodes on a shared-nothing cluster so that queries can be run in parallel across multiple machines. It also involves exploring how ontology reasoning can be integrated inside the database system so that it can benefit from the near limitless scalability a shared-nothing cluster can offer. SW-Store further investigates providing iterative query interfaces and integrating complex queries with text search. Finally, the project involves studying the design of the storage layer for a Semantic Web data management system, looking at how data should be laid out, updates should be performed, and what materialized views to create.<br/><br/>Further information about the project can be found at the project Webpage: <br/>http://db.cs.yale.edu/swstore/<br/>"
742302,"CAREER: Synthesis of Autonomous, Realistic Human Motion",CCF,COMPUTING PROCESSES & ARTIFACT,7/1/2007,2/14/2008,C. Karen Liu,"Liu, CK","Liu, CK",GA,Georgia Tech Research Corporation,Standard Grant,Lawrence Rosenblum,6/30/2013,"$400,000.00 ",,ckarenliu@gmail.com,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7352,"1045, 9218, HPCC",$0.00 ,normalFunding,"Modeling believable human characters in the virtual environment is crucial for unleashing the potential of computers as an interactive medium. A realistic depiction of human motion drastically enhances the perceptual immersion for task training, social communication, or tele-learning. In a believable virtual environment, a human character must be able to plan its locomotion, react to the environment, and engage other virtual characters or real humans with realistic display of emotion and personality. This daunting task requires simulation from the musculoskeletal system to the nervous system, as these intricate components must coordinate in synchrony when a functional activity is undertaken. Physics-based character animation today can simulate complex locomotion sequences with stunning visual realism, albeit under the careful guidance of the animator. What is missing from most character animation techniques is autonomous control, both conscious and unconscious. In this project, the investigator expands computer-generated character animation from a visualization tool to an interdisciplinary research area focused on autonomous control and realistic locomotion.<br/><br/>This project focuses on two inter-related research thrusts fundamentally aligned with the interdisciplinary nature of the investigator's research theme: (1) synthesis of non-ballistic, low-energy human locomotion, and (2) synthesis of interaction among multiple characters. Unlike ballistic and highly dynamic motion, non-ballistic motion is not stringently determined by physics, thus requiring more sophisticated models to address the complex interplay of unconscious autonomous control, such as physiology and emotion, and conscious autonomous control, such as the intents of the character. The autonomous control becomes even more crucial when multiple character interaction comes into play. Synthesis of interaction is challenging because the high-level artificial intelligence algorithms and low-level locomotion intertwine in an unpredictable manner when the interaction takes place. Beyond the scope of computer animation, this computational model can provide a device for recognizing emotion, diagnosing musculoskeletal anomalies, or validating biomechanical hypotheses."
643795,"CAREER: Synthesis of Autonomous, Realistic Human Motion",CCF,COMPUTING PROCESSES & ARTIFACT,7/1/2007,6/18/2007,C. Karen Liu,"Liu, CK","Liu, CK",CA,University of Southern California,Standard Grant,Lawrence Rosenblum,3/31/2008,"$400,000.00 ",,ckarenliu@gmail.com,University Park,Los Angeles,CA,900890001,2137407762,CSE,7352,"1045, 9218, HPCC",$0.00 ,normalFunding,"Modeling believable human characters in the virtual environment is crucial for unleashing the potential of computers as an interactive medium. A realistic depiction of human motion drastically enhances the perceptual immersion for task training, social communication, or tele-learning. In a believable virtual environment, a human character must be able to plan its locomotion, react to the environment, and engage other virtual characters or real humans with realistic display of emotion and personality. This daunting task requires simulation from the musculoskeletal system to the nervous system, as these intricate components must coordinate in synchrony when a functional activity is undertaken. Physics-based character animation today can simulate complex locomotion sequences with stunning visual realism, albeit under the careful guidance of the animator. What is missing from most character animation techniques is autonomous control, both conscious and unconscious. In this project, the investigator expands computer-generated character animation from a visualization tool to an interdisciplinary research area focused on autonomous control and realistic locomotion.<br/><br/>This project focuses on two inter-related research thrusts fundamentally aligned with the interdisciplinary nature of the investigator's research theme: (1) synthesis of non-ballistic, low-energy human locomotion, and (2) synthesis of interaction among multiple characters. Unlike ballistic and highly dynamic motion, non-ballistic motion is not stringently determined by physics, thus requiring more sophisticated models to address the complex interplay of unconscious autonomous control, such as physiology and emotion, and conscious autonomous control, such as the intents of the character. The autonomous control becomes even more crucial when multiple character interaction comes into play. Synthesis of interaction is challenging because the high-level artificial intelligence algorithms and low-level locomotion intertwine in an unpredictable manner when the interaction takes place. Beyond the scope of computer animation, this computational model can provide a device for recognizing emotion, diagnosing musculoskeletal anomalies, or validating biomechanical hypotheses."
1025682,VOSS: Culture and Coordination in Global Engineering Teams,OAC,"ENGINEERING EDUCATION, INNOVATION & ORG SCIENCES(IOS), VIRTUAL ORGANIZATIONS",9/1/2010,7/7/2015,Catherine Cramton,"Cramton, C","Cramton, C|Koehler, T|Levitt, R",VA,George Mason University,Standard Grant,Rajiv Ramnath,8/31/2016,"$400,000.00 ","Tine Koehler, Raymond Levitt",ccramton@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,"1340, 5376, 7642","110E, 7969",$0.00 ,normalFunding,"Construction engineering provides the foundation for society: the buildings, bridges, roads and other infrastructure we use every day. Engineering work has become increasingly complex, and big engineering projects are almost always undertaken by teams of engineers whose members are multicultural and distributed around the globe.  Effective coordination is crucial for success, yet recent research suggests that team coordination practices vary with national culture. Experts have warned that engineering education fails to prepare engineers for these differences.<br/><br/>We will use scripts theory, which lies at the intersection of the fields of social psychology and artificial intelligence, to characterize the culturally-specific coordination practices of engineering teams, introducing the notion of ""cultural coordination scripts."" We will 1) characterize and understand the coordination scripts of several specific cultures, 2) show how cultural coordination scripts are intertwined with technical training and technical tasks and 3) determine how differences in cultural coordination scripts in multi-cultural globally-distributed teams affect their capacity to coordinate highly precise work and achieve innovative, safe, timely and cost-effective outcomes. We seek to predict likely points of coordination failure. Data collection will include unobtrusive longitudinal observation of the coordination activities of mono-cultural and multi-cultural collocated and distributed engineering design teams.<br/><br/>This research program will help engineers -- and others who work in multicultural, multi-national project teams -- become more adept in anticipating and working across different cultural expectations related to project coordination. Recommendations will be developed for engineering education and practice. Cultural differences in coordination practices are understudied across domains of application, so our work will provide new knowledge concerning this central team process. We also offer a new approach to capturing the complexity of teamwork ""an approach grounded in scripts theory"" that has the potential to influence research across disciplines."
245291,Robust Learning Control for Building Energy Systems,ECCS,"CONTROL, NETWORKS, & COMP INTE, INTEGRATIVE SYSTEMS, ARTIFICIAL INTELL & COGNIT SCI",5/1/2003,5/4/2005,Douglas Hittle,"Hittle, D","Hittle, D|Young, P|Anderson, C",CO,Colorado State University,Continuing grant,Paul Werbos,4/30/2007,"$399,999.00 ","Peter Young, Charles Anderson",hittle@engr.colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,ENG,"1518, 1519, 6856","0000, 7238, OTHR",$0.00 ,normalFunding,"This project will develop of new control strategies for heating, ventilating, and air-conditioning (HVAC) systems that combine artificial intelligence and robust control theory. A primary objective of the work is to develop learning controllers, which provide (a-priori) guaranteed closed-loop stability even while the controller trains online. It is a follow-on project to NSF project 9804757, i8Robust Learning Control for Heating, Ventilating and Air-Conditioning Systems, it where several significant advancements in the state of the art were achieved.<br/><br/>The primary objectives of the proposed research are:<br/><br/>New analysis tools and algorithms, which allow for new theoretical approaches for learning including: Continuous learning algorithms; recurrent dynamic networks; and learned dynamic models.<br/><br/>New theoretical tools, including enhanced Integral Quadratic Constraints (IQCs) for improved speed and accuracy the more general classes of networks, and advanced systematic algorithms for tunneling, to facilitate navigation of the learning around regions of instability.<br/><br/>Design and test of more advanced robust reinforcement learning algorithms;<br/><br/>Extensive experimental study of the new tools being developed here for multi-input, multi-output (MIMO) robust reinforcement learning control, utilizing a recently developed experimental platform for heating, ventilating, and air-conditioning (HVAC) system control.<br/><br/>Disseminate in through conference and journal publications and by assisting colleagues at Korea Institute for Energy Research in conducting their own tests of these methods.<br/><br/>To accomplish these objectives, an interdisciplinary team has been formed consisting of a specialist in robust control from the Electrical & Computer Engineering Department, a specialist in reinforcement learning for neural networks from the Department of Computer Science, and a specialist in design, modeling and control of HVAC systems from the Mechanical Engineering Department.<br/>"
1637544,AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World,CCF,Algorithms in the Field,9/1/2016,8/30/2016,David Sontag,"Sontag, D","Sontag, D",NY,New York University,Standard Grant,Tracy J. Kimbrel,1/31/2017,"$399,999.00 ",,dsontag@mit.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,CSE,7239,,$0.00 ,normalFunding,"Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br/> <br/>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science."
1723344,AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World,CCF,Algorithms in the Field,1/1/2017,12/28/2016,David Sontag,"Sontag, D","Sontag, D",MA,Massachusetts Institute of Technology,Standard Grant,Tracy J. Kimbrel,8/31/2020,"$399,999.00 ",,dsontag@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7239,,$0.00 ,normalFunding,"Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br/> <br/>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science."
9804793,The Turbo Decoding Algorithm and its Relatives,CCF,COMMUNICATIONS RESEARCH,8/1/1998,9/21/2001,Robert McEliece,"McEliece, R","McEliece, R",CA,California Institute of Technology,Standard Grant,Julia Abrahams,7/31/2002,"$399,997.00 ",,rjm@systems.caltech.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,CSE,4096,"9218, HPCC",$0.00 ,normalFunding,"In 1993, a group of French researchers announced the invention of  ``turbo-codes,'' a fundamentally new approach to the problem of  attaining near Shannon limit performance on a variety of  communications channel models. Many researchers believe that  turbo codes are the most important new idea in error-correcting  codes since Shannon's original paper. Professor McEliece's work  under this NSF grant is motivated by the desire to provide a  sound theoretical explanation for the experimentally verified  iterative turbo decoding algorithm, which is the key innovation  of the French group.  McEliece's research has led to the  discovery of a close connection between the turbo decoding  algorithm and a number of other algorithms known in the  cryptography, information theory, digital communications, signal  processing, statistics, and artificial intelligence communities.  McEliece and his co-workers have shown that all of these  algorithms can be unified by a single technique which he calls  the generalized distributive law, or GDL. In this work, the goal  is to exploit the GDL to (a) search for a theoretical explanation  of the turbo decoding algorithm, and (b) to devise new decoding  algorithms in non-turbo situations."
1637585,AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World,CCF,Algorithms in the Field,9/1/2016,8/30/2016,Aravindan Vijayaraghavan,"Vijayaraghavan, A","Vijayaraghavan, A",IL,Northwestern University,Standard Grant,Tracy J. Kimbrel,8/31/2020,"$399,939.00 ",,aravindv@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7239,,$0.00 ,normalFunding,"Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br/> <br/>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science."
914793,(MOD) Metrics for Capturing Crucial Social Dynamics of Innovative Regions: Implications for S&T Policy,SBE,SCIENCE OF SCIENCE POLICY,8/1/2009,5/21/2009,Mary Walshok,"Walshok, M","Walshok, M",CA,University of California-San Diego,Standard Grant,Joshua Rosenbloom,7/31/2012,"$399,866.00 ",,mwalshok@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,SBE,7626,"0000, OTHR",$0.00 ,normalFunding,"This research quantifies and documents the role of social dynamics in the economic growth and development of regions with great scientific institutions. The presence of major scientific research institutions in a region does not, by itself, lead to social and economic benefit in that region.  The importance of hard assets such as R&D expenditures, patents and venture capital, as well as the critical mass and propinquity of scientific talent is well known. However, this research probes in detail a set of social mechanisms which are postulated to enable some regions to transfer and commercialize knowledge more effectively than others.  It examines the importance of the robust activity of S&T boundary-spanning organizations in a region in contributing to successful technology commercialization as measured by number of new business startups.  These S&T boundary-spanning organizations, social gatherings of cross-disciplinary and cross-functional groups including both technologists and their business supporters, are of three types:  formal groups that support local technologies (trade associations and entrepreneur-aiding groups); volunteer-run chapters affiliated with national organizations (e.g. IEEE, AeA, Sigma Xi, AWIS); and informal volunteer-run affinity groups focused often on a particular interdisciplinary subject such as systems biology or nanotechnology.<br/><br/>Intellectual Merit <br/>Previous research on social dynamics, largely descriptive and anecdotal, has yet to inform policy.  This project studies and quantifies the following aspects of the region's boundary-spanning groups:  their types, numbers, meeting frequency and attendance, their membership diversity (Shannon-Wiener index), and the region's overall membership overlap among these boundary-spanning groups.  These independent variables are then correlated with new business startups  including controls for R&D expenditures, patent activity, venture capital, critical mass and propinquity of the region?s scientific workforce.  <br/><br/>An initial set of three pilot case studies represent the first step in the development of a predictive model based on machine learning techniques.  A recommended data structure is being developed so that other research institutions or their regions may also gather data to perform self assessments and thus add to the training and test data used to test and enhance the resulting model.<br/><br/>Broader impacts:   This work develops  metrics which capture ""cultural and social dynamics"" and correlates them with successful knowledge flows between research institutions and a dynamic regional commercialization ecology.  It searches for the social factors that distinguish vibrant regions with the capacity to innovate from those that do less, in order to better understand the processes by which investments in S&T research are transformed into positive social and economic outcomes.<br/> <br/>This information may influence how regions and research organizations set policy to stimulate social networks and inclusive interdisciplinary discourse groups. The increased understanding of previously-uncharacterized aspects of knowledge flows should lead directly to new mechanisms available for optimization by policy makers. The application of artificial intelligence machine learning techniques in this work should also lead to new capabilities in the science of science policy."
1318374,AF: Small: Identifying sampling problems with efficient algorithms,CCF,ALGORITHMS,9/1/2013,6/21/2013,Daniel Stefankovic,"Stefankovic, D","Stefankovic, D",NY,University of Rochester,Standard Grant,Tracy J. Kimbrel,8/31/2018,"$399,703.00 ",,stefanko@cs.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,7926,"7923, 7926",$0.00 ,normalFunding,"Sampling problems are fundamental in many areas of science and engineering, for example, statistics, artificial intelligence (machine learning and vision), and biology (phylogeny). Efficiency of sampling has impact on other important algorithms, for example, the speed of statistical tests and the reliability of estimators and classifiers. This project seeks to characterize combinatorial problems that admit efficient sampling algorithms. The research under this award addresses both sides of the characterization for a broad class of ubiquitous graphical models: 1) complexity theoretic obstacles to efficient sampling and 2) efficient sampling algorithms.<br/><br/>Recent results established a useful characterization for antiferromagnetic 2-spin models (for example, weighted independent sets and Ising model) in terms of the behavior of the model on regular trees. This created a connection to problems and techniques studied in the statistical physics community. This project aims to use the connection to the statistical physics and its techniques (for example, belief propagation recurrences) to generalize the characterization to models with more than two spins (multi-spin models, such as the Potts model, frequently occur in the applications). As a first step towards this generalization a relation between the efficiency of commonly used Markov chains (Glauber dynamics, Swendsen-Wang algorithm) and the behavior of the models on regular trees will be explored. Beside Markov chains the PI will also investigate other approaches to sampling problems (for example, dynamic programming and utilizing strong spatial mixing).<br/><br/>The product of the research will be efficient sampling algorithms and an improved understanding of obstacles to efficient sampling. The algorithmic  problems, concepts, and techniques will be transferred to both undergraduate and graduate teaching (in the form of guided problems and implementation challenges). The award will support the training of two PhD students in the area of sampling and counting algorithms at the University of Rochester."
1400784,A Grammar-Based Approach to Visual-Haptic Object Perception,BCS,"PERCEPTION, ACTION & COGNITION, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE",9/1/2014,8/14/2014,Robert Jacobs,"Jacobs, R","Jacobs, R",NY,University of Rochester,Standard Grant,Betty H. Tuller,8/31/2019,"$399,049.00 ",,robbie@bcs.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,SBE,"7252, 7367, 7495","7252, 7367, 7495, 9251",$0.00 ,normalFunding,"People can perceive the shape of objects accurately and reliably but how this occurs is not yet understood. This ability may stem, at least in part, from our use of both visual information and haptic information (information obtained when an object is touched or grasped). Moreover, if we learn to recognize an object based on visual information, we can often recognize the same object when our eyes are closed but we are allowed to grasp it. Similarly, if we learn to recognize an object based on haptic information, we can often recognize the object when we see it but cannot touch it. In other words, we exhibit cross-modal transfer of object shape information. How does information from the eyes and hands link up in the brain to yield a coherent representation of object shape? Insights obtained from this research can contribute both to our understanding of how humans perceive object shape using vision and/or touch and to development of improved robotic and other artificial intelligence systems operating in multi-modal settings in industrial, medical, military, and other applications.<br/><br/>The present project develops a theory of visual-haptic object shape perception in which people's notions of object similarity are not based on sensory features but rather on latent or hidden variables that represent object parts and their spatial relations in an abstract, modality-independent format. Object representations are formalized using a probabilistic ""shape grammar"" with Bayesian inference used to infer grammar-based object representations when an object is viewed, when it is grasped, or both. The model is tested using data obtained from behavioral studies of visual, haptic, and visual-haptic object shape perception by humans. The investigators will explore the types of representational change that underlie the transition from perceptual novice to expert (e.g, radiologists) and will assess whether perceptual expertise is well characterized as category learning, grammar learning, both, or neither. The research program will also develop a large public database of code for re-creating both visual and haptic features of complex objects. This will allow other researchers to fabricate the objects using a 3D printer, enhancing complementarity and comparison across research sites. Finally, training undergraduate and graduate students in the emerging field of computational cognitive science will contribute to a new generation of multidisciplinary scientists working across traditional boundaries between cognitive science and computer science."
507542,RUI: Eclipsing Binaries and Variable Stars in the Local Group: Maximizing Return with an Intelligent Data Pipeline,AST,GALACTIC ASTRONOMY PROGRAM,8/1/2005,7/1/2010,Edward Guinan,"Guinan, E","Guinan, E",PA,Villanova University,Standard Grant,Donald M. Terndrup,7/31/2011,"$398,745.00 ",,edward.guinan@villanova.edu,800 Lancaster Avenue,Villanova,PA,190851676,6105196000,MPS,1216,"0000, 1206, 7569, 9229, OTHR",$0.00 ,normalFunding,"AST-0507542<br/>INSTITUTION: Villanova University<br/>PI: Edward Guinan<br/><br/>TITLE: ""Eclipsing Binaries and Variable Stars in the Local Group: Maximizing Return with an Intelligent Data Pipeline"" <br/><br/>ABSTRACT<br/><br/><br/>Dr. Edward Guinan, at Villanova University, will develop new data processing techniques and methodologies using minimal human intervention, focused on exploiting the potential of eclipsing binaries and variable stars found in new surveys. The goal is to integrate technologies of Artificial Intelligence into the data processing pipelines of major current and future ground- and space-based observational programs. The motivation for the proposed program lies in the expected growth in number of discovered variables with the growth of observational capabilities. A direct benefit of the research will be the use of eclipsing binaries in the Local Group for the study of galaxy evolution and cosmology. The broader impact of the work will be a large number of variable star datasets that will be made available to the astronomical community, as well as algorithms that will be useful for a broad range of instruments now in existence, and many that are planned. Undergraduates will also participate in the work, providing for a research-based educational experience for the students."
1718846,RI: Small: Linguistic Structure in Neural Sequence Models,IIS,ROBUST INTELLIGENCE,8/1/2017,7/27/2017,Jason Eisner,"Eisner, J","Eisner, J",MD,Johns Hopkins University,Standard Grant,Tatiana D. Korelsky,7/31/2020,"$395,002.00 ",,jason@cs.jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Over the past 25 years, the field of artificial intelligence has made great strides in the ability to automatically analyze and generate sequential data.  Much of this progress has come by building probabilistic models.  For example, mathematical descriptions of how words are typically used in context are based on a scientific understanding of the relationships among letters, sounds, words, and phrases, thanks to the field of linguistics.  Probabilistic models based on this understanding have allowed us to develop computational, data-driven methods for reasoning about the likely structure and meaning of sentences.  In the same way, probabilistic models of sequences of events have led to computational methods for predicting the unfolding of future events and reconstructing the ordering of past ones.  This project starts with sophisticated probabilistic models of linguistic structure and event sequences, and aims to make them more powerful, by using ""deep learning"" (neural networks) to increase their sensitivity to contextual effects.  Deep learning has already recently had a revolutionary impact on artificial intelligence.  This research will focus on using deep learning to enhance probabilistic models in settings where the model must discover structure that is not provided in its training data, such as the compositional units of language or the causal relations among events.<br/><br/>The planned model design will not focus on hand-engineered features, but rather on broad representational choices.  The overall architectures are motivated by certain basic notions that linguists and other modelers have found indispensable in their analyses of empirical data as follows: (1) stick-breaking processes that respect duality of patterning, the linguistic notion that a word's internal form is not necessarily related to its external usage but is governed by separate rules or by chance; (2) finite-state transducers that can capture local editing that transforms an input sequence into an output sequence; (3) context-free grammars that can model hierarchical structure to help explain word sequences; and (4) temporal point processes that can capture process intensity, where different events are competing to occur next, and combinations of earlier events combine to elevate or suppress the rates of later events.  The project will infuse these probabilistic techniques with recurrent neural networks, in particular, long short-term memory (LSTM) networks.  In some cases, exact inference in the resulting models will not be tractable, necessitating the design of Monte Carlo or variational approximations."
1068026,I/UCRC CGI: Collaborative Research - I/UCRC for Identification Technology Research,CNS,"GRANT OPP FOR ACAD LIA W/INDUS, INDUSTRY/UNIV COOP RES CENTERS, ",3/15/2011,5/27/2015,Judee Burgoon,"Burgoon, J","Burgoon, J|Nunamaker, J",AZ,University of Arizona,Continuing grant,Dmitri Perkins,2/28/2017,"$391,141.00 ",Jay Nunamaker,jburgoon@cmi.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,"1504, 5761, L528","0000, 1049, 116E, 122E, 170E, 5761, 8038, 8039, 8046, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"The purpose of this proposal is to start a new I/UCRC ""Identification Technology Research (CITeR)"" with a focus on technologies of human measurement, identity, and intent that rest on firm pillars of trust, privacy, security, and reliability. The lead of the proposed Center will be Clarkson (CU) with site locations at the West Virginia University (WVU) and the University of Arizona (UA). <br/><br/>Technologies to measure, monitor, identify humans and human intent are needed for a broad range of commercial and security applications. The use of technology to both improve performance (e.g. as minimizing false alarms for a given desired positive detection rate) or improving user interface (e.g. speeding lines through airports) will have a strong benefit to society. The proposed center will seek advanced theoretical and analytical techniques for developing algorithms and assessing performance of tools and systems that for human and intent identification. Such tools are needed for a variety of applications, and the current state of the art provides significant room for advancement. <br/><br/>The proposed center builds upon the past success of an existing center that has been in operation since 2001. West Virginia University and University of Arizona have been the key players in CITeR since its inception, while others such as Michigan State have made notable contributions in areas such as image processing. In this proposal, Clarkson University as the lead institution adds complementary Center capabilities for measurements and signal processing to identity humans and human intent, and expands the center in an important way. <br/><br/>The proposed research plan represents an appropriate set of projects for comprehensively addressing needs in this area. The investigators are well-qualified to carry out the research, and many have a significant, well-respected research track record in their fields. <br/><br/>CITeR will focus on research, education, and technology dissemination. CITeR's leadership with Clarkson to develop the Diversity 2050 Initiative program is an active program to identify and address educational needs of next-generation professionals in the identification technology arena, and is likely to lead to a broad-reaching and positive impact to higher education in these areas. The proposal lays out a clear plan for engaging the other CiTER sites in this effort. The proposed and re-organized CITeR will extend its research core while building on the solid foundation of the past. The proposed program builds on an existing center that has had great success since its inception in 2001, with more than 80 projects that have involved 22 faculty and 130 students."
712113,RI: Nonpropositional Nonmonotonic Languages for Knowledge Representation,IIS,ROBUST INTELLIGENCE,8/15/2007,8/29/2008,Vladimir Lifschitz,"Lifschitz, V","Lifschitz, V",TX,University of Texas at Austin,Continuing grant,Edwina L. Rissland,7/31/2011,"$389,100.00 ",,vl@cs.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7495,"7495, 9218, HPCC",$0.00 ,normalFunding,"<br/><br/>ABSTRACT<br/><br/>Knowledge representation formalisms are precisely defined languages designed for expressing declarative knowledge (assertions), just as typical programming languages are used to express procedural knowledge (algorithms). Because of the important role of declarative knowledge in intelligent behavior, the theory of knowledge representation is a key part of artificial intelligence. Nonmonotonic knowledge representation languages are particularly valuable in view of the fact that they allow reasoning about defaults and exceptions. Research on nonmonotonic knowledge representation is becoming increasingly experimental and applied, in connection with the emergence of efficient answer set solvers--software systems for computing stable models.<br/><br/>The goal of this project is to reformulate the semantics of variables in nonmonotonic logic in a way that will bring this theory closer to the reality of state-of-the-art implementations. This will be achieved using a new definition of a stable model that is based on translating logic programs with variables into classical logic. This work seeks to clarify and simplify the semantics of several knowledge representation languages that are used in applications of artificial intelligence to many areas of science and technology.<br/><br/>"
702758,Interactive and Verifiable Composition of Web Services To Satisfy End-User Goals,CCF,"COMPUTING PROCESSES & ARTIFACT, SOFTWARE ENG & FORMAL METHODS",7/1/2007,7/11/2012,Samik Basu,"Basu, S","Basu, S|Lutz, R|Honavar, V",IA,Iowa State University,Standard Grant,Sol J. Greenspan,12/31/2012,"$387,375.00 ","Robyn Lutz, Vasant Honavar",sbasu@cs.iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,CSE,"7352, 7944","9218, 9251, HPCC",$0.00 ,normalFunding,"Proposal Number P0702758<br/><br/>TITLE Interactive and Verifiable Composition of Web Services to Satisfy End-User Goals<br/><br/><br/>PI    Samik Basu, Vasant Honavar, Robyn Lutz<br/><br/>Web services are beginning to play an increasingly important role in scientific, engineering, government, health-care, and business applications.  Complex applications call for tools that support users to assemble composite services from independently developed component services to achieve the desired functionality. This research brings together a team of investigators with complementary expertise in formal methods, artificial intelligence, and software engineering to develop novel approaches to service composition that address this need.  The main contributions of this research include powerful interactive methods for service composition with provable guarantees with respect to user-specified functional and non-functional requirements. A main focus of the research is on investigation of functional and non-functional failure analysis of composition, and user-guided and automated reformulation of requirements based on such analysis, techniques for handling semantic mismatches between user specifications and service descriptions, and the use of interactive as opposed to fully automated methods.  Products of the research include software tools for interactive service composition as well as benchmarks for evaluation of alternative approaches to service composition.  Broader impact of the research includes enhanced opportunities for research-based training of graduate students. Results of the research including publications, software, and benchmarks will be disseminated through the project web-page at http://www.moscoe.org.<br/>"
1454190,CAREER: Automated scientific discovery and the philosophical problem of natural kinds,SES,"CROSS-DIRECTORATE  ACTIV PROGR, SCIENCE, TECH & SOCIETY",4/1/2015,8/3/2017,Benjamin Jantzen,"Jantzen, B","Jantzen, B",VA,Virginia Polytechnic Institute and State University,Continuing grant,Frederick M Kronz,3/31/2020,"$386,618.00 ",,bjantzen@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,SBE,"1397, 7603","1045, 1353, 9179",$0.00 ,normalFunding,"General Audience Summary <br/><br/>This is a Faculty Early Career Development (CAREER) award, the NSF's most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. This award supports an integrated research and education project that addresses a fundamental scientific question:  Out of countless number of empirical quantities related to some phenomenon of interest, to which quantities should attention be directed in order to successfully discover the regularities or laws behind the phenomenon? Only a special few facilitate accurate generalization from a few particular facts to a great many that are not in evidence, and yet in the course of their work scientists efficiently choose variables that support generalization. That scientists are able to do this is both fascinating and perplexing. This project will clarify and test a new approach to solving this puzzle by constructing a series of computer algorithms that automatically carry out a process of variable choice in the service of autonomous scientific discovery. The inductive success of these algorithms when applied to genuine problems in current scientific settings will serve as tangible validation of the theory underlying these algorithms. The automated discovery algorithms produced will be leveraged to introduce a generation of graduate students in philosophy and science to the deep connections between physical computing and formal epistemology. A recurring summer school will train graduate students in basic programming and formal methods, with hands on development of automated discovery systems.<br/><br/>Technical Summary <br/><br/>This project connects the philosophical problem of natural kinds with computational problems of automated discovery in artificial intelligence. It tests a new approach, a dynamical natural kinds theory, denoted the Dynamical Kinds Theory, by deriving discovery algorithms from that theory's normative content and then applying these algorithms to real-world phenomena. The inductive success of these algorithms when applied to genuine problems in current scientific settings will serve as tangible validation of the philosophical theory. More dramatically, these discovery algorithms have the potential to produce more than one equally effective but inconsistent classification of phenomena into kinds. The existence of such alternatives plays a central role in debates over scientific realism. Outside of philosophy, the application of the discovery algorithms to open problems in areas of ecology, evolution, metagenomics, metabolomics, and systems biology has the potential to suggest previously unconceived theories of the fundamental ontology in these fields. In particular, the algorithms will be applied to agent-based models of evolutionary dynamics to search for population-level laws, and to publicly available long-term ecological data to search for stable dynamical kinds outside the standard set of ecological categories."
1740225,E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays,CCF,Energy Efficient Computing: fr,9/15/2017,7/11/2018,Jae-sun Seo,"Seo, Js","Seo, Js|Yu, S",AZ,Arizona State University,Continuing grant,Sankar Basu,8/31/2020,"$386,044.00 ",Shimeng Yu,jaesun.seo@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,015Y,7945,$0.00 ,normalFunding,"In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform innovative and interdisciplinary research to address many limitations in today?s resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today's binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ?NeuroSim?. With vertical innovations across material, device, circuit and architecture, tremendous potential and research needs will be pursued towards energy-efficient artificial intelligence in ubiquitous resource-constrained hardware systems."
98807,Understanding and Improving On-Line Planning Methods,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2001,5/22/2006,Sven Koenig,"Koenig, S","Koenig, S|Tovey, C",GA,Georgia Tech Research Corporation,Continuing grant,Edwina L. Rissland,6/30/2006,"$385,662.00 ",Craig Tovey,skoenig@usc.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"<br/>This is the first year funding of a three year continuing award.   A variety of on-line planning methods are used in artificial intelligence including, for example, real-time search methods such as LRTA*, reinforcement-learning methods such as Q-learning, and robot-navigation methods such as D*.  The PIs intend to improve the performance of these and other on-line planning methods substantially so that, for example, future robot-navigation methods will be able to map unknown terrain significantly faster than is now possible, yet have the same advantageous properties as existing on-line planning methods.   Many on-line planning methods, either always or most of the time, execute actions that move the agent in the perceived direction of the goal, that is, move the agent so that it reduces the estimates of the goal distances the most.   However, the PIs preliminary theoretical results show that executing actions that move the agent in the perceived direction of the goal is usually not a good idea.   For example, D* does not reach a goal location in unknown terrain with a minimal travel distance in the worst case.  The key to improving the performance of these on-line planning methods then is to exploit the distance estimates that they maintain (or can maintain) in a way that is more directly related to the planning or learning objective.   The PIs will study the properties of on-line planning methods both theoretically and experimentally, and will develop improved on-line planning methods that have the same interface as the existing methods, which allows users of these methods to easily substitute the new methods for the ones they are currently using.   Side benefits of the proposed research include developing a test-bed for the experimental evaluation of robot navigation methods in unknown terrain, and creating a solid theoretical foundation for understanding robot-navigation methods in unknown terrain, including D*.<br/>"
1525943,AF: Small: Is the Simulation of Quantum Many-Body Systems Feasible on the Cloud?,CCF,ALGORITHMIC FOUNDATIONS,8/1/2015,8/21/2017,Pawel Wocjan,"Wocjan, P","Wocjan, P|Marinescu, D|Mucciolo, E",FL,University of Central Florida,Standard Grant,Dmitry Maslov,7/31/2019,"$385,434.00 ","Dan Marinescu, Eduardo Mucciolo",wocjan@cs.ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,7796,"7923, 7928, 9251",$0.00 ,normalFunding,"Simulating quantum mechanics with its unique effects such as superposition, interference, and entanglement is a hard problem for classical computing systems including supercomputers and computer clouds with a very large number of servers. To efficiently simulate large quantum-mechanical systems using a computer cloud one has to overcome major obstacles. This research investigates optimal algorithms for contracting tensor networks which arising in the study of condensed matter physics. These algorithms minimize the required communication between the nodes of the computer cloud and exploit its hierarchical organization. The broader research objective in this effort is to optimally exploit the architecture of hierarchically organized systems for big data applications that exhibit fine-grained parallelism.<br/>This research project aims to find new efficient methods for simulating large quantum systems that are important for quantum information processing, condensed matter physics, materials science, and chemistry. Its goals are to design and implement novel parallel and distributed simulation algorithms optimized for cloud computing environments such as Amazon Web Services and the National Science Foundation?s future cloud for scientific computing. The ultimate motivation of this project is to enable researchers world-wide to significantly push the boundary in terms of the size of quantum systems that they can simulate reliably and within a reasonable time and with a reasonable budget. While the research mainly concentrates on efficient algorithms and their implementation for the study of properties of condensed matter systems, it also attempts to derive generic strategies to other classes of applications, for instance, in artificial intelligence and in machine learning."
414976,Interactive Visual Methods for Partitioning Multidimensional Spatial Data,IIS,INFORMATION & KNOWLEDGE MANAGE,9/15/2005,9/6/2005,Marie desJardins,"desJardins, M","desJardins, M|Rheingans, P",MD,University of Maryland Baltimore County,Standard Grant,Maria Zemankova,8/31/2010,"$385,000.00 ",Penny Rheingans,mariedj@cs.umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,CSE,6855,"9218, HPCC",$0.00 ,normalFunding,"The goal of this research project is to develop innovative tools for interactive visual exploration of spatial multivariate data, using methods from artificial intelligence and information visualization.  The tools is motivated by the problem of school redistricting, and is conducted in collaboration with staff from the Howard County (Maryland) Public School System. The approach developed in this project produces multiple similar solutions with respect to optimization criteria, but trying to ensure that the solutions are qualitatively different. The interactive environment allows the user to browse through ""nearby"" solutions, investigate minor perturbations of each solution, while reducing the number of critically different solutions. This interactive visual method is expected to be very effective in the school redistricting domain, resulting in a substantial reduction in the time to develop new redistricting plans, and a corresponding increase in the number of plans that can effectively be generated and compared. This will result improved school redistricting process, where the visual tools will improve the ability of the school system to explain, justify, and disseminate proposed plans and the associated quantitative evaluation. The methods developed in this project will also be applicable in almost any other domain where multidimensional spatial data need to be partitioned according to some criteria. The project's Web site (http://maple.cs.umbc.edu/redistricting/) will be used to disseminate the results of this research."
513553,Collaborative Research: Information Integration for Locating and Querying Geospatial Data,IIS,"BE: NON-ANNOUNCEMENT RESEARCH, ITR-INFORMATION INTEGRATION",7/15/2005,4/15/2010,Maria Cruz,"Cruz, M","Cruz, M",IL,University of Illinois at Chicago,Standard Grant,Sylvia J. Spengler,6/30/2011,"$384,673.00 ",,isabelcfcruz@gmail.com,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,"1629, 7373","9216, 9218, HPCC",$0.00 ,normalFunding,"The objective of this work is to extend significantly the capabilities of portals created by the geospatial community, by providing semantic integration over diverse data sets. For example, the Wisconsin Land Information System and the new Federal Geospatial One-Stop portals disseminate data and support procedures and simulations in emergency situations. However, geospatial data are complex and highly heterogeneous, having been developed independently by various levels of government and the private sector. This project includes metadata integration methods to enable more precise location of data sources over the web and to provide geospatial portals with query capabilities and semantic resolution for the types of information integration that could help in information discovery, problem-solving, or emergency response.<br/><br/>The research will develop methods and tools to support the integration of information in such a way that end users will have a homogeneous view over heterogeneous data sources. An ontology-based architecture will be developed with which each individual heterogeneous data source can be added to the network of information with relatively little effort. Ontology mappings will establish correspondences between terms in heterogeneous sources and those of standard models and ontologies. The approach also extends ontology mappings to incorporate semantics regarding spatial considerations, such as accuracy, for spatial integration.<br/><br/>Information integration is an area of research that stretches over databases, artificial intelligence, digital libraries, and the semantic web. This project will extend significantly the state of the art of information integration in general and of geospatial information integration in particular, by providing a robust and scalable framework that encompasses techniques and algorithms for integrating heterogeneous data sources using an ontology-based approach.<br/><br/>This project's goal of semantic integration for geospatial data fits into a broad vision for creating a cyberinfrastructure on the Web. In a geospatial cyberinfrastructure, data will be automatically located and semantically matched to other relevant data sources. Manual intervention will not be needed or will be minimal. With such a structure, emergency managers, government officials, and the general public will not be constrained to pre-formulated queries. Instead, ad hoc, exploratory queries and analyses will be possible. From an educational viewpoint, the project will significantly benefit the training of graduate and undergraduate students, in particular of women and minorities, and will include the design of new graduate and undergraduate courses.<br/>"
1439052,XPS: FULL: DSD: Collaborative Research: Rapid Prototyping HPC Environment for Deep Learning,CCF,Exploiting Parallel&Scalabilty,8/1/2014,8/5/2014,Jack Dongarra,"Dongarra, J","Dongarra, J|Luszczek, P",TN,University of Tennessee Knoxville,Standard Grant,Vipin Chaudhary,7/31/2017,"$382,500.00 ",Piotr Luszczek,dongarra@icl.utk.edu,1 CIRCLE PARK,KNOXVILLE,TN,379960003,8659743466,CSE,8283,9150,$0.00 ,normalFunding,"The impact of Big Data is all around us and is enabling a plethora of commercial services. Further it is establishing the fourth paradigm of scientific investigation where discovery is based on mining data rather than from theories verified by observation. Big Data has established a new discipline (Data Science) with vibrant research activities across several areas of computer science. This ?Rapid Python Deep Learning Infrastructure? (RaPyDLI) project advances Deep Learning (DL) which is a novel exciting artificial intelligence approach to Big Data problems, which also involves a sophisticated model and a corresponding ?big compute? needing high end supercomputer architectures. DL has already seen success in areas like speech recognition, drug discovery and computer vision where self-driving cars are an early target. DL uses a very general unbiased way of analyzing large data sets inspired by the brain as a set of connected neurons. As with the brain, the artificial neurons learn from experience corresponding to a ?training dataset? and the ?trained network? can be used to make decisions. Trained on voices, the DL network can enhance voice recognition and trained on images, the DL network can recognize objects in the image. A recent study by the Stanford participants in this project trained 10 billion connections on 10 million images to recognize objects in an image. This study involved a dataset that was approximately 0.1% the size of data ?learnt? by an adult human in their lifetime and one billionth of the total digital data stored in the world today. Note the 1.5 billion images uploaded to social media sites every day emphasize the staggering size of big data. The project aims to enhance by DL by allowing it to use large supercomputers efficiently and by providing a convenient DL computing environment that enables rapid prototyping i.e. interactive experimentation with new algorithms. This will enable DL to be applied to much larger datasets such as those ?seen? by a human in their lifetime. The RaPyDLI partnership of Indiana University, University of Tennessee, and Stanford enables this with expertise in parallel computing algorithms and run times, big data, clouds, and DL itself.<br/>RaPyDLI will reach out to DL practitioners with workshops both to gather requirements for and feedback on its software. Further it will proactively reach out to under-represented communities with summer experiences and DL curriculum modules that include demonstrations built as ?Deep Learning as a Service?.<br/>RaPyDLI will be built as a set of open source modules that can be accessed from a Python user interface but executed interoperably in a C/C++ or Java environment on the largest supercomputers or clouds with interactive analysis and visualization. RaPyDLI will support GPU accelerators and Intel Phi coprocessors and a broad range of storage approaches including files, NoSQL, HDFS and databases. RaPyDLI will include benchmarks as well as software and will offer a repository so users can contribute the high level code for a range of neural networks with benefits to research and education."
1230187,SBIR Phase II: Artificial Intelligence Software to Tutor Literary Braille to the Blind and Visually Impaired,IIP,SMALL BUSINESS PHASE II,10/1/2012,4/2/2014,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Glenn H. Larsen,9/30/2014,"$382,028.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,5373,"5373, 8031, 8032, 8042",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase II project focuses on developing the first artificial intelligence (AI) educational software to tutor literary Braille to blind/visually impaired students. Braille is the primary medium for written communication for persons who are blind and there has been a dramatic decline in Braille literacy, negatively impacting academic performance, ability to navigate the everyday world and employment opportunities. The ability to bring proven effective AI technology to the table, which is unprecedented in this area of special education, will make a meaningful difference in providing equitable education opportunities to all students, as this project speaks directly to issues of basic literacy. The proposed intervention is an Internet-based adaptive learning system that provides expert instruction on demand during general and special education at school and at home. The software is supplemental to existing curricula, uses standard accessibility technology and integrates directly with existing lessons. In addition to improving learning outcomes for students, this project also includes support for mainstream teachers and teachers of the visually impaired (TVIs). To ensure the product is effective in real-world settings, ongoing formative evaluations with teachers/TVIs will be conducted and student outcomes will be measured during a year two field study.<br/><br/>The broader impact/commercial potential of this project will be the first-ever Braille education software based on AI, delivered on-demand through the Internet. The anticipated impact is that students achieve literacy and are able to perform at a higher level (e.g. academics, daily living, employment) resulting in improved quality of life and increased societal contributions. To have an impact, the product must be affordable, effective for a heterogeneous population in diverse learning environments, easy to use and easily accessed at convenient times and locations in informal and formal educational settings. In SBIR research supported by NIH, Quantum has successfully created the first-ever AI-based educational software that is accessible to the blind (in chemistry and mathematics). Furthermore, Quantum has patented and commercialized unique AI technologies in chemistry and accounting using a business-to-business licensing model that provides educational companies with first-to-market and strong sustainable advantages. This model engages the entire spectrum of educational vendors, offering breakthrough technology that permits increased market share for customers and rapid dissemination to end users. For this project, Quantum will partner with organizations with established channels, who distribute the software as an online service, such as the American Printing House for the Blind, a partner on this project."
1560478,Research Experience for Undergraduates in UAV Technologies,EEC,,8/1/2016,7/21/2016,Subodh Bhandari,"Bhandari, S","Bhandari, S|Tang, F",CA,"Cal Poly Pomona Foundation, Inc.",Standard Grant,Mary Poats,7/31/2019,"$380,001.00 ",Fang Tang,sbhandari@cpp.edu,"3801 West Temple, Bldg 55",Pomona,CA,917682557,9098692948,ENG,P226,"7736, 9250",$0.00 ,normalFunding,"This Research Experiences for Undergraduates (REU) Site program at California State Polytechnic University, Pomona (CPP), offers state-of-the-art, multi-disciplinary research experiences in unmanned aerial vehicles (UAV) technologies, engineering, and computer science to diverse and talented cohorts of undergraduates, particularly women and Hispanic students, from 2 and 4 year institutions with limited or no research opportunities. UAV's have the potential of replacing manned aircraft for dull, dirty, and dangerous missions. In addition, UAV's are less expensive than manned aircraft and pose no risk to human operators. Military applications include intelligence, surveillance, and reconnaissance (ISR), battlefield damage assessment, and force protection.  Civilian applications include remote sensing, scientific research, search and rescue missions, border patrol, surveillance of disaster-affected areas, aerial photography, aerial mapping for geotechnical survey, vegetation growth analysis, crop dusting, and precision agriculture.  The UAV industry is the fastest growing sector of the aerospace industry.  However, there is a lack of professionals entering the workforce for UAV related jobs.  This REU program is designed to increase students' interest in UAV technologies by means of first-hand experience on UAV research with direct mentorship by faculty advisors from various departments within the CPP Colleges of Engineering and Science.  <br/><br/>This REU Site offers undergraduates, in collaboration with CPP faculty and graduate students, opportunities to conduct research during a 10-week summer program, on state-of-the-art technologies and advanced research projects in UAV flight dynamic and control, computer vision, artificial intelligence, embedded systems, and robotics. In addition to their research, students will participate in weekly research seminars, research meetings, and professional development seminars. The seminars will include topics such as literature review, writing a scientific paper, improving written and oral communication skills, technical presentations, graduate education, career paths, resume building, and ethics in science and engineering. The 10-week program will also include outreach activity. The students will give presentations on UAV technologies, engineering, and computer science to K-12 students at local schools. This will enhance students' communication skills, allow them to see the broader implications of their research, and see how they can positively impact society through research. The discoveries made during these collaborations will be communicated to the broader scientific community via publications and presentations. <br/><br/>This site is supported by the Department of Defense in partnership with the NSF REU program."
1124651,Collaborative Research:   CDI Type-1: A Computer Framework for Modeling Complex Pattern Formation,EF,CDI TYPE I,9/1/2011,9/12/2011,Michael Levin,"Levin, M","Levin, M",MA,Tufts University,Standard Grant,James O. Deshler,8/31/2014,"$380,000.00 ",,michael.levin@tufts.edu,136 Harrison Ave,Boston,MA,21111817,6176273696,BIO,7750,"7721, 7722",$0.00 ,normalFunding,"The mechanisms living systems use to establish and maintain complex 3-dimensional shapes during embryonic development are poorly understood even though molecular and cell biologists have generated mountains of data about genes and their effects on organisms. Fundamental advances in controlling biological form are stymied by the difficulty of obtaining shape information through the analysis of gene networks such that it is currently difficult or impossible for scientists to generate testable models of shape based on experimental results from current biological research. These investigators will apply state-of-the-art computational science and artificial intelligence to create a novel suite of computational tools that will fundamentally integrate numerous areas of biology and engineering to promote research into the mechanisms used by organisms for establishing and maintaining their 3-dimensional shape. This ""Bioinformatics of Shape"" project will integrate experimental data, a new mathematical language, a system for storing and mining data, a modeling environment within which rule sets for regulatory mechanisms can be simulated on computers, and an artificial intelligence module that will help scientists discover and test novel ideas about how shape is generated through genetics. The benefits to society of this new kind of collaboration between computer scientists and biologists include the translation of molecular and cell biological data into a new level of understanding that could have implications for regenerative medicine, adaptive and self-repairing devices for robotics and other engineering applications. The work will provide unique training opportunities for students, establish a proof-of-principle for new educational tools at the boundary between artificial intelligence and biology, and facilitate data to knowledge production in a number of fields, such as developmental biology, evolutionary biology, and the engineering of complex adaptive systems."
93841,CAREER: Knowledge Discovery in Databases and Data Mining as New Tools to Support Research and Educational Advances in Modern Construction Management,CMMI,CIVIL INFRASTRUCTURE SYSTEMS,6/1/2001,7/17/2003,Lucio Soibelman,"Soibelman, L","Soibelman, L",IL,University of Illinois at Urbana-Champaign,Standard Grant,,8/31/2006,"$379,979.00 ",,lucio@andrew.cmu.edu,1901 South First Street,Champaign,IL,618207406,2173332187,ENG,1631,"1039, 1045, 1057, 9102, 9251, CVIS",$0.00 ,normalFunding,"ABSTRACT CMS0094022 ""Knowledge Discovery in Databases and Data Mining as New tools to Support Research and Educational Advances in Modern Construction Management "" PI: Lucio Soibelman, University of Illinois at Urbana-Champaign<br/><br/>The construction industry is seeing an explosive growth in its capabilities to both generate and collect data. Advances in scientific data collection, the introduction of bar codes for almost all-commercial products, new sensor technologies, wireless computing, and new laser scanning technologies, have generated a flood of data. These advances coupled with advances in data storage technology, such as faster, higher capacity, and cheaper storage devices, better database management systems, and data warehousing technology, have increased the availability of computerized construction data. However, in most cases, these data are used only for communication purposes and stored in a file or a database without being analyzed. This project intends to study this increasing amount of available data by applying data mining and knowledge discovery in databases. Knowledge discovery in databases and data mining are technologies that combine techniques from machine learning, artificial intelligence, pattern recognition, statistics, databases and visualization to automatically extract concepts, concepts interrelationships, and patterns of interest from large databases. <br/>The objectives of this CAREER program are to: 1) Generate improved methods to obtain novel knowledge from large construction databases developing model-building templates and wizards to guide novice construction knowledge model builders through the process of creating models based on their own data; 2) Improve access to past construction management experience and knowledge by practitioners and students; 3) Use active learning techniques to improve education of students at all levels by developing an educational simulation game with the knowledge generated during this research; and 4) Teach civil and environmental engineering graduate students the process of knowledge generation through the application and development of data mining, machine learning and artificial intelligence tools.<br/>Given the importance of the construction industry in the U.S economy and the large amount of money wasted in litigation due to project delays, impractical budgets, and projects that neither satisfy quality requirements nor meet performance expectations, improved management tools are critically needed. This research promises to result in valuable management tools for improving project planning and control, which, if applied to large-scale infrastructure projects, may result in substantial cost savings nationwide. These research benefits can be extended to all sub-fields of construction management<br/>"
9752204,Teaching Scientific Reasoning Skills in Physics: Students and Computers Coaching Each Other,DUE,DUE COURSE & CURRICULUM PROG,7/1/1998,5/29/1998,Frederick Reif,"Reif, F","Reif, F|Larkin, J",PA,Carnegie-Mellon University,Standard Grant,Duncan E. McBride,6/30/2001,"$377,811.00 ",Jill Larkin,freif@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,EHR,7410,"1338, 7419, 9178, SMET",$0.00 ,normalFunding,"Students in science courses often receive far too little guidance to allow reliable learning of needed reasoning skills. As a result, many students fail to acquire flexibly usable scientific knowledge (even with modern well-designed instruction and materials). Furthermore, students often lack some basic cognitive abilities needed for complex intellectual tasks (e.g., making well-considered decisions or adequately assessing their own performance). The goals of this project are to improve science instruction by the following approach: 1. Use cognitive analyses to specify the procedural knowledge needed for effectively applying scientific concepts or principles and for solving problems. 2. Help students learn such procedural knowledge, teach them explicitly the basic cognitive functions of deciding on an action, implementing it, and assessing the result. 3. Do this by adapting a ""reciprocal-teaching strategy"" (very effective in teaching reading) where a student and tutor trade roles, alternately (a) deciding and assessing or (b) implementing. 4. Develop novel computer programs (""PALs"", i.e., Personal Assistants for Learning) that can play the role of the tutor--so that students and computers coach each other. Such PALs, which involve careful instructional design but no artificial intelligence, can provide every student with good individual guidance and feedback. (Preliminary experiments suggest that such PALs might achieve instructional effectiveness approaching that of expert human tutors.) This work is expected to lead to the following results: 1. Production of PALs of demonstrated instructional efficacy and utility in basic physics. 2. Effective methods for developing PALs, in physics as well as in other domains. 3. Increased understanding of relevant cognitive and human-computer interaction processes."
830450,Justification Logic and Applications,CCF,THEORY OF COMPUTING,9/1/2008,8/26/2008,Sergei Artemov,"Artemov, S","Artemov, S|Nogina, E|Fitting, M",NY,CUNY Graduate School University Center,Standard Grant,Dmitry Maslov,8/31/2011,"$374,996.00 ","Elena Nogina, Melvin Fitting",sartemov@gc.cuny.edu,365 Fifth Avenue,New York,NY,100164309,2128177523,CSE,2860,"9218, HPCC",$0.00 ,normalFunding,"Artemov, Fitting, and Nogina will continue their development of Justification Logic, which offers a possible breakthrough in the quest to create a fundamental theory of knowledge, belief, and evidence, and has the potential for significant impact on applications. The celebrated account of knowledge as ""justified true belief,"" which is attributed to Plato, has long been a focus of epistemic studies. About a half-century ago, the notions of knowledge and belief acquired formalization by means of modal logic. However the notion of justification, an essential element of epistemic studies, was conspicuously absent, and this led to well-known deficiencies inherent in modal logics of knowledge.<br/><br/>Justification Logic extends the logic of knowledge in three major ways. First, it adds a long-anticipated mathematical notion of justification, making the logic more expressive. We now have the capacity to reason about justifications, simple and compound. We can compare different pieces of evidence pertaining to the same fact. We can measure the complexity of justifications, thus connecting the logic of knowledge to a rich complexity theory, etc. Second, justification logic furnishes a new, evidence-based foundation for the logic of knowledge, according to which `F is known' is interpreted as `F has an adequate justification.' Third, justification logic provides a novel, evidence-based mechanism of truth tracking which can be a valuable tool for extracting robust justifications from a larger body of justifications which are not necessarily reliable.<br/><br/>Knowledge, belief, and evidence are fundamental concepts whose significance spans many areas of human activity: computer science and artificial intelligence, mathematics, economics and game theory, cryptography, philosophy, and other disciplines. Justification Logic promises significant impact on the aforementioned areas. In particular, the capacity to keep track of pieces of evidence, compare them, and select those that are appropriate would be a valuable new tool."
9813654,Learning with Distributed Instruction,DUE,LEARNING & INTELLIGENT SYSTEMS,9/15/1998,10/18/2000,Beverly Woolf,"Woolf, B","Woolf, B|Clement, J|Day, R|Poli, C|Adrion, WR",MA,University of Massachusetts Amherst,Standard Grant,Herbert Levitan,8/31/2001,"$373,800.00 ","John Clement, Roberta Day, Corrado Poli, W Richards Adrion",bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,EHR,8888,"7419, 8888, 9178, SMET",$0.00 ,normalFunding,"This research is intended to identify appropriate roles for technology, assessed in part in the context of open, inquiry-oriented learning.  We will<br/>*quantify the cost-effectiveness of instructional technology, looking at several web-based, intelligent systems with large user bases for empirical studies,<br/>*evaluate the impact on student's learning while using these systems, and<br/>*identify and build key component technologies that will allow others to construct cost-effective instructional applications.<br/><br/>Major research questions include: how can technology be used effectively, and just how effective are these uses?  Are these uses cost-effective?  Our group has worked with educators for a decade and has built four large web-based systems used by thousands of students.  We will examine existing and on-going conversions to intelligent, web-based systems and look for economies of scale that will help to reduce development costs.<br/><br/>Careful evaluation studies are also key.  Solid evidence is required about student learning and pedagogical effectiveness.  We need to accommodate students with varied backgrounds, motivations and educational goals.  Empirical evidence is necessary to confirm individual student outcomes using these systems and support continuous systems refinement based on the evidence collected.  This research will include qualitative and quantitative measures as a means of providing moth meaningful, action-oriented feedback and rich documentation of the project and its accomplishments.  Through careful studies of existing and emerging systems we will quantify their impact on learning effects and working with affiliates in other universities, will demonstrate that these systems will be of general use on a national scale.<br/><br/>Component software promises to reduce cost by encouraging software reuse.  However the obvious benefits of software reuse have not been realized.  In this project, we will develop reusable components for creating web-based homework, lecture and tutoring systems.  We will assemble components of existing systems into larger pieces (e.g. connecting the web-based lecture system with a homework and tutoring system).  This component assembly process will drive development of reusable component technologies.<br/>"
1716333,RI: Small: Algorithmic Mechanism Design for Multi-Type Resource Allocation,IIS,ROBUST INTELLIGENCE,8/15/2017,7/27/2017,Lirong Xia,"Xia, L","Xia, L",NY,Rensselaer Polytechnic Institute,Standard Grant,James Donlon,7/31/2020,"$373,536.00 ",,xial@cs.rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Allocating indivisible items to multiple agents without monetary transfer is a pressing problem in our society. In many situations, items are categorized into multiple types and each agent must get at least one item per type. Such problems are called multi-type resource allocation (MTRA). For example, MTRA arises in allocating courses to students, allocating computational resources to users in cloud computing, allocating medical resources to patients, as well as in multi-type exchange market and centralized welfare programs that involve multiple sub-programs. Unfortunately, most previous research overlook information regarding resource type, and are thus hindered by three barriers: preference bottleneck, computational bottleneck, and threats of agents' strategic behavior. The project aims at establishing theoretical and algorithmic foundations of mechanism design for MTRA with the help of Artificial Intelligence. The newly designed mechanisms will improve the economic efficiency and computational efficiency of resource allocation in multiagent systems, socio-economics systems, and operations research.<br/><br/>In doing so, the researcher will design and evaluate novel graphical languages to address the preference bottleneck; design novel frameworks for discovering new mechanisms, including sequential allocation mechanisms and extensions of the top-trading-cycles mechanism, to address the computational bottleneck; use game theory to analyze and measure agents' strategic behavior; and use high computational complexity to prevent agents' strategic behavior. Outcomes of the research will be integrated into an open-source Online Preference Reporting and Aggregation (OPRA) system, which serves as a platform to bridge theory, practice, and education."
114598,GOALI:  Principle-Based Knowledge Management System for Cellular Manufacturing,CMMI,"PRODUCTION SYSTEMS, GRANT OPP FOR ACAD LIA W/INDUS, MANFG ENTERPRISE SYSTEMS",10/1/2001,7/10/2003,Wallace Hopp,"Hopp, W","Hopp, W|Tirpak, T|Birnbaum, L|Iravani, SMR",IL,Northwestern University,Standard Grant,Abhijit V. Deshmukh,9/30/2005,"$372,000.00 ","Thomas Tirpak, Larry Birnbaum, Seyed M. R. Iravani",whopp@umich.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,ENG,"1465, 1504, 1786","1049, 1504, 9147, 9251, MANU",$0.00 ,normalFunding,"This research project has two thrusts.  First, the research aims to  develop a set of benchmarking and diagnostic modes based on queuing, material flow, and stochastic optimization models for generic manufacturing cells.  These will be used to evaluate the current performance of a system relative to both external (industry) and internal (theoretical) standards.  Second, the  research will use models to classify improvement areas into broad categories and use these to develop a fundamentally new framework for organizing experiential information related to the design and improvement of cellular production systems.  The ultimate goal is to create a prototype web-based knowledge management tool that will diagnose problems, suggest improvement options, and accumulate and classify information for future shared use by the organization.  In theory, modern information technology makes it possible to place information previously available only to experts in the hands of users throughout the firm.  But converting data to useful information presumes an ability to capture, organize, and link knowledge to the practical concerns of decision-makers.  Evolving methods of artificial intelligence provide exciting new ways to search and retrieve text-based information, based largely on matching documents to user interests on the basis of keywords.  However, such an approach is not entirely suited to many production environments because users do not necessarily know what keywords they should be interested in to find help with their problems.  What is needed is a more proactive system for diagnosing problems and leading users to relevant information.  <br/><br/>The need for knowledge creation and sharing systems is becoming even more crucial as manufacturing systems emphasize highly customized products and quick response to customer demands.  Agile manufacturing relies on production in small scale, often modular, flexible manufacturing cells that use multi-functional machinery and cross-trained workers.  While there has been some recent modeling research into the design and control of agile manufacturing systems, almost nothing has been done on linking models to the information needs of managers trying to evaluate and improve their systems.  This research will develop models of cellular systems and use them to establish a framework for organizing information in a knowledge management system to support the process of continual improvement in agile manufacturing systems<br/>"
92308,CAREER: Assisted Navigation in Large Visualization Spaces,CCF,"ADVANCED COMP RESEARCH PROGRAM, GRAPHICS & VISUALIZATION",2/1/2001,1/24/2007,Christopher Healey,"Healey, C","Healey, C",NC,North Carolina State University,Continuing grant,Lawrence Rosenblum,1/31/2008,"$370,403.00 ",,healey@ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,"4080, 7453","1045, 9216, HPCC",$0.00 ,normalFunding,"This project is an investigation of methods for assisting with the navigation of large, complex<br/>information spaces. Although results from these studies are relevant to a number of research areas, interest will be focused on construction of a navigation system designed to help viewers visualize,<br/>explore, and analyze large, multidimensional datasets. Methods to assist with the analysis and navigation of these types of datasets was specifically cited as an<br/>important open problem by the joint DOE/NSF panel on future research in visualization.<br/><br/>The work will combine a detailed local display and a high-level global overview of the locations and structure of areas of interest within the dataset. The local view will use perceptual cues to harness the abilities of the low-level human visual system. The global overview will be built in two separate stages. First, elements of interest will be identified using a combination of: (1) explicit rules provided by the viewer, and (2) implicit rules built by watching what viewers select, where they move, and what they examine. Next, the elements will be clustered into one or more areas of interest. The use of graph construction techniques like planar triangulations and minimum spanning trees will be investigated to link the elements together. An underlying graph that: (1) supports efficient navigation via the application of graph traversal algorithms, and (2) provides an effective global overview to visualize the areas of interest and the relationships that exist between them will be sought.<br/><br/>A set of validation experiments will be designed to identify the strengths and limitations of our navigation<br/>techniques. Datasets from the oceanography and e-commerce domains will be used to test the system in a<br/>practical, real-world environment. The first set of experiments will work with domain experts, in part to provide anecdotal feedback on our system, and in part to identify fundamental navigation and exploration tasks performed during visualization. These tasks will then be integrated into a controlled experiment that studies the performance of our system vis-a-vis a system without navigation aids, and existing focus+context visualization techniques specifically designed to display these types of large, complex datasets.<br/><br/>The research in visualization, navigation, perception, and automated inference of viewer<br/>preferences provides a unique opportunity to design a multidisciplinary course curriculum that includes instruction in computer graphics and scientific visualization, cognitive psychology, and a variety of real-world application areas.<br/><br/>The education plan includes the construction of an instructional visualization laboratory, the identification of collaborators from academia and industry, the design of a self-contained course curriculum, and the creation of a collection of real-world visualization projects to encourage student participation in our research programs. The laboratory will include state-of-the-art graphics workstations, as well as visualization-specific hardware and software.The priority is to expose students to emerging<br/>research issues and real-world visualization problems. This will be accomplished in part by building course projects that introduce students to active research programs, both in our visualization laboratory and in academic and industrial research centers located on our campus.The curriculum will instruct students in areas of cognitive and perceptual psychology that impact scientific visualization, computer graphics, computer vision, and artificial intelligence.<br/><br/>The result will be a collection of courses that introduce students of psychology, egineering, natural science and other disciplines to both the theoretical and practical issues of perception and assisted computation techniques, and their relationship to scientific visualization and computer graphics."
938964,CPATH-1: Revitalizing Computing Education through Community-Based Video Game Development Projects,CNS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, CPATH",9/1/2009,4/17/2012,David Turner,"Turner, D","Turner, D|Yu, TL|Concepcion, A",CA,University Enterprises Corporation at CSUSB,Continuing grant,Harriet G. Taylor,8/31/2012,"$370,256.00 ","Tong Lai Yu, Arturo Concepcion",dturner@csusb.edu,5500 University Parkway,San Bernardino,CA,924072397,9095375929,CSE,"1640, 1714, 7640","7218, 7640, 9178, 9218, 9251, HPCC",$0.00 ,normalFunding,"This CPATH project uses free open source libraries and tools for a student-centered,community-based video game development project called Mythic for the purpose of revitalizing interest in computing studies. The Mythic project is student centered in the sense that students define project goals, and it is community-based in the sense that students from different institutions, ranging from high school to community college to university, contribute to the development of a common project. The project promises to help revitalize computing education by engaging students in meaningful and enjoyable work activities that lead to greater mastery of computing concepts through the use of software development tools, the use of software libraries, and the use of computing concepts. Project investigators are also establishing internships with local game development companies to increase the relevance to students and assist faculty in aligning learning outcomes to meet the needs of industry.<br/><br/>The intellectual merit lies in the strong collaborative team with significant experience in game development and building real software in class settings. The project has an excellent conceptual foundation that could lead to new research findings in both video game development as well as in computing education.<br/><br/>The broader impacts involve the potential to attract a more diverse student population to computing fields.  Students from the local community who go into the video game industry will serve as role models for younger students at the high school and college levels. Similarly, students going into computing jobs outside the video game industry will also demonstrate to younger students as well as their parents and teachers that focusing on video game development when young can result in the development of skills needed for rewarding careers later in life. Black and Hispanic students account for more than 50% of enrollments at the lead institution. Thus, the project helps to broaden the participation of these underrepresented groups in pursuing degrees in computing disciplines. The associated learning materials that are produced can serve as a resource for other institutions and as a foundation for collaborative research. This project activity should demonstrate to other departments and institutions the value of student-centered, community-based video game development projects to cultivate interest in and mastery of computational thinking in students from high school through university."
350584,Incremental Heuristic Search,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/15/2003,9/13/2007,Sven Koenig,"Koenig, S","Koenig, S",CA,University of Southern California,Continuing grant,Douglas H. Fisher,8/31/2008,"$368,933.00 ",,skoenig@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"This project will develop incremental heuristic search methods, study their properties analytically and experimentally, and demonstrate their applicability and advantages for different artificial intelligence applications, including symbolic planning problems, reinforcement-learning problems, and control problems.  Heuristic search methods are widely used in artificial intelligence. They find shortest paths for graph search problems much faster than uninformed search methods. Incremental search methods, on the other hand, are almost unknown in artificial intelligence. They find shortest paths for series of similar graph search problems much faster than is possible by solving each graph search problem from scratch.  Incremental heuristic search methods have four advantageous properties:<br/><br/>1. Incremental heuristic search techniques speed up replanning substantially since they combine two different principles for speeding up the search. They can speed up replanning by one to two orders of magnitude compared to replanning from scratch. This is important because replanning problems are often time critical and have large state spaces.<br/><br/>2. The quality of the plans that result from replanning with incremental heuristic search techniques is as good as the quality of the plans that result from planning from scratch. This property is an important difference to many conventional replanning methods (such as case-based planning, planning by analogy, plan adaptation, transformational planning, planning by solution replay, and repair-based planning) that usually cannot make guarantees about the resulting plan quality.<br/><br/>3.  Incremental heuristic search techniques are very versatile and apply, for example, to symbolic planning problems, path-planning problems, reinforcement-learning problems, and control problems.<br/><br/>4.  Heuristic incremental search techniques have a solid theoretical foundation and thus well-understood properties. Their simplicity allows one to prove a number of properties about them, including their termination, correctness, efficiency, and similarity to A*, which makes them easy to understand, easy to analyze, easy to program, easy to optimize for efficiency, and easy to extend. Incremental heuristic search methods have the potential to improve a variety of artificial intelligence applications, that might, for example, result in decision-support systems with smaller response times but higher quality plans than is possible today, in crisis situations such as marine oil spills. <br/><br/>The research results will be made available to a broad audience by presenting them at conferences, on web pages, and via tutorials. The project will improve the education of graduate students, undergraduate students, high-school students, and minority students (mostly by volunteering for educational activities).  For example, interested undergraduate students will be very actively involved in the research. <br/>"
1736185,EXP: Collaborative Research: Empowering Learners to Conduct Experiments,IIS,"IUSE, Cyberlearn & Future Learn Tech",9/1/2017,3/30/2018,Casper Harteveld,"Harteveld, C","Harteveld, C|Smith, G",MA,Northeastern University,Standard Grant,William Bainbridge,8/31/2019,"$367,662.00 ",Gillian Smith,c.harteveld@neu.edu,360 HUNTINGTON AVE,BOSTON,MA,21155005,6173733004,CSE,"1998, 8020","8045, 8209, 8841, 9178",$0.00 ,normalFunding,"This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
1456221,Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod,IOS,ANIMAL BEHAVIOR,8/1/2015,7/24/2015,Wulfila Gronenberg,"Gronenberg, W","Gronenberg, W",AZ,University of Arizona,Standard Grant,Michelle M. Elekonich,7/31/2019,"$365,000.00 ",,wulfi@neurobio.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,BIO,7659,"7659, 9179",$0.00 ,normalFunding,"The ability of animals to navigate through their environment often far exceeds human capabilities (without the help of technology). Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night over distances exceeding 10 meters through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning, memory and associated behavior. To support engagement with K-12 students, their teachers and the general public, researchers will, among other activities, develop internet-based educational materials in both English and Spanish and develop various scientific inquiry activities for science events. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after they are displaced from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as the ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely be crucial for the design of any sophisticated artificial system. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
9813259,Computing Purposes of Geometric Features,CMMI,ENGINEERING DESIGN AND INNOVAT,9/1/1998,1/15/1999,Thomas Stahovich,"Stahovich, T","Stahovich, T|Heckbert, P",PA,Carnegie-Mellon University,Standard Grant,Delcie R. Durham,8/31/2002,"$364,866.00 ",Paul Heckbert,stahov@engr.ucr.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,ENG,1464,"9148, MANU, 9178, 9251",$0.00 ,normalFunding,"This grant provides funding for research that will result in techniques for automatically computing the purposes of the geometric features on the parts of a mechanical device. These purposes serve as a form of design documentation. This work will employ a combination of techniques from computer graphics, artificial intelligence, and mechanical engineering. The first step in the process is identifying the features on a part. This will be accomplished by creating new model simplification algorithms. These algorithms will remove the small geometric details (protrusions, cavities, etc.) from a part to reveal the simple underlying geometry. Subtracting this simplified geometry from the original geometry will reveal the set of features. To explain the purpose of a particular feature, a simulation of the device with the feature removed will be compared to a simulation of the original device. The differences in the simulations indicate which of the device's many behaviors are produced by that feature. Causal reasoning techniques will then be used to construct an explanation for how the feature causes its behaviors. These explanations, which constitute one of the purposes of the feature, will be automatically translated into natural language (English) and will then be incorporated into the device's documentation. If successful, the results of this research will lead to advanced design documentation tools which will increase the scope and completeness of design documentation while at the same time reducing the cost of producing documentation. The particular kind of rationales computed by this approach (the purposes of features) will facilitate a variety of common engineering tasks including coordinating collaborative design and enabling product redesign without creating unintended side-effects, thereby reducing design cost. Furthermore, if successful, this research will produce fundamental advances in model simplification and causal reasoning."
1409549,RI: Medium: Collaborative Research: Experience-Based Planning: A Framework for Lifelong Planning,IIS,"ROBUST INTELLIGENCE, National Robotics Initiative",8/1/2014,6/20/2016,Maxim Likhachev,"Likhachev, M","Likhachev, M",PA,Carnegie-Mellon University,Standard Grant,James Donlon,7/31/2018,"$363,995.00 ",,maxim@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7495, 8013","7495, 7924, 9251",$0.00 ,normalFunding,"Robots need to improve their behavior over time, yet produce consistent behavior in order to allow humans to predict their actions, which is necessary to develop trust in their behavior or even cooperate with them. Furthermore, many tasks repeat, such as opening drawers. This project develops technology that addresses these issues by viewing planning as a lifelong process and exploiting the structure of human environments for efficiency, for example that drawers typically open in similar ways.<br/><br/>This research collaboration is developing a framework for lifelong planning based on experience graphs that aims to improve performance of planning over time by exploiting past experiences when solving similar planning tasks. The concept is novel because experiences are used to guide the heuristic search as opposed to be used for mere replay or adaptation. The idea that makes this possible is a novel heuristic search-based framework that can take advantage of prior experiences and still provide rigorous guarantees on completeness and path quality. The team studies how experiences can be utilized effectively during planning, how planning should gather experiences, how it should prune redundant experiences and how it can obtain experiences from demonstrations. Applications include everyday household tasks and low-volume manufacturing tasks. The software developed in this collaborative research is being integrated into the SBPL library, one of the core libraries in ROS. The project also incorporates educational activities as well as activities that help to bridge the research communities in robotics and artificial intelligence, two separate communities despite their common interest in autonomous systems."
1701565,Exploiting Metal-Insulator-Transition in Strongly Correlated Oxides as Neuron Device for Neuro-Inspired Computing,ECCS,"ELECT, PHOTONICS, & MAG DEVICE",8/1/2017,5/1/2017,Shimeng Yu,"Yu, S","Yu, S",AZ,Arizona State University,Standard Grant,Dimitris Pavlidis,7/31/2020,"$360,000.00 ",,shimeng.yu@ece.gatech.edu,ORSPA,TEMPE,AZ,852816011,4809655479,ENG,1517,100E,$0.00 ,normalFunding,"A radical shift in computing paradigm towards the neuro-inspired computing is attractive for performing data-intensive applications such as image/speech recognitions. The neuro-inspired architecture leverages the distributed computation in the neuron nodes and the localized storage in the synaptic elements. The neuron node today is generally implemented by tens of silicon transistors. Compared to the crossbar array of synaptic elements, the silicon neuron is power-hungry and area-inefficient, thereby reducing the parallelism of computing system. In such context, how to design a single device that can efficiently emulate the neuronal behavior (e.g. integrate-and-fire) is critical to the neuromorphic hardware design. This project aims to exploit the metal-insulator-transition phenomenon in strongly correlated oxides as a compact neuron node that can self-oscillate, namely oxide neuron, to overcome the aforementioned limitations of silicon neuron. The proposed research will have a profound impact on the society that is embracing the artificial intelligence. For instance, a compact design of neuromorphic hardware may enable intelligent information processing on power-efficient mobile platforms, e.g. autonomous vehicle, personalized healthcare, wearable devices, and smart sensors. The objective of the research and education integration is to train undergraduate/graduate students and next-generation workforce with interdisciplinary skills. The cross-layer nature of this project ranging from materials engineering, semiconductor device, circuit-device interaction and artificial neural network provides an ideal platform for this educational goal. The project also plans to engage minority and unrepresentative students in research. Technology transfer will be performed through video or on-site seminars and student internships with industrial collaborators.<br/><br/><br/>The goal of this research is to advance the artificial neuron device design by exploiting the volatile and threshold switching behavior in strongly correlated oxides, with the purpose of significantly reducing the area and energy of the neuron node, and making it compatible for the integration with crossbar array of resistive synaptic elements. The scope of the project is to explore various material systems of the strongly correlated oxides, in particular, NbO2 and SmNiO3 to demonstrate the self-oscillation behavior in the artificial neuron node. When such oxide device is connected with a series synaptic element whose resistance is within the on/off dynamic range of the oxide device, the node voltage between the oxide device and the synaptic element will start self-oscillation, and the oscillation frequency represents the synaptic conductance. This project aims to explore such self-oscillation to emulate the integrate-and-fire neuronal behavior. To achieve the aforementioned research goal, device fabrication, physical and electrical characterization, device modeling, and circuit-device co-design will be performed to demonstrate the feasibility of the concept and further optimize the device performance. The intellectual significance of this project is two folded. From the fundamental science perspective, the physical switching mechanism of metal-insulator-transition in strongly correlated oxides will be investigated. From the applied engineering perspective, the oxide neuron device will be integrated with the resistive crossbar array for demonstration of a neural network for solving a practical problem, i.e. the image pattern classification."
1350008,CAREER: Teaching Machines to Design Self-Assembling Materials,DMR,CONDENSED MATTER & MAT THEORY,6/1/2014,3/23/2017,Andrew Ferguson,"Ferguson, A","Ferguson, A",IL,University of Illinois at Urbana-Champaign,Continuing grant,Daryl W. Hess,8/31/2018,"$360,000.00 ",,andrewferguson@uchicago.edu,1901 South First Street,Champaign,IL,618207406,2173332187,MPS,1765,"1045, 8400, 9216",$0.00 ,normalFunding,"TECHNICAL SUMMARY<br/><br/>This CAREER award supports theoretical and computational research and education in the understanding and design of self-assembling biomaterials. Self-assembly of structured aggregates by the spontaneous organization of their constituent building blocks is prevalent in the natural world, and is an attractive route to fabricate artificial materials with desirable properties that cannot be easily produced by other means. The design of building blocks programmed to self-assemble custom materials is a grand challenge in materials science.<br/><br/>In this work, the PI will integrate statistical mechanics theory with nonlinear machine learning algorithms to establish a new theoretical and computational approach to understand and program the self-assembly of nanostructured biomaterials. Using these tools, the PI will extract from molecular simulations the pathways and mechanisms by which building blocks self-assemble into structured aggregates. This methodology overcomes a key scientific challenge by integrating thermodynamics and kinetics in a unified framework that identifies both what stable aggregates form (thermodynamics) and how they assemble (kinetics and mechanisms). <br/><br/>The collective order parameters unveiled by this approach are good descriptors of the slow dynamical motions driving assembly, and present a natural parameterization for kinetically meaningful free energy landscapes that link building block properties to collective assembly behavior. By ""sculpting"" the landscape topography through rational manipulation of building block structure and chemistry the PI's group will program the assembly of desired structures that are thermodynamically stable and kinetically accessible (design).<br/><br/>The PI will apply a new approach to three technologically important self-assembling biomaterials: 1) ""patchy colloid"" polyhedral clusters for small molecule encapsulation, 2) ultra-short peptide mineralization templates for silica nanotubes for controlled drug release, heavy metal ion adsorption, and catalysis, and 3) antimicrobial peptide amphiphile nanostructures for antibiotic resistant bacteria. This work will establish new basic understanding and control of materials assembly, and accelerate development of new structural and functional biomaterials. <br/><br/>The integrated education and outreach plan incorporates the scientific outcomes into education and outreach, and supports graduate training, undergraduate research, and mentoring of underrepresented minority groups. The PI will create a new materials science course to equip the next generation workforce with computational tools, support undergraduate students in performing portions of the work, and promote the recruitment, retention, and success of students of color through mentorship of minority students and high school outreach.<br/><br/>NONTECHNICAL SUMMARY<br/><br/>This CAREER award supports a theoretical and computational research program to design microscopic building blocks with the ability to spontaneously self-organize into materials with desirable properties. This way of making materials is known as ""bottom-up self-assembly"", as opposed to more familiar ""top-down"" manufacturing. Imagine if it will be possible one day to design molecules with just the right shape and properties so that shaking them in a flask spontaneously self-assembled a solar cell! In this work, the PI will combine ideas from the fields of thermodynamics and machine learning (sometimes known as artificial intelligence) to establish a new tool to allow computers to learn both what structures can be formed by a particular building block, and how they assemble. The PI will then flip this problem to use our tool to help reverse-engineer building blocks to assemble custom materials. <br/><br/>The PI's group will apply these tools to the design of three useful biological materials: 1) micron-sized particles possessing directional sticky patches that assemble polyhedral clusters to hold and deliver small molecules, 2) short peptides that assemble networks to template the synthesis of silica nanotubes for drug delivery, cleanup of heavy metal pollutants, and catalysis of chemical reactions, and 3) longer peptides that assemble into nanometer sized rods that can kill antibiotic resistant bacteria such as the MRSA ""superbug"".<br/><br/>This award also supports an integrated research and education program in which the scientific results from this work will enrich and enhance undergraduate and graduate classes, and high school outreach activities. Undergraduate students will directly participate in the scientific research by working with the PI during the summer months. The PI will also design and teach a new class providing hands-on experience in the computational materials modeling, analysis, and design, and maintain his commitment to promote the recruitment and success of students of color through mentorship of undergraduate and graduate minority students."
1733686,AitF: Collaborative Research: Efficient High-Dimensional Integration using Error-Correcting Codes,CCF,Algorithms in the Field,9/1/2017,8/11/2017,Stefano Ermon,"Ermon, S","Ermon, S",CA,Stanford University,Standard Grant,Tracy J. Kimbrel,8/31/2021,"$360,000.00 ",,ermon@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7239,,$0.00 ,normalFunding,"Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br/><br/>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory."
1335137,"GOALI: Improving Blood Collection, Production, and Inventory Operations",CMMI,"GRANT OPP FOR ACAD LIA W/INDUS, MANFG ENTERPRISE SYSTEMS, OPERATIONS RESEARCH",5/15/2014,8/16/2013,Turgay Ayer,"Ayer, T","Ayer, T|White, C|DeShane, J|Ozkaynak, Z",GA,Georgia Tech Research Corporation,Standard Grant,Georgia-Ann Klutke,4/30/2017,"$360,000.00 ","Chelsea White, John DeShane, Zeynep Ozkaynak",turgay.ayer@isye.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,ENG,"1504, 1786, 5514","071E, 1504, 1786, 5514, 9147, MANU",$0.00 ,normalFunding,"The objectives of this Grant Opportunity for Academic Liaison with Industry (GOALI) award are: (1) to develop and analyze mathematical and computational models of key elements of the blood products collection, production, and inventory system at a large regional level in order to improve the overall system performance and (2) to advance the state of knowledge in the analysis of these models. The methods that will be used and extended include: completely observed and partially observed Markov decision processes (MDPs) and Markov games, chance constrained MDPs, artificial intelligence-based heuristic search algorithms, mathematical programming, exact and approximate dynamic programming, and stochastic programming.  In collaboration with the American Red Cross (ARC), a comprehensive decision support system (DSS) based on proposed models and algorithms will be built. The outcomes of this DSS will be tested for validation in real collection, production, and inventory environments at the ARC production facility, and at hospitals and blood banks in the region.<br/><br/>This research is intended to directly impact the quality of delivery in 120 regional hospitals and health facilities and hence can potentially affect millions of people in the Southeast United States. If successful, this research will lead to a more cost-effective blood products collection, production, and inventory system with fewer blood product unit stock outs and with a reduced number of blood product units exceeding their lifetime. Furthermore, the models and decision support tools developed as part of these projects may ultimately be adapted by other service regions in the United States."
1659774,REU Site: Carnegie Mellon University Robotics Institute REU Site,IIS,RSCH EXPER FOR UNDERGRAD SITES,6/1/2017,3/27/2017,John Dolan,"Dolan, J","Dolan, J",PA,Carnegie-Mellon University,Standard Grant,Wendy Nilsen,5/31/2020,"$359,938.00 ",,jmd@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,1139,9250,$0.00 ,normalFunding,"This Research Experiences for Undergraduates (REU) Site will advance knowledge by training students in the key technological area of robotics and preparing them for graduate study and technical leadership.  The sciences that make up the discipline of robotics provide a unique opportunity to immerse students in research with real-world applications. Rapid research advances place robotics at the forefront of the nation's interests. Furthermore, robotics plays a vital role in science, technology, engineering, and mathematics education due to its multi-disciplinary nature. Robotics-related technologies are becoming ubiquitous, for example sensors and wearable devices, and they are dominating national headlines and discussions on such innovations as driverless cars, big data and data mining, or medical robotics.  An emphasis on increasing the participation of under-represented groups in this site has the potential to extend both the range of research projects within the robotics field and the range of societal concerns and problems addressed by these researchers as they enter upon and conduct their careers. <br/><br/>This site will provide high-quality guided research experiences for undergraduate students with leading faculty in computer vision, field and space robotics, artificial intelligence, manipulation, and machine learning. Additional mentors, including researchers and graduate students, will provide unique perspectives and insights into science and engineering education careers. Mentors will meet weekly with scholars to facilitate their research experience and positive learning outcomes. The strategic goal of this site is to provide research experiences and mentorship to U.S. citizens and permanent residents from under-represented groups and those from higher education institutions with fewer research opportunities. Student recruitment and selection will be conducted accordingly and will draw on broad past experience in attracting under-served populations.  The leadership team and participating faculty share this commitment and bring expertise in mentoring students from diverse backgrounds to communicate their research results to coming generations of students, middle school and high school teachers, and the general public."
1359008,REU Site: Undergraduate Research on Artificial Intelligence and Text Analysis,IIS,RSCH EXPER FOR UNDERGRAD SITES,5/1/2014,4/23/2014,Sharon Small,"Small, S","Small, S|Medsker, L",NY,Siena College,Standard Grant,Wendy Nilsen,4/30/2017,"$359,923.00 ",Larry Medsker,ssmall@siena.edu,515 LOUDON ROAD,LOUDONVILLE,NY,122111462,5187822322,CSE,1139,9250,$0.00 ,normalFunding,"The Siena College Research Experiences for Undergraduates (REU) Site provides unique opportunities for undergraduates to develop research expertise in the field of Artificial Intelligence (AI). The Siena College REU Site environment fosters learning through research by means of faculty advisors and peer mentors. The students work in teams on real problems in information extraction in areas such as information gathering for military and security needs to targeted marketing of products. Especially due to the emerging area of Big Data, this REU program is having an impact on applications that address national and global societal problems, such as medical information retrieval systems that identify people for clinical trials and systems to predict the focus of a groups with adverse intentions from automated text analysis. Teams working in these areas need to have diversity in skills, knowledge, and cultural perspectives, and the Siena REU program is recruiting a wide range of students, including a focus on women and other under-represented groups, so that the students can gain the broad experience needed to address the big problems in today's society. <br/><br/>The REU students are involved in research teams with Siena College faculty and student mentors working on projects that are conducted at the Siena College Institute for Artificial Intelligence (SCIAI) in computational linguistics (CL) for information extraction. The projects are improving the state of the art in CL, as well as investigating interesting real-world applications. Students are learning about the nature of scientific research and how to communicate their work in student-authored publications and through presentations at research conferences. The results of the students' work, including transcripts of presentations and copies of posters, are disseminated via the Siena College REU Site website (http://www.siena.edu/reu)."
534897,Visual Learning in Context,IIS,"COMPUTER VISION, ROBUST INTELLIGENCE",7/15/2005,4/24/2007,Carlo Tomasi,"Tomasi, C","Tomasi, C",NC,Duke University,Continuing grant,Qiang Ji,6/30/2009,"$358,490.00 ",,tomasi@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,"7339, 7495","7495, 9216, HPCC",$0.00 ,normalFunding,"Recent successes in computer vision, machine learning, and combinatorial optimization are leveraged to tackle once more the image interpretation problem as defined in the early days of computer vision. Interpretation is cast as a problem of simultaneous image segmentation and region classification: Given an image and a list of class labels, the goal is to compute the most probable image segmentation and labeling, one label per segment. This is learning in context in that learning techniques are used to recognize several objects in the context of complex, cluttered images<br/><br/>A manual image labeling method is proposed that enlists the help of both web surfers and the students in a junior-high school and a high school to tackle this labor intensive task, while at the same time exposing young pupils to computer vision research.<br/><br/>The proposed work has intellectual merit of relevance to the fields of computer vision, artificial intelligence, and cognition in general. In particular, the notion of defining ``words for pictures'' that this proposal offers may establish a new, fruitful bridge to text retrieval research and widen the discourse computer vision has been entertaining with other areas of science.<br/><br/>The understanding of visual perception in its more semantic sense of ``image interpretation'' will undeniably have a broader impact on society. From a practical point of view, image understanding systems are useful for information retrieval, surveillance, medical imaging, and in many other endeavors. In addition, the proposed activities include collaboration with industry and government agencies and involve postdocs, graduate and undergraduate students. These activities also explicitly involve younger pupils in grades 6 through 12, and will hopefully help attract them to computer vision.<br/> <br/>0535152/0535166<br/><br/>This project addresses the problem of category-level object recognition in images: Its aim is to develop effective methodologies for representing object classes; learning the corresponding object models from cluttered sample images in a semi-supervised manner; and efficiently and robustly recognizing instances of these models in novel images despite clutter, occlusion, viewpoint and illumination changes, and individual variations within each class. <br/><br/>Intellectual Merit. The scientific objective of this project is to develop a representation of the salient parts of an object and their relationships that can effectively be learned from<br/>heavily cluttered data in a weakly supervised way, correctly captures within-class variability and appearance changes due to variations in viewpoint and illumination, and effectively supports inference over object models and the automated construction of efficient classification machines.<br/><br/>Broader Impacts.  This project will investigate applications of category-level object recognition to image retrieval, video annotation, human-computer interaction; surveillance and security; and robotics via international academic and industrial collaborations.  Contributions to education and outreach will include training PhD students and post-doctoral researchers, and involving underrepresented groups in graduate research and undergraduate data collection and empirical evaluation projects.<br/>"
524831,CT-ISG: Learning to Protect Computer Networks via Proactive Vulnerability Assessment,IIS,CYBER TRUST,9/1/2005,8/10/2005,Thinh Nguyen,"Nguyen, T","Nguyen, T|Fern, A",OR,Oregon State University,Standard Grant,Xiaoyang Wang,8/31/2009,"$355,990.00 ",Alan Fern,thinhq@eecs.orst.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7371,"7254, 9218, HPCC",$0.00 ,normalFunding,"This project applies artificial-intelligence (AI) techniques to proactive vulnerability assessment (VA) in computer networks. Current library-based approach to VA does not allow the exploitation of vulnerabilities outside the library of the known attack characteristics. This proposal takes the first step toward the next generation of proactive VA software by developing advanced AI techniques that learn to attack a computer network, and hence discover its vulnerabilities and weaknesses before these weaknesses are exploited. The initial work casts VA within the framework of reinforcement learning (RL) as this approach has demonstrated previous successes for other networking problems. RL researchers study algorithms for learning high reward strategies for one or more agents based on reward signals received while interacting with an environment. For VA, the environment corresponds to a specific computer network; the reward signal provides positive reward for activity that is detrimental to a network and negative reward for activity that is detected as malicious (hence cannot harm the network). The strategy discovered by RL gives a method for one or more agents to attack the network without being detected. In this proposal, the focus is on using RL techniques to discover VA in Peer-to-Peer networks. The broader impact of this project will include bridging the gap between AI and network research communities for the purpose of providing a strong defense against network attacks. Research results will be disseminated through a website at http://www.eecs.orst.edu/~thinhq/research/AI_Security/index.html. The research project will provide a hands-on research and learning environment for students and contribute to the development of Cyber Trust workforce."
853685,GOALI: A Quantum Mechanics Based Method for Properties Predictions and Product Improvements Using Molecular Design,CBET,"INTERFAC PROCESSES & THERMODYN, GRANT OPP FOR ACAD LIA W/INDUS",9/1/2009,8/26/2009,Stanley Sandler,"Sandler, S","Sandler, S|Lustig, S",DE,University of Delaware,Standard Grant,Eddie Chang,8/31/2012,"$354,998.00 ",Steven Lustig,sandler@udel.edu,210 Hullihen Hall,Newark,DE,197162553,3028312136,ENG,"1414, 1504","0000, 051E, 077E, 1504, 6890, 9150, OTHR","$354,998.00 ",normalFunding,"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br/><br/>The research proposal is supported in part through the funds from the Grant Opportunities for Academic Liaison with Industry (GOALI) program for cooperative research between the research group of Professor Stanley I. Sandler of the Department of Chemical Engineering at the University of Delaware and Drs. Steven Lustig and Michael Crawford at the Experimental Station of the DuPont Company in Wilmington Delaware.  The project will have long term energy and environmental impact. It involves simulation/modeling and comparisons with experimentation.<br/><br/>The thermodynamics research will focus on improvements to the recent quantum mechanics based physical and chemical properties prediction method, COSMO-SAC, developed at the University of Delaware, and its combination with a molecular design methodology developed by Steven Lustig at DuPont to areas of both scientific and industrial interest. There are three specific, but related areas of research in this proposal are improvement of the basic COSMO-SAC model to better represent London dispersion interactions, and then reparameterization of the model using databases available at the University of Delaware and at the DuPont Company; an experimental test of a fundamental assumption of the COSMO-SAC and related models of the independence of the solute molecular conformation on the solvent in which it is located using Raman spectroscopy at the DuPont Company; and combination of the proposed refinements with the COSMOdesign methodology to develop a self contained tool that can be used to design molecules to achieve certain performance goals. <br/><br/>Intellectual Merit <br/><br/>There are three features of this proposal of original and distinct intellectual merit. The first is the combination of a quantum mechanics based approach to predicting the thermodynamic properties in a novel manner with an artificial intelligence based method to choose fluids and mixtures to meet specifications for the optimal design of a product or process. Second is the further development of this quantum based method by a significant improvement in the way dispersion and hydrogen bonding energies are treated based on better physiochemical theory and descriptions. Finally, while the solution effects on conformations of molecules is known to be important, for example, in the coiling and uncoiling or polymers and folding and unfolding (denaturation) of proteins, this effect is largely ignored in the description of smaller molecules. The PIs will examine the importance of changes in molecular conformation experimentally in this research, and then incorporate this information into thermodynamic properties model. <br/><br/>Broader Impacts <br/><br/>The most important impact of the research proposed is the development of a publically-available, completely new design tool for chemists and engineers to use in reverse engineering of a product or solvent, and especially those with environmentally acceptability. That is, once a desired set of properties for a product or solvent have been specified, the result of the proposed research will allow pure fluids or mixtures to be identified that have these properties, even if there are no experimental data or the substance(s)has not yet even been synthesized. One such example is ionic liquids, of which there are many possible based on different choices of anion and cation, while only a few have been synthesized. Another would be in choosing a new refrigerant or refrigerant to meet energy efficient or environmental standards. Still other applications of the method include using the quantum mechanical based theory to selective binding of substances to electronic and biological substrates; estimating toxicity; and to the design of pharmaceutical and other biologics with desired drug formulation and/or delivery properties. <br/><br/>In addition to the scientific and engineering impact of the research, at least one Ph.D. and one postdoctoral associate will receive training under the proposed grant, thereby increasing the U.S. pool of trained professionals. Also, through the RISE program of the University of Delaware, we will involve undergraduate students from underrepresented minorities in the research."
1123617,DIP: Collaborative Research: A Personalized Cyberlearning System Based on Cognitive Science,IIS,Cyberlearn & Future Learn Tech,9/1/2011,9/7/2011,Elizabeth Marsh,"Marsh, E","Marsh, E",NC,Duke University,Standard Grant,John Cherniavsky,8/31/2016,"$354,850.00 ",,emarsh@psych.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,8020,"8045, 8842",$0.00 ,normalFunding,"Investigators from Rice University and Duke University will build a Personalized Cyberlearning System, designed around three principles from cognitive science (retrieval practice, spacing, and enhanced feedback), that leverages advances in machine learning and makes use of an existing instructional content material and problem set database aimed at undergraduate engineering students. The system will use artificial intelligence methods to optimize practice and feedback for students. Research will seek to advance knowledge, in a real-world setting, about a range of issues concerning how feedback facilitates learning, how individual differences come in to play, as well as those more specifically aimed at the development of the learning technology system itself.<br/><br/>The project is important as part of the effort to harness the vast quantities of information on the web to personalize instruction for a wide range of learners. Moreover, the development of such cyberlearning technologies holds promise for opening up STEM education for motivated self-learners while also allowing access to a large volume of material for a range of students who might not otherwise have it."
9624495,A Program for CAREER Development at Chicago State           University,CHE,MATERIALS SYNTHESIS & PROCESSN,5/1/1996,5/19/1999,David Kanis,"Kanis, D","Kanis, D",IL,Chicago State University,Continuing grant,Katharine J. Covert,4/30/2000,"$354,750.00 ",,dkanis@csu.edu,9501 South King Drive,Chicago,IL,606281598,7739952400,MPS,1984,"1045, 9161, 9178, SMET",$0.00 ,normalFunding,"This CAREER award is made in the Office of Special Projects in support of   the research and teaching activities of Dr. David Kanis at Chicago State   University. The research will focus on two main objectives. First,   methods will be developed for the calculation of the third-order    response for nonlinear optical materials. Algorithms based on the   Fenske-Hall model Hamiltonian will be developed and compared to the ZINDO   methodology for computed third-order responses. These calculations are   expected to uncover generalities governing chromophore design and   identify specific molecular structures for synthesis and   characterization. The second element of the research will focus on the   use of neural networked based artificial intelligence to screen the   ZINDO-generated database for structure-activity relationships between   nonlinear optical response and electronic  and molecular structure.   Through the CAREER plan, undergraduates will be equipped and encouraged   to attend graduate school by involving them in challenging research   projects, implementing curricular reforms and encouraging student   participation at scientific meetings. A Physical  Science lecture class   will be transformed into a participatory, discovery-based course for   nonscience majors highlighting concepts rather than procedures. Outreach   activities toward the African-American community will bring outstanding   pre-college students and high school teachers to the university to   participate in laboratory studies. A `Science in the Hood` program will   provide outreach to a segment of the urban population not typically   served by science education programs."
83421,A Perceptual Visualization Architecture,CCF,"ADVANCED COMP RESEARCH PROGRAM, HUMAN COMPUTER INTER PROGRAM",9/15/2000,4/30/2002,Christopher Healey,"Healey, C","Healey, C",NC,North Carolina State University,Continuing grant,Almadena Y. Chtchelkanova,8/31/2005,"$354,029.00 ",,healey@ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,"4080, 6845","9216, HPCC",$0.00 ,normalFunding,"This project will perform fundamental investigations of the strenghts and limitations of the low-level human visual system. It will seek to identify image properties that people can see quickly, to test how those properties interact with one another, and to determine how to harness those properties. Understanding how we perceive the world around us will benefit many research areas including information display, image generation, image analysis, and the simulation of vision. This project will apply this knowledge to an important area of computer graphics: the visualization of large, complex, multidimensional datasets. The goal in this area is to design visualizations that support rapid and accurate exploration and analysis of such complex data. To do this, the project must display all of the data without overwhelming the viewer's visual system. It will solve this problem by constructing a perceptual visualization architecture, which will inclued a ""visualization assistant"". This assistant will use artificial intelligence search techniques to help viewers choose perceptually optimal methods of converting their data into effective visualizations."
1319912,HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative,IIS,Cyber-Human Systems (CHS),8/1/2013,7/14/2014,Robert Young,"Young, R","Young, R",NC,North Carolina State University,Continuing grant,William Bainbridge,10/31/2016,"$352,696.00 ",,young@cs.utah.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,7367,"7367, 7923",$0.00 ,normalFunding,"The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments.  Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure.  The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves.  Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br/><br/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br/><br/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines.  Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process."
1527497,"AF: Small: Using Ordinal Information to Approximate Cardinal Objectives in Social Choice, Matching, Group Formation, and Assignment Problems",CCF,ALGORITHMIC FOUNDATIONS,6/15/2015,2/22/2016,Elliot Anshelevich,"Anshelevich, E","Anshelevich, E",NY,Rensselaer Polytechnic Institute,Standard Grant,Tracy J. Kimbrel,5/31/2019,"$350,470.00 ",,eanshel@cs.rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,7796,"7923, 7926, 7932, 9251",$0.00 ,normalFunding,"Many modern algorithms must make decisions using only limited information: they not only need to make the best choices given the input, but also don't know what the ""true"" input actually is; and yet they are required to make good choices anyway. This problem arises often in settings where the goal is to maximize the total happiness (a.k.a. social welfare or total utility) of the system, such as social choice settings in which voters submit their preferences for different alternatives, matching settings (e.g., matching people with job openings or organ donors with patients), assigning people to groups or projects, economic market settings, and many others. In all of these settings, the people or agents involved may care deeply about which outcome is selected (e.g., which alternative is selected by the voting mechanism, or which patients are assigned a donated kidney), with the mechanism designer's goal being to maximize the overall welfare and satisfaction. Unfortunately, in all these applications, only limited information is usually available: it is relatively easy to obtain *ordinal* information (which choice is preferred to which other choice by each participant), but almost impossible to obtain the underlying numerical information (how *much* each choice is preferred by each participant). This project will use a novel notion of approximation to give new insight into the design and evaluation of many mechanisms for the settings mentioned above. The approximation algorithms resulting from this project will be used to suggest new protocols, which would not only optimize some notion of fairness (as is common in social choice), or maximize the size of a matching (as is common in kidney exchange), but would have provable guarantees on the quality of the outcomes. One reason why such guarantees have not been considered in the past is that without the knowledge of exact numerical utilities or exact compatibilities between matches, protocols can only rely on ordinal, or otherwise limited, information. However, as preliminary work shows, one can often design algorithms which behave well no matter what the *true* information is, as long as the underlying (unknown) numerical values have some reasonable structure, or are at least correlated in some way, which is certainly the case for most applications. Because of this, this project will provide a different perspective, and will result in algorithms which produce provably good outcomes while using only limited ordinal information.  Due to the applications touched by this project, the work done should be of interest to researchers in many fields, including Social Choice, Artificial Intelligence, Game Theory, Social Networks, and Economics. This research will be strongly complemented by the PI's education plan, which includes teaching several courses with research components, presenting this work at numerous scientific seminars, and recruiting several graduate and undergraduate students to work on this project.<br/><br/>The primary goal of this project is to design and analyze algorithms which only know ordinal information, and yet create solutions which are provably close to the ""true"" optimal solution: the one which would be chosen if the full numerical information were known. The project will specifically focus on the settings of social choice, matching, group formation, and economic markets. Very little is known about approximation algorithms in the presence of ordinal information, and designing such algorithms for the settings above will likely require new and interesting techniques. When the numerical values are completely uncorrelated, it is of course impossible to form good approximations from only ordinal information, so this work will involve looking at different kinds of correlations (e.g., lying in a metric space, symmetric values, values from a common distribution, etc), and determining how much power this structure gives to the ordinal information, as compared to the true numerical information. The PI will also consider optimization problems with other interesting constraints which deserve further study, focusing especially on computing good solutions in the presence of self-interested agents, in the contexts of social choice, matching, and envy-free pricing. This work should lead to basic understanding of the fundamental power of ordinal information, by determining under which settings and conditions ordinal information is enough to approximate the numerical truth, and when such an approximation is impossible."
9619233,Computing with Default Logic,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/1/1997,4/22/1999,Miroslaw Truszczynski,"Truszczynski, M","Truszczynski, M|Marek, V",KY,University of Kentucky Research Foundation,Continuing grant,Ephraim P. Glinert,4/30/2001,"$350,379.00 ",Victor Marek,mirek@cs.uky.edu,109 Kinkead Hall,Lexington,KY,405260001,8592579420,CSE,6856,"9218, HPCC",$0.00 ,normalFunding,"Since  its introduction by Reiter in 1980 default logic  has  been  widely  studied  for  its potential as a knowledge  representation  mechanism. Recent results indicate that default logic not only can  serve as a declarative knowledge representation tool but also  has  the  potential to evolve into a practical high-level computational  environment.  This  project develops fast  systems  for  automated  default  reasoning  including  implementations  for  parallel  and  distributed  environments. A systematic methodology  of  computing  with  default  logic  is  also  under development.  Usefulness  of  default  logic as a computational tool is demonstrated  through  a  comprehensive  experimentation with  default  theories  describing  combinatorial    optimization   problems.    To    support    this  experimentation  effort,  a tool to automatically  generate  large  families  of  default theories, logic programs  and  propositional  theories is implemented.  Due to the declarative nature of default  logic, this new programming tool, based on default logic, will  be  easy to use, will allow for fast prototyping and will be effective  in  a  wide  range  of artificial intelligence  applications.  The  testing  system  will  become  a standard  benchmarking  tool  for  automated reasoning based on default logic and related formalisms."
218861,ITR---Reinventing Artificial Intelligence,IIS,ITR SMALL GRANTS,9/1/2002,8/5/2004,Patrick Winston,"Winston, P","Winston, P",MA,Massachusetts Institute of Technology,Continuing grant,James French,8/31/2005,"$350,000.00 ",,phw@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,1686,"9216, HPCC",$0.00 ,normalFunding,"The Genesis Group of the MIT Artificial Intelligence Laboratory is working<br/>on a computational theory of human intelligence. Their work is grounded in<br/>two key assumptions: first, that humans think with their language, vision,<br/>and motor systems, and their interaction; and second that humans can think<br/>abstractly because they can build on a foundation of thinking about concrete<br/>events in the physical world.<br/><br/>Their plan includes the development of a testbed that features paths,<br/>agents, causes, both language and visual inputs and outputs, complex state<br/>transitions, and support for abstract reasoning in abstract worlds.<br/><br/>They propose to exploit both symbolic and nonsymbolic representations. The<br/>symbolic representations will include a representation for describing the<br/>movement of animals and artifacts along trajectories and a representation<br/>for describing state transitions in terms of a vocabulary of qualitative<br/>changes. The nonsymbolic representations will include memory traces lying<br/>close to experienced sensory inputs.<br/><br/>The Genesis Group expects success to lead not only to a better<br/>understanding of natural intelligence buy also, in the long term, to<br/>important practical results, such as computer applications with genuine<br/>commonsense and educational applications that exploit an understanding of<br/>how best to engage human linguistic and visual problem solving faculties."
808653,INT2-Large: Collaborative Research: Developing Social Robots,IIS,ROBUST INTELLIGENCE,9/1/2008,8/26/2008,Daniel Messinger,"Messinger, D","Messinger, D",FL,University of Miami,Standard Grant,Richard Voyles,8/31/2012,"$350,000.00 ",,dmessinger@miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,CSE,7495,"7717, 9215, HPCC",$0.00 ,normalFunding,"Last Modified Date: 08/04/08 Last Modified By: C.S. George Lee <br/><br/>Abstract <br/>The goal of this project is to make progress on computational problems that elude the most sophisticated computers and Artificial Intelligence approaches but that infants solve seamlessly during their first year of life. To this end we will develop a robot whose sensors and actuators approximate the levels of complexity of human infants. The goal is for this robot to learn and develop autonomously a key set of sensory-motor and communicative skills typical of 1-year-old infants. The project will be grounded in developmental research with human infants, using motion capture and computer vision technology to characterize the statistics of early physical and social interaction. An important goal of this project is to foster the conceptual shifts needed to rigorously think, explore, and formalize intelligent architectures that learn and develop autonomously by interaction with the physical and social worlds. The project may also open new avenues to the computational study of infant development and potentially offer new clues for the understanding of developmental disorders such as autism and Williams syndrome."
620062,"Attention, Memory, and Judgment",SES,DECISION RISK & MANAGEMENT SCI,9/1/2006,8/18/2006,Michael Dougherty,"Dougherty, M","Dougherty, M",MD,University of Maryland College Park,Standard Grant,Robert E. O'Connor,3/31/2011,"$350,000.00 ",,mdougher@umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,SBE,1321,"0000, OTHR",$0.00 ,normalFunding,"A fundamental component of human decision making is how people generate, assess, and test diagnostic hypotheses. Take the task of a clinical diagnostician as an example. The clinician's task is similar to that of a detective in that he or she is compelled to search for clues (i.e., data) that can be used to generate and test possible explanations of the presenting symptoms. The clinician presumably generates likely diagnoses (i.e., disease hypotheses) and actively seeks information to evaluate the generated diagnoses. The clinician's search for information in the environment likely is not random, but is instead guided by those diagnostic hypotheses he or she is presently entertaining. The information or data newly revealed through the search process is used to both evaluate the diagnoses currently under consideration as well as generate new diagnoses. The generation of new diagnoses may, in turn, lead to fresh information search threads where new hypotheses might be brought to mind. At some point, either the search space is exhausted, the clinician continually fails to generate additional plausible hypotheses, or one particular hypothesis gains enough evidential support that the clinician can render a diagnosis with confidence. <br/><br/>The goal of the proposed research is two fold. One goal is to better understand the cognitive constraints that govern hypothesis generation, probability judgment, and information search in humans. Understanding these cognitive constraints hopefully will enable us to developed methodologies or technologies to improve diagnostic decision making in real-world decision tasks such as medical diagnosis or intelligence analysis. The second goal is to develop a cognitive model of human judgment that can take as input a piece of data (e.g., a symptom) and generate a set of diagnostic hypotheses to explain that datum, provide probability estimates of the generated hypotheses, and revise both the generated hypotheses and the probability judgments iteratively as new data are experienced. This type of system has natural implications both for understanding human decision making in dynamic tasks and for developing artificial intelligence systems that can outperform human decision makers."
345746,Multiple stages of motion processing,BCS,"COGNEURO, PERCEPTION, ACTION & COGNITION",5/15/2004,4/6/2006,Takeo Watanabe,"Watanabe, T","Watanabe, T|Andersen, G|Tootell, R|Kim, NG",MA,Trustees of Boston University,Continuing grant,Douglas H. Whalen,4/30/2007,"$349,998.00 ","George Andersen, Roger Tootell, Nam-Gyoon Kim",takeo@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,SBE,"1699, 7252","0000, 1699, OTHR",$0.00 ,normalFunding,"Optical flow motion processing is fundamental to everyday life. In order to obtain important environmental information to the viewer that will allow her/him to react appropriately, the visual system needs to extract and differentiate different patterns of optical flow motion signals from the environment. For example, systematic transformation of moving objects is one of the most powerful sources for reconstructing the 3-dimensional surfaces of the objects. With support from the National Science Foundation, Dr. Takeo Watanabe's research aims at understanding how different types of motion signals are related to each other in the brain from a global framework of motion processing. The research will be conducted using psychophysics and fMRI in which Dr. Watanabe will systematically measure brain activity with different types of motion and can learn how they are related to each other.<br/> Broader impacts of the project include educational and medical advances, improved navigational skills of drivers and pilots, and enhanced artificial intelligence/robotics. Educational benefits will include the training of graduate and undergraduate students in use of the methodology and technology. The research also has the potential to be directly applied to clinical research in neurosurgery by contributing to scientific knowledge leading to development of medical tools for improved diagnosis and treatment of brain disorders or lesions. The research can also provide important knowledge to enhance the navigation skills of drivers and pilots. Finally, construction of robots with the artificial intellectual power to effectively detect and utilize motion information would be of benefit to both the civilian/medical and military fields."
1715475,RI: Small: Integrating Flexible Normalization Models of Visual Cortex into Deep Neural Networks,IIS,ROBUST INTELLIGENCE,9/1/2017,8/17/2017,Odelia Schwartz,"Schwartz, O","Schwartz, O",FL,University of Miami,Standard Grant,Kenneth C. Whang,8/31/2020,"$349,996.00 ",,odelia@cs.miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,CSE,7495,"7495, 7923, 8089",$0.00 ,normalFunding,"Recent advances in artificial intelligence models of deep neural networks have led to tremendous progress in artificial systems that recognize objects in scenes, and in a host of other applications such as speech recognition, and robotics. Although deep neural networks often incorporate computations inspired by the brain, these have typically been applied in a fairly simple and restrictive manner, rather than based on more principled models of neural processing in the brain. Using vision as a paradigmatic example, this project proposes that artificial systems can benefit from integrating approaches that have been developed in biological models of neural processing of scenes. The biological models make use of contextual flexibility, whereby neurons are influenced in a rich way by the image structure that spatially surrounds a given object or feature. This flexibility is expected to improve task performance in deep neural networks, and to impact development of artificial systems that are more compatible with human cognition. The resulting framework, with its deep architecture spanning multiple layers of processing, will, in turn, make predictions about neural processing in the brain, which will impact the neuroscience and cognitive science communities. <br/><br/>This project focuses specifically on normalization, a nonlinear computation that is ubiquitous in the brain, and that has been shown to benefit task performance in deep neural networks. The project will develop more principled strategies for determining normalization in deep convolutional neural networks. The main focus will be on learning a form of flexible normalization based on scene statistics models of visual cortex. In this framework, normalization is recruited only to the degree that a visual input is inferred to contain statistical dependencies across space. Performance will be tested for classification and segmentation on large-scale image databases, and will also target tasks more suited to mid-level vision such as figure/ground judgment. This will result in better understanding of normalization nonlinearities in deep convolutional networks, and the implications of flexible normalization for task performance and generalization compared to other forms of normalization. Biologically, normalization is poorly understood beyond primary visual cortex. The models developed will help shed light on the equivalence of this inference for middle cortical areas, and make predictions about what image structure leads to recruitment of normalization. This project will also include launching of an interdisciplinary Deep Learning Discussion Group."
1409987,RI: Medium: Collaborative Research: Experience-Based Planning: A Framework for Lifelong Planning,IIS,ROBUST INTELLIGENCE,8/1/2014,6/10/2016,Sven Koenig,"Koenig, S","Koenig, S",CA,University of Southern California,Standard Grant,James Donlon,7/31/2019,"$348,000.00 ",,skoenig@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,"7495, 7924, 9251",$0.00 ,normalFunding,"Robots need to improve their behavior over time, yet produce consistent behavior in order to allow humans to predict their actions, which is necessary to develop trust in their behavior or even cooperate with them. Furthermore, many tasks repeat, such as opening drawers. This project develops technology that addresses these issues by viewing planning as a lifelong process and exploiting the structure of human environments for efficiency, for example that drawers typically open in similar ways.<br/><br/>This research collaboration is developing a framework for lifelong planning based on experience graphs that aims to improve performance of planning over time by exploiting past experiences when solving similar planning tasks. The concept is novel because experiences are used to guide the heuristic search as opposed to be used for mere replay or adaptation. The idea that makes this possible is a novel heuristic search-based framework that can take advantage of prior experiences and still provide rigorous guarantees on completeness and path quality. The team studies how experiences can be utilized effectively during planning, how planning should gather experiences, how it should prune redundant experiences and how it can obtain experiences from demonstrations. Applications include everyday household tasks and low-volume manufacturing tasks. The software developed in this collaborative research is being integrated into the SBPL library, one of the core libraries in ROS. The project also incorporates educational activities as well as activities that help to bridge the research communities in robotics and artificial intelligence, two separate communities despite their common interest in autonomous systems."
1219142,"RI: Small: Semantics-Based, Weakly-Supervised Coreference Resolution",IIS,ROBUST INTELLIGENCE,8/1/2012,6/15/2017,Vincent Ng,"Ng, V","Ng, V",TX,University of Texas at Dallas,Continuing grant,Tatiana D. Korelsky,7/31/2018,"$347,410.00 ",,vince@hlt.utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,7495,7923,$0.00 ,normalFunding,"This research seeks to push the frontiers of coreference resolution research via achieving two objectives. First, it addresses the Winograd Schema Challenge by examining a class of difficult-to-resolve anaphors whose resolution requires commonsense knowledge involving the roles played by the participants in an event and their causal relationships. It adopts a deep text-understanding approach to this problem. Specifically, it ventures into unexplored areas of coreference research, including the use of script-like knowledge and sentiment analysis, as well as an examination of the role of discourse connectives. Second, it enables the acquisition of coreference resolvers for a substantially larger number of natural languages and domains than is currently possible. One of the major obstacles to the deployment of coreference technologies across a large number of languages and domains is the high cost associated with coreference-annotating data in a language and domain. It investigates two cost-effective approaches to data annotation, one involving translation-based projection and the other bootstrapping.<br/><br/>As coreference is an enabling technology for many traditional and emerging text-processing applications, the project has the potential to improve these applications. Through the construction of a multi-lingual, multi-domain coreference resolver and the availability of annotated data produced in the course of this investigation, the project may stimulate research in under-studied languages and domains by a broader community of researchers. Equally importantly, the use of commonsense knowledge in the resolver mimics the human coreference resolution process, bringing artificial intelligence researchers one step closer to building an intelligent agent that can truly understand natural language."
321385,MRI/RUI - Aquisition of robotics equipment for an Intelligent Systems Laboratory,CNS,MAJOR RESEARCH INSTRUMENTATION,8/15/2003,8/6/2003,Ben Juliano,"Juliano, B","Juliano, B|Renner, R|Varahamurti, R",CA,"California State University, Chico Research Fdtn",Standard Grant,Rita V. Rodriguez,7/31/2007,"$346,188.00 ","Renee Renner, Ramesh Varahamurti",BJuliano@csuChico.edu,Office of Sponsored Programs,Chico,CA,959290001,5308985700,CSE,1189,"1189, 9218, HPCC",$0.00 ,normalFunding,"This project, acquiring robotics equipment for an Intelligent Systems Laboratory (ISL), aims at facilitating the development of cross-disciplinary courses and providing exciting research possibilities. Furnishing opportunities of joint collaborations with other disciplines, ISL enables students and faculty to investigate, design, and implement control algorithms using non-traditional techniques derived from various subdisciplines of Artificial Intelligence, such as fuzzy logic, neural networks, genetic algorithms, hybrid approaches. ISL fosters research and development of solitary cooperating autonomous or teleoperative mobile robots for a variety of tasks such as gathering data from potentially hazardous environments and facilitating search and rescue missions.<br/>Areas identified for research, motivated by terrorist attacks, include:<br/> Design and deployment of intelligent agents for bio-surveillance and threat detection, and<br/> Design and implementation of large-scale hybrid systems tools for soft computing, complexity analysis, and intelligent applications.<br/>Robotics kits will be acquired, facilitating research, research training, and integrated research/education activities at various academic levels. New interdisciplinary courses will be developed and cross-listed in Machine Intelligence, Intelligent Systems, Design and Applications, Intelligent Control, and Autonomous Robots. Moreover, participants will be recruited for Girls SRC, a Summer Robotics Camp for junior high school.<br/>"
9704530,Sensorimotor Cognition---The Earliest Knowledge Structures,IIS,"ROBOTICS, ARTIFICIAL INTELL & COGNIT SCI",9/15/1997,8/3/1999,Roderic Grupen,"Grupen, R","Grupen, R|Cohen, P",MA,University of Massachusetts Amherst,Continuing grant,Ephraim P. Glinert,8/31/2001,"$344,885.00 ",Paul Cohen,grupen@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"6840, 6856","9216, HPCC",$0.00 ,normalFunding,"This research investigates the origins of knowledge and conceptual structure. An interactionist perspective   leads to a computational model in which the earliest knowledge structures are influenced by both native   structure in the agent and its exposure to the world. `Physical schemas` are learned that form stable,   dynamical relationships between the agent and the world based on closed-loop `physical primitives.`   A   preimaging technique is used to form context-dependent categories spontaneously in order to improve the   quality of sensory and motor behavior. Declarative models are lifted from the sensorimotor substrate in the   form of `figurative schema.` This representation includes explicit predictive models of sensation and   affect, and thus captures some of the underlying semantics of behavioral policies.  An integrated robot   system is used as the experimental platform. The implications of this work extend to developmental   psychology, epistemology, and psycholinguistics, artificial intelligence and machine learning.   Computational agents built on these principles refer ultimately to the physical world for meaning --- the   same physical world that shapes human conceptual structure. We foresee interfaces to electronic agents   that appeal to semantics based in the physical world to understand the `meaning` of a human request."
1526301,RI: Small: Knowledge Representation and Reasoning under Uncertainty with Probabilistic Answer Set Programming,IIS,ROBUST INTELLIGENCE,8/1/2015,8/4/2015,Joohyung Lee,"Lee, J","Lee, J",AZ,Arizona State University,Standard Grant,James Donlon,7/31/2019,"$342,795.00 ",,joolee@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,7495,"7495, 7923",$0.00 ,normalFunding,"Combining logic and probability is an important subject in Artificial Intelligence, and is recently being extensively studied in the area of statistical relational learning, where the main goal of representation is to express probabilistic models in a compact way that reflects the relational structure of the domain and ideally supports efficient learning and inference. However, in comparison with main knowledge representation languages, such languages do not allow natural, elaboration tolerant representation of commonsense knowledge. Currently, there is a big gap between the state of the art languages that are used in knowledge representation and the state of the art languages in which machine learning is done.  The success of this project will identify fundamental issues in bridging the gap between the two areas, will produce a uniform framework for both expressive representation and learning, and will contribute to the integration of knowledge representation and machine learning. The outcome of the research will be useful for many applications that require integration of knowledge representation and other areas, such as vision, robotics, and event recognition, where commonsense reasoning has to be applied on uncertain knowledge and data. The software systems developed under this project will be freely available as open source software. The research will involve both graduate and undergraduate students, contributing to a strengthened relationship between education and research. <br/><br/>The goal of the project is to design and implement a knowledge representation language that allows elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in related areas.  The proposed research aims at shifting the current logic-based foundation of answer set programming to a novel foundation that combines logic and probability, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning. It will build upon the existing works on answer set programming, statistical relational learning, and probabilisitic logic programming.  The project will (i) enhance the mathematical foundation of answer set programming to the novel foundation that combines logic and probability. (ii) relate it to other existing approaches in statistical relational learning, Pearl's causal models, and P-Log; (iii) design inference and learning algorithms; (iv) design a high level action language that allows elaboration tolerant representation of probabilistic transition systems; (v) apply probabilistic answer set programming to event recognition; (vi) implement and evaluate involved software systems."
78206,Statistical Signal Processsing Models of Electrosensory Acquisition,IOS,COMPUTATIONAL NEUROSCIENCE,8/15/2000,4/24/2003,Mark Nelson,"Nelson, M","Nelson, M",IL,University of Illinois at Urbana-Champaign,Continuing grant,Cole Gilbert,7/31/2004,"$340,698.00 ",,m-nelson@uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,BIO,1162,"1096, 9107, 9178, 9251, BIOT, SMET",$0.00 ,normalFunding,"The goal of this project is to understand how animals acquire and process sensory information about their environment. The focus is on identifying and characterizing brain mechanisms and information<br/>processing principles that allow animals to enhance signals that are important to their behavior and to suppress irrelevant background noise.  The specific studies are centered around the ability of weakly electric<br/>fish to detect and localize small prey in the dark using an active electric sense. While much is known about the neural circuitry in these animals, there is a gap in the theoretical understanding of how the brain should best process incoming sensory data.  This proposal helps fill that gap by using statistical signal processing theory to develop optimal signal processing models of electrosensory target detection.  These models are expected to provide a quantitative link between neurophysiology and behavior, and will provide valuable insights into the structural and functional organization of the nervous system. <br/><br/>The issues addressed in these studies are of broad interest in sensory neurobiology, including the role of feedback pathways from higher brain centers, mechanisms for generating predictions of incoming sensory data, and synergistic interactions between sensory and motor aspects of sensory acquisition. In addition to advancing basic knowledge in neuroscience, the models of optimal sensory acquisition have relevance in applied areas of science and engineering such as artificial intelligence and robotics. This project also provides cross-disciplinary training for young scientists with interests that cut across the fields of physics, mathematics, computer science and neurobiology.  <br/>"
93302,CAREER:  Support Vector Methods for Functional Genomic Analysis,IIS,ARTIFICIAL INTELL & COGNIT SCI,3/15/2001,3/1/2004,William Noble,"Noble, W","Noble, W",NY,Columbia University,Continuing grant,Edwina L. Rissland,10/31/2004,"$337,591.00 ",,noble@gs.washington.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,6856,"1045, 1187, 9216, HPCC",$0.00 ,normalFunding,"As the Human Genome Project nears completion the need grows for functional genomic analyses which in addition to the primary genomic sequence involve other types of data such as gene expression measurements from microarray hybridization experiments. Research in functional genomics involves a range of computational problems including visualization, clustering, classification, regression, knowledge representation, and predictive modeling.   This project will touch on each of these areas, but the primary focus will be on developing machine learning techniques that learn to place genes into discrete functional categories in order to simplify and render more tractable the problem of inferring gene function from genomic data.  To the end the PI will build on his prior work which showed that a support vector machine (SVM) can be successfully trained using DNA microarray expression data to recognize various gene functional categories, and will develop methods for combining coding sequence, promoter region, gene expression, and other types of genomic data in SVM-based learning algorithms.   The research will lead to improved understanding of the ability of various machine learning techniques to recognize different types of gene functional classes, and will also yield new techniques for learning simultaneously from multiple types of data.  Learning from heterogeneous data sets is a core issue in artificial intelligence and machine learning;  the ability to combine knowledge from various types of genomic data is critical for understanding the cell at the molecular level, and should lead to important insights into gene function."
702505,Communication and Synchronization Mechanisms for Emerging Multi-Core Processors,CCF,COMPUTER SYSTEMS ARCHITECTURE,9/1/2007,5/15/2008,Sandhya Dwarkadas,"Dwarkadas, S","Dwarkadas, S|Scott, M",NY,University of Rochester,Standard Grant,Ahmed Louri,8/31/2010,"$337,000.00 ",Michael Scott,sandhya@cs.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,4715,"9218, 9251, HPCC",$0.00 ,normalFunding,"CCF-CPA:  Communication and Synchronization Mechanisms for Emerging <br/>Multi-Core Processors<br/>Sandhya Dwarkadas and Michael L. Scott<br/>March 2007<br/><br/><br/>As a result of increasing chip density and power limitations, explicit hardware parallelism will soon dominate the computing spectrum, with multicore chips replacing uniprocessors throughout the desktop and<br/>laptop markets.  If these chips are to be used effectively, new programming models must ease the task of writing multithreaded code. These models must in turn be supported by architectural mechanisms that<br/>minimize the cost of data communication and synchronization.<br/><br/>The sponsored research addresses the challenge of mainstream parallelism using a combined hardware-software approach.  The key idea is to identify common time-critical operations, across a variety of applications and programming models, that might be accelerated or simplified by new architectural mechanisms, and then to design those mechanisms in as general a fashion as possible.  By leaving policy to<br/>software whenever possible, this strategy aims to maximize opportunities for adaptive and application-specific protocols that increase scalability.  Candidate hardware mechanisms include alert-on-update, which leverages cache coherence for fast event-based communication; programmable data isolation, which allows a processor to hide local writes for speculation and transactions; and adaptive cooperative caching, which re-engineers the on-chip coherence protocol to accommodate different patterns of data sharing and to communicate values efficiently between cores.  These mechanisms will be studied mainly at the hardware level, but system software will also be developed to support new programming models (transactions, speculation) and to enable detailed evaluation of performance and programmability.<br/><br/>Through better parallel programming models and efficient implementations, the sponsored research aims to continue the computing revolution over the course of the coming decade.  By enabling the effective use of larger numbers of simpler cores, it also addresses the critical need to reduce energy consumption in mainstream processors. Driving applications will be drawn from multiple sources, including collaborative efforts with University colleagues in Biology, Astrophysics, and Chemistry; department colleagues in Artificial Intelligence and Internet services; and local and remote colleagues in data mining.  Programming models and tasks will include transactional computing, speculative execution, and performance and correctness debugging.<br/>"
1661529,Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution,DBI,ADVANCES IN BIO INFORMATICS,9/1/2017,1/26/2018,Wasila Dahdul,"Dahdul, W","Dahdul, W|Mabee, P|Dahdul, W",SD,University of South Dakota Main Campus,Standard Grant,Peter H. McCartney,8/31/2020,"$336,493.00 ","Paula Mabee, Wasila Dahdul",Wasila.Dahdul@usd.edu,414 E CLARK ST,Vermillion,SD,570692307,6056775370,BIO,1165,9150,$0.00 ,normalFunding,"The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
80888,Practical Reasoning in Autonomous Agents,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/1/2000,6/7/2002,John Pollock,"Pollock, J","Pollock, J",AZ,University of Arizona,Continuing grant,Edwina L. Rissland,8/31/2004,"$331,169.00 ",,pollock@arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"    AI is approaching the point where it will be possible to build autonomous robotic agents capable of performing human-like tasks without direct human control.  Such autonomous agents must be able to plan their activities in the face of incomplete knowledge of their environment.  This project aims at understanding how such planning works and building implemented systems that accomplish it.  Specifically, this investigation is aimed at the construction of an artificial rational agent capable of engaging in decision-theoretic planning in environments of realistic complexity and unpredictability. The design of a system to do automated planning is one of the traditional goals of artificial intelligence research, and some highly successful planning systems have been constructed for use in narrowly constrained environment;  however, these systems presuppose that the planner knows everything it needs to know when it is first presented with the planning problem, and most of them further require complete knowledge of all relevant aspects of the agent's environment and knowledge of precisely what will result from performing any relevant act in any circumstance the planner will encounter.  While such assumptions might be satisfied by an industrial robot operating in a constrained environment, human beings plan without satisfying any of these conditions.  In particular, planning problems often drives the search for new knowledge rather than presupposing that the planning agent knows everything it needs to know from the beginning.  And human beings do not assume that they can predict with certainty what will happen when they perform any available action under any conceivable circumstances.  In constructing and evaluating plans, people take account of the varying probabilities of different consequences of actions, and they assign values and costs to those consequences before deciding whether to adopt a proposed plan.   In other words, they plan decision-theoretically.   The objective of this project is to understand how decision-theoretic planning is possible in an agent operating in an uncooperative and only partially predictable environment, and then to build an artificial agent whose planning capabilities more closely approximate those of human beings.  This should illuminate some of the structure of rational cognition in both artificial agents and human agents."
635147,Mechanism Design for Profit Maximization,CCF,THEORETICAL FOUNDATIONS (TF),10/1/2006,9/22/2006,Anna Karlin,"Karlin, A","Karlin, A",WA,University of Washington,Standard Grant,Petros Drineas,9/30/2010,"$330,000.00 ",,karlin@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7351,"9218, HPCC",$0.00 ,normalFunding,"Abstract for Proposal No. 0635147:<br/>Mechanism Design for Profit Maximization<br/>The Internet, with its varying degrees of collaboration and competition, has become the de facto platform for large scale distributed computing. This has motivated a great deal of research into the design of protocols for resource allocation and electronic commerce among parties with diverse and selfish interests. The investigators continue this line of research, focusing on the study of mechanism design, also known as incentive engineering. A mechanism is a protocol (or algorithm) that is explicitly designed so that rational participants, motivated solely by their self-interest, end up achieving the designer's goals. Research into mechanism design for private value optimization problems is fundamental to the design and effective functioning of systems, such as networks and peer-to-peer systems, systems based on software agents (as studied in artificial intelligence), and systems for data mining and electronic commerce.<br/>The major intellectual challenges being undertaken include: (1) the design and analysis of new, more effective and efficiently implementable techniques for profit maximization in mechanism design, especially in online and repeated settings; (2) the development of a theory of profit benchmarks; (3) the design and analysis of profit-maximizing pricing schemes; (4) the development and study of alternative solution concepts and appropriate corresponding analysis frameworks; (5) the incorporation of new aspects of utility into the study of mechanism design; (6) the exploration of new design and analysis techniques in repeated games such as the use of low internal regret strategies to achieve approximate correlated equilibria; (7) the development of a theory of reputation; and (8) the theoretical and empirical study of other practical problems with interesting incentive structures, including ad auctions, routing, and backoff in wireless networks.<br/>"
86260,Educational Innovation:  Integrating Intelligent Agent and Wireless Computing Research into the Undergraduate Curriculum,CNS,EXPERIMENTAL SYSTEMS/CADRE,1/1/2001,9/27/2000,Diane Cook,"Cook, D","Cook, D|Das, S|Holder, L|Kamangar, F|Yerraballi, R",TX,University of Texas at Arlington,Standard Grant,Anita J. LaSalle,12/31/2004,"$329,915.00 ","Sajal Das, Lawrence Holder, Farhad Kamangar, Ramesh Yerraballi",cook@eecs.wsu.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,CSE,4725,"2888, 9218, HPCC",$0.00 ,normalFunding,"EIA- 0086260<br/>Cook, Diane J.<br/>University of Texas at Arlington<br/><br/>CISE Educational Innovation:  Integrating Intelligent Agent and Wireless Computing Research into the Undergraduate Curriculum<br/><br/>The research-base for this project is Artificial Intelligence (AI), in particular, rational agent development. The project provides undergraduate students with access to a large-scale distributed mobile agent laboratory containing both real and simulated agents. The focus of the project is new curriculum material for AI, mobile computing, multimedia, and robotics courses that allow students to test their knowledge in a real and virtual environment as well as new courses in human-computer interaction and wireless-multimedia computing. The PIs have demonstrated successful research and development of AI simulators that provide students with environments for testing agent design ideas in decision making, multi-agent cooperation, and learning.  The PIs expanded agent environment includes real-world tasks involving distributed decision-making, cooperation with both human and computer agents, and wireless communication. The project increases students' interest and expertise in this area through hands-on experiences with physical and simulated collaborative environments.  In particular, the project uses a wireless communication system, called Wireless Intelligent Simulator Environment (WISE), in this institution's Computer Science area that permits human, software, and robot agents to interact over a distributed environment. The WISE environment, in addition to supporting new features of this university's existing courses (in AI, Mobile Networking and Computing, Multimedia, Robotics, and Senior Capstone Design Courses), supports new courses in Human-Computer Interaction and Wireless Multimedia Computing. <br/>"
1551866,CompCog: The edge of the lexicon: Productive knowledge and direct experience in the acquisition and processing of multiword expressions,BCS,"LINGUISTICS, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",8/15/2016,8/22/2016,Roger Levy,"Levy, R","Levy, R",MA,Massachusetts Institute of Technology,Standard Grant,William J. Badecker,1/31/2020,"$329,233.00 ",,rplevy@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,SBE,"1311, 7252, 7495","1311, 7252, 7495, 9179",$0.00 ,normalFunding,"Language is the most discrete, measurable cultural record of the human mind, and is uniquely expressive among the communicative systems found in nature. Every day we comprehend hundreds of sentences that we hear or read but have never encountered before, and we produce hundreds more. Yet our success at these many acts of communication belies the difficulty of the task: language is rife with ambiguity, our attention is limited, our environments may be noisy, and we often have incomplete information about the shared knowledge and beliefs of the people we engage with. This ability, unique to our species, poses profound challenges for our scientific understanding of the capabilities of the human mind.  Deepening our understanding of these capabilities requires a combination of ideas and methods from linguistics, psychology, and computer science. Advances in this area help lay the groundwork for improvements in natural language technologies such as document summarization, paraphrasing, question answering, and machine translation, and in better identification, diagnosis, and treatment of language disorders.<br/><br/>Within this broader research enterprise, this project focuses on the ""edge of the lexicon"", elucidating the conditions under which a linguistic expression begins to get stored in the mind of the native speaker who uses it, and the consequences of the expression being stored as a holistic unit. Native speakers know both productive rules that license and allow interpretation of phrases and sentences that they have never before encountered and a rich inventory of lexical items that can be combined through these productive rules. Many of these lexical items are individual words, but there is evidence that specific, frequent multi-word expressions, such as ""meat and potatoes"" or ""large majority"" may also get stored in the lexicon. This project combines artificial intelligence-based computational models, large linguistic datasets, and controlled psychological experimentation to explore the edge of the lexicon, probing how direct experience with specific multi-word expressions leads to their being stored in one's mental lexicon, how such storage is reconciled with productive knowledge in language comprehension and production, and how these expressions emerge and change over time."
119270,Automating the Evolution of Agent Communication Languages Using Negotiation,IIS,DIGITAL SOCIETY&TECHNOLOGIES,10/1/2001,7/10/2003,Piotr Gmytrasiewicz,"Gmytrasiewicz, P","Gmytrasiewicz, P",IL,University of Illinois at Chicago,Continuing grant,William Bainbridge,9/30/2005,"$327,992.00 ",,piotr@cs.uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,6850,"9218, HPCC",$0.00 ,normalFunding,"This research aims to understand and automate the mechanisms by which language can emerge among artificial, knowledge-based and rational agents that interact in open, heterogeneous, and distributed environments. The intent is to design and implement agents that, upon encountering other agent(s) with which they do not share an agent communication language, are able to initiate creation of, and further are able to evolve and enrich, a mutually understandable communication language. The novelty of this research is that it enables the agents to develop and evolve, on their own, the capacity of communicating via a common language, as opposed to relying on this ability to be pre-designed and built into the agents by their designers. This research is supported by two streams of research, 1) the design of rational, socially competent artificial agents, and 2) the mechanism of negotiation as developed in game theory and automated in artificial intelligence research. This work will contribute to fundamental research in heterogeneous and open multiagent systems, effective communication among artificial agents in realistic settings, practical multiagent system design and the training of undergraduate and graduate students.<br/><br/><br/><br/>"
9423967,Negotiation and Cooperation in Multi-Agent Environments,IIS,DIGITAL SOCIETY&TECHNOLOGIES,6/1/1995,3/12/1997,Jonathan Wilkenfeld,"Wilkenfeld, J","Wilkenfeld, J|Kraus, S",MD,University of Maryland College Park,Continuing grant,C. Suzanne Iacono,5/31/1999,"$326,139.00 ",Sarit Kraus,jwilkenf@gvpt.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,6850,"9217, HPCC",$0.00 ,normalFunding,     This is the first year funding of a three-year continuing  grant.  Research in distributed artificial intelligence (DAI) is  concerned with how automated agents can be designed to interact  effectively.  This proposal involves the use of a strategic-  negotiation model to achieve inter-agent cooperation.  During the  strategic-negotiations agents communicate their respective desires  and compromise to reach mutually beneficial agreement.  Strategic-  negotiation is a process that may include several iterations of  offers and counter offers.  A major consideration in this domain  has been to reduce overhead costs resulting from planning and  negotiation time.  This research examines resource allocation and  task distribution problems among autonomous agents.  The objective  is the development of an automated agent capable of efficient  cooperation with other agents in its environment.
1623091,EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL),IIS,Cyberlearn & Future Learn Tech,9/1/2016,8/26/2016,Andee Rubin,"Rubin, A","Rubin, A",MA,TERC Inc,Standard Grant,Amy Baylor,8/31/2019,"$324,979.00 ",,andee_rubin@terc.edu,2067 Massachusetts Avenue,Cambridge,MA,21401339,6178739600,CSE,8020,"8045, 8841",$0.00 ,normalFunding,"The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
9625489,Theory and Applications of Approximate Dynamic Programming,CMMI,"CONTROL, NETWORKS, & COMP INTE, OPERATIONS RESEARCH",7/1/1996,6/16/1998,John Tsitsiklis,"Tsitsiklis, J","Tsitsiklis, J|Bertsekas, D",MA,Massachusetts Institute of Technology,Continuing grant,Lawrence M. Seiford,12/31/1999,"$324,799.00 ",Dimitri Bertsekas,jnt@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,ENG,"1518, 5514","9147, MANU",$0.00 ,normalFunding,"9625489 Tsitsiklis This project deals with problems of sequential decision making under uncertainty that are too large for the classical methods of dynamic programming. The focus is on approximate dynamic programming which is a rich field that combines classical dynamic programming, reinforcement learning and other methods from artificial intelligence, approximation theory and neural networks, and simulation. The objectives of the research are as follows: (1). Resolve several outstanding question related to simulation-based methods involving lookup table representations. (2). Provide a theoretical understanding of approximate dynamic programming methods, when a compact representation of the cost-to-go function is employed. In particular, identifying classes of algorithm/architecture combinations for which convergence is guaranteed, together with error bounds. (3). Develop the theory and algorithms for average cost approximate dynamic programming. (4). Develop the theory and algorithms for approximate dynamic programming for the case of Markov games. (5). Carry out a number of case studies that will provide a better understanding of the comparative performance of different methods, and to demonstrate the usefulness of the methods on realistic problems of real-world importance. Three case studies involve: (a) Dynamic scheduling of a fleet of trucks (b) Pricing of complex derivative financial instruments. (c) The game of football. The overall objectives are to provide a comprehensive mathematical foundation for the field of approximate dynamic programming and at the same time succeed in solving some difficult and important problems."
1709641,BRAIN: Brain-Inspired Memristive Nanofiber Neural Networks,ECCS,"ENERGY,POWER,ADAPTIVE SYS",8/1/2017,6/26/2017,Juan Nino,"Nino, J","Nino, J",FL,University of Florida,Standard Grant,Anthony Kuh,7/31/2020,"$323,660.00 ",,jnino@mse.ufl.edu,1 UNIVERSITY OF FLORIDA,GAINESVILLE,FL,326112002,3523923516,ENG,7607,155E,$0.00 ,normalFunding,"The human brain is currently the most powerful information processor known to man. Recent advances in neural networks and network science indicate that in order to match the power and efficiency of the brain, there is a need for a brand-new type of neuromorphic hardware that is able to connect physically independent neurons with dedicated, modifiable synapses. The PI and coworkers have developed a brain-inspired concept where, preliminary theoretical and experimental results show that a mat of memristive nanofibers is anticipated to yield neural networks with enhanced connectivity, functionality, and overall performance. This project aims at assessing the potential of this concept and it is guided by the overarching fundamental question can these brain-inspired memristive nanofiber neural network (MN3) architectures be effectively used for advanced neuromorphic computing.<br/><br/>The intellectual merit of the project stems from its goal to investigate the potential of MN3 architectures as the basis for novel neural network architectures that emulate the brain's computational abilities. This BRAIN project has three main objectives: 1) Manufacture MN3 architectures based on connective matrices of conductive-core, memristive-shell nanofibers and electrically characterize the networks in order to compare their characteristics to theoretical simulations; 2) Develop a simulation framework for modeling the proposed MN3 architectures in order to investigate and predict the signal behavior and computational properties of the networks; and 3) Investigate methods for implementing and training the networks as artificial neural networks, and evaluate the resulting networks on a set of benchmark machine learning tasks to determine performance characteristics. <br/><br/>The broader impacts of the project can be summarized in four main areas: a) investigation of a new brain-inspired design paradigm for fabricating neural networks that, if successful, can potentially transform the broad fields of neuromorphic hardware and machine learning; b) advancement of the discovery and understanding of neural network architectures while training undergraduate and graduate students in STEM fields; c) dissemination of the gained scientific and technological understanding of memristive networks through professional conferences, peer-review publications, and online hubs; and d) dissemination of tutorials and workshops on Artificial Intelligence targeting the general population in collaboration with the Cade Museum."
9357761,NSF Young Investigator,IIS,HUMAN COMPUTER INTER PROGRAM,8/1/1993,7/12/1999,Lynn Stein,"Stein, L","Stein, L",MA,Massachusetts Institute of Technology,Continuing grant,Ephraim P. Glinert,1/31/2000,"$322,300.00 ",,las@olin.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,6845,"9218, 9297, HPCC",$0.00 ,normalFunding,"The purpose of this project is to bridge the gap between the interactive capacities of current robotic agents and human-like cognitive abilities that have long been the aim of artificial intelligence research. The basic thesis is the concept that embodiment itself both enables and constraints our cognitive capacities. Through interaction with imagined stimuli we reuse concrete machinery for abstract tasks. By agreeing as a society to interpret arbitrary signals in terms of our experiences, we develop symbolic language. We understand music, metaphor, and even mathematics by virtue of their relationships to our physical experiences. This project utilizes this thesis as a foundation and further explores the ways in which sophisticated, symbolic, and abstract forms of cognition are built on our embodied experiences."
99091,Issues in the Applied Analysis of Markets,SES,ECONOMICS,6/1/2001,4/26/2006,Ariel Pakes,"Pakes, A","Pakes, A",MA,National Bureau of Economic Research Inc,Continuing grant,Daniel H. Newlon,5/31/2007,"$321,712.00 ",,apakes@fas.harvard.edu,1050 Massachusetts Avenue,Cambridge,MA,21385398,6178683900,SBE,1320,"0000, OTHR",$0.00 ,normalFunding,"Abstract: Issues in the Applied Analysis of Markets.<br/><br/>This proposal has several parts. The first is to extend prior models of demand<br/>systems in characteristic space. These models were primarily developed to<br/>provide a tool that enables the user to analyze (own and cross) price and<br/>characteristic elasticities of demand. The same models can (and have) been<br/>used to evaluate the demand for and the utility derived from new goods, but<br/>their implications in those contexts are questionable (these include applica-<br/>tions like evaluating the returns to innovations, or constructing price indices).<br/>This is because some of the model's properties vis a vis the evaluation of new<br/>goods are ""counterintuitve"".<br/><br/>We consider a change in the demand model that gets rid of these coun-<br/>terintuitive implications, and then compare alternative ways of evaluating<br/>new goods. One of the alternatives is \hedonic"" analysis; a technique which<br/>is currently used to correct the CPI for new goods bias. In doing this com-<br/>parison I will provide a detailed analysis of alternative ways of computing<br/>hedonic corrections. Hopefully this will be of use to the statistical agencies.<br/><br/>The second section of the proposal seeks to extend methods for computing<br/>and analyzing dynamic games to allow for asymmetric information. We focus<br/>on models which can detect and analyze collusive outcomes, and show how<br/>the learning and artificial intelligence literatures can help provide a simple<br/>tool for such an analysis.<br/><br/>The third section of the proposal outlines a new and relatively simple<br/>procedure for estimation and subsequent empirical analysis of oligopolistic<br/>markets when either asymmetric information, or dynamic considerations, are<br/>important. I hope to explore the range of application and performance of<br/>this technique. The technique was developed while I was trying to sort out<br/>research strategies for two new empirical projects, one on the demand for<br/>pharmaceuticals and one on deregulated electric utility markets. The two<br/>final sections of the proposal outline these projects.<br/><br/>Both empirical projects are joint with colleagues who have worked exten-<br/>sively on the industries studied. Our goal in the project on the demand for<br/>pharmaceuticals is to understand how past experience, marketing, and infor-<br/>mation on product performance, interact with other market characteristics<br/>to shape demand. We are particularly interested in the impact of advertis-<br/>ing on demand and on welfare, and on how recent institutional changes, like<br/>the development of the Over the Counter market for some durgs, impact on<br/>demand and welfare.<br/><br/>The project on deregulated British electric utility markets will initially<br/>focus on getting estimates of start up and capital costs. This should enable<br/>us to provide measures of profitability that take account of these costs. This,<br/>in turn, will enable us to quantify the incentives to invest in more generating<br/>capacity that are provided by the institutions which determine the newly<br/>derregulated market outcomes. Later we hope to engage in a more in depth<br/>analysis of the relationship between different aspects of these institutions<br/>and the price and quantity allocations that are likely to be generated by the<br/>market."
513605,Collaborative Research: Information Integration for Locating and Querying Geospatial Data,IIS,"BE: NON-ANNOUNCEMENT RESEARCH, INFO INTEGRATION & INFORMATICS, ITR-INFORMATION INTEGRATION",7/15/2005,11/23/2010,Nancy Wiegand,"Wiegand, N","Wiegand, N",WI,University of Wisconsin-Madison,Standard Grant,Sylvia J. Spengler,6/30/2011,"$320,754.00 ",,wiegand@cs.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,CSE,"1629, 7364, 7373","9216, 9251, HPCC",$0.00 ,normalFunding,"The objective of this work is to extend significantly the capabilities of portals created by the geospatial community, by providing semantic integration over diverse data sets. For example, the Wisconsin Land Information System and the new Federal Geospatial One-Stop portals disseminate data and support procedures and simulations in emergency situations. However, geospatial data are complex and highly heterogeneous, having been developed independently by various levels of government and the private sector. This project includes metadata integration methods to enable more precise location of data sources over the web and to provide geospatial portals with query capabilities and semantic resolution for the types of information integration that could help in information discovery, problem-solving, or emergency response.<br/><br/>The research will develop methods and tools to support the integration of information in such a way that end users will have a homogeneous view over heterogeneous data sources. An ontology-based architecture will be developed with which each individual heterogeneous data source can be added to the network of information with relatively little effort. Ontology mappings will establish correspondences between terms in heterogeneous sources and those of standard models and ontologies. The approach also extends ontology mappings to incorporate semantics regarding spatial considerations, such as accuracy, for spatial integration.<br/><br/>Information integration is an area of research that stretches over databases, artificial intelligence, digital libraries, and the semantic web. This project will extend significantly the state of the art of information integration in general and of geospatial information integration in particular, by providing a robust and scalable framework that encompasses techniques and algorithms for integrating heterogeneous data sources using an ontology-based approach.<br/><br/>This project's goal of semantic integration for geospatial data fits into a broad vision for creating a cyberinfrastructure on the Web. In a geospatial cyberinfrastructure, data will be automatically located and semantically matched to other relevant data sources. Manual intervention will not be needed or will be minimal. With such a structure, emergency managers, government officials, and the general public will not be constrained to pre-formulated queries. Instead, ad hoc, exploratory queries and analyses will be possible. From an educational viewpoint, the project will significantly benefit the training of graduate and undergraduate students, in particular of women and minorities, and will include the design of new graduate and undergraduate courses."
1016713,RI: Small: Decision-Theoretic Control of Crowd-Sourced Workflows,IIS,"Cyber-Human Systems (CHS), ROBUST INTELLIGENCE",9/15/2010,4/11/2012,Daniel Weld,"Weld, D","Weld, D|Mausam, M",WA,University of Washington,Standard Grant,todd leen,8/31/2014,"$320,669.00 ",Mausam Mausam,weld@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7367, 7495","7367, 7923, 9251",$0.00 ,normalFunding,"Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people as an open request for services. Requesters use crowd-sourcing for a wide variety of jobs like dictation-transcription, content screening, linguistic tasks, user-studies, etc. These requesters often use complex workflows to subdivide a large task into bite-sized pieces (including the management of these tasks), each of which is independently crowd-sourced. These workflows are paramount to the success of crowd-sourcing, still, there has been little attention paid to methods for dynamically optimizing the throughput of a workflow. Controlling and optimizing such a workflow is an excellent application for AI research for two reasons. First, it is challenging in that the agent has to understand the dynamics of an uncertain, real-time environment and reason about distinct choices for a decision. More importantly, the domain has significant economic value -- progress can potentially impact hundreds of thousands of people and spur economic development in a fast growing sector.<br/><br/>This project is investigating complex workflows using a decision-theoretic framework that optimizes for a quality/price trade-off, with aims of (1) building statistical models of worker behavior derived from a large corpus of online behavior, (2) defining a declarative representation language to describe a wide range of workflows, and (3) developing an automated scheme that optimizes a general workflow resulting in an automated controller for making informed decisions at various stages of the process and for monitoring worker accuracies and computing corrections based on them. In the longer term, perhaps beyond the scope of this project, is (4) development of an interface optimizer that automatically learns the best user interface for a task based on user behavior increasing throughput of the workflow, and (5) integrating these ideas in an open-source, software toolkit to directly benefit the various requesters in managing their tasks."
851783,"REU Site for Artificial Intelligence, Natural Language Processing and Information Retrieval",IIS,RSCH EXPER FOR UNDERGRAD SITES,7/1/2009,6/22/2009,Jugal Kalita,"Kalita, J","Kalita, J|Boult, T",CO,University of Colorado at Colorado Springs,Standard Grant,Maria Zemankova,6/30/2013,"$320,510.00 ",Terrance Boult,jkalita@uccs.edu,"1420, Austin Bluffs Parkway",Colorado Springs,CO,809183733,7192553153,CSE,1139,"6890, 9218, 9250, HPCC","$320,510.00 ",normalFunding,"<br/> <br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>This site at the University of Colorado at Colorado Springs hosts 8 students for 10 weeks in the summers of three years to do research in the areas of computer vision, artificial intelligence, natural language processing, information retrieval, knowledge management, and related topics. The experience includes a combination of theoretical reading and research with a hands-on environment to increase the scope of participants? knowledge of the project areas. The students attend classes to be introduced to the topics and also to obtain and in-depth understanding of selected topics. They also perform hands-on research, and are exposed to ethical issues. Researchers from MITRE, an industrial partner, are also serving as mentors in this project. This provides the students with an interesting introduction to, and training in, both applied and academic research.<br/><br/>Intellectual Merit: The research areas of computer vision, artificial intelligence, natural language processing, information retrieval, knowledge management are especially important to applied research and technology transfer in our age of information based society and workplaces. The researchers have strong track records in their areas of expertise, and have tied their scholarly strengths to interesting, timely, and useful interdisciplinary projects that connect to linguistics, biometrics, and bioinformatics, for example.<br/><br/>Broader Impact: The projects that have been chosen are attractive to students in that they show the transfer of research to practical problems of our time. This assures that students who engage in this experience are more likely to continue to engage in technology research and development.<br/><br/>"
1710302,Magneto-optoelectronic response in 2D atomic-layered materials,ECCS,"ELECT, PHOTONICS, & MAG DEVICE",8/1/2017,7/3/2017,Ramesh Mani,"Mani, R","Mani, R",GA,"Georgia State University Research Foundation, Inc.",Standard Grant,Paul Lane,7/31/2020,"$320,418.00 ",,rmani@gsu.edu,58 Edgewood Avenue,Atlanta,GA,303032921,4044133570,ENG,1517,"094E, 100E",$0.00 ,normalFunding,"Abstract:<br/>Non-technical Description:<br/>The United States has the highest Gross Domestic Product in the world because it has been the leader in technological breakthroughs. Relatively recent advances such as the personal computer, the World Wide Web, the cell phone, high definition television, the forth-coming autonomous car and artificial intelligence, all have roots in government funded research and development. The meteoric growth in these areas has been made possible by the rapid advances in semiconductor capability for both electronics and photonics. To access new areas for growth, there is now a need to develop flexible, faster, thinner, and more power efficient semiconductor materials with new capability. This aim has led to the so-called van der Waals bonded materials, which are materials that can be peeled, layer by layer, down to the thickness of a single 2-dimensional (2D) atomic layer. Such materials promise high speed, greater power efficiency, flexibility, and novel electro-optic properties not found in materials utilized thus far. Thus, this research aims to study their material properties with a view towards applications. <br/>The research is to be carried out in the Physics & Astronomy Department of Georgia State University [GSU], one of the most diverse universities in the nation. The undergraduate Science, Technology, Engineering and Mathematics (STEM) educational component of this proposal aims to translate the abilities of general university students from historically underrepresented groups and women in STEM fields, into the pursuit of a career path in a STEM field, by providing them early exposure to a supportive, confidence building, research experience through mini-science projects in the 2D materials area. Such education/training provided in a southern urban inner-city academic institution in downtown Atlanta, Georgia, will help to add underrepresented sections of society to the nation's science and technology skill base for the electronics, photonics, defense, and wireless communications industries. <br/>Technical Description:<br/>Single atomic layers of bulk van der Waals bonded crystals, and stacks built up by van der Waals epitaxy including a number of single atomic layers with differing electronic, optical, spin, and superconducting properties, offer the possibility of obtaining new physical properties not available in existing bulk materials' properties that can be utilized to address outstanding technological problems in low power and flexible electronics, sensing, and photonics. Thus, this research will experimentally examine the magneto-optoelectronic response under steady state photo-excitation of 2D atomic-layered materials including mono-layer and bilayer graphene, atomically thin hexagonal boron nitride (h-BN), mono- and bilayer-molybdenum disulfide (MoS2), and other transition metal-dichalcogenides. A research team consisting of graduate students and a postdoc, with help from undergraduates participating in mini science projects, will build up 2D atomic-layered crystals by van der Waals epitaxy; fabricate devices by electron beam lithography, plasma etch, and metallization; and examine the properties of electrically contacted and non-contacted devices in the presence of a magnetic field under microwave, mm-wave, and terahertz photo-excitation. Here, some specific problems of interest include the mm-wave magneto-response of graphene, the electric field effect on photoresponse in h-BN encapsulated graphene and MoS2, and the study of the spin properties in graphene across the neutrality point. Such studies are expected to provide insight into the electronic structure of 2D materials, their photo response, spin-g-factors, spin lifetimes, and the dependence of induced bandgaps on applied electric and magnetic fields - attributes that would identify the suitability of such systems for various desirable applications.  Potentially transformative results could include the observation of novel radiation-induced magnetoresistance oscillations in graphene, the realization and measurement of long spin lifetimes in h-BN encapsulated graphene, and the measurement of bandgaps in electric field biased bilayer h-BN encapsulated graphene or MoS2 or other transition metal dichalcogenides in the small bandgap limit."
238323,CAREER:     Statistical Methods for Dimensionality Reduction in Machine Learning,IIS,"ITR SMALL GRANTS, ARTIFICIAL INTELL & COGNIT SCI",7/1/2003,5/22/2006,Lawrence Saul,"Saul, L","Saul, L",PA,University of Pennsylvania,Continuing grant,Edwina L. Rissland,11/30/2006,"$320,000.00 ",,saul@cs.ucsd.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,"1686, 6856","1045, 1187, 9218, HPCC",$0.00 ,normalFunding,"This research addresses the problem of dimensionality reduction, discovering low dimensional structure hidden in high dimensional data.  It arises in many fields of information processing, and poses a particular challenge to researchers attempting to build machines that emulate feats of human perception, such as recognizing faces and understanding speech. It also plays an increasingly prominent role in many applications of statistical and scientific computing. With the advent of widespread information technologies, it has become possible to collect and manipulate ever-increasing amounts of experimental data. Thus, scientists interested in the exploratory analysis and visualization of large multivariate data sets face similar challenges in information processing as our perceptual systems.<br/><br/>This research focuses on two recently proposed algorithms for dimensionality reduction. The two algorithms address the ""curse of dimensionality"" as it arises in two different settings of machine learning: (1) unsupervised learning, where the dimensionality reduction is performed without any feedback from the learning environment, and (2) supervised learning, where the dimensionality reduction is performed with the benefit of labeled examples.<br/><br/>The first algorithm to be studied is Locally Linear Embedding (LLE), an unsupervised learning algorithm that computes low dimensional, neighborhood preserving embeddings of high dimensional data. The data, assumed to lie on a nonlinear manifold, is mapped into a single global coordinate system of lower dimensionality. The mapping is derived from the symmetries of locally linear reconstructions, and the actual computation of the embedding reduces to a sparse eigenvalue problem. Notably, the optimizations in LLE (though capable of generating highly nonlinear embeddings) are simple to implement, and they do not involve local minima. LLE has applications to exploratory data analysis, scientific visualization, and computer vision.<br/><br/>The second algorithm is Multiplicative Margin Maximization (M3), a supervised learning algorithm for nonnegative quadratic programming in support vector machines (SVMs). Support vector machines currently provide state-of-the-art solutions to many problems in machine learning, particularly those involving data sets of high dimensionality. Solving the quadratic programming problem in SVMs, however, remains a significant bottleneck in their implementation. The M3 algorithm is designed to alleviate this bottleneck. Its update rules have a simple closed form, and they converge monotonically to the solution of the maximum margin hyperplane. Moreover, they do not involve any heuristics such as choosing a learning rate or deciding which variables to update at each iteration. They optimize the traditionally proposed objective function for SVMs and can be applied to problems in classification, regression, and novelty detection.<br/><br/>The algorithms to be studied in this research are easy to implement, but the problems they solve are quite complex. Compared to previous approaches, they are distinguished not only by their novel simplicity and well-behaved optimizations, but also by the unexpected connections they make to other areas in mathematics, computer science, and statistics. The work will not only develop the theoretical foundations of these algorithms, but also attempt to scale them up to increasingly large problems in machine learning.<br/><br/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century.  The research is expected to have a broad impact across many areas of science and engineering, by overcoming the challenges posed by data sets of extremely high dimensionality. Software toolkits will be published, so that researchers everywhere will have access to state-of-the-art methods for dimensionality reduction. The educational innovations will include new undergraduate and graduate courses in artificial intelligence, machine learning, statistical computing, and sensory processing.<br/>"
110991,Neural Mechanisms of Nutritional Homeostasis,IOS,"BEHAVIORAL NEUROSCIENCE, NEUROENDOCRINOLOGY",9/15/2001,11/4/2004,Rhanor Gillette,"Gillette, R","Gillette, R",IL,University of Illinois at Urbana-Champaign,Continuing grant,Diane M. Witt,8/31/2005,"$319,993.00 ",,rhanor@uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,BIO,"1191, 1193","1096, 1162, 9183, BIOT",$0.00 ,normalFunding,"Simple and complex animals, including humans, are always faced with the need to decide wisely upon actions using incomplete information. How the nervous system is organized to do this has been a major puzzle. However, we know that animals make most decisions using their own affective state as information, and that in their computations they integrate their own internal state with sensation and experience to arrive at decisions. The result represents a cost-benefit analysis of a behavioral decision in terms of probable benefit, resource loss and possible self-damage. This proposal describes plans to study the neural basis of cost-benefit analysis in decision-making in foraging behavior using a model predator species with simple body form, behavior and nervous system. Three goals are outlined: 1) to find how satiation and prey-avoidance learning influence decision-making mechanisms in the nervous system for attack or avoidance; 2) to determine the role of serotonin, a critical biasing factor, in the mechanisms of decision-making; and 3) to summarize and test the results in a computational model of the neural networks. The expected results are significant to the development of autonomous robots capable of making least-probable-error decisions in a noisy environment, and to the evolution of artificial intelligence for which motivation-based processes may provide the critical regulation of goal related activity, just as in real intelligence systems. The results also relate directly to health issues of weight-control in anorexia and obesity, in that they approach the organization of processes regulating nutritional homeostasis.<br/><br/>"
632546,Collaborative Research:  Learning About Complex Systems in Middle School by Constructing Structure-Behavior-Function Models,DRL,"REAL, DISCOVERY RESEARCH K-12",9/15/2006,8/29/2009,Rebecca Jordan,"Jordan, R","Jordan, R|Hmelo-Silver, C",NJ,Rutgers University New Brunswick,Standard Grant,Elizabeth VanderPutten,8/31/2011,"$319,232.00 ",Cindy Hmelo-Silver,rebecca.jordan@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,EHR,"7625, 7645","1707, 9177, 9251, SMET",$0.00 ,normalFunding,"Background: Artificial Intelligence theories of model-based analogy in conceptual design have led to a<br/>methodology and a language for building functional and causal models of complex systems called<br/>Structure-Behavior-Function (SBF) models. An SBF model of a system explicitly represents its structure<br/>[S] (i.e., its configuration of components and connections), its functions (F) (i.e., its output behaviors), and<br/>internal causal behaviors [B] (i.e. its causal processes that compose the functions of the components into<br/>the functions of the system). The SBF language provides a vocabulary for expressing and organizing<br/>knowledge in a hierarchy, which captures functionality and causality at multiple levels of aggregation and<br/>abstraction.<br/>Empirical research in the Learning Sciences using the SBF methodology have led to substantial evidence<br/>that while experts model a complex system in terms of its structure, behaviors and functions, novices<br/>express primarily the structure of the system, demonstrate minimal understanding of its functions, and<br/>largely miss its behaviors."
9805366,Graphical Structures for Coding and Verification,CCF,"COMMUNICATIONS RESEARCH, DES AUTO FOR MICRO & NANO SYS",9/1/1998,6/14/2000,John Lafferty,"Lafferty, J","Lafferty, J|Bryant, R",PA,Carnegie-Mellon University,Continuing grant,Rodger E. Ziemer,8/31/2001,"$319,106.00 ",Randal Bryant,john.lafferty@yale.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"4096, 4710","9218, HPCC",$0.00 ,normalFunding,"Algorithms on graphical structures play a central role in both  communications technology and formal verification.  Minimal  trellises are graphical representations of error-correcting codes  that have emerged as a unifying framework for understanding and  manipulating codes of all types.  Ordered binary decision  diagrams and their variants are graph-based data structures for  representing Boolean functions that have found widespread use in  formal verification for a range of problems, including circuit  checking, logic synthesis and test generation.  This project  builds on the close correspondence that has recently been  established between the code trellis and binary decision diagram,  and investigates the transfer of ideas between these previously  disparate fields.  The fundamental challenge that confronts both  uses of graphical methods is the same: devise techniques to  combat the exponential blowup in the size of the graph.  The  research is interdisciplinary, and can be expected to have a  broad range of application, both within coding and verification,  as well as to such areas as artificial intelligence, database  search, and combinatorial optimization."
1241434,UTEP Summer Program in Applied Intelligent Systems,IIS,IIS SPECIAL PROJECTS,6/15/2012,6/1/2012,Olac Fuentes,"Fuentes, O","Fuentes, O",TX,University of Texas at El Paso,Standard Grant,William Bainbridge,5/31/2016,"$317,286.00 ",,ofuentes@utep.edu,ADMIN BLDG RM 209,El Paso,TX,799680001,9157475680,CSE,7484,7484,$0.00 ,normalFunding,"The Computer Science Department at the University of Texas at El Paso (UTEP), in collaboration with the departments of Biological Sciences, Mathematics, Electrical Engineering, and Psychology, offers an interdisciplinary REU summer program in applied intelligent systems. The program hosts eight students for a period of ten weeks during the summer. It emphasizes interdisciplinary research, where techniques developed in the area of artificial intelligence are applied to real-world problems in science and engineering. This will allow the students to gain a broader overview of science and engineering as a potential career than would be possible in more narrowly-defined research areas. <br/><br/>Each student will work on an individual interdisciplinary research project under the co-supervision of a faculty member from the computer science department and a faculty member from one of the collaborating departments. The unifying research theme will be the use of intelligent systems techniques, including machine learning, data mining, optimization, and image analysis, to solve relevant data analysis problems in science and engineering fields. Students will be able to choose from a large list of projects that includes automated analysis of astronomical images, seismic tomography using machine learning, and identifying foreign accents in speech, among many others.<br/><br/>To assist the development of each student's oral communication skills and broaden their views of science and engineering beyond their project, each student will informally present the progress of their research project to all other REU participants, including mentors, the REU Program Director, and to their fellow REU students at the REU weekly meeting. In addition to the weekly meetings, there is a seminar series with the main goals of improving students' research skills and increasing their understanding of potential career paths in computing-related fields. The program will conclude with a one-day symposium to highlight the achievements of the REU students."
1143713,EAGER: Shared Visual Common Ground in Human-Robot Interaction for Small Unmanned Aerial Systems,IIS,Cyber-Human Systems (CHS),8/1/2011,3/27/2012,Robin Murphy,"Murphy, R","Murphy, R|McKee, B",TX,Texas A&M Engineering Experiment Station,Standard Grant,Ephraim P. Glinert,7/31/2014,"$316,000.00 ",Bob McKee,murphy@cse.tamu.edu,TEES State Headquarters Bldg.,College Station,TX,778454645,9798477635,CSE,7367,"7367, 7916, 9251",$0.00 ,normalFunding,"This project will create a computational theory of visual common ground, allowing users to give directives to a robot (or other team members) and receive confirmation or constraints through visual communication over a shared visual display. The motivating example is an urban search and rescue (US&R) professional tapping, sketching, and annotating on an iPad in order to direct a small unmanned aerial system (sUAS) without training. Previous work in human-robot interaction with common ground has been limited to natural language, but recent work has shown that having all team members see the robot's eye view in unmanned ground robots significantly improved performance and situation awareness. The proposed work populate the computational theory using the Shared Roles Model to represent the inputs (directives, notations), outputs (display viewpoint, form, size, location, content, etc.), and transformations (visual communication engine). The computational theory will be prototyped, refined, and tested by US&R practitioners flying realistic sUAS missions at Texas A&M's Disaster City.<br/><br/>Intellectual merit: The project will create a computational theory of visual common ground that will enable two-way human-robot interaction using visual communication mechanisms such as tapping, sketching, and annotation on shared visual displays on mobile devices such as iPads, smartphones, and tablet PCs. The results will advance the fields of human-robot interaction, artificial intelligence, and cognitive science. <br/><br/>Broader impacts: The results could revolutionize how people use mobile devices to interact with robots (and with each other) using naturalistic visual mechanisms, bypassing extensive training. The project will actively recruit women, Hispanics, and persons with disabilities to participate through REU programs. An open source visual communication toolkit for HRI researchers will be produced. The results will improve robots for public safety, remote medicine, and telecommuting, and could also immediately help save lives through incorporation into Texas Task Force 1."
1048632,HCC: EAGER:  Authoring Game AIs by Demonstration for Real-Time Strategy Games,IIS,Cyber-Human Systems (CHS),9/1/2010,4/14/2011,Ashwin Ram,"Ram, A","Ram, A",GA,Georgia Tech Research Corporation,Standard Grant,William Bainbridge,2/29/2012,"$315,898.00 ",,ashwin.ram@parc.com,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"7367, 7916, 9251",$0.00 ,normalFunding,"This research will explore novel ""authoring by demonstration"" techniques for real-time strategy (RTS) games. Creating rich artificial intelligence (AI) behavior sets for complex computer games requires significant engineering effort. Developers need to anticipate all imaginable circumstances that the AI may encounter within the game world. The resulting AI is often static and results in predictable behaviors, detracting from the player experience. In addition, it is difficult for average players to create AI behaviors, without significant expertise in both AI and scripting. Modeling human-like goals and behaviors required for multiplayer games with semi-autonomous avatars adds additional complexity. This potentially transformative project will develop novel learning techniques that allow users to create intelligent behaviors simply by demonstrating them. The research will be done within the domain of RTS games, as these domains pose significant challenges that must be tackled in order to scale up the learning techniques to real-world tasks.<br/><br/>Case-based planners, hierarchical task network planners, or industry-standard behavior-tree execution engines require a library of base behaviors or methods in order to generate complete plans, which traditionally are coded by hand. The project will investigate ways to automate the process of generating such behavior libraries based on novel methods for learning strategic plans from user demonstrations. The techniques will be evaluated in the context of a case-based planning system for RTS games. RTS games are complex and involve strategic decision-making, multi-agent coordination, real-time interaction, and partially-observable environments. These properties pose significant challenges to existing AI methods for planning and learning. This research will make fundamental scientific contributions to learning, case-based reasoning, and AI for real-time strategic domains, addressing key problems in goal recognition, plan learning, and authoring support. <br/><br/>This research will enable game designers and other non-programmers to create the behavior sets for RTS games without requiring programming knowledge. This capability has two main consequences: first, it allows game developers to create games with less effort, and second it will enable a new genre of games where players would be able to create their own AIs as part of the game play. Additionally, as RTS games are essentially domain-specific simulations, the research will support authoring of behavior sets for domains such as simulation environments for training, real-time robotic control, organizational modeling for business decision-making, or sophisticated market simulations for economics strategy or public policy. The educational impact of the project is twofold. First, the project will constitute an important advance towards easy authoring of training simulators for educational applications that require environment with complex AI behaviors. This will enable development of new educational technologies with simulators or virtual worlds. Second, the project will involve undergraduate and graduate students in all phases of the work."
9817572,DLI-Phase 2: A Distributed Information Filtering System for Digital Libraries,IIS,DIGITAL LIBRARIES AND ARCHIVES,6/15/1999,5/24/2001,Mathew Palakal,"Palakal, M","Palakal, M|Raje, R|Mukhopadhyay, S|Mostafa, J",IN,Indiana University,Continuing grant,Stephen Griffin,2/28/2003,"$315,387.00 ","Rajeev Raje, Snehasis Mukhopadhyay, Javed Mostafa",mpalakal@iupui.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,CSE,6857,"1086, 9139, HPCC",$0.00 ,normalFunding,"Abstract <br/><br/>IIS-9817572 <br/>Palakal, Mathew <br/>Indiana University<br/>$101,604 - 12 mos.<br/><br/>DLI Phase 2: A Distributed Information Filtering System for Digital Libraries<br/><br/>This is the first year funding of a three year continuing award.  The proposed research is aimed at designing and developing a distributed intelligent information distribution and filtering system that provides personalized information services to the user while minimizing direct user involvement.  The system is intended to traverse the internet to retrieve the most relevant information of interest to the user.  Information filtering will be realized using a information agents, and will involve integration of advanced concepts and techniques from the domains of artificial intelligence, information retrieval, and distributed object computing.  The agents will contain models of network-based dynamic information resources and will have the capability to learn changing patterns of an individual user's interest. <br/><br/>Four key basic research areas to be addressed are:                                                                                        methods for adapting various knowledge structures associated with an agent <br/>new and robust agent architectures <br/>agent collaboration protocols based on a natural or artificial economic framework <br/>agent-driven information service operations<br/>"
852066,REU Site: UTEP Summer REU Program in Applied Intelligent Systems,IIS,"RSCH EXPER FOR UNDERGRAD SITES, SCIENCE, TECH & SOCIETY",4/15/2009,3/25/2011,Olac Fuentes,"Fuentes, O","Fuentes, O",TX,University of Texas at El Paso,Continuing grant,todd leen,3/31/2012,"$315,000.00 ",,ofuentes@utep.edu,ADMIN BLDG RM 209,El Paso,TX,799680001,9157475680,CSE,"1139, 7603","9216, 9250, HPCC",$0.00 ,normalFunding,"This project will be performed by the Computer Science Department at the University of Texas at ElPaso (UTEP), in collaboration with the departments of Psychology, Biological Sciences, Industrial Engineering, and Civil Engineering.  The topical focus will be Applied Intelligent Systems. The main goals of the project are to increase participation in science and engineering fields by traditionally underrepresented groups, to introduce science and engineering students to cutting edge interdisciplinary research, and toprovide students with an opportunity to familiarize themselves with graduate programs in science and engineering at a regional university. The program will host students for a period of ten weeks during the summer. It will emphasize interdisciplinary research, where techniques developed in the area of artificial intelligence will be appliedto real-world problemsinscience and engineering. This will allowthe students togain a broader overviewof science and engineering as a potential career than would be possible in more narrowly-defined research areas. An emphasis will be placed on recruiting students from minority-serving institutions and institutions that do not offer graduate programs in computer science. The proposed program will provide undergraduate students an opportunity to conduct full-time collaborative interdisciplinary research under the co-supervision of a faculty member fromthe computer science departmentand a faculty member from one of the collaborating departments hold a seminar series in which academic and non-academic careers in science will be discussed, promote extensive student-faculty and student-student interaction through weekly gatherings (research meetings and social/cultural activities) and undertake activities to mprove students' confidence and communication skills through oral and written presentations of project results and through Career Development Workshops.<br/><br/>Intellectual Merit<br/>The intellectual merit of this proposal lies in the unique combination of: a)well-planned interdisciplinary research projects, which can realistically be expected to be completed by an undergraduate student during one summer; b) mentorship by at least two faculty members from two different research departments,which enables students to gain a richer perspective about careers in science; c) emphasis on development of research skills over knowledge about a particular discipline; d) emphasis on recruitment by individualized invitation over self-selection of applicants, which is expected to attract larger numbers of minority applicants, and, f) participate in a proven mentor training program.<br/><br/>Broader Impacts<br/>The broader impact of this project will ultimately be increased numbers of students, in particular members of underrepresented groups, pursuing graduate studies in science and engineering and engagingin successful careers.It is expected that most of the students who participate in the project will enroll and successfully complete graduate studies and that a significant fraction of them will become faculty members at colleges and universities."
414722,Creating Effective Task Descriptions from Action Plans,IIS,"HUMAN LANGUAGE & COMMUNICATION, IIS SPECIAL PROJECTS",8/15/2004,7/27/2006,Robert Young,"Young, R","Young, R",NC,North Carolina State University,Continuing grant,Tatiana D. Korelsky,7/31/2008,"$315,000.00 ",,young@cs.utah.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,"7274, 7484","0000, 7274, 9178, 9218, 9251, HPCC, OTHR, SMET",$0.00 ,normalFunding,"Artificial intelligence planning systems are being put to use to determine the activities of a wide range of intelligent interactive systems. The ability for these kinds of systems to explain their plans to human users is essential for the systems' successful adoption and use. This project is investigating the generation of natural language descriptions of computer plans.<br/><br/>This work is developing a cognitive and computational model of task context and its role in the generation of action descriptions, specifically, the means by which negative constraints and justifications are used to create more effective task descriptions.  The project methodology includes both experimental and theoretical aspects; naturally occurring text corpora collected by the project is used to form a computational model for the production of plan descriptions that accounts for the discourse features described above. This model is then empirically evaluated to determine the model's efficacy.<br/><br/>The work demonstrates the effective use of automatically generated plan structures as underlying knowledge representations for task-based discourse.  The results have a direct impact on the use of intelligent information technologies used in training and education.   This enables applications that provide context-sensitive help to computer users that are themselves not experts in information technology, for example in the automatic generation of instructions in situations where pre-designed instructional materials or other resources are not available.<br/>"
1439007,XPS: FULL: DSD: Collaborative Research: Rapid Prototyping HPC Environment for Deep Learning,CCF,Exploiting Parallel&Scalabilty,8/1/2014,8/5/2014,Geoffrey Fox,"Fox, G","Fox, G|Qiu, J|Laszewski, Gv",IN,Indiana University,Standard Grant,Vipin Chaudhary,7/31/2017,"$315,000.00 ","Judy Qiu, Gregor von Laszewski",gcf@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,CSE,8283,,$0.00 ,normalFunding,"The impact of Big Data is all around us and is enabling a plethora of commercial services. Further it is establishing the fourth paradigm of scientific investigation where discovery is based on mining data rather than from theories verified by observation. Big Data has established a new discipline (Data Science) with vibrant research activities across several areas of computer science. This ?Rapid Python Deep Learning Infrastructure? (RaPyDLI) project advances Deep Learning (DL) which is a novel exciting artificial intelligence approach to Big Data problems, which also involves a sophisticated model and a corresponding ?big compute? needing high end supercomputer architectures. DL has already seen success in areas like speech recognition, drug discovery and computer vision where self-driving cars are an early target. DL uses a very general unbiased way of analyzing large data sets inspired by the brain as a set of connected neurons. As with the brain, the artificial neurons learn from experience corresponding to a ?training dataset? and the ?trained network? can be used to make decisions. Trained on voices, the DL network can enhance voice recognition and trained on images, the DL network can recognize objects in the image. A recent study by the Stanford participants in this project trained 10 billion connections on 10 million images to recognize objects in an image. This study involved a dataset that was approximately 0.1% the size of data ?learnt? by an adult human in their lifetime and one billionth of the total digital data stored in the world today. Note the 1.5 billion images uploaded to social media sites every day emphasize the staggering size of big data. The project aims to enhance by DL by allowing it to use large supercomputers efficiently and by providing a convenient DL computing environment that enables rapid prototyping i.e. interactive experimentation with new algorithms. This will enable DL to be applied to much larger datasets such as those ?seen? by a human in their lifetime. The RaPyDLI partnership of Indiana University, University of Tennessee, and Stanford enables this with expertise in parallel computing algorithms and run times, big data, clouds, and DL itself.<br/>RaPyDLI will reach out to DL practitioners with workshops both to gather requirements for and feedback on its software. Further it will proactively reach out to under-represented communities with summer experiences and DL curriculum modules that include demonstrations built as ?Deep Learning as a Service?.<br/>RaPyDLI will be built as a set of open source modules that can be accessed from a Python user interface but executed interoperably in a C/C++ or Java environment on the largest supercomputers or clouds with interactive analysis and visualization. RaPyDLI will support GPU accelerators and Intel Phi coprocessors and a broad range of storage approaches including files, NoSQL, HDFS and databases. RaPyDLI will include benchmarks as well as software and will offer a repository so users can contribute the high level code for a range of neural networks with benefits to research and education."
413335,Probabilistic Imitation Learning in Infants and Robots,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/1/2004,7/30/2004,Rajesh Rao,"Rao, R","Rao, R",WA,University of Washington,Standard Grant,Douglas H. Fisher,7/31/2007,"$314,975.00 ",,rao@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6856,"9218, HPCC",$0.00 ,normalFunding,"The overall goal of this project is to study learning through imitation and endow robots with the ability to learn in this manner. This cross-disciplinary project has two major goals. The first is to create models for imitation learning in robots that combines techniques from Artificial Intelligence and Bayesian machine learning with insights from cognitive and psychological studies of imitation. The project will use these models to develop a humanoid robot that can learn by watching humans perform specific tasks. The second is to determine what characteristics of a humanoid robot can cause human infants and toddlers to imitate it. This will help shed light on the question of whether infants ascribe intentions to robots. The PI will collaborate with cognitive psychologist, Dr. Andrew Meltzoff also from the University of Washington. The project will foster collaboration between students from both of their labs and provide them with training in carrying out interdisciplinary research.<br/>"
1524565,Comp Cog:  Collaborative Research on the Development of Visual Object Recognition,BCS,"DS - Developmental Sciences, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",8/1/2015,9/2/2016,James Rehg,"Rehg, J","Rehg, J|Li, F|Kunda, M",GA,Georgia Tech Research Corporation,Continuing grant,Chalandra Bryant,7/31/2019,"$313,582.00 ","Fuxin Li, Maithilee Kunda",rehg@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,SBE,"1698, 7252, 7495","1698, 7252, 7298, 7495, 9179",$0.00 ,normalFunding,"Human visual object recognition is fast and robust.  People can recognize a large number of visual objects in complex scenes, from varied views, and in less than optimal circumstances.  This ability underlies many advanced human skills, including tool use, reading, and navigation.  Artificial intelligence devices do not yet approach the level of skill of everyday human object recognition. This project will address one gap in current knowledge, an understanding of the visual experiences that allow skilled object recognition to develop, by capturing and analyzing the visual experiences of 1- to 2-year-old toddlers.  This is a key period for understanding human visual object recognition because it is the time when toddlers learn a large number of object categories, when they learn the names for those objects, and when they instrumentally act on and use objects as tools.  Two-year-old children, unlike computer vision systems, rapidly learn to recognize many visual objects.  This project seeks to understand how the training experiences (everyday object viewing) of toddlers may be optimal for building robust visual object recognition. The project aims to (1) understand the visual and statistical regularities in 1- to 2-year-old children's experiences of common objects (e.g., cups, chairs, trucks, dogs) and (2) determine whether a training regimen like that experienced by human toddlers supports visual object recognition by state-of-the art machine vision. <br/><br/>Considerable progress in understanding adult vision has been made by studying the visual statistics of ""natural scenes."" However, there is concern about possible artifacts in these scenes because they typically photographs taken by adults and thus potentially biased by the already developed mature visual system that holds the camera and frames the pictures. Also, photographed scenes differ systematically from the scenes sampled by people as they move about and act in the world.  Accordingly, there is increased interest in egocentric views collected from body-worn cameras, the method used in the present work.  Toddlers will wear lightweight head cameras as they go about their daily activities, allowing the investigators to capture the objects the toddlers see and the perspectives and contexts in which they see them.  The research will analyze the frequency, views, visual properties, and range of seen objects for the first 100 object names normatively learned by young children, providing a first description of the early learning environment for human visual object recognition.  These toddler-perspective scenes  will be used as inputs to machine learning models to better understand how the visual information in the scenes supports and constrains the development of visual object recognition. Machine-learning experiments will determine which properties and statistical regularities are most critical for learning to recognize common object categories in multiple scene contexts.  Data collected will be shared through Databrary, an open data library for developmental science."
9984827,CAREER:  Artificial Intelligence Planning with Realistic Preference Models,IIS,ARTIFICIAL INTELL & COGNIT SCI,2/15/2000,3/2/2005,Sven Koenig,"Koenig, S","Koenig, S",GA,Georgia Tech Research Corporation,Continuing grant,Edwina L. Rissland,10/31/2005,"$312,785.00 ",,skoenig@usc.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,6856,"1045, 9216, HPCC",$0.00 ,normalFunding,"This is the first year of funding of a 4-year continuing award. Preference models determine which one of several plans to prefer. It is important that planners use the same preference models as human decision makers because planners should make the same decisions as their human users, otherwise the planners are not of much use. The PI will investigate how to build planners that fit the preference models of human decision makers better than current planners, by combining constructive methods from artificial intelligence with more descriptive methods from utility theory in order to take advantage of the strengths of the two decision-making disciplines and to extend the applicability of Al planners. The PI will study optimal vs. good or near-optimal (""satisficing"") planning with a variety of preference models. He win explore how to exploit the structure of complex sequential planning tasks to solve them efficiently for realistic preference models suggested by utility theory, with an emphasis on preference models in high-stakes decision situations. To this end, he will focus on representation changes that make use of existing planners from AI by transforming planning tasks with nonlinear utility functions into others that these planning methods can solve, and will study the errors that result for the original planning task when satisficing planning methods are used instead. The research will be performed in the context of managing environmental crisis situations, such as cleaning-up marine oil-spills."
9634712,Nonhomogeneous Markov Decision Processes,CMMI,OPERATIONS RESEARCH,9/15/1996,10/20/2000,James Bean,"Bean, J","Bean, J|White, C",MI,University of Michigan Ann Arbor,Standard Grant,Lawrence M. Seiford,8/31/2001,"$312,419.00 ",Chelsea White,jcbean@uoregon.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,ENG,5514,"9147, MANU",$0.00 ,normalFunding,"9634712  Bean   This research involves the development of theory and algorithms to solve nonhomogeneous Markov decision problems.  The application area to be considered results from just-in-time production and distribution practices.  Massive data requirements and extremely long computation times make solving nonhomogeneous Markov a formidable task.  This research will develop theory that isolates the data important to making good decisions from the large volume of data that have no direct effect.  The primary approach will integrate forecast horizons, parametric Markov decision processes and genetic algorithms.  This theory will be embedded in algorithms that will be implemented and evaluated against data from production and transportation problems.    The relatively high-risk research objectives of (1) developing theory for solving nonhomogeneous Markov through treatment as parametric Markov decision processes and acceleration of parametric Markov decision processes algorithms using sampling information and (2) developing implementable algorithms to solve nonhomogeneous Markov using forecast horizon theory to reduce problem size, genetic algorithms to eliminate the bulk of the computation, and then the results of the genetic algorithms to accelerate parametric Markov decision processes algorithms to obtain a provably optimal solution have an excellent chance of being met.  The result will be a unique hybrid of artificial intelligence-based algorithms that result in fast computation times and provable optimality."
513376,Mining Structured Data with Applications in Chemistry and Biology,IIS,"SCIENCE & ENGINEERING INFORMAT, COLLABORATIVE RESEARCH",7/15/2005,3/28/2008,Pierre Baldi,"Baldi, P","Baldi, P",CA,University of California-Irvine,Standard Grant,Sylvia J. Spengler,6/30/2009,"$311,291.00 ",,pfbaldi@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,"7294, 7298","5914, 5979, 7298, 7364, 9215, 9216, HPCC",$0.00 ,normalFunding,"This project will develop novel data analysis algorithms that will enable scientists to discover new knowledge from large data sets of variable-size structured data. It will specifically focus on small molecules in organic chemistry that can be represented in various ways, such as the two-dimensional graph of covalent bonds. The project will develop new methods to explore chemical space and predict the physical, chemical, and biological properties of small organic molecules. <br/><br/>The research will directly address these problems by using annotated datasets of compounds in combination with machine learning approaches. Specifically, this project will develop new fingerprint representations of small molecules, for instance, by indexing the paths and trees contained in the molecular graphs, or by building histograms of three-dimensional distances between labeled pairs of atoms. Kernels methods - currently one of the leading methods in machine learning - will be used to measure similarity between fingerprints and to develop predictive algorithms for classification and regression tasks. The algorithms will be quantitatively evaluated in terms of their ability both to describe observed data and to predict new data. Selected applications to the prediction of critical temperatures, toxicity, mutagenicity, anti-cancer and other biological activity of small molecules will serve as testbeds for validating the techniques developed. Algorithms and data developed during the project will be made publicly available on the Web for research and scientific use. Educational activities included in this project will foster in computer science students an understanding of the increasingly important role of computer science and data mining in data-driven sciences such as chemistry. <br/><br/>New informatics methods for structured data will greatly benefit chemistry. The penetration of computational, artificial intelligence, and informatics methods in chemistry has been slower than in biology, because of the single-investigator nature of chemical research and the dominance of genome sequencing and other high-throughput projects in biology. Data on millions of compounds, however, are becoming readily available. By developing efficient fingerprints, kernels, and other machine learning methods for graphs and molecular structures, this project will address some of the most outstanding problems in the field and help accelerate the penetration of modern computational methods in chemistry. <br/><br/>The project has the potential for significant benefit to society. Small molecules have numerous applications in biology, pharmacology, and bioengineering. They can be used to probe and study biological pathways and systems and to develop new drugs. The algorithms developed by this project will provide basic building blocks and important steps towards understanding and predicting molecular properties from molecular structures. They will allow scientists to screen large data sets of compounds  rapidly, while searching for compounds that satisfy particular structural or functional constraints. This will produce cost savings, accelerate the development of new drugs, and promote the understanding of chemical space.  <br/>"
755534,"REU Site: Coordination, Communication, Autonomy: Principles and Technologies",IIS,RSCH EXPER FOR UNDERGRAD SITES,4/1/2008,2/26/2008,Gaurav Sukhatme,"Sukhatme, G","Sukhatme, G|Golubchik, L",CA,University of Southern California,Standard Grant,Kenneth C. Whang,3/31/2012,"$310,000.00 ",Leana Golubchik,gaurav@cs.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,1139,"9178, 9250, SMET",$0.00 ,normalFunding,"IIS - 0755534    <br/>Title: REU Site: Coordination, Communication, Autonomy: Principles and Technologies<br/>PIs: Gaurav Sukhatme and Leana Golubchik<br/><br/>Institution: University of Southern California<br/><br/>REU Site: Coordination, Communication, Autonomy: Principles and Technologies<br/><br/>PI: Gaurav S. Sukhatme Institution: University of Southern California<br/><br/>The objective of this REU site is to train students in research methodology and to enthuse them about Computer Science research. The intended impact is that a signicant proportion of the students go on to graduate school. Students will work with faculty mentors and their graduate students at the Computer Science department at the University of Southern California. A training program in ethics is planned as are three external research visits to local research labs in the Los Angeles area. A vibrant social program is planned to facilitate a sense of community wherein students will interact with participants in summer internship programs on the USC campus. A formal assessment of outcomes is planned via a principled and rigorous site evaluation program. The participating faculty mentors are well established in their fields and span a spectrum of cutting edge research topics in Computer Science.<br/><br/>Students participating in the program will have a chance to work on projects spanning robotics, agents and artificial intelligence, networks and systems, algorithms and modeling, and software engineering. Within robotics, projects are available in the newly emerging societally relevant area of robotics for healthcare and at- risk populations, networked robotics for scientic discovery covering water and air pollution monitoring, and humanoid robotics. Agents and artificial intelligence projects span multi-agent systems, planning and learning. Networking and systems projects include networked sensing and its use in scientic applications, scalable and robust routing infrastructures in large networks such as the Internet, data dissemination in wireless sensor networks, structural properties of the Internet and high level abstractions and analytical models.  <br/>Within algorithms and modeling, students may work on graph algorithms, applications to networks, randomized algorithms, and information flow through networks. Finally, projects are available in software architecture modeling and analysis for embedded systems, middleware facilities for architectural implementation and software reliability modeling.<br/><br/>We are especially interesting in attracting participation in the USC Computer Science REU site from three populations: 1. academically talented students from traditionally underserved colleges and universities, 2. women, and 3. underrepresented minorities.<br/>"
1145949,Diffusional Landscapes for the Study of Neural Differentiation,IOS,"ORGANIZATION, EPSCoR Co-Funding",8/1/2012,7/18/2012,Scott Collins,"Collins, S","Collins, S|Smith, R|Cox, G",ME,University of Maine,Standard Grant,Sridhar Raghavachari,7/31/2016,"$310,000.00 ","Rosemary Smith, Gregory Cox",scott.collins@maine.edu,5717 Corbett Hall,ORONO,ME,44695717,2075811484,BIO,"7712, 9150","1096, 9150, 9178, 9179",$0.00 ,normalFunding,"During early development of the central nervous system, the global landscape and concentration of chemical species within the spinal cord serve to direct neuron differentiation and development.  The chemical constituency and concentrations of myriad chemical stimulants within the spinal cord signals both the type of neural cells that will develop as well as provide a ""trail of breadcrumbs"" to direct the precise synaptic connections to other neurons.  This research presents a microsystem that generates specific concentration profiles of multiply relevant chemical species to study the development and differentiation of neurons.  Using micro and nanofabrication, a microsystem will be designed, fabricated, characterized, and used to generate chemical profiles of known chemicals that affect spinal cord development.  An anthology of four mouse spinal cord chemical mediators will be studied:  sonic hedgehog (Shh), bone morphogenic protein (BMP), retinoic acid (RA), and noggin, and the spatial and temporal histological distributions of resulting neural cells will be mapped to the imposed chemical mediator concentrations. The advantage of this approach is that cells can be studied in biologically relevant environments without the introduction of the myriad unknown and uncontrolled parameters found in vivo.  <br/><br/>This project will support the education and laboratory research training of both graduate and undergraduate students at the University of Maine in a collaborative, multi-disciplinary research project involving biological, micro/nano fabrication, and engineering methods in instrumentation and techniques. The project will also be highlighted in UMaine's ""Consider Engineering"" summer program for high school students and in several undergraduate and graduate level courses to introduce science & engineering initiates to interdisciplinary research. The microsystem will be extended within these programs/courses to encompass applications involving: cognition models, artificial intelligence, biocomputing, and neural networks."
934413,"Collaborative Research: I/UCRC for Safety, Security, and Rescue Research",CNS,INDUSTRY/UNIV COOP RES CENTERS,8/1/2009,9/27/2012,Richard Voyles,"Voyles, R","Voyles, R|Valavanis, K|Bauer, A|Mahoor, M|Anaraki, SP",CO,University of Denver,Continuing grant,Thyagarajan Nandagopal,7/31/2015,"$306,998.00 ","Kimon Valavanis, Amy Bauer, Mohammad Mahoor, Siavash Pourkamali Anaraki",rvoyles@purdue.edu,2199 S. University Blvd.,Denver,CO,802104711,3038712000,CSE,5761,"0000, 1049, 116E, 122E, 5761, 8039, 8042, 9102, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"0934327 University of Minnesota (UMN); Nikolas Papanikolopoulos <br/>0934413 University of Denver (UD); Richard Voyles<br/>   <br/>The purpose of this proposal is to renew and expand the Center for Center for Safety, Security and Rescue Research (SSR-RC) as an NSF Industry/University Cooperative Research Center.  This proposal is based upon UMN's successful completion of five years of operation of the SSR-RC; and the commitment by companies to join a research site at the University of Denver. UMN will be the lead research site for SSR-RC with the University of Pennsylvania (joined the Center a few years ago) and the University of Denver as research partners.  <br/> <br/>This proposal covers the renewal for the second-five years of UMN and the expansion to include UD.  The proposed Center will provide integrative robotics, sensing, and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, transportation safety, and emergency response to mass casualty-related events.  The Center is built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, human factors, and psychology at the three institutions.  The renewed and expanded Center will be successful because it builds on existing strengths developed during the first five years of operation.  The Center will also educate and train researchers for industry and government. <br/><br/>The broader impact of the proposed center is to radically improve homeland defense in all dimensions.  The proposed Center will encourage collaboration, and will nurture an emerging field of research and the associated industries, thus helping to establish the challenges of the field and acceptable research and evaluation methodologies.  SSR-RC will expose students and faculty to state-of-the-art research projects of value to the industry, and plans to attract large companies to the SSR domains and energize innovative start-up companies.  Students will have opportunities for industrial internships with members.  Faculty in the SSR-RC will continue to aggressively recruit women and minority graduate students through the various I/UCRC supplemental programs, and to host annual summer camps for middle-schoolers from under-represented groups.   <br/><br/>"
1205664,CI-ADDO-EN: Collaborative Research: 3D Dynamic Multimodal Spontaneous Emotion Corpus for Automated Facial Behavior and Emotion Analysis,CNS,COMPUTING RES INFRASTRUCTURE,9/1/2012,6/28/2012,Lijun Yin,"Yin, L","Yin, L",NY,SUNY at Binghamton,Standard Grant,Ephraim P. Glinert,8/31/2016,"$306,800.00 ",,lijun@cs.binghamton.edu,4400 VESTAL PKWY E,BINGHAMTON,NY,139026000,6077776136,CSE,7359,7359,$0.00 ,normalFunding,"Emotion is the complex psycho-physiological experience of an individual's state of mind. It affects every aspect of rational thinking, learning, decision making, and psychomotor ability. Emotion modeling and recognition is playing an increasingly important role in many research areas, including human computer interaction, robotics, artificial intelligence, and advanced technologies for education and learning. Current emotion-related research, however, is impeded by a lack of a large spontaneous emotion data corpus. With few exceptions, emotion databases are limited in terms of size, sensor modalities, labeling, and elicitation methods. Most rely on posed emotions, which may bear little resemblance to what occurs in the contexts wherein the emotions are really triggered. In this project the PIs will address these limitations by developing a multimodal and multidimensional corpus of dynamic spontaneous emotion and facial expression data, with labels and feature derivatives, from approximately 200 subjects of different ethnicities and ages, using sensors of different modalities. To these ends, they will acquire a 6-camera wide-range 3D dynamic imaging system to capture ultra high-resolution facial geometric data and video texture data, which will allow them to examine the fine structure change as well as the precise time course for spontaneous expressions. Video data will be accompanied by other sensor modalities, including thermal, audio and physiological sensors. An IR thermal camera will allow real time recording of facial temperature, while an audio sensor will record the voices of both subject and experimenter. The physiological sensor will measure skin conductivity and related physiological signals. Tools and methods to facilitate and simplify use of the dataset will be provided. The entire dataset, including metadata and associated software, will be stored in a public depository and made available for research in computer vision, affective computing, human computer interaction, and related fields.<br/><br/>Intellectual Merit <br/>This research will involve construction of a corpus of spontaneous multi-dimensional and multimodal emotion and facial expression data, which is significantly larger than any that currently exist. To elicit natural and spontaneous emotions from subjects, the PIs will employ five approaches using physical experience, film clips, cold pressor, relived memories tasks, and interview formats. The database will employ sensors of different modalities including high resolution 2D/3D video cameras, infrared thermal cameras, audio sensors, and physiological sensors. The video data will be labeled according to a number of categories, including AU labeling and emotion labeling from self-report and perceptual judgments of na???ve observers. Comprehensive emotion labeling will include dimensional approaches (e.g., valence, arousal), discrete emotions (e.g., joy, anger, smile controls), anatomic methods (e.g., FACS), and paralinguistic signaling (e.g., back-channeling). Additional features will be derived from the raw data, including 2D/3D facial feature points, head pose, and audio parameters.<br/><br/>Broader Impact <br/>Project outcomes will immediately benefit researchers in computer vision and emotion modeling and recognition, because the database will allow them to train and validate their facial expression and emotion recognition algorithms. The new corpus will facilitate the study of multimodal fusion from audio, video, geometric, thermal, and physical responses. It will contribute to the development of a comprehensive understanding of mechanisms involving human behavior, and will allow enhancements to human computer interaction (e.g., through emotion-sensitive and socially intelligent interfaces), robotics, artificial intelligence, and cognitive science. The work will likely also significantly impact research in diverse other fields such as psychology, biometrics, medicine/life science, law-enforcement, education, entrainment, and social science."
431059,Complexity Aspects of  Knowledge Representation and Learning,CCF,"THEORY OF COMPUTING, THEORETICAL FOUNDATIONS (TF)",9/15/2004,12/19/2007,Robert Sloan,"Sloan, R","Sloan, R|Turan, G",IL,University of Illinois at Chicago,Continuing grant,Richard Beigel,8/31/2008,"$305,000.00 ",Gyorgy Turan,sloan@uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,"2860, 7351","9216, 9218, 9251, HPCC",$0.00 ,normalFunding,"The proposed research touches on both theoretical computer science and artifcial intelligence (AI).<br/>In particular, the techniques of theoretical computer science will be applied to two significant<br/>problem areas in AI: knowledge representation and machine learning. Certain forms of knowledge<br/>representation are extremely important for AI applications. Some, such as conjunctions of Horn<br/>clauses, have been studied from AI's earliest days; others, such as decomposable negation normal<br/>form (DNNF), are relatively new. This project will study the computational complexity aspects of<br/>these and other forms of knowledge representation, and formal learnability results for them.<br/>Knowledge representation is interesting because the choice of representation determines the ease<br/>or difficulty of various tasks that an intelligent agent must perform, such as reasoning or planning.<br/>The representations of interest for this research include various forms of propositional logic, ranging<br/>from disjunctive normal form to DNNF, and various more powerful logics, such as modal logics,<br/>some forms of predicate logic, and probabilistic description logic. This proposal includes a variety<br/>of problems and approaches, unified by recurring themes drawn from combinatorics and logic.<br/>One main goal of the proposed work is to advance the understanding of several aspects of im-<br/>portant knowledge representation formalisms. This includes answering questions on expressiveness<br/>for both basic formalisms such as disjunctive normal forms and decision trees, and also for recent<br/>formalisms such as DNNFs. It also includes determining the complexity of handling exceptions in<br/>different formalisms, which is both a practical problem and is also closely related to some questions<br/>on the efficient learnability of the representations. The proposed work will include a probabilistic<br/>analysis of the important reasoning technique of Horn approximations, in order to identify situ-<br/>ations when the method can be expected to work efficiently in spite of examples demonstrating<br/>its worst-case behavior, and an analysis of the possibilities for compiling a knowledge bases into a<br/>more efficient form having short resolution proofs of its consequences.<br/>Another goal of the project is to obtain a better integration of the learnability aspect of the<br/>different knowledge representation formalisms into the emerging comparative theory of knowledge<br/>representation. This line of research includes making new progress on old, well established problems,<br/>such as learning Horn sentences, the further study of recently introduced problems, such as revising<br/>Horn sentences, and the exploration of representations that have not been studied yet from the point<br/>of view of learnability, such as modal logics. Work is also proposed on the exclusion dimension, a<br/>promising recent notion, in both propositional and predicate logic.<br/>Intellectual merit: The proposal addresses several key issues in knowledge representation<br/>and learning: expressiveness, efficient manipulation, efficient reasoning, and efficient learning and<br/>revision, in propositional, predicate, and modal logic. The proposal builds on the previous re-<br/>search results of the proposers, which includes the development of new approaches to logic learning<br/>and theory revision, and their technical expertise in computational learning theory, computational<br/>complexity theory, combinatorics and logic, leading up to a comprehensive, in-depth study of core<br/>problem areas of artificial intelligence, emphasizing the interactions between the different aspects.<br/>The proposers have initial results in several of the suggested research directions.<br/>Broader impact: The rapid increase in both the amount of, and the inherent complexity<br/>of data greatly increases the importance of expressive knowledge representation formalisms that<br/>are suitable for efficient manipulation, reasoning, automated acquisition and revision. Symbolic<br/>knowledge representation formalisms based on propositional, predicate, modal and other logics<br/>form an indispensable component in a large number of applications. Understanding the complexity<br/>obstacles in these applications, and identifying possible avenues for circumventing them, is a crucial<br/>component of further development."
535061,Improving the Scalability of Stochastic Planning Algorithms,IIS,"ARTIFICIAL INTELL & COGNIT SCI, ROBUST INTELLIGENCE",9/1/2005,6/4/2007,Shlomo Zilberstein,"Zilberstein, S","Zilberstein, S",MA,University of Massachusetts Amherst,Continuing grant,Paul Yu Oh,8/31/2009,"$304,854.00 ",,shlomo@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"6856, 7495","7495, 9218, HPCC",$0.00 ,normalFunding,"This is a research project intended to overcome barriers that have limited the usefulness of partially-observable Markov decision process algorithms. In the area of planning under uncertainty, the Markov decision process (MDP) has emerged as a powerful and elegant framework for solving problems in a wide range of application domains such as mobile robot control, machine maintenance, gesture recognition, medical diagnosis and treatment, and policy making. For situations in which the decision maker can fully observe the intermediate state of the domain, there are many effective algorithms that can solve large problems. However, in many applications, it is unrealistic to assume that perfect state information is available. The more general, partially-observable MDP (POMDP) addresses this difficulty, but in this case the computational complexity of planning makes it hard to apply existing solution techniques to practical applications. <br/><br/>This project will study new ways to address the key computational bottlenecks in POMDP algorithms. To achieve this, it will (a) Identify and examine new types of belief-space structures that can be used to accelerate significantly each of the key components of POMDP solution techniques; (b) Evaluate the impact of these improvements on a wide range of exact and approximate algorithms with the goal of demonstrating exponential acceleration; (c) Integrate the new approach with previously identified methods for accelerating MDP and POMDP algorithms using search, symbolic representations, and parallelization; (d) Develop a new set of challenging test problems and benchmarks that are significantly harder than the existing toy problems and perform a rigorous evaluation and comparison of the developed techniques; and (e) Increase the interaction between the artificial intelligence community and other communities that employ POMDP solution techniques such as operations research and management sciences, and exploit the synergy that arises when the best solution techniques from these communities are brought together. <br/><br/>The approach is based on exploring new types of structures in the belief space that make it possible to decompose the main computational components into faster, region-based operations. A theoretical analysis of the new approach and a preliminary implementation show that it can significantly increase the efficiency of both exact and approximate algorithms and thus it can improve the scalability of POMDP algorithms and increase their applicability. The newly designed technique is particularly suitable for parallel implementation on grid computers, offering significant additional opportunities for performance gains. <br/><br/>The technical impact of this project involves fundamental contributions to the understanding of the complexity of planning in stochastic domains as well as the development of efficient planning algorithms that provide exponential savings in computing time. The new approach improves several computational operations that are often used as components of existing algorithms - both exact and approximate. Therefore, the benefits of the approach transfer easily to many existing solution techniques. The broader impact of the project stems from the broad applicability of the resulting technology in several scientific and engineering disciplines, the immediate educational impact at the University of Massachusetts Amherst, an extensive plan for non-traditional dissemination efforts, making the experimental testbed available to the research community, and enhancing an existing alliance between the principal investigator and an international research team at INRIA, France. <br/>"
1116826,NeTS: Small: Networking over Random Fields: A Statistical Model for Cognitive Radio Networks,CNS,"SPECIAL PROJECTS - CISE, Networking Technology and Syst",8/1/2011,2/6/2012,Husheng Li,"Li, H","Li, H",TN,University of Tennessee Knoxville,Standard Grant,Min Song,7/31/2014,"$302,685.00 ",,husheng@eecs.utk.edu,1 CIRCLE PARK,KNOXVILLE,TN,379960003,8659743466,CSE,"1714, 7363","7363, 7923, 9150, 9251",$0.00 ,normalFunding,"Experiments have demonstrated the temporal and spatial correlations of spectrum availability, which are of key importance in the design and analysis of cognitive radio networks. Motivated by the observation, this research applies the theory of random fields, which describes the behavior of multiple correlated random variables, to model the spectrum availabilities in time and space domains. For global spectrum activity, a homogeneous random field like Ising model is used to model the spatial correlation and analyze the performance. For local spectrum activities, Bayesian networks are used to describe the causality in spectrum and statistically infer the future spectrum situations. Furthermore, the model of controlled random fields is employed to design the networking protocols in cognitive radio networks. A low-cost spectrum sensor is designed to collect the real spectrum measurement in multiple locations simultaneously. The research promotes the understanding of frequency spectrum activities and enhances the design and analysis of the next generation cognitive radio networks. The research involves aspects of wireless communications, networking, artificial intelligence and imaging processing; thus the inter-disciplinary essence of the research also lends itself to cross-disciplinary education. Novel courses will be devised, which involve the topics of cognitive radio networks, machine learning and image processing. This project also expects to attract traditionally underrepresented groups, as well as outreach high school students."
212134,"Simulation, Situations, and Embodiment in Conceptual Processing",BCS,"HUMAN COGNITION & PERCEPTION, PERCEPTION, ACTION & COGNITION",9/1/2002,9/5/2006,Lawrence Barsalou,"Barsalou, L","Barsalou, L",GA,Emory University,Continuing grant,ping li,8/31/2007,"$300,480.00 ",,barsalou@emory.edu,"1599 Clifton Rd NE, 4th Floor",Atlanta,GA,303224250,4047272503,SBE,"1180, 7252","0000, 1180, OTHR",$0.00 ,normalFunding,"With National Science Foundation support, Dr. Lawrence Barsalou will conduct three years of basic research.  The funded project will examine the knowledge that underlies typical high-level cognitive activities such as human discourse, reasoning, or perception.  The hypotheses that guide this research are quite new.  The key assumption is that high level, abstract, cognitive activities are actually grounded in the situated everyday workings of the body-thus the terms situated cognition or embodied cognition.  <br/>For example, our knowledge of cars reflects how we interact with cars, what it is like to actually drive a car; to see, hear, touch, and smell a real car; or to feel an emotional response to a car.  This view contrasts with a tradition in psychology, whereby our knowledge of the world is assumed to be fully abstract and detached-something like the ""centralized"" one-kind-of-knowledge-structure-fits-all way in which a computer program can be written.  The funded research will test predictions derived from the new alternative.  Human participants will perform classic ""knowledge tasks,"" responding to questions such as ""What are the properties of a car?"" or ""Is a tire a property of a car?"".  Carefully-controlled laboratory experiments have been designed around such questions and tasks to assess whether situated and embodied forms of knowledge are used to perform them.<br/>This research has broad implications.  First, support for its working hypotheses would motivate big changes in basic scientific theories of human knowledge; this work could contribute to a fundamental shift in how we think about ourselves.  Second, the outcomes of this research could have broad applied impact in education (i.e., how best to teach a knowledge domain) or cognitive engineering (i.e., how machines should be designed to best interact with human beings).  Finally, this work may suggest new forms of artificial intelligence.  Intelligent machines that use situated knowledge, shaped around their peripheral devices, are more robust than traditional centralized intelligent machines.  Possible new machines could resemble the robots used in exploration of Mars, for example, a second-generation of robots that better situate themselves in their environments.<br/>"
92591,CAREER:   Automatic Synthesis of Bidding Strategies for Trading Agents,IIS,DIGITAL SOCIETY&TECHNOLOGIES,8/1/2001,5/5/2005,Peter Wurman,"Wurman, P","Wurman, P",NC,North Carolina State University,Continuing grant,William Bainbridge,7/31/2007,"$300,010.00 ",,wurman@csc.ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,6850,"1045, 1187, 9218, HPCC",$0.00 ,normalFunding,"In this project, trading agents---software programs that participate in markets---will be designed to ascertain the rules of auctions of interest and dynamically construct a decision representation.  A strategy generation engine is the component of a flexible trading agent that converts the inputs (user preferences, auction rules, and models of other agents) into a decisionable format. Game theory and Markov Decision Processes are techniques that will be applied to making decisions in these markets. Previous research in the area of trading agents assumes that the market configuration is predetermined. However, the Internet marketplace is far more fragmented; a particular product will often be offered for sale in a variety of auction formats. Thus, flexible trading agents are necessary. The software programs will be made publicly available as Web-based learning materials for e-commerce courses. These materials will enable instructors in e-commerce and artificial intelligence courses to use trading agent games for class projects."
9734128,CAREER:  Compute Intensive Methods for Artificial           Intelligence,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/15/1998,7/9/2001,Bart Selman,"Selman, B","Selman, B",NY,Cornell University,Continuing grant,William Bainbridge,7/31/2003,"$300,000.00 ",,selman@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,6856,"1045, 1187, 9216, HPCC",$0.00 ,normalFunding,"The objectives of this research and educational program are to develop new formalisms   and methods for artificial intelligence by combining a sound theoretical approach with a   principled experimental component, to provide a practical evaluation of the proposed   models and relate them to real-world applications and challenges, and to educate the next   generation of computer science students about the ambitious and challenging goals of   artificial intelligence.  To develop successful applications, general search and reasoning has   been avoided in recent years by  explicitly incorporating large amounts of domain-specific   knowledge.  Such a knowledge-intensive approach has been successful in, for example,   expert systems; but in areas such as general planning or reasoning, progress has been   disappointing, and specific knowledge acquisition is often difficult and expensive.    However, recent advances in general methods combined with faster hardware and better  implementations provide strong evidence that a compute-intensive approach is not only   suitable for dealing with the combinatorial nature of many AI formalisms, but may also be   required to supplement domain-specific knowledge.  This research studies fast general   reasoning and search methods, with an emphasis on stochastic procedures, which are a   promising recent development for solving computationally hard problems.  It also  investigates the various sources of complexity in hard problems, using both theoretical and   experimental methods, exploring interesting connections between computer science,   artificial intelligence, and statistical physics. In addition, it is studying issues in problem   representation, including robustness of encodings, abstraction, compilation, and   approximation methods.  The result is expected to be new general approaches to artificial  intelligence that are applicable to a wide variety of problems in such areas as planning,   operations research, and computational biology.   http://simon.cs.cornell.edu/home/selman/"
1124665,Collaborative Research: CDI Type-1: A Computer Framework for Modeling Complex Pattern Formation,EF,"CDI TYPE I, EPSCoR Co-Funding",9/1/2011,9/12/2011,Jeffrey Habig,"Habig, J","Habig, J|Andersen, T",ID,Boise State University,Standard Grant,James O. Deshler,8/31/2015,"$300,000.00 ",Timothy Andersen,jeffreyhabig@boisestate.edu,1910 University Drive,Boise,ID,837250001,2084261574,BIO,"7750, 9150","7721, 7722, 9179",$0.00 ,normalFunding,"The mechanisms living systems use to establish and maintain complex 3-dimensional shapes during embryonic development are poorly understood even though molecular and cell biologists have generated mountains of data about genes and their effects on organisms. Fundamental advances in controlling biological form are stymied by the difficulty of obtaining shape information through the analysis of gene networks such that it is currently difficult or impossible for scientists to generate testable models of shape based on experimental results from current biological research. These investigators will apply state-of-the-art computational science and artificial intelligence to create a novel suite of computational tools that will fundamentally integrate numerous areas of biology and engineering to promote research into the mechanisms used by organisms for establishing and maintaining their 3-dimensional shape. This ""Bioinformatics of Shape"" project will integrate experimental data, a new mathematical language, a system for storing and mining data, a modeling environment within which rule sets for regulatory mechanisms can be simulated on computers, and an artificial intelligence module that will help scientists discover and test novel ideas about how shape is generated through genetics. The benefits to society of this new kind of collaboration between computer scientists and biologists include the translation of molecular and cell biological data into a new level of understanding that could have implications for regenerative medicine, adaptive and self-repairing devices for robotics and other engineering applications. The work will provide unique training opportunities for students, establish a proof-of-principle for new educational tools at the boundary between artificial intelligence and biology, and facilitate data to knowledge production in a number of fields, such as developmental biology, evolutionary biology, and the engineering of complex adaptive systems."
9610015,Tractable Reasoning,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/15/1997,6/7/2000,Rina Dechter,"Dechter, R","Dechter, R",CA,University of California-Irvine,Continuing grant,Ephraim P. Glinert,4/30/2001,"$300,000.00 ",,dechter@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"The aim of this research is to devise new methods for  automating reasoning via understanding and exploiting  computationally tractable classes of reasoning tasks.  Fundamental to the approach is the hypothesis that  intelligent behavior is accomplished through utilization of  idealized models of the task's environment. To explain how  people perform so well on tasks that are theoretically  intractable, we must assume that approximation methods based  on idealized tractable models cover a significant portion of  intelligent activity, and hence such methods should serve as  the basis for automated reasoning systems.  A language that  has been found useful for modeling and solving  compuationally intensive tasks in artificial intelligence is  constraint networks, and use of these networks.  By using  idealized tractable models, constraint networks, and other  techniques found useful in this area, it is hoped that real-  life problemq can be solved automatically in reasonable time  as well as humans solve them."
9702576,CAREER:  Planning Under Uncertainty in Large Domains,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/1/1997,6/12/2000,Michael Littman,"Littman, M","Littman, M",NC,Duke University,Continuing grant,William Bainbridge,4/30/2001,"$300,000.00 ",,mlittman@cs.brown.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,6856,"1045, 9216, HPCC",$0.00 ,normalFunding,"This  research project advances artificial-intelligence  research  in the areas of planning and reinforcement learning.  The primary  goal  of  the  research  is  to  create  theoretically  justified  planning  algorithms with wide applicability to  tasks  including  robot  navigation and control, medical decision making,  flexible  manufacturing,  communications-network  monitoring,  and   space  mission scheduling.  The research takes a two-pronged approach to  develop  algorithms for solving large-scale domains derived  from  practical, real-world problems: careful formal analysis to aid in  the  construction  and identification of justifiable  algorithms,  and  the  development  and  intensive  empirical  validation   of  algorithms.  This strategy encourages the creation of  algorithms  that  will  be  useful in solving practical tasks while  avoiding  ``over fitting'' (i.e., losing generality by tailoring algorithms  to  attributes  of  specific domains).  New  planning  algorithms  developed  in  the course of this research combine insights  from  the  areas  of  planning and reinforcement learning  to  make  it  possible  to solve larger and more difficult problems than  could  be  addressed  previously. The research is creating  methods  for  approximately solving large control problems that could  be  used  in  engineering applications ranging from elevator design to  the  adaptive  control  of  computer systems; this  will  help  create  systems that aremore efficient, safe, and reliable."
1611742,Teaching Critical Thinking Skills in Science with sInvestigator,DUE,IUSE,10/1/2016,10/6/2016,Gheorghe Tecuci,"Tecuci, G","Tecuci, G|Trefil, J|Marcu, D|Boicu, M|Holincheck, N",VA,George Mason University,Standard Grant,R. Corby Hovis,9/30/2019,"$300,000.00 ","James Trefil, Dorin Marcu, Mihai Boicu, Nancy Holincheck",tecuci@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,EHR,1998,"8209, 8244, 9178",$0.00 ,normalFunding,"A team of experts from computer science, artificial intelligence, science teaching and pedagogy, systems architecture, software engineering, knowledge engineering and human computer interaction at George Mason University (GMU) is developing a cognitive assistance tool, ""sInvestigator,"" to help students acquire critical thinking skills in addressing scientific problems. The sInvestigator cognitive assistant is a significant technological innovation, based upon a computational theory of reasoning in science. It incorporates a substantial amount of general knowledge about scientific reasoning with evidence guiding and helping the student with the scientific inquiry process. The tool is novel and operates on multiple computer platforms. It is designed for students to use at home and in the lab and supports their acquisition of the core competency of evidence-based reasoning. The resulting theory is extendable to all STEM disciplines both undergraduate and K-12. Broadening participation is achieved through workshops having the capacity of 50-70 participants. Recruiting targets community colleges and minority serving institutions to attract women and underrepresented groups to the workshops organized in collaboration with the GMU Center for Teaching and Faculty Excellence. Evidence based reasoning is at the core of problem solving and decision making not only in STEM disciplines but also law, intelligence analysis, forensics, medicine, history, archeology and other domains. The developed educational materials together with sInvestigator exercises are widely distributed. Information on how teachers and researchers can freely obtain the sInvestigator are posted on GMU's Learning Agents Center website.<br/><br/>The three-year project is first piloted in two Honors courses enrolling 30-40 students. Working in teams, students are guided to approach a scientific problem as ceaseless discovery of evidence, hypothesis and arguments. New knowledge is added by answering research questions that explore improvements in student perception of science process skills and gains in student content knowledge, as measured by course assessments. Students experience numerous opportunities to exercise imagination and creativity and acquire critical scientific practices, particularly: (1) Asking questions; (2) Constructing explanations; (3) Engaging in argument from evidence; and (4) Obtaining, evaluating and communicating explanations (NRC, 2012 p.3). The use of sInvestigator is explored in a sequence of courses to learn what works and what does not work and incrementally evolve the theory and the approach while developing and testing case studies. The mixed-methods evaluation is mostly formative with a focus on understanding students' collaborative experiences with sInvestigator through surveys and interviews. Modification of assessment tools is made based upon evaluation which allows for analysis of student intrinsic motivation, career motivation, self-determination, self-efficacy and grade motivation. In the final year a quasi-experimental research design will be used to evaluate the impact of sInvestigator in a general science course with 250-300 students in two course sections. The design allows for a comparison group on student achievement scores using course assessments, a Science Motivation Questionnaire and a Science Process skills inventory."
105985,Meta-MAC Protocols: A New Dimension to Adaptation in Medium Access Control,CNS,NETWORKING RESEARCH,9/1/2001,8/8/2003,Andras Farago,"Farago, A","Farago, A|Syrotiuk, V",TX,University of Texas at Dallas,Standard Grant,Darleen L. Fisher,8/31/2006,"$300,000.00 ",Violet Syrotiuk,farago@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,4097,"9218, HPCC",$0.00 ,normalFunding,"     In all networks that have a broadcast channel as the basis of communication, the medium access control (MAC) protocol serves a vital role, as it directly controls the access to communication resources.  As the networks and the traffic they carry both become more heterogeneous the question is how to best adapt to the unknown or changing network conditions.                                                                                                                     The natural answer provided by most existing protocols is to include some kind of adaptivity in order to dynamically adust their operation to the actual network conditions. Examples of adaptivity include hybrid protocols that periodically recompute slot assignments, adjustment of retransmission probabilities (e.g., backoff mechanisms), as well as many other ad hoc solutions that tend to become unstable under high load.             Rather than what amounts to essentially tuning parameters of the protocol ""on the fly,"" we instead propose a new ""meta-MAC"" protocol framework that implements new dimension of adaptivity, on top of existing MAC protocols.  Specifically, we propose research on a method, whose roots are in Artificial Intelligence (A1), to systematically and automatically combine a set of existing protocols into a single MAC protocol in a novel way, such that the resulting combined protocol has provable optimality properties.                 Each protocol in the set may be a good candidate for certain situations.  For example, a randomized contention based protocol is good for low loads, due to its low delay, while an allocation based protocol is desirable for high loads, as it avoids the breakdown induced by too many collisions.  Then the meta-protocol will automatically find combined decisions that dynamically represent the ""best of the team,"" under the actual network conditions, without having to know in advance which of the conditions will actually occur and how they will change.  Thus, rather than tuning parameters in an ad hoc manner, we systematically and automatically optimize the medium access approach itself.                                                                                          The proposed research program intends to fully explore the promising potential of the novel meta-MAC protocol aggregation approach, in which encouraging initial results of the PI and co-PI have already shown the principal feasibility.  Specifically, the three main research directions include aggregating more sophisticated MAC protocols (such as IEEE 802.11), dynamically altering the protocol mix to support Quality of Service (QoS) at the MAC layer, and an in-depth study of the correctness, stability, and consistency of meta-MAC protocols.                                                                                                                                                      Our proposed meta-MAC optimization runs autonomously without any centralized control or any message exchanges.  This makes the meta-MAC approach inherently scalable to arbitrarily large networks.  Thus, the meta-MAC approach is ideally suited for the evolving application requirements of today's increasingly heterogeneous networking environments.                                                                                                                    In addition to the above, we plan to incorporate the general approach into the graduate curriculum in the new Telecommunications Engineering Program at the University of Texas at Dallas, thus enriching the traditional telecommunications curriculum with novel adaptive methodologies that provide intelligent, highly  adaptive solutions in large, dynamically changing, heterogrneous networks."
347903,CAREER: Evolving and Self-Managing Data Integration Systems,IIS,INFORMATION & KNOWLEDGE MANAGE,6/1/2004,5/26/2006,AnHai Doan,"Doan, A","Doan, A",IL,University of Illinois at Urbana-Champaign,Continuing grant,Gia-Loi Le Gruenwald,4/30/2007,"$300,000.00 ",,anhai@cs.wisc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,6855,"1045, 9218, HPCC",$0.00 ,normalFunding,"Data integration systems provide a uniform access to a multitude of data sources. They have the potential to revolutionize the way we access data, and provide a basis on which to build even more advanced information processing architectures. However, today such systems are still extremely hard to build and costly to maintain. They must be told in tedious detail how to interact with data sources, and must be constantly modified to deal with changes at the sources. To address this problem, the project envisions building data integration systems that learn to evolve and self-manage over time, with minimal human intervention. To make fundamental contributions toward realizing this vision, the project employs database and artificial intelligence (especially machine learning) techniques to attack the following central challenges: (a) effectively automating key labor-intensive tasks, including schema matching, global schema creation, and duplicate detection, (b) detecting system failures due to changes at the sources, with minimal human intervention, and (c) further reducing the tremendous data integration burden of the system administrators by spreading the burden thinly over the mass of users. <br/><br/>The education plan leverages the research to prepare students and the broader community for the novel data management challenges raised by the Internet world. In terms of intellectual merit, the project takes a next logical step in data integration research. It brings conceptually novel solutions to fundamental issues underlying virtually any data integration or sharing efforts. The project results have the potential for autonomic-computing applications. In terms of broader impacts, the project will facilitate the widespread deployment of data integration systems, thus resulting in more effective information management and access for society. It plays an integral part in educating next-generation professional workers and researchers. The research will also help integrate data for rural Illinois fire fighters, and train them in access and use of the integrated information systems. The project information will be disseminated via publications, workshops, tutorials, and the Web site http://anhai.cs.uiuc.edu/home/projects/aida.html that will include the resulting research results, data and system artifacts."
600538,Markov Decision Processes and Discrete Optimization,CMMI,OPERATIONS RESEARCH,9/1/2006,8/25/2006,Eugene Feinberg,"Feinberg, E","Feinberg, E",NY,SUNY at Stony Brook,Standard Grant,Robert L. Smith,8/31/2009,"$300,000.00 ",,eugene.feinberg@sunysb.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,ENG,5514,"071E, 9147, MANU",$0.00 ,normalFunding,"This grant provides funding for the investigation of the links between two important classes of optimization problems: stochastic dynamic programming, also known under the name of Markov Decision Processes, and discrete optimization.  In particular, this project studies applications of discrete optimization to stochastic dynamic programming,  applications of stochastic dynamic programming to discrete optimization, and applications of stochastic and discrete optimization to production, service, telecommunication, and surveillance systems.  The first task of this project studies classification problems for Markov Decision Processes.  These problems are important for the implementation of efficient algorithms for Markov Decision Processes.  The second task investigates representations of discrete optimization problems via Markov Decision Processes and develops new solution methods for certain discrete optimization problems. The third task develops efficient algorithms for several production, service, telecommunication, and homeland security problems.<br/><br/>If successful, this research will develop new methodologies and algorithms to solve important optimization problems.  It will develop classification algorithms for Markov Decision Processes that identify their specific structural properties. Such algorithms are important for efficient optimization of Markov Decision Processes, which are broadly used for various applications such as control of production and service systems, reinforcement learning in artificial intelligence, and decision making.  This project will also study new approaches to important discrete optimization problems including the Hamiltonian Cycle, Traveling Salesman, and Generalized Pinwheel Problems.  These approaches are based on the representations of discrete optimization problems via Markov Decision Processes and studying the properties of these representations.  This project will develop new solution techniques for certain production, service, and telecommunication applications by developing efficient scheduling, admission, and resource allocation algorithms. This project will contribute to the development of human resources in science and engineering, to technological progress, and to mutually beneficial interactions between industry and academia.<br/><br/>"
1629395,XPS: EXPL: Hippogriff: Efficient Heterogeneous Servers for Data Centers and Cloud Services,CCF,Exploiting Parallel&Scalabilty,10/1/2016,9/8/2016,Steven Swanson,"Swanson, S","Swanson, S",CA,University of California-San Diego,Standard Grant,M. Mimi McClure,9/30/2019,"$300,000.00 ",,swanson@cs.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,8283,,$0.00 ,normalFunding,"The growing importance of artificial intelligence, network services, and cloud storage drives the demand of building powerful computer systems that can perform many operation at once.  Building computers with different kinds of computing processors (i.e., heterogeneous processing) is an effective way to achieve this goal. However, this approach also creates new problems that can negate some of the benefits it provides.  In particular, using different processors for different tasks requires moving data between those processors.  This movement takes time and can cancel out saving heterogeneous processing provides. This project is addressing this problem in heterogeneous computing systems by making the movement of data between different processors more efficient.  This improved efficiency leads directly to benefits for applications of scientific and commercial importance.<br/><br/>Much of the cost of data movement heterogeneous computing systems stems from the entrenched central processing unit (CPU)-centric programming model.  This project is revisiting the design of the application interface, system software and hardware components to remove CPUs and main memory from the critical path of moving data.  The project provides an efficient programming model that allows the system software stack to automatically and efficiently setup the data movements between heterogeneous processors. We are applying the system to large-scale database systems, massive parallel programming systems like Spark and MapReduce as well as scientific computing that power important daily applications and research projects."
9407569,Improved Technologies for Protein Structure Determination   by NMR,MCB,MOLECULAR BIOPHYSICS,8/15/1994,6/3/1996,Gaetano Montelione,"Montelione, G","Montelione, G",NJ,Rutgers University New Brunswick,Continuing grant,Kamal Shukla,7/31/1998,"$300,000.00 ",,gtm@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,BIO,1164,"9183, 9216, BIOT, HPCC",$0.00 ,normalFunding,"9407569  Montelione  The objectives of this work are to develop pulse sequences and  computer software which will automate the process of protein  structure determination by multidimensional NMR.  Pulsed-field  gradient (PFG) technology will be optimized to provide improved  sensitivity and better H2O solvent suppression by using two-and  three-gradient pulse sequences.  A family of PFG triple resonance  NMR pulse sequences will be designed which provide optimal input  for automated analysis software.  Artificial intelligence will be  applied in developing user-friendly software for analyzing these  data, including automation of the processes of resonance  assignment, compilation of experimental distance constraints, and  structure generation.  This software will accelerate the structure  determination process for small (<10 KDa) proteins.  This  technology development will be carried out on samples of isotope-  enriched protein growth factors, transcription factors, IgG binding  domains, and protease inhibitors for which prokaryotic production  expression systems are already available in the laboratory.   %%%  The technology will greatly enhance the applicability and  accessibility of NMR spectroscopy as a tool for protein engineering  and structural biology, and improve the competitiveness of the  United States in these important biotechnology areas.  It will make  amenable to NMR studies many proteins which are presently  inaccessible for various technical reasons, and accelorate the  process of molecular structure analysis.  The techniques and the  data which result from this work will provide important  infrastructure for determining the three-dimensional structures of  many different proteins by NMR, and will have important  implications in several related fields including protein  engineering, protein chemistry, protein folding and agricultural  biotechnology.  The work will have a significant impact on the  infrastructure of biophysical chemistry by enhancing the  effectiveness, informat ion content, and interpretability of NMR  technology.  ***"
1451202,BRAIN EAGER: Cell-type-specific Optogenetics in Wild-type Animals,IOS,"CROSS-EF ACTIVITIES, ORGANIZATION",9/1/2014,8/18/2014,Ian Wickersham,"Wickersham, I","Wickersham, I|Desimone, R|Tye, K|Tsai, LH",MA,Massachusetts Institute of Technology,Standard Grant,Evan Balaban,8/31/2017,"$300,000.00 ","Robert Desimone, Kay Tye, Li-Huei Tsai",wickersham@MIT.EDU,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,BIO,"7275, 7712","7916, 8091, 9178",$0.00 ,normalFunding,"This project consists of engineering a system for producing selective expression of light-inducible molecules in targeted neuron population in non-genetically modified animals of any species.  The result will be a set of reagents that will be made freely available to the scientific community through nonprofit repositories and service centers.  This new set of tools will enable the study of neural circuitry with greater resolution, power, and throughput than is currently possible, allowing major advances to be made in understanding the organization of the complex neural systems underlying perception, cognition, and behavior.  This increased understanding could also result in improved artificial intelligence and machine learning.  Finally, the future direct application of the technology in human patients holds promise for potentially treating conditions such as Parkinson's disease and epilepsy, by allowing the selective activation or inactivation of distinct components of the compromised neural circuitry that is associated with these disorders.<br/><br/>Over the last decade, sophisticated genetic tools have been developed that allow control and monitoring of neuron electrical activity using light alone.  ""Optogenetics"", as this area of technology has become known, is only useful if optogenetic molecules can be specifically expressed in functionally meaningful groups of neurons instead of broadly in all the diverse neuron types that are present in any brain region.  This requirement has confined their use almost entirely to genetically modified (transgenic) mice and rats.  The approach of using transgenic animals has three major disadvantages.  First, the production and maintenance of transgenic rodents is very expensive.  Second, even within transgenic rodents, it allows the optogenetic study and manipulation of only one or two cell types at a time, preventing powerful combinatorial experiments in which different neuron types are independently controlled within the same tissue.  These combinatorial experiments will be critical for deciphering the complex interactions between cell types. Third, it restricts the experiments to rodents, preventing studies in other important taxa including primates, in which optogenetic experimentation during complex cognitive tasks would almost certainly provide major insights into the neural circuitry underlying cognition. This project aims to create engineered binding proteins that recognize selected endogenous proteins that will then act as scaffolds for assembly of transcription factors that will activate gene expression in specific neurons."
917417,"AF: Small:  Learnability, Randomness, and Lower Bounds",CCF,COMPLEXITY & CRYPTOGRAPHY,5/15/2010,5/19/2010,John Hitchcock,"Hitchcock, J","Hitchcock, J",WY,University of Wyoming,Standard Grant,Tracy J. Kimbrel,4/30/2015,"$300,000.00 ",,jhitchco@cs.uwyo.edu,1000 E. University Avenue,Laramie,WY,820712000,3077665320,CSE,7927,"9150, 9216, 9217, 9218, HPCC",$0.00 ,normalFunding,"This project is motivated by new connections between the research fields of computational complexity theory and machine learning theory.  Computational complexity theory aims to understand which problems can be solved efficiently on a computer by determining the amounts of computational resources such as CPU time, memory space, or circuit area that are required to solve problems.  At the center of this field is the famous P vs. NP question which impacts virtually every scientific and engineering discipline, given the thousands of diverse NP-complete problems that have been discovered.  Machine learning theory studies the extent to which computers can learn from data and their ability to make future predictions and classifications based on what has been learned.  Some powerful learning algorithms have been discovered, but whether computers can be programmed to accomplish many learning tasks remains an open question.<br/><br/>Both computational complexity and machine learning aim to understand the capabilities and limitations of computation, but the two fields study different types of problems and use different kinds of techniques.  This research will employ techniques and ideas from each of these two fields to impact the other field, specifically with the goal of proving ""lower bound"" results.  This research will be accomplished by making use of a new vantage point provided by algorithmic randomness to relate complexity and learning problems.  Learning algorithms will be utilized to establish lower bounds on the computational resources required to solve problems in computational complexity.  The converse direction will be investigated to apply techniques and ideas from computational complexity to show that ""attribute-efficient"" learning algorithms do not exist for certain concept classes.  Algorithmic randomness and Kolmogorov complexity will be used to improve our understanding of the capabilities and limitations of learning algorithms.<br/><br/>This research will improve our understanding of computational complexity, which is informative to many areas of science and engineering where computation plays a role.  This project aims to better understand what learning tasks can be accomplished efficiently by computers, which has applications to the foundations of artificial intelligence.  In particular, this research will identify new obstacles that must be overcome in order to design successful automatic learning systems.  A greater synergy will be developed between computational complexity theory and machine learning theory, with the benefit of laying a foundation for future collaboration and interdisciplinary work across these fields."
1543986,MATH: EAGER: Online Collaborative Problem Solving in Remedial College Mathematics,DUE,IUSE,9/15/2015,9/11/2015,Mark Warschauer,"Warschauer, M","Warschauer, M|Xu, D|Eichhorn, S",CA,University of California-Irvine,Standard Grant,Myles G. Boylan,8/31/2017,"$300,000.00 ","Di Xu, Sarah Eichhorn",markw@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,EHR,1998,"005Z, 7916, 8209, 8244, 9178",$0.00 ,normalFunding,"This is a study of the impact of the learning environment on undergraduate students learning problem-solving in remedial pre-calculus mathematics. The study will examine the comparative effectiveness of face-to-face discussion groups and 2 different types of online designs, compared to individual practice. Students will be randomly assigned to one of four groups: three treatment groups that carry out collaborative problem solving using (1) face-to-face discussion, (2) an audio capability with a whiteboard online tool, or (3) an online virtual environment combining audio plus whiteboard plus avatar-based interaction; or a control group of individual problem solving. Currently, pre-calculus instruction is been carried out online in this university using the web-based ALEKS tutorial software, an online interactive learning system that uses an artificial intelligence algorithm to assess and report student mastery of content material. In search of improved student performance, this project is conducting an early in-depth study of the effectiveness of a richer online design for learning problem solving that was recently constructed for management courses, called VirBELA (Virtual Business Education Leadership Assessment). It is a learning platform that offers students the opportunity to work in teams. In mathematics, VirBELA has good potential for facilitating group problem-solving. It provides a whiteboard that allows students to draw diagrams and functions as needed and also provides an audio capability for discussion. It has the added feature of giving students a virtual online embodiment by creating an avatar for each student. There is evidence from other sources that avatars create a richer, more interactive and engaging online collaborative environment that more closely replicates the advantages of in-person communication. <br/><br/>A wide range of data will be collected and assessed, including usage logs of the tutorial learning software, common final exam scores in both pre-calculus and calculus, and individual institutional data. Other outcome variables will include how students perform on the problem solving, how they use the tutorial-based mathematics software before and after problem solving sessions, and whether they persist to the next calculus course, what grades they earn in the following calculus course, and how their attitudes toward STEM study change based on pre- and post-surveys. The study will be repeated in three different quarters."
1635253,Improved Human-Computer Interaction for Design of Complex Systems,CMMI,ENGINEERING DESIGN AND INNOVAT,9/1/2016,6/19/2018,Daniel Selva Valero,"Valero, DS","Valero, DS|Yoon, SY|Hoffman, G|Valero, DS",NY,Cornell University,Standard Grant,Georgia-Ann Klutke,8/31/2019,"$299,999.00 ","So-Yeon Yoon, Guy Hoffman, Daniel Selva Valero",ds925@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,ENG,1464,"067E, 068E, 073E",$0.00 ,normalFunding,"Future design of complex systems, for example, the design of aircraft, buildings, and transportation systems, will be done collaboratively by mixed teams of humans and artificial intelligence (AI) systems. The success of this collaboration depends on the degree to which the humans and the AI systems can effectively communicate with each other their goals, intentions and plans of actions. This award seeks to improve how humans and AI systems communicate when designing such systems. In particular, the investigators will give intelligent design agents the ability to provide explanations of their actions and suggestions to humans through both verbal and non-verbal communication channels. It also investigates how the AI system can use robotic body language to improve the collaborative design process. This has potential to have an impact on many aspects of our society which engage in system design, including architecture, medicine, urban planning, industrial design, and business management. Additionally, the research project provides opportunities for education and outreach during its execution.<br/><br/>The research objective of this award is to enable mixed-initiative human-computer design of complex systems by giving intelligent design agents self-explaining abilities, modeling human-computer joint design as a collaborative activity, and leveraging the use of non-verbal channels and embodied interaction to improve human-machine communication in design. Starting from a model of design tools as intelligent agents, and based on the knowledge generated by the Human-Robot Collaboration literature, we will lay out the foundations of a new paradigm for engineering design based on mixed-initiative human-agent collaboration. The four pillars of this new paradigm are: (a) the coordination and meshing of shared plans and intentions between humans and design agents, and their resolution into individual agent plans and actions; (b) the dynamic allocation of roles and gradation of autonomy; (c) the reasoning about, generation, and maintenance of shared attention and common ground; and (d) the integration of verbal and nonverbal channels in communication about agent beliefs, intentions, and goals. Controlled experiments with human subjects will be used to test the effectiveness of the new framework and algorithms. If successful, this research can radically improve the quality of the designs and reduce the resources spent during the design process of complex engineering systems of national importance and high value to society such as systems-of-systems for weather forecasting, climate monitoring, disaster relief, or intelligence, surveillance, and reconnaissance. This research will also have broader impacts into areas outside of engineering that engage in system design activities, including architecture, medicine, urban planning, industrial design, and business management."
1549515,Enhancing Education and Awareness of Shannon Theory,CCF,"SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, IIS SPECIAL PROJECTS",8/15/2015,8/8/2016,Christina Fragouli,"Fragouli, C","Fragouli, C|Verdu, S",NJ,"Institute of Electrical & Electronics Engineers, Inc.",Standard Grant,Phillip Regalia,7/31/2018,"$299,935.00 ",Sergio Verdu,christina.fragouli@ucla.edu,445 HOES LANE,Piscataway,NJ,88544141,7325626520,CSE,"1714, 2878, 7484",7916,$0.00 ,normalFunding,"Consistent with the National Science Foundation's goal ""to initiate and support ... programs to strengthen scientific and engineering research potential [and] science and engineering education programs at all levels"", this project develops materials that will support education and broad awareness of the importance of key engineering advances . In particular, it will support creation of educational films and corresponding lesson materials for K-12 mathematics and science teachers that will allow students to be exposed not just to the advances in information theory, but also to how an ordinary person played a pivotal role in fostering them. By adapting material previously restricted to graduate-level courses and technical conferences to a larger audience, a broader dissemination of information theory should profitably inform teachers and researchers in other fields, thereby fueling the nation's STEM workforce and improving commercial technology. <br/><br/>This project focuses on the efforts and advances of Claude Shannon, who established the field of information theory by stating some of its most fundamental problems and solving them. The technologies that his work made possible form a major driving force of our economy. His information theory concepts provide the foundation for nearly every aspect of modern information technology and have been applied to many fields, including communication, language, genetics, computing, cryptography, psychology, perception, memory, artificial intelligence, quantum physics, and others."
534881,Learning from Interdependent Examples,IIS,ARTIFICIAL INTELL & COGNIT SCI,11/1/2005,10/19/2005,Pedro Domingos,"Domingos, P","Domingos, P",WA,University of Washington,Standard Grant,Douglas H. Fisher,10/31/2009,"$299,925.00 ",,pedrod@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6856,"6856, 7495, 9218, HPCC",$0.00 ,normalFunding,"This project investigates machine learning that takes into account dependencies among examples. In contrast, most machine learning methods assume that all examples are independent and identically distributed (""i.i.d.""). Domains where this assumption does not hold are widespread -- from the WWW, where the relevance of a page affects the relevance of linked pages, to molecular biology, where a protein's properties determine its role in metabolic networks. By lifting the i.i.d. assumption, this project will develop learning algorithms that can exploit the information each example carries about the others. This has the potential to improve predictive performance and broaden the range of phenomena that can be effectively modeled. However, it also greatly increases the complexity of learning. This project focuses on developing techniques to make non-i.i.d. learning practical, including: (1) feature search guided by known relations among examples; (2) aggregation of variable quantities of relevant information back into examples of fixed length; (3) increasing the efficiency of learning and inference by performing them at multiple levels of abstraction; and (4) using relational domain knowledge to constrain the search space and combat overfitting. The project will apply the resulting algorithms to modeling the WWW and scientific citation networks. The broader impact of this project includes extension of machine learning to domains, within and beyond computer science, where interdependencies among examples cannot be ignored (e.g., the WWW, social networks, ubiquitous computing). It will also create a publicly available repository of data sets with interdependent examples. The project involves undergraduates, particularly those from underrepresented groups."
454056,CRI: A Core Experimental Facility for Computer Vision and Artificial Intelligence,CNS,COMPUTING RES INFRASTRUCTURE,7/1/2005,7/14/2006,Carlo Tomasi,"Tomasi, C","Tomasi, C|Parr, R",NC,Duke University,Standard Grant,Joseph Urban,6/30/2007,"$299,848.00 ",Ronald Parr,tomasi@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7359,"9218, HPCC",$0.00 ,normalFunding,"Abstract<br/>Proposal: CNS 0454056<br/>PI: Carlo Tomasi<br/>Institution: Duke University<br/>Program: NSF 04-588 CISE Computing Research Infrastructure<br/>CRI: A Core Experimental Facility for Computer Vision and Artificial Intelligence  <br/><br/>Duke University will construct a facility for the measurement of three-dimensional shapes and the motion of human bodies, to be used for both training and performance evaluation of computer vision and artificial intelligence algorithms.<br/>Shapes will be measured with a high-quality laser range finder. Structured light, stereoscopic and monocular images of the same scene or object also will be collected from sensor systems of varying quality, and whose positions and orientations relative to the laser range finder are precisely known through calibration. Similarly, the motions in space of one or a few people will be recorded with an accurate motion capture system, as well as with several sets of color and black-and-white cameras and structured-light systems recording at the same time. Research project on stereo vision, robot localization, visualization, gesture analysis and dermatology are planned.<br/>The laser range finder and motion-capture system provide accurate training and ground-truth data, and the other sensors yield the type of input that a computer vision algorithm or an artificial intelligence inference system would use to determine or reason about a scene or an event. Because of the broad need for this data, the proposal also envisions the creation of a course on the principles underlying sensing and geometric measurements whose materials will also be made public, and of a web repository for the measurement data collected both at the facility and elsewhere. <br/>"
1723440,SaTC: EDU: Learning Moving Target Defense Concepts: Teaching and Training Curricula Development Based on Software Defined Networking and Network Function Virtualization,DGE,Secure &Trustworthy Cyberspace,9/1/2017,8/11/2017,Dijiang Huang,"Huang, D","Huang, D",AZ,Arizona State University,Standard Grant,Victor P. Piotrowski,8/31/2019,"$299,756.00 ",,dijiang@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,EHR,8060,"7254, 7434, 9178, 9179, SMET",$0.00 ,normalFunding,"Moving Target Defense (MTD) is a new security concept to increase uncertainty and complexity for attackers, reduce their window of opportunity and increase the costs of their attack efforts. MTD solutions involve a wide-range of advanced technical expertise, which current education models lack. The project from Arizona State University proposes to develop an MTD courseware for both senior undergraduate level and graduate level in computer science focusing on network-based MTD technologies. Additionally, a cloud-based hands-on laboratory will be established to support MTD labs, which will increase access to students and educators in lab environments with limited computer networking and system security capabilities. The proposed MTD curricula will be published as a textbook associating with a MTD lab repository allowing instructors to build a new MTD course or pick part of the teaching materials to incorporate them into their current curricula. The project team will also work with industry partners to develop the course content and provide a Teacher Training workshop to disseminate the course materials. All the created course content and labs will be freely downloadable by instructors and students.<br/><br/>MTD solutions involve technologies in machine learning, artificial intelligence, and big data analysis models, and current education resources in this realm should address these fields. The proposed project will address the research challenge on how to build-out a much-needed hands-on learning module that can be easily deployed on existing cloud service platforms to learn and experiment with new computer networking and security technologies such as Software Defined Networking (SDN), Network Function Virtualization (NFV), and MTD. This project will focus on four interdependent tasks: (a) building the MTD education capability by creating software components to support SDN, NFV, and MTD, and establishing MTD lab repository and APIs to enhance MTD learning outcomes; (b) developing both long-term semester-based course curriculum, and short-term training oriented MTD teaching contents; (c) conducting a comprehensive evaluation plan by involving both internal and external independent evaluators to use the developed course content and labs; and (d) working with industry partners and hosting a Teacher Training workshop to maximally disseminate developed MTD learning contents and hands-on exercises."
420996,MRI:    Acquisition of CAVE for Experiments in the Creation of Collaborative Learning Environments,CNS,MAJOR RESEARCH INSTRUMENTATION,9/1/2004,8/18/2004,Lori Scarlatos,"Scarlatos, L","Scarlatos, L|Parsons, S|Jannone, J",NY,CUNY Brooklyn College,Standard Grant,Rita V. Rodriguez,8/31/2007,"$299,750.00 ","Simon Parsons, John Jannone",Lori.Scarlatos@stonybrook.edu,Office of Research & Sponsored P,Brooklyn,NY,112102889,7189515622,CSE,1189,"9135, 9218, HPCC",$0.00 ,normalFunding,"This project, creating learning environments where children can be fully immersed in and engaged with their learning materials, aims at acquiring high-end visualization and motion capture in the form of the Tangible Interfaces Collaborative Learning Environments (TICLE) project. The project centers around the development of learning environments; techniques for handling multi-sensory cues in user interfaces, and the use of visual technology in learning and adaptation in intelligent agents. While studying interfaces amenable for human computer interaction and learning, proposed is the acquisition of a CAVE-based immersive environment as well as a motion capture system that will be integrated with it. Exploring techniques such as virtual reality, full motion tracking, and sensor input devices, the work involves working on gesture tracking and recognition/ interpretation, determining how to relate gestures to manipulation of objects. The proposal addresses the following research directions:<br/><br/>Tangible Interfaces for Collaborative Learning Environments<br/>Interaction Paradigms<br/>Tracking and Representing the Learning Environment<br/>Rectifying and Resolving Conflicts among Data Sources<br/>Multi-Parametric Interfaces and Complex Multi-Media Control Situations<br/>Increasingly Multi-Parametric Real-Time Multi-Media Control Situations<br/>User Feedback Strategies for Multi-Parametric Real-Time Multi-Media Control Situations<br/>Training and Learning Multi-Parametric Real-Time Multi-Media Control<br/>Learning and Adaptation in Intelligent Agents<br/>Learning and Adaptation by Artificial Intelligent Agents<br/>Learning and Adapting Human Agents<br/>Learning and Adapting as a Programming Metaphor<br/>Several subprojects extend previous work into a 3D cave environment, requiring a significant jump in complexity of the system including computer vision, graphics, and systems; as well as quite a bit of training. For the latter project, a motion tracking system monitors the robots and the CAVE to give feedback to the robots. In the area of human computer interfaces (HCI), strategies will be developed for tracking and representing what is going on in the learning environment, including algorithms for rectifying and resolving conflicts among disparate sources (such as multiple pairs of cameras and sensors). Experimentation with various paradigms determines how students may best interact with the objects and information. Ways of interacting with the space and the data in natural, expressive ways, affecting multiple parameters will be explored. In the area of artificial intelligence, the focus will be in determining what the users understand or intend. The investigation of adaptive agents will continue, allowing the system to fill in missing data and learn over time. All tracks focus on how the HCI can enhance collaborative educational environments. <br/><br/>Broader Impact:  Supporting research at a minority institution, the work involves undergraduate and graduate students, including those from underrepresented groups. Exposing a wider audience into science, the work on TICLE exhibits high potential for broader impact in education. Moreover, outreach to K-12 is already under way.<br/>"
453463,"A Computer Science and Engineering REU Site for Florida, Puerto Rico and Latin America",IIS,RSCH EXPER FOR UNDERGRAD SITES,2/1/2005,10/31/2006,Miguel Labrador,"Labrador, M","Labrador, M|Perez, R",FL,University of South Florida,Continuing grant,Daniel F. DeMenthon,1/31/2008,"$299,369.00 ",Rafael Perez,labrador@cse.usf.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,CSE,1139,"9218, 9250, HPCC",$0.00 ,normalFunding,"The primary goal of this NSF REU site proposal is to systematically increase<br/>the graduation rate of undergraduate students and the enrollment in graduate<br/>school by involving undergraduate students in state-of-the-art Computer<br/>Science and Engineering research activities. This project emphasizes the<br/>participation of minority students belonging to groups with significant<br/>growth rates, in particular, Hispanic students from the University of Puerto<br/>Rico Mayaguez, students from USF and other minority universities in Florida,<br/>and students from Latin American countries. During a 10-week summer session,<br/>participating students will learn to use tools and techniques to solve<br/>current research problems in Artificial Intelligence, Robotics, Computer<br/>Networks, and Digital Image Processing, as well as work on other research<br/>projects in collaboration with the H. Lee Moffitt Cancer Center & Research<br/>Institute, the Center for Urban Transportation and Research, and the Center<br/>for Robot-Assisted Search and Rescue. After an initial week of formal<br/>orientation on the topics of research methodology, literature searching,<br/>research writing and presentation skills, participating students will spend<br/>nine continuous weeks with a faculty mentor working to solve a well defined<br/>problem in a selected area of interest. Formal and informal interactions<br/>with other students, faculty members and industry members will also be<br/>included in as students work on projects and attend social events."
851618,"REU Site: REU-University of New Orleans Site, TRACK: Training and Research in Computing Knowledge",CNS,RSCH EXPER FOR UNDERGRAD SITES,8/1/2009,7/27/2009,Dimitrios Charalampidis,"Charalampidis, D","Charalampidis, D|Chen, H",LA,University of New Orleans,Standard Grant,Harriet G. Taylor,7/31/2013,"$299,222.00 ",Huimin Chen,dcharala@uno.edu,2000 Lakeshore Drive,New Orleans,LA,701480001,5042806836,CSE,1139,"6890, 9218, 9250, HPCC","$299,222.00 ",normalFunding,"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>This REU site at the University of New Orleans (UNO) provides research experience for undergraduates in the area of integrated sensing and data processing for surveillance missions and automated scene understanding. The project recruits groups of diverse and talented undergraduate students from around the nation to actively engage in this cutting-edge Integrated Sensing and Automated Scene Understanding (ISASU) research, and to enhance the Electrical Engineering program at UNO.<br/><br/>Intellectual Merit<br/>The participants are performing research that is expected to impact the field of ISASU, as well as other associated scientific disciplines such as Image Processing,<br/>Artificial Intelligence, Pattern Recognition, Computer Vision, Bioinformatics, Data Mining, Knowledge Discovery, Automated Decision Making & Planning, and Information Fusion, among others. The REU PIs have extensive expertise in ISASU, as evidenced by their publications and current funded support. The student projects address cutting-edge research themes, directly stemming from the PIs? current research, and the PI has significant experience in student advising, as evidenced by the large number of graduate and undergraduate advisees. The proposed REU experience is expected to be successful in training undergraduates in ISASU; the goal is for this work to lead to significant results in the field.<br/><br/>Broader Impacts<br/>The recruitment plan, in conjunction with strong commitment from faculties at affiliated institutions attracts undergraduate students, including females and under-represented groups, to the REU UNO site. The project engages in total a diverse group of 30 students, and two graduate students who will be involved in undergraduate teaching, research and mentoring activities. The REU research results will be published in peer reviewed conferences, and potentially, technical journals. These REU research advances are fed back and integrated into the teaching of related courses at UNO, and/or affiliated institutions. Finally, the project leverages industrial contacts through the Information and Systems Technology Research Center (IST-RC) and UNO?s Research and Technology Park."
1231620,SHB: Type I (EXP): Algorithms for Unsupervised and Online Learning of Hierarchy of Features for Tuning Cochlear Implants for the Hearing Impaired,IIS,Smart and Connected Health,1/1/2013,8/31/2012,Bonny Banerjee,"Banerjee, B","Banerjee, B|Mendel, L",TN,University of Memphis,Standard Grant,Sylvia J. Spengler,12/31/2016,"$298,203.00 ",Lisa Mendel,bbnerjee@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,8018,"8018, 8061, 9150",$0.00 ,normalFunding,"Since noteworthy events happen only occasionally in any data, it is imperative for smart sensors to learn the norms in data so that authorities can be alerted and appropriate action can be taken at the occurrence of an abnormal or noteworthy event. The aim of this project is to develop algorithms that can learn the norm in terms of a hierarchy of meaningful features from data in an unsupervised and online manner. The application testbed is the problem of automatically tuning cochlear implants (CIs) of patients with severe-to-profound hearing loss by continuously monitoring their speech output. The working hypothesis is that deficiencies in hearing for people with significant hearing loss are reflected in their speech production. This project will develop and use unsupervised, online, and biologically plausible machine learning algorithms to learn feature hierarchies from the speech output data of severely-to-profoundly hearing-impaired patients. The learned feature hierarchy from the speech of a patient will be compared to those learned from the speech of a comparable normal hearing population. Deficiencies in the patient's hearing will be ascertained by identifying the missing or distorted features. Algorithms will be developed to map this information into the signal processing strategies used in CIs to enhance the audibility of speech.<br/><br/>The proposed project promises transformative changes to three major interdisciplinary fields: machine learning and artificial intelligence, healthcare, and sensors. It will transform the traditional ways in which the clinical needs of patients are met. For example, the results of this project will provide doctors with evidence-based practices that will better address the specific needs of individual patients by monitoring each patient around the clock at minimal effort and cost.<br/><br/>Hearing loss is the most common birth defect in the U.S. with slightly over 15,000 new pediatric cases each year and societal losses amounting to $4.6 billion over a lifetime. A proven technology for CI tuning would make a significant difference to the lives of over 1.2 million CI candidates in the U.S. and many more around the world, thereby leading to substantial health and economic benefits to society. Other than CI tuning, the proposed algorithms will be applicable to a variety of monitoring applications within healthcare, such as blood pressure, cerebrospinal fluid pressure, intracavitary pressure of the bladder, etc., and beyond healthcare, such as web, machine health, traffic, etc. Continuous monitoring with wearable and implantable body sensors will increase early detection of emergency conditions and diseases in at-risk patients and also provide a wide range of healthcare services for people with various degrees of cognitive and physical disabilities. Not only the elderly and chronically ill, but also the families in which both parents have to work will benefit from these systems to provide high-quality care services for their babies and children. Finally, the proposed project will integrate diversity by promoting teaching, learning, and interdisciplinary research among underrepresented groups."
1526431,III: Small: Collaborative Research: Adaptive Integration of Textual and Geospatial Information for Mining Massive Map Collections,IIS,INFO INTEGRATION & INFORMATICS,9/1/2015,8/18/2015,Erik Learned-Miller,"Learned-Miller, E","Learned-Miller, E",MA,University of Massachusetts Amherst,Standard Grant,Maria Zemankova,8/31/2019,"$297,859.00 ",,elm@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7364,"7364, 7923",$0.00 ,normalFunding,"Libraries and archives are digitizing historical maps for widespread online access. Without technology for searching them, large map collections relevant to a given problem or question may remain obscure even in online archives. If all of the text in a map can be read automatically by computer, a wealth of information becomes quickly available -- location names, geographic features, and often statistics. This project will increase capacity for search and analysis of historical maps by automatically recognizing place names and other text in these digitized artifacts while simultaneously aligning them with modern geography. The improvements this project will make to current text recognition methods will facilitate more powerful uses of humanity's trove of old maps -- for example, by allowing scientists and policymakers to establish changes in land usage, waterways, or borders over time. By creating free, open-source tools for studying historical maps, this project will increase public engagement with science and technology and empower any Internet user to explore the intersection of technology and history. This research will train a diverse group of graduate and undergraduate students in constructing, learning, and making predictions with adaptive models featuring heterogeneous yet highly interdependent entities.<br/><br/>Although many institutions are digitizing hundreds of thousands of historical maps, most digitized map images are poorly annotated, limiting their usefulness. Manual annotation and metadata association is highly laborious. This project's primary objectives are (1) to fully automate text and shape-based georeferencing (aligning map images to the known global geography) while (2) indexing words and place names (for search) by enhancing text detection and recognition methods in these complex artifacts. These innovations will address the shortcomings of manual georeferencing and current automated text recognition algorithms. The researchers will employ an iterative interpretation process for solving problems including text/graphics separation, text recognition, and georeferencing. For example, the fact that all members of a given class of text entities on a map (e.g., county names) are typically rendered in the same text style can be used to inform predictions about difficult members of the category with information derived from more easily-recognized members. The researchers will use a dataset of annotated maps containing over 12,000 words in 9,000 place names as benchmark data for testing the algorithms developed in the project. Software, data, and benchmarks will be broadly distributed on the project website (http://www.cs.grinnell.edu/~weinman/research/maps.shtml). Findings will be shared with the research community through journals and conferences in the computer vision, artificial intelligence, and GIS communities."
9057331,"PYI: Studies in Population Genetics, Life History Traits and Host-Parasite Dynamics",DEB,"PHYLOGENETIC SYSTEMATICS, POPULATION DYNAMICS, SPECIAL PROGRAMS-RESERVE",10/1/1990,9/16/1996,Steven Frank,"Frank, S","Frank, S",CA,University of California-Irvine,Continuing grant,,9/30/1998,"$296,396.00 ",,safrank@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,BIO,"1171, 1174, 9145","9169, 9227, EGCH, ENVI, 0000, OTHR",$0.00 ,normalFunding,"During his five-year Presidential Young Investigator Award, Dr. Steven Frank, University of California, Irvine, plans to continue and expand his research activities in four areas. The first two concern the inherent instability and resulting dynamics caused by conflict at different genetic and ecological levels. Specifically, Dr. Frank will extend his present work on genomic conflict to explain uniparentally inherited sex-biasing elements and the role of meiotic drive in maintaining chromosomal inversions and genetic differences between species. Using host-parasite systems, he will also attempt to relate observable statistics about spacial variation to models of long-term ecological and evolutionary dynamics that maintain observable patterns. A third research goal involves understanding the patterns of parental investment in male vs. female offspring, including exploring a different interpretation of sex allocation in warm- blooded vertebrates. Finally, Dr. Frank will initiate research on the evolution of learning by merging advances in artificial intelligence and computers with classic methods from population genetics and evolutionary biology. His goal of applying advanced computer technology to evolutionary genetics is particularly innovative and, if successful, may herald a new era in evolutionary biology research."
1002507,Pilot: Assisted Musical Composition through Functional Scaffolding,IIS,CreativeIT,8/15/2010,7/20/2010,Kenneth Stanley,"Stanley, K","Stanley, K",FL,University of Central Florida,Standard Grant,Ephraim P. Glinert,7/31/2015,"$295,229.00 ",,kstanley@cs.ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,7788,7788,$0.00 ,normalFunding,"As a ubiquitous creative endeavor across all human cultures, musical composition is an effective microcosm for the study of creativity in general. This project will impact computer science by showing through assisted musical composition how computers can genuinely improve upon the creative capabilities of humans alone. By introducing an interactive framework that enables even inexperienced users to realize their creative vision, this project also helps pave the way for such systems to amplify our creative potential in other areas in the future, such as in engineering and design. The technology that will be developed, called Functional Scaffolding for Musical Composition (FSMC), takes the unique approach of computing accompaniment for existing musical tracks (called the ?scaffold?) by generating special functions that take the scaffold as input and output accompanying tracks. In this way, generated tracks are in effect transformations of the scaffold, allowing them to inherit the global structure and implicit nuance of the preexisting music. The implication for computational creativity in general is thus to harness the richness of preexisting human-generated content as a seed for further elaboration. Furthermore, the user will be provided an interactive evolutionary interface that makes it possible to search the space of such transforming functions, in effect allowing the user to continually breed and elaborate new concepts that build upon preexisting incomplete works.<br/><br/>The primary target audience for FSMC as a practical technology will be musicians who lack the resources, collaborators, or expertise to produce complete musical compositions. For example, while a hobbyist with a keyboard might be able to compose a compelling melody, lack of expertise in other instruments may prohibit adding accompanying guitar or base. In addition, even more experienced musicians may benefit from the capability to quickly propose accompaniment as a new means of concept generation. In fact, existing computer programs that aid in musical composition often register millions of downloads online, demonstrating broad public interest in applications that enhance musical creativity. In addition to dissemination through scientific conferences focusing on computational creativity, the results of this research will be released in a form compatible with such programs, thereby directly impacting the public with a practical utility and consequently raising awareness of the potential for artificial intelligence and machine learning to enhance creativity in general."
1636859,"BD Spokes: Spoke: South: Collaborative: Using Big Data for Environmental Sustainability: Big Data + AI Technology = Accessible, Usable, Useful Data!",IIS,"BD Spokes -Big Data Regional I, INFORMATION TECHNOLOGY RESEARC",10/1/2016,8/21/2017,Jennifer Hammock,"Hammock, J","Hammock, J",VA,Smithsonian Institution,Standard Grant,Beth Plale,9/30/2019,"$294,320.00 ",,hammockj@si.edu,Office of Sponsored Projects,Arlington,VA,222023709,2026337110,CSE,"024Y, 1640","028Z, 043Z, 7433, 8083",$0.00 ,normalFunding,"Protecting the environment is among the biggest challenges facing our society. As the effects of environmental degradation, global warming and climate change continue to grow, there is an increasingly urgent and critical need for research and education in biological diversity, ecological modeling and environmental sustainability. On one hand, professional and citizen scientists need ready access to large-scale biological, ecological and environmental data for modeling, simulation and analysis. On the other, college teachers and students in biology and ecology need to access large-scale data in a form meaningful to them. The various audiences will engage with big data in different ways and so a variety of knowledge-building tools are needed. This project brings together two dozen scientists from a dozen institutions in academia, government and industry to address the problem of translating big data into meaningful knowledge in support of research and education in environmental sustainability.  <br/><br/>Encyclopedia of Life  (EOL) is the world's largest database of biological species and other biodiversity information. EOL also works closely with scores of other biodiversity datasets such as BISON, GBIF, and OBIS. This project seeks to make EOL and related biodiversity data sources accessible, usable, and useful, by integrating extant artificial intelligence tools for information extraction, modeling and simulation, and question answering. The focus of this project will be on the data engineering required for this integration and construction of a resulting EOL+ system. The project team will provide access to EOL+ such that users can build their own tools and services on top of EOL+. The team will work with the NSF South Big Data Hub to organize yearly workshops for building and supporting a community of users of EOL+. Professional and citizen scientists, and teachers and students alike, will be able to access EOL+ through NSF's South Big Data Hub webportal, and use it for modeling and analysis, explanation and prediction, as well as education and workforce development in biological diversity, ecological modeling and environmental sustainability."
1555079,CAREER: Biologically inspired neural network models for robust speech processing,IIS,ROBUST INTELLIGENCE,6/1/2016,5/22/2018,Nima Mesgarani,"Mesgarani, N","Mesgarani, N",NY,Columbia University,Continuing grant,Kenneth C. Whang,5/31/2021,"$292,379.00 ",,nm2764@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,7495,"1045, 7495, 8091",$0.00 ,normalFunding,"The recent parallel breakthroughs in deep neural network models and neuroimaging techniques have significantly advanced the current state of artificial and biological computing. However, there has been little interaction between these two disciplines, resulting in simplistic models of neural systems with limited prediction, learning and generalization abilities. The goal of this project is to create a coherent theoretical and mathematical framework to understand the computational role of distinctive features of biological neural networks, their contribution to the formation of robust signal representations, and to model and integrate them into the current artificial neural networks. These new bio-inspired models and algorithms will have adaptive and cognitive abilities, will better predict experimental observations, and will advance the knowledge of how the brain processes speech. In addition, the performance of these models should approach human abilities in tasks mimicking cognitive functions, and will motivate new experiments that can further impose realistic constraints on the models. <br/><br/>This interdisciplinary project lies at the intersection of neurolinguistics, speech engineering, and machine learning, uniting the historically separated disciplines of neuroscience and engineering. The proposed innovative approach integrates methods and expertise across various disciplines, including system identification, signal processing, neurophysiology, and systems neuroscience. The aim of this proposal is to analyze and transform the artificial neural network models to accurately reflect the computational and organizational principles of biological systems through three specific objectives: I) to create analytic methods that can provide insights into the transformations that occur in artificial neural network models by examining their representational properties and feature encoding, II) to model and implement the local, bottom-up, adaptive neural mechanisms that appear ubiquitously in biological systems, and III) to model the top-down, knowledge driven abilities of cognitive systems to implement new computations in response to the task requirements. Accurate computational models of the neural transformations will have an overarching impact in many disciplines including artificial intelligence, neurolinguistics, and systems neuroscience. More realistic neural network models will not only result in human-like pattern recognition technologies and better understanding of how the brain solves speech perception, but can also help explain how these processes are impaired in people with speech and language disorders. Therefore, the proposed project will advance the state-of-the-art in multiple disciplines."
1262805,REU Site: CAAR: Combinatorial Algorithms Applied Research,CCF,"RSCH EXPER FOR UNDERGRAD SITES, COMPUT GAME THEORY & ECON",5/1/2013,4/19/2013,Samir Khuller,"Khuller, S","Khuller, S|Gasarch, W",MD,University of Maryland College Park,Standard Grant,Anindya Banerjee,4/30/2016,"$292,154.00 ",William Gasarch,samir@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,"1139, 7932","7932, 9250",$0.00 ,normalFunding,"This funding will establish a new CISE Research Experiences for Undergraduates (REU) Site at the University of Maryland-College Park.  This Site focuses on research in combinatorial algorithms, which are algorithms that work on discrete objects such as numbers, graphs, or data where one needs to optimize over a space of possible solutions.  To help create a climate in which students learn new techniques, understand a few real world problems, and work on designing and implementing algorithms, the students will be involved in applied algorithms research projects that will be jointly advised by members of the UMD theory group in conjunction with faculty in different research areas, such as systems, artificial intelligence, and databases.<br/><br/>This REU Site will support eight undergraduate students for ten weeks each year.  The Site will recruit computer science, computer engineering, and mathematics majors, with a focus on students from Historically Black Colleges and Women's colleges.  The Site will help bridge the gap between theory and practice, which will benefit both as it gives theorists new and exciting problems and non-theorists tools they can use.  The students will have the opportunity to see what research is like, obtain a solid grounding in algorithms, and encourage them to go to graduate school."
1443861,Enhancement of Spectrum Decision through Probabilistic Graphical Models,AST,EARS,9/15/2014,9/6/2014,Naima Kaabouch,"Kaabouch, N","Kaabouch, N",ND,University of North Dakota Main Campus,Standard Grant,Jonathan Williams,8/31/2018,"$291,599.00 ",,naima.kaabouch@engr.und.edu,264 Centennial Dr Stop 7306,Grand Forks,ND,582027306,7017774151,MPS,7976,"7976, 9150",$0.00 ,normalFunding,"The goal of this research is increase the consumer's quality of service in environments where more and more services are competing for use of the radio spectrum.  It is widely believed that future regulation of the spectrum will change from the current static environment, where opening new channels for communications takes years, to highly dynamic environment where smart radios will jump from frequency channel to frequency channel.   In this dynamic environment, the consumer will share the spectrum with many different types of devices, including radars, other phones, Wi-Fi servers and a host of new smart devices. <br/><br/>The new smart devices will constantly change their frequencies, data rates and modulation schemes, thereby creating a dynamic, more uncertain, environment. The scientists will explore how uncertainty influences the characterization of radio spectrum usage. The focus is on the sensing and decision-making aspects of the problem rather than management issues.   The scientists will apply their experience with Artificial Intelligence and transfer techniques of dynamic problem solving from other domains. The proposed study has the potential to develop decision support models that will inform new policies for spectrum management in the future. <br/><br/>This research project's primary aim is to advance the knowledge and understanding of wireless communication scenarios to enrich the spectrum decision process in cognitive radio by evaluating the impact of uncertainty on the different cognitive cycle changes of adaptive radios. To achieve this goal, they propose to identify, classify, and characterize the random and deterministic variables present in a typical wireless scenario and model their causal relations, using probabilistic graphical models, such as Bayesian networks and influence diagrams."
845683,CAREER: Enabling Community-Scale Modeling of Human Behavior and its Application to Healthcare,IIS,ROBUST INTELLIGENCE,3/1/2009,3/3/2009,Tanzeem Choudhury,"Choudhury, T","Choudhury, T",NH,Dartmouth College,Continuing grant,Edwina L. Rissland,11/30/2011,"$290,445.00 ",,tanzeem.choudhury@cornell.edu,OFFICE OF SPONSORED PROJECTS,HANOVER,NH,37551404,6036463007,CSE,7495,"1045, 1187, 9102, 9150, 9215, HPCC",$0.00 ,normalFunding,"Research supported by this award is developing community-based methods for sensing, recognizing, and interpreting human activities from body-worn sensors. Specifically, this research is<br/><br/>1) developing systems that learn new classes of activity with minimal human supervision, where the system queries a human user for additional information on an activity being learned, but only when such queries are informationally necessary and behaviorally unobtrusive,<br/><br/>2) developing the paradigm of community-guided learning, which leverages people's social ties and behavioral similarities, in order to define an efficient scheme for sharing various aspects of the underlying activity classes across many individuals, and<br/><br/>3) evaluating the new community-guided learning methods by using them to learn about (a) social isolation and functional independence among elderly persons, and (b) social interaction among high-functioning autistic children.<br/><br/>Speaking generally, the research is advancing machine learning and artificial intelligence, especially in the areas of semi-supervised, active, and relational learning. Beyond these basic scientific contributions, the resulting research has the potential to transform community health assessment by collecting fine-grained clinically-relevant information continuously, cheaply, and unobtrusively, over long periods of time. This research also opens up many opportunities for education and outreach, in part because it is pushing machine learning and artificial intelligence into social and societally-important realms, promising to attract groups, notably women, who are under-represented in computer science.<br/>"
9612355,Computer-Supported Meeting Scheduling,IIS,"CISE RESEARCH RESOURCES, DIGITAL SOCIETY&TECHNOLOGIES",9/1/1996,7/28/2000,Jonathan Grudin,"Grudin, J","Grudin, J",CA,University of California-Irvine,Standard Grant,C. Suzanne Iacono,8/31/2001,"$289,915.00 ",,jgrudin@microsoft.com,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,"2890, 6850","2891, 9139, HPCC",$0.00 ,normalFunding,"This is a 3-year standard award. Computer support for  meeting scheduling is a focus of active research in several  areas, including distributed artificial intelligence (DAI)  and intelligent agents, software engineering, and  information systems. It is also of very high applied  interest. However, meeting scheduling is most significant in  being one of the first desktop group support applications  that is widely used in some organizations. The researchers  will conduct empirical studies of the use of this group  support technology in settings where existing technical  infrastructures and organizational practices enable all  employees, numbering hundreds or thousands, to fully  participate in the use of a shared system. A deep  understanding of successful practice will itself extend  knowledge of organizational behavior in this new  technological context, and it can also guide the research  and application of technologies and approaches developed in  the fields mentioned above. The researchers will conduct  detailed interviews, longitudinal observational studies, and  broad surveys to determine factors underlying the success of  particular applications, adoption trajectory within  organizations, and emergent behaviors including differences  in successful use across settings. They will also explore  the possibility of using this newly-emergent technology to  better understand issues of coordination of work and  technological impact within firms."
9800929,Constructing Diagnostic Explanations Using Schema-Structured Bayesian Networks,IIS,ARTIFICIAL INTELL & COGNIT SCI,10/1/1998,12/4/2000,George Luger,"Luger, G","Luger, G",NM,University of New Mexico,Continuing grant,William Bainbridge,9/30/2002,"$288,560.00 ",,luger@cs.unm.edu,"1700 Lomas Blvd. NE, Suite 2200",Albuquerque,NM,871310001,5052774186,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"The goal of this research is to develop a representation and algorithms that  characterize diagnostic  reasoning. Human experts in a problem domain frequently interpret data in that domain in the context of a  particular causal hypothesis. This type reasoning contrasts with deductive inference where from a set of  general  rules and facts further information is deduced by sound inference rules. Diagnostic reasoning,  often called abductive inference, however, moves from a set of facts to the ""best explanation""  for the  existence of these facts. This process often requires the expert to make a hypothetical conjecture that  would explain the facts and then search for specific new information that can  confirm that conjecture.  Thus the human expert searches through a space of possible  explanations for the observed information.  This research uses Bayesian Belief Networks to build  causal models of a domain. This approach  represents in a precise way the interrelationship of  causal patterns and their  use in moving towards an explanation. The research supports handling of  conflicting and ambiguous evidence, as well as a clear method for rating plausible  inferences and the possibility of learning relative strengths of conditional  probabilities from available statistical data. Although the research domain is  built on data from investigation of failures of discrete component semiconductors  as well as the analysis of failure mechanisms in complex real time control,  diagnostic reasoning is a general research area.  Results could be important in  modeling medical decision-making, integrated circuit fault analysis, as well as  used in real time process monitoring and control.  http://www.cs.unm.edu/CS_Dept/faculty/homepage/luge  r/"
113933,ITR/SY: Mandatory Human Participation: A New Paradigm for Building Secure Systems,CNS,ITR SMALL GRANTS,9/15/2001,9/21/2001,Jun Xu,"Xu, J","Xu, J|Essa, I|Lipton, R",GA,Georgia Tech Research Corporation,Standard Grant,Joseph B. Evans,8/31/2004,"$288,000.00 ","Irfan Essa, Richard Lipton",jx@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,1686,"1667, 9218, HPCC",$0.00 ,normalFunding,"Currently, automatic attacks are a major threat to computer security.  For example, the cheapest home PC can try thousands of ""probes"" against a targeted system.  A brute-force password (or PIN number) guessing program can generate and try tens of thousands of candidate passwords each second.  Or a home PC could attempt to flood a web site with thousands of ""bogus"" requests.  <br/><br/>While there methods that attempt to stop such attacks they all can be defeated to some degree.  We propose a new approach to this security based on technology that can tell the difference between robots and humans.  Thus, we can disallow automatic attacks.  Our technology allows a new kind of restriction: now systems can insist that only humans have access to their valuable resources and they can disallow robots.<br/><br/>The proposed solution to the problem is inspired by Turing's test for artificial intelligence.  The fundamental idea of the solution is for a computer system to first ask the author of every transaction to solve a puzzle before accepting or executing the transaction.  The content of the puzzle will be based on grand challenge problems in the domains of pattern recognition, visual interpretation, and natural language understanding. These problems have the essential property that people can solve them easily while computers are not likely to solve them in the foreseeable future.  A typical puzzle would consist of the computer system sending the agent a bit-mapped image and the agent replying with an ascii string.  The image might include a picture and a question and a question about that picture, such as ""Please type the following handwritten word"" or ""Which of the objects in this picture are edible?"" The computer system determines whether the transaction author is a human based on the answer supplied.<br/><br/>This puzzle-solving process leads to a new framework for building secure computer systems.  In this framework, a human being has to be directly involved (by solving the puzzle and typing in the answer) in the authentication or other processes that are vulnerable to automatic attacks, referred to as Mandatory Human Participation (MHP).  Apparently, no automatic attack to the protected process would be possible under this framework.<br/><br/>Our proposed research is to build a pilot system that can be used to demonstrate the basic idea of MHP.  This will be based mostly on character based methods.  We then, plan to carefuly test and measure how well our system performs and how well it is received by users."
708517,Formation of Asteroid Satellites,AST,PLANETARY ASTRONOMY,6/1/2008,5/27/2010,Daniel Durda,"Durda, D","Durda, D|Bottke, W",TX,Southwest Research Institute,Continuing grant,Thomas S. Statler,5/31/2012,"$287,742.00 ",William Bottke,durda@boulder.swri.edu,6220 Culebra Road,San Antonio,TX,782385166,2105222231,MPS,1214,"0000, 1206, OTHR",$0.00 ,normalFunding,"Collisions are a fundamental process in the origin and evolution of planetary systems. For this reason, investigating impacts and impact outcomes is a prerequisite for accurately modeling the formation and evolution of planetary bodies. The inventory of satellites orbiting small Solar System bodies provides critical constraints that can be used to understand small body collisions. The ongoing work of this team represents the first systematic investigation of binary asteroid formation and produces modeled satellite systems and families of collision fragments consistent with those observed in the main asteroid belt. The research with this award will make the numerical models of asteroid satellite formation increasingly more realistic, in order to address several fundamental issues about binary asteroid formation that are still not fully understood and to enhance the ability to compare modeled binary properties with the ever increasing variety of observed asteroid satellite systems. The research team will investigate asteroid satellite and family formation via impacts onto rubble-pile targets (collisional evolution models suggest that most asteroids have been substantially fractured or shattered and reassembled by impacts since their formation), using the same numerical methods already employed to simulate solid-target impacts. Finally, the formation and survival of satellite systems during the late stages of planet formation will be investigated to determine the steady-state fraction of asteroid binaries capable of surviving from the planet formation epoch to today.  <br/> <br/>The work on this award will provide a strong synergistic link to existing observational programs that are detecting minor planet satellite systems at an ever-increasing rate. The work will help to understand the origin of the observed systems and will assist in directing future observations with scarce telescopic resources. The work continues to advance and solidify the partnerships formed between the Southwest Research Institute and The University of California Santa Cruz and The University of Maryland, and opens a new partnership with the Planetary Science Institute, providing an avenue through which scientists with different types of expertise can work together to achieve synergistic research results. The work will also continue intimate interaction with ongoing development of cutting-edge Artificial Intelligence (AI) techniques, in collaboration with JPL?s Machine Learning Group, aimed at improving the efficiency of numerical simulations. The many results of the ongoing research project have been presented to scientific colleagues at major, international astronomical meetings, and in journal papers and book articles in the peer-reviewed press. The research results are shared with students as research activities and results are incorporated into lecture and discussion material in college-level astronomy courses and in presentations in primary school classrooms where visually exciting results are shared with eager young students. Research results are also shared with the general public through extensive public outreach efforts that include television documentaries, radio interviews, and popular articles in magazines.<br/>"
1461192,REU Site: BME Community of Undergraduate Research Scholars for Cancer (BME CUReS Cancer),EEC,HUMAN RESOURCES DEVELOPMENT,6/1/2015,1/23/2015,Mia Markey,"Markey, M","Markey, M|Suggs, L",TX,University of Texas at Austin,Standard Grant,Mary Poats,6/30/2018,"$287,684.00 ",Laura Suggs,mia.markey@utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,ENG,1360,"116E, 9178, 9250",$0.00 ,normalFunding,"BROADER SIGNIFICANCE OF THE PROJECT:<br/><br/>An underlying theme of the current project is that CUReS Cancer Scholars will make contributions towards fundamental understanding of the physical principles of cancer development, prevention, and treatment during their summer experience, but more importantly, will go on in their careers to function in multi-disciplinary teams of researchers from disparate fields in medicine, biological science, physical science, engineering, and healthcare fields to advance human health. This ability is a hallmark of Biomedical Engineering and will positively impact Scholars' respective scientific fields as well as the health of our society. Increasing the number of PhDs from underrepresented groups is also a critical step toward increasing minority role models, in turn making the academic engineering culture more appealing to underrepresented minorities and women. A key feature of this REU site is the development of a partnership with Texas 4000, a non-profit organization that cultivates student leaders and engages communities in the fight against cancer. The partnership with the Texas 4000 will increase public awareness of cancer research, in particular how physical science and engineering positively impact healthcare.<br/><br/>PROJECT DESCRIPTION:<br/><br/>The scientific theme of the ""BME Community of Undergraduate Research Scholars for Cancer (BME CUReS Cancer),"" REU Site is leveraging Biomedical Engineering to Open a New Frontier in Oncology. This project is supported by the Division of Engineering Education and Centers for three summers, for 10 weeks each summer, from late May to early August. The focus of this experience is rising juniors, particularly students from groups traditionally underrepresented in engineering. BME CUReS Cancer Scholars are able to choose a project of appropriate scope from 36 different labs representing a wide range of research topics pertinent to cancer research, such as biomaterials, drug delivery, optical imaging, ultrasound, and artificial intelligence in medicine. This topics were selected based on a 2008 National Cancer Institute meeting where a number of barriers to achieving progress in cancer research were identified. The result of the meeting was a series of ""strategic actions"" that represent scientific challenges that need to be addressed. Following the NCI Meeting Report of 2008 it is becoming more broadly recognized that understanding how the range of physical laws and principles governing the behavior of all matter are operative in cancer at every scale will be critical to understanding and controlling cancer. Cancer is a disease of complexity and engineering principles in particular are developed to study, model, and solve complex problems. Hence, Biomedical Engineering is uniquely poised to make a significant intellectual contribution. These critical lines of investigation are used to organize our community of cancer Scholars towards shared goals and synergistic activities. The intellectual merit of this project is in addressing these key challenges in cancer research using an engineering approach."
716338,Machine Learning Experiences in Artificial Intelligence: A Multi-Institutional Project,DUE,"CCLI-Type 2 (Expansion), S-STEM:SCHLR SCI TECH ENG&MATH",9/15/2007,8/8/2010,Ingrid Russell,"Russell, I","Russell, I|Markov, Z",CT,University of Hartford,Standard Grant,Victor P. Piotrowski,8/31/2011,"$287,556.00 ",Zdravko Markov,irussell@hartford.edu,200 Bloomfield Avenue,West Hartford,CT,61171545,8607685938,EHR,"7492, 1536","9178, SMET",$0.00 ,normalFunding,"Computer Science (31)<br/><br/>It is generally recognized that an introductory Artificial Intelligence (AI) course is challenging to teach. This is, in part, due to the diverse and seemingly disconnected core AI topics that are typically covered. This project addresses this problem and enhances the student learning experience in the introductory Artificial Intelligence course by (1) introducing machine learning elements into the AI course, (2) implementing a set of unifying machine learning laboratory projects to tie together the core AI topics, and (3) developing, applying, and testing an adaptable framework for the presentation of core AI topics which emphasizes the strong tie between AI and computer science. This is a multi-institutional effort that engages a community of 20 scholars from a broad range of universities working together on the development, implementation, and testing of curricular material, in a manner that fosters the integration of research and education. The target audience is juniors and seniors in Computer Science, Computer Engineering, and Computer Information Systems enrolled in an introductory Artificial Intelligence course. The project deliverable is a laboratory manual consisting of a suite of adaptable, self-contained, hands-on laboratory projects that can be closely integrated into a one-term AI course and which would supplement introductory AI texts. The curricular material builds on existing successful work, funded by NSF CCLI A&I. It involves further development and testing of an adaptable framework for the presentation of core AI topics through a unifying theme of machine learning. Through the design and implementation of learning systems that enhance commonly-deployed applications, the innovative model for teaching artificial intelligence provides a simple and elegant means to communicate the power of the core ideas of AI in a manner that engages students in experiential education."
1262901,REU Site:  Undergraduate Research in Computational Biology at Mississippi State University,DBI,RSCH EXPER FOR UNDERGRAD SITES,4/1/2013,3/13/2013,Andy Perkins,"Perkins, A","Perkins, A",MS,Mississippi State University,Standard Grant,Amanda Simcox,3/31/2017,"$286,304.00 ",,perkins@cse.msstate.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,BIO,1139,"1228, 9150, 9178, 9250",$0.00 ,normalFunding,"A Research Experience for Undergraduates (REU) award has been made to Mississippi State University that will provide research training for 10 students, for 10 weeks during the summers of 2013-2015. Undergraduate students will work on interdisciplinary research projects in computational biology. Students will work closely with their faculty mentors on projects in the areas of genome analysis, functional genomics, artificial intelligence, scientific visualization, and bioinformatics algorithms, among others. Recruitment will be targeted at colleges and universities within Mississippi and the surrounding states with the goal of providing a meaningful research experience to promising undergraduate students who otherwise would not have had the opportunity to engage in research. There is a particular focus on increasing the participation of underrepresented groups in computational biology research. Educational and professional development sessions will be conducted to train students in the basics of computational biology and to provide information on graduate school and pursuing scientific careers. Students will also receive training and mentoring in the responsible conduct of research. The program will culminate with a poster session where the students will present their research findings to the computational biology community at Mississippi State University. Program objectives will be assessed through the use of a common web-based assessment tool available to BIO-funded REU PIs. Students will be tracked to document their educational and professional path through periodic communication with students via email and social media. More information about this program can be obtained by contacting the project PI, Dr. Andy Perkins (perkins@cse.msstate.edu) at (662) 325-0004, or by visiting the project website at http://www.cse.msstate.edu/~compbio/."
1004842,REU Site:   Undergraduate Research in Computational Biology at Mississippi State University,DBI,"RSCH EXPER FOR UNDERGRAD SITES, EPSCoR Co-Funding",3/1/2010,1/27/2014,Andy Perkins,"Perkins, A","Perkins, A|Bridges, S",MS,Mississippi State University,Standard Grant,Sally E. O'Connor,5/31/2014,"$286,250.00 ",Susan Bridges,perkins@cse.msstate.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,BIO,"1139, 9150","9150, 9178, 9250, 9251, SMET",$0.00 ,normalFunding,"An award has been made to Mississippi State University that will provide research training for 10 weeks for 10 students, during the summers of 2010-2012. This project is supported by the Directorates for Biological Sciences (BIO) and Computer Information Science and Engineering (CISE). Undergraduate students will be recruited from institutions throughout Mississippi and the surrounding area to work on interdisciplinary research projects in computational biology. Students will work closely with their faculty mentors on projects in the areas of genome analysis, functional genomics, artificial intelligence, scientific visualization, and bio-ontologies, among others. Recruitment will be targeted at colleges and universities within Mississippi and the surrounding states with the goal of providing a meaningful research experience to promising undergraduate students who otherwise would not have had the opportunity to engage in research. There is a particular focus on increasing the participation of underrepresented groups in computational biology research. Educational and professional development sessions will be conducted to train students in the basics of computational biology and to provide information on graduate school and pursuing scientific careers. Students will also receive training and mentoring in the responsible conduct of research. The program will culminate with a poster session where the students will present their research findings to the computational biology community at Mississippi State University. Program objectives will be assessed through the use of a common web-based assessment tool. More information about this program can be obtained by contacting the project PI, Dr. Andy Perkins (perkins@cse.msstate.edu) at (662) 325-0004, or by visiting the project website at http://www.cse.msstate.edu/~compbio/."
451293,"REU SITE: Harvey Mudd REU Site on Artificial Intelligence, Systems, and Optical Networking",CNS,RSCH EXPER FOR UNDERGRAD SITES,5/1/2005,10/31/2006,Ran Libeskind-Hadas,"Libeskind-Hadas, R","Libeskind-Hadas, R",CA,Harvey Mudd College,Continuing grant,Harriet G. Taylor,4/30/2009,"$286,209.00 ",,hadas@cs.hmc.edu,301 Platt Boulevard,CLAREMONT,CA,917115901,9096218121,CSE,1139,"9217, 9218, 9250, HPCC",$0.00 ,normalFunding,"Abstract<br/>CNS-0451293<br/>PI: Ran Libeskind-Hadas<br/>Institution: Harvey Mudd College<br/><br/>Title: REU Site: Harvey Mudd REU Site on Artificial Intelligence, Systems, and Optical Networking<br/><br/>This project creates a new Research Experience for Undergraduates site focused on the areas of artificial intelligence, systems, and optical networking. Cohorts of undergraduate students from the greater Los Angeles area participate in a ten-week summer research program at the host institution. The project includes mentorship by the experienced computer science faculty members, weekly presentations and seminars, and laboratory visits and other professional development opportunities.<br/><br/>The intellectual merit of this project lies in strong research basis and the expertise of the faculty. The projects are in major current research areas that are of interest to the community at large and that have clear practical applications. The students participate in a full range of research activities from preparing research literature reviews to production and dissemination of research results.<br/><br/>The broader impacts of the project include providing a quality research experience to undergraduate students, particularly students from underrepresented groups. The participating faculty members are committed to engaging women and under-represented minority students in their research. The partnership with nearby campuses in the California State University system should enable recruitment of a diverse set of students who might not have access to similar experiences on their own campuses. Thus this project has the potential to produce new computer science graduate students and faculty members and to advance discovery and understanding while promoting learni"
1456817,Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod,IOS,"AISL, ANIMAL BEHAVIOR",8/1/2015,4/1/2016,Eileen Hebets,"Hebets, E","Hebets, E",NE,University of Nebraska-Lincoln,Standard Grant,Michelle M. Elekonich,7/31/2019,"$285,215.00 ",,ehebets2@unl.edu,151 Prem S. Paul Research Center,Lincoln,NE,685031435,4024723171,BIO,"7259, 7659","7259, 7659, 9178, 9179, 9251, SMET",$0.00 ,normalFunding,"The ability of animals to navigate through their environment often far exceeds human capabilities (without the help of technology). Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night over distances exceeding 10 meters through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning, memory and associated behavior. To support engagement with K-12 students, their teachers and the general public, researchers will, among other activities, develop internet-based educational materials in both English and Spanish and develop various scientific inquiry activities for science events. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after they are displaced from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as the ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely be crucial for the design of any sophisticated artificial system. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
312510,ITR: Large-Scale Applications and Theory of Extremal Optimization,DMR,ITR SMALL GRANTS,9/1/2003,7/30/2003,Stefan Boettcher,"Boettcher, S","Boettcher, S",GA,Emory University,Standard Grant,Daryl W. Hess,8/31/2007,"$284,000.00 ",,stb@physics.emory.edu,"1599 Clifton Rd NE, 4th Floor",Atlanta,GA,303224250,4047272503,MPS,1686,"1271, 1765, 9218, HPCC",$0.00 ,normalFunding,"This award was made on a 'small' category proposal submitted in response to the ITR solicitation, NSF-02-168. The Divisions of Materials Research and Mathematics jointly fund this grant. It supports the application of the extremal optimization heuristic, developed by the PI, to hard optimization problems, ranging from the physics of disordered materials to combinatorial problems in computer science and artificial intelligence. The PI aims to (1) measure ground-state energies, entropies, and overlaps for spin glasses on networks and lattices, and (2) elucidate the order parameter at the SAT/UNSAT transition in combinatorial optimization problems. Extremal optimization has produced many results for lattice spin-glasses, and agrees with recent theoretical predictions on finite-connectivity Bethe-lattices to within 0.1%. A short-term objective is to produce numerical results for spin-glass systems to test the cutting-edge predictions of replica symmetry breaking on low-connectivity systems. Central to the research is the investigation of hybrid methods, derived from experimental and theoretical advances, which enable the study of much larger and more realistic systems. Comparative studies will educate practitioners about the potential of this approach to optimization with the hope of inspiring further applications. <br/>This project will introduce students to computational techniques and a spectrum of simulation methods in the process of experimenting with optimization problems on networks relevant for many physical and cross-disciplinary problems. Students will interact at the interface between computer science and physics, and as part of their education will conduct student research at Los Alamos National Laboratory's Computer and Computational Sciences division under an existing collaboration. Assessing the potential of this novel method in comparison with other optimization methods will afford undergraduate students in particular with a comprehensive learning experience. <br/>%%%<br/>This award was made on a 'small' category proposal submitted in response to the ITR solicitation, NSF-02-168. The Divisions of Materials Research and Mathematics jointly fund this grant. It supports research and education in the statistical mechanics of disordered systems. The PI will continue work on an optimization algorithm he developed and apply it to problems ranging from the physics of disordered materials to combinatorial problems in computer science and artificial intelligence.  Successful algorithmic strategies will be applied to realistic systems, for instance, to help settle long-standing questions about three dimensional spin glasses.<br/>This project will introduce students to computational techniques and a spectrum of simulation methods in the process of experimenting with optimization problems on networks relevant for many physical and cross-disciplinary problems. Students will interact at the interface between computer science and physics, and as part of their education will conduct student research at Los Alamos National Laboratory's Computer and Computational Sciences division under an existing collaboration. Assessing the potential of this novel method in comparison with other optimization methods will afford undergraduate students in particular with a comprehensive learning experience. <br/>***<br/><br/><br/><br/><br/><br/>"
966963,Intent Seeking Algorithms for New Human-Machine Interface,CBET,Disability & Rehab Engineering,8/1/2010,7/27/2010,Sanjay Joshi,"Joshi, S","Joshi, S",CA,University of California-Davis,Standard Grant,alexander leonessa,7/31/2015,"$283,362.00 ",,maejoshi@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,ENG,5342,010E,$0.00 ,normalFunding,"PI: Joshi, Sanjay S.<br/>Proposal Number: 0966963<br/><br/>Project Summary: We have created a novel human-machine interface (HMI) technology for paralyzed persons which uses the surface electromyography (sEMG) signal of a single, facial muscle for simultaneous multidimensional control of external devices. Our new controller has the potential to significantly increase the quality of life for its users. Unlike many existing humancomputer interfaces for this population, our interface is: unobtrusive & inconspicuous, noninterfering with eyes/mouth/tongue, continuously available when needed, multifunctional, easy-to-use in almost any head position, and portable. We have recently discovered that humans can learn how to simultaneously manipulate power levels in two separate frequency-bands of a sEMG power spectrum (simply by contracting the muscle). Each frequency band becomes a separate control channel, which can simultaneously control different aspects of a device. Thus, we may exploit a single muscle?s natural electrical signals in far more complex ways than previously known. Using this underlying discovery, we have developed a new user interface that relies on a single head muscle?s surface EMG signal, which is easy to obtain and restricted to a small non-descript area near the ear. Our system is somewhat similar to some electroencephalographic (EEG) based brain-computer interfaces (BCI) in which a person learns to ?guide? a cursor to certain positions on a computer screen. These positions on the screen could be virtual buttons that open computer applications (human-computer interfaces), turn on/off lights (environmental control units), or control wheelchairs (mobility applications). Two central challenges in all ?cursor-guided? HMI systems are 1) intent (how does the computer know where the user intended to place the cursor?), and 2) speed at which the cursor can achieve the intended position. These two questions are intertwined in that earlier knowledge of intent can lead to faster systems. We propose to develop new ?intent-seeking? algorithms that could make our HMI much faster than our currently instantiated system. In addition, in order to conduct evaluation studies on subjects with disabilities who cannot leave either home or hospital, we will develop a new smaller mobile version of our hardware that is very easy to transport, setup, and use anywhere.<br/>Intellectual Merit: The use of a single sEMG signal for simultaneous multidimensional control in human-computer interfaces is potentially transformative. The notion of predicting the future location of a target (in this case a computer cursor) arises in many different applications (e.g. aerospace engineering, robotics, brain-computer interfaces). These applications employ a combination of mathematical and computer-science techniques including statistical decision making, optimal filtering, and artificial intelligence. We intend to draw from these fields to develop accurate, fast algorithms for our human-computer interface application. From a hardware perspective, entire new classes of computing devices are appearing that can perform complex computations and run graphics-intensive applications from a hand-held (or smaller) footprint.<br/>Designing our interface around these operating platforms will advance the area of highly portable and easy-to-use assistive interfaces.<br/>Broader Impact: A recent study initiated by the Reeve Foundation (2009) estimates that more than 5.5 million people live with paralysis in the United States. Many of the most severely paralyzed use ventilators to breathe, and are confined to certain head/body positions at different times during the day. Our goal is for severely paralyzed persons to regain some control of their surroundings and some basic independence. We are committed to including disabled persons in our research, not only as subjects but also as researchers themselves. As such, our work will create an additional broader impact in terms of research inclusiveness. In terms of intellectual broader impact, our new intent-seeking algorithms could have applications for many computer operating systems/programs for which disabled or non-disabled persons use various devices to guide cursors on a screen."
1659585,"REU Site: Language, Cognition and Computation",SMA,,6/15/2017,6/13/2017,Michael Frank,"Frank, M","Frank, M|Potts, C",CA,Stanford University,Standard Grant,Josie S. Welkom,5/31/2020,"$283,231.00 ",Christopher Potts,mcfrank@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,SBE,Q170,"7736, 9250",$0.00 ,normalFunding,"This site is supported by the Department of Defense in partnership with the NSF's Research Experiences for Undergraduates (REU) Sites program. The REU program has both scientific and societal benefits integrating research and education. Recent developments in cognitive science have led to breakthrough new scientific results and are providing the basis for exciting new applications in areas like social computing and assistive technologies. These developments present a challenge for education, however. Even at top research universities, students are hard-pressed to receive the appropriate training; the situation is even more difficult at institutions that do not provide extensive research training. This REU addresses this challenge. Based at Stanford's Center for the Study of Language and Information (CSLI), a top institution for interdisciplinary cognitive science, the program provides talented undergraduates from diverse backgrounds with both an opportunity to do mentored research in a top laboratory and a supportive program framework that includes technical training, professional development, and academic discussion.<br/><br/>The scientific and technological innovations motivating this REU derive from a convergence within the core disciplines of cognitive science -- psychology, linguistics, and computer science -- around themes of uncertainty, approximation, and learning. As psychology and linguistics are becoming more computational, computation is returning to its cognitive roots. Artificial intelligence techniques developed in psychology are undergoing a resurgence in machine learning, and natural language processing models of syntactic structure are becoming the standard cognitive modeling frameworks in psycholinguistics. The prerequisites for research in this new intellectual environment include an understanding of how the mind works, familiarity with the nature of human language and communication, proficiency in statistical analysis, and advanced programming skills. Yet a classic psychology or linguistics degree provides almost no programming or technical experience, and a standard computer science education doesn't include any content on how the mind works. This REU fills such gaps in the training of undergraduates and helps to foster a new, more diverse generation of researchers entering cognitive science."
1725447,SPX: Collaborative Research: Ula! - An Integrated Deep Neural Network (DNN) Acceleration Framework with Enhanced Unsupervised Learning Capability,CCF,SPX: Scalable Parallelism in t,9/1/2017,7/22/2017,Yuan Xie,"Xie, Y","Xie, Y",CA,University of California-Santa Barbara,Standard Grant,Anindya Banerjee,8/31/2021,"$280,000.00 ",,yuanxie@ece.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,CSE,042Y,026Z,$0.00 ,normalFunding,"In light of very recent revolutions of unsupervised learning algorithms (e.g., generative adversarial networks and dual-learning) and the emergence of their applications, three PIs/co-PI from Duke and UCSB form a team to design Ula! - an integrated DNN acceleration framework with enhanced unsupervised learning capability. The project revolutionizes the DNN research by introducing an integrated unsupervised learning computation framework with three vertically-integrated components from the aspects of software (algorithm), hardware (computing), and application (realization). The project echoes the call from the BRAIN Initiative (2013) and the Nanotechnology-Inspired Grand Challenge for Future Computing (2015) from the White House. The research outcomes will benefit both Computational Intelligence (CI) and Computer Architecture (CA) industries at large by introducing a synergy between computing paradigm and artificial intelligence (AI). The corresponding education components??? enhance existing curricula and pedagogy by introducing interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices, and give special attentions to women and underrepresented minority groups.<br/><br/>The project performs three tasks: (1) At the software level, a generalized hierarchical decision-making (GHDM) system is designed to efficiently execute the state-of-the-art unsupervised learning and reinforcement learning processes with substantially reduced computation cost; (2) At the hardware level, a novel DNN computing paradigm is designed with enhanced unsupervised learning supports, based on the novelties in near data computing, GPU architecture, and FGPA + heterogeneous platforms; (3) At the application level, the usage of Ula! is exploited in scenarios that can greatly benefit from unsupervised learning and reinforcement learning. The developed techniques are also demonstrated and evaluated on three representative computing platforms: GPU, FPGA, and emerging nanoscale computing systems, respectively."
1057624,"EAGER:  Long-term View on Nanotechnology R&D as Reflected in Scientific Papers, Patents, and NSF Awards",CBET,SOCIETAL IMPLICATIONS OF NANO,9/15/2010,9/2/2010,Hsinchun Chen,"Chen, H","Chen, H",AZ,University of Arizona,Standard Grant,Nora Savage,8/31/2014,"$279,522.00 ",,hchen@eller.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,ENG,7702,"011E, 014E, 080E, 7702, 7735, 7916",$0.00 ,normalFunding,"The National Nanotechnology Initiative (NNI) has been underway since 2001, with attempts at coordinating federal work dating back even earlier. Over its history, NNI has been instrumental in establishing more than 60 state-of-the-art interdisciplinary research and education centers working in fields as diverse as health, aeronautics, energy, and defense. In this award, researchers at the Artificial Intelligence Laboratory at the University of Arizona will conduct a longitudinal examination of the output of the twenty years of nanotechnology research and development (1991-2010), including statistical trends and topic analysis. <br/><br/>This will be accomplished using a information diffusion model to understand the influences on nanotechnology R&D and the outcomes resulting from the many billions spent on these efforts over the past two decades. Sources of data will include articles and scientific papers, United States Patent and Trademark Office (USPTO) patents, and NSF awards. This modeling technique, typically used in the context of epidemics and the spread of infectious diseases, will be used to analyze emerging topics and possible future knowledge patterns. By examining the patterns by which information diffuses from scientific discovery into patents and commercial products, the model can be used to help estimate the probability of a granted patent document to be cited by others in the future. This is important as in a rapidly changing field such as nanotechnology, past performance is not necessarily the best predictor of future success.<br/><br/>The results of this analysis can help stakeholders, policymakers, and funding agencies such as NSF understand what the impact of funding and knowledge diffusion is on nanotechnology research and development. This understanding can then in turn be used as a tool to help influence future policies, procedures, and R&D funding."
9602317,Computer Information Systems Research Facilities            Infrastructure Modernization Project,OIA,ACADEMIC RESEARCH INFRASTRUCTU,7/1/1997,8/18/1999,Marion Harmon,"Harmon, M","Harmon, M|Hamilton, F|Adams, S",FL,Florida Agricultural and Mechanical University,Standard Grant,Sherrie B. Green,12/31/1999,"$277,645.00 ","Franklin Hamilton, Sterlin Adams",harmon@cis.famu.edu,1700 Lee Hall Drive,Tallahassee,FL,323073200,8505993531,O/D,9155,"0000, 9155, OTHR",$0.00 ,normalFunding,"  Founded in 1887, Florida A&M University (FAMU), a Historically Black University, is one of the three oldest institutions of higher education in the State of Florida.  FAMU has been successful in producing minority students interested in pursuing advance degrees in scientific and engineering disciplines, including computer science.  Faculty and students of the Department of Computer and Information Science are currently engaged in basic research involving software engineering, real-time systems, parallel computing, artificial intelligence, object-oriented databases, computer architecture, data encryption and stimulation.  Research and training activities are performed in  the Benjamin Banneker Building Unit A, a facility that was constructed in 1966.  Present conditions, such as the lack of required communication and utility infrastructure impedes progress in conducting state of the art research in computer science.  Inadequate ventilation, and air conditioning often results in equipment failure and poor network connectivity does not facilitate access to computer equipment. To rectify these problems, the National Science Foundation and FAMU will establish a partnership to renovate research and research training laboratories in the Banneker Building. Renovations will  not only consist of remodeling lab space, upgrading the electrical and telecommunications infrastructure, and improving the HVAC and lighting systems, but will provide the necessary modifications to ensure the facility is compliant with ADA regulations.  Upon completion,  the project will enhance the ability of faculty to compete for extramural funding, continue to attract outstanding student scholars and faculty, and facilitate in the increase of the nation's minority doctorates in the sciences, engineering, and mathematics."
9504138,An Ontological Hierarchy for Spatial Knowledge,IIS,ARTIFICIAL INTELL & COGNIT SCI,12/1/1995,11/5/1997,Benjamin Kuipers,"Kuipers, B","Kuipers, B",TX,University of Texas at Austin,Continuing grant,Ephraim P. Glinert,11/30/1999,"$276,479.00 ",,kuipers@umich.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,6856,"9139, HPCC",$0.00 ,normalFunding,"IRI-9504138  Kuipers, Benjamin  University of Texas-Austin  $93,501-12 mos    An Ontological Hierarchy for Spatial Knowledge    Spatial knowledge is an important and ubiquitous kind of  commonsense knowledge.  it also raises a critical issue facing  computational models of mind: the relationship between behavior  in the continuous world and  inference with discrete symbolic representations.  in this  project, a hierarchy of representations for spatial knowledge  called the Spatial Semantic Hierarchy (SSH) developed in a  previous NSF grant is being formalized so that it can be more  widely useful.  The formalization will clarify precisely when and  how different descriptive ontologies and inference methods can  interact effectively.  It will also identify the minimal  preconditions on sensors, effectors, and environment required for  the spatial model to apply and identify the minimal set of  targets for machine learning and discovery required to learn an  instance of the hierarchical spatial model from experience.  It  will be evaluated both mathematically and experimentally on  simulated and physical robots.  The results should be  theoretically important to the foundations of artificial  intelligence and practically important to intelligent robotics  applications."
1337300,XPS: DSD: Collaborative Research: NeoNexus: The Next-generation Information Processing System across Digital and Neuromorphic Computing Domains,CCF,Exploiting Parallel&Scalabilty,9/15/2013,9/6/2013,Qinru Qiu,"Qiu, Q","Qiu, Q",NY,Syracuse University,Standard Grant,Tao Li,8/31/2017,"$275,884.00 ",,qiqiu@syr.edu,OFFICE OF SPONSORED PROGRAMS,SYRACUSE,NY,132441200,3154432807,CSE,8283,,$0.00 ,normalFunding,"The explosion of ""big data"" applications imposes severe challenges of data processing speed and scalability on traditional computer systems. The performance of traditional Von Neumann machines is greatly hindered by the increasing performance gap between CPU and memory, motivating the active research on new or alternative computing architectures. By imitating brain's naturally massive parallel architecture with closely coupled memory and computing as well as the unique analog domain operations, neuromorphic computing systems are anticipated to deliver superior speed for applications in image recognition and natural language understanding.<br/><br/>The objective of this research is to establish the fundamental framework and design methodology for NeoNexus -- the next-generation information processing system inspired by human neocortex. It integrates neuromorphic computing accelerators with conventional computing resources by leveraging large scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays. The computation and data exchange will be carefully coordinated and supported by the innovative interconnect architecture, i.e., a hierarchical network-on-chip (NoC). The software-hardware co-design platform will be developed to address the various design challenges. The project will help computer architecture and high-performance computing communities to overcome the ever-increasing technical challenges of traditional architectures and accelerate the fusion between conventional computing technology and cognitive computing model. It will also promote the applications of artificial intelligence technology advances in modern computer architectures and motivate the inventions at both software and hardware levels. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce."
1658392,Collaborative research: Combining models and observations to constrain the marine iron cycle,OCE,CHEMICAL OCEANOGRAPHY,7/1/2017,3/3/2017,Timothy DeVries,"DeVries, T","DeVries, T",CA,University of California-Santa Barbara,Standard Grant,Simone Metz,6/30/2020,"$274,355.00 ",,tdevries@geog.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,GEO,1670,,$0.00 ,normalFunding,"Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
1662731,Collaborative Research: Computational Design of Metal-Organic Framework Materials,CMMI,Design of Eng Materials (DEMS),6/15/2017,6/13/2017,Matthew Campbell,"Campbell, M","Campbell, M",OR,Oregon State University,Standard Grant,Richard Malak,5/31/2020,"$274,135.00 ",,matt.campbell@oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,ENG,8086,"024E, 067E, 073E",$0.00 ,normalFunding,"This award supports research in computational methods for the automatic exploration of the search space of metal-organic frameworks to obtain desired combinations of mechanical, thermal and chemical properties. A metal-organic framework is a repeating three-dimensional crystal lattice with a large open space-frame structure composed of organic linking molecules bonded to inorganic nodal units. The interconnected pore-spaces in these materials endow them with a rich variety of unusual properties that can be exploited for gas storage, gas separation, and catalysis. Given the constraints of chemical bonds and bond angles, one cannot easily customize the lattice for a particular size and shape. Thankfully there is an astronomically large number of permutations for combining various atomic elements together. However, human designers are confounded on how to find one for their particular problem domain. What is needed is a computational process to search the space for a best solution. By formalizing the molecular design as a decision tree, the developed computer algorithms will invent new materials whose functional behavior is defined by its chemical makeup and the resulting geometry and movement of the lattice structure. As part of testing the design approach, the project will address two technologically important problems:  designing new metal organic frameworks optimized for gas storage, and materials for separating isomers in industrially important chemical feed stocks. STEM outreach activities to high school students and teachers will also be performed.<br/><br/>Specifically, the project seeks materials that exhibit highly chemically selective adsorption or permeability of gases through mechanisms that arise from chemical, steric, and vibrational behavior of the frameworks. The computational search for this incorporates a unique graph transformation approach that mimics correct stoichiometric reactions and leads to a large search tree that is amenable to recent advances in artificial intelligence planning algorithms. Furthermore, machine learning methods will establish a link between the structure and function of organic frameworks by leveraging data from complex molecular simulations. This will lead to more efficient search of the decision tree so that meaningful results can be obtained. Through detailed simulations of the resulting metal organic frameworks, the researchers will publish how their new materials can be used to tackle challenging problems in energy storage, high-tech manufacturing, and the creation of new sensitive sensor equipment."
329026,Cognitive Simulation of Qualitative Symmetry Detection,IIS,"ARTIFICIAL INTELL & COGNIT SCI, ROBUST INTELLIGENCE",12/1/2003,4/13/2006,Ronald Ferguson,"Ferguson, R","Ferguson, R",GA,Georgia Tech Research Corporation,Standard Grant,Edwina L. Rissland,11/30/2006,"$274,123.00 ",,rwf@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,"6856, 7495","9178, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"The objective of this research is to develop a self-adapting vision system inspired by biological systems. The proposed system will construct models of its environment and will employ feedback processes in a hierarchical framework based on natural systems. The project will investigate a new class of symmetry phenomena involving approximate or qualitative symmetry; qualitative symmetry is beyond the scope of most cognitive models of perception and humans often classify nearly symmetric figures as not symmetric. The model offers the potential of explaining a number of unintuitive and surprising aspects of human performance on the task. The work proposed is aimed at fleshing out and testing these explanations, and secondarily at developing a robust modeling tool for this task.<br/><br/>The proposed research is meritorious intellectually since it addresses the problem of qualitative symmetry detection, an aspect of qualitative spatial reasoning, a topic that is a very important in artificial intelligence. This work has a broad impact on many areas important to computer science and engineering including computer-aided design, interpretation of diagrams and the creation of diagramatic representations. This work will also have a broad impact on understanding human qualitative reasoning in general.<br/>"
553246,ITR:  Beyond the Talking Head and Animated Icon: Behaviorally Situated Avatars for Tutoring,IIS,ITR SMALL GRANTS,9/1/2004,7/3/2007,Francis Quek,"Quek, F","Quek, F",VA,Virginia Polytechnic Institute and State University,Continuing grant,Ephraim P. Glinert,8/31/2008,"$273,504.00 ",,quek@tamu.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,CSE,1686,"1654, 9216, HPCC",$0.00 ,normalFunding,"Behaviorally Situated Avatars for Tutoring: Beyond the Talking Head and Animated Icon<br/>Abstract<br/><br/>One-on-one tutoring is a critical component of teaching and learning. This project investigates technology to deploy an anywhere-tutor anywhere-student system that permits a tutor to provide instruction via an animated avatar. Exploiting psycholinguistic information, the system translates time-situated pointing and communicative gestures performed on a LCD tablet in conjunction with speech into a stream of behaviorally correct, spatially situated 3D gestures performed by the avatar tutor.  A camera tracks the student, facilitating socially aware behavior by the avatar.  The system exploits the student's ability to use body motion cues in the embodied avatar to direct her attention to appropriate locations of projected graphics that serve as artifacts of instruction.  The technology will potentially facilitate a tutoring program in which students may connect to a pool of tutors for help with a variety of topics.  The approach essentially implements tutoring 'telephone handsets' at both ends of the interaction.  Tutors may be distributed across multiple sites at their convenience and take calls as they are needed. Widespread access to such tutoring will facilitate the vision of universally available educational opportunities.  The project will investigate the necessary artificial intelligence and interaction technologies and evaluate the efficacy of this tutoring methodology.<br/><br/><br/>"
9634727,Integration of Computer Aided Design and Dimensional        Inspection Through Automatic Process Planning and Probe     Path Generation,CMMI,INTEGRATION ENGINEERING,9/15/1996,9/5/1996,Aristides A. Requicha,"Requicha, AA","Requicha, AA",CA,University of Southern California,Standard Grant,george hazelrigg,8/31/2000,"$271,343.00 ",,requicha@lipari.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,ENG,1463,"9148, MANU",$0.00 ,normalFunding,"9634727  Requicha   This award provides funding for investigating the development of software   systems for automatically generating all the information necessary to inspect mechanical parts with computer-controlled Coordinate Measuring Machines (CMMs). The focus will be on unsculptured parts that may contain many 2.5-dimensional features such as bosses, slots and pockets. The primary input will be a solid model of a workpiece to be measured and toleranced according to the American National Standards Institute (ANSI)   dimensioning and tolerancing standard. The output will be a set of setups, each associated with surface features to be inspected, probes to be used, probe orientations, points to be inspected in each feature, and CMM programs expressed in the ANSI standard language for CMM control. This work will provide a direct link between the Computer Aided   Design and metrology activities in a product's life cycle.   If successful, this research will result in both scientific and industrial advances. Scientifically, it will improve the current understanding of spatial reasoning, which is a difficult area of artificial intelligence. Industrially, it will provide a means for significantly reducing the costs of dimensional inspection of mechanical parts, for reducing inspection time, and for promoting consistency in part measurement. All of these benefit the overall   manufacturing process and product quality, which is increasingly important in today's marketplace. This work impacts directly the measurement of mechanical parts (1) to decide whether final products or supplier parts are acceptable, (2) to qualify manufacturing processes, that is, to show that they produce the required features, and (3) to control processes by identifying dimensional trends that must be corrected by adjusting process parameters."
1457304,Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod,IOS,ANIMAL BEHAVIOR,8/1/2015,7/24/2015,Verner Bingman,"Bingman, V","Bingman, V|Wiegmann, D",OH,Bowling Green State University,Standard Grant,Michelle M. Elekonich,7/31/2019,"$270,000.00 ",Daniel Wiegmann,vbingma@bgnet.bgsu.edu,302 Hayes Hall,Bowling Green,OH,434030230,4193722481,BIO,7659,"7659, 9178, 9179, 9251, SMET",$0.00 ,normalFunding,"The ability of many animals to navigate through their environment far exceeds what humans are able to do without the help of technology. Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning and memory. To support engagement with K-12 students, their teachers and the general public, researchers supported by this grant will develop internet-based educational materials in both English and Spanish. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after displacement from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely have applied potential for design of sophisticated artificial systems. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
9808400,Neural Mechanisms of Nutritional Homeostasis,IOS,BEHAVIORAL NEUROSCIENCE,8/1/1998,6/9/2000,Rhanor Gillette,"Gillette, R","Gillette, R",IL,University of Illinois at Urbana-Champaign,Continuing grant,Carol Van Hartesveldt,7/31/2001,"$270,000.00 ",,rhanor@uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,BIO,1191,"9107, BIOT",$0.00 ,normalFunding,"LAY ABSTRACT  IBN-9808400  Neural Mechanisms of Nutritional Homeostasis    Motivational processes, in particular hunger, are driving  influences in behavioral decision-making; however, it is not known  how neural networks mediating feeding or other motivated behaviors  are organized by the physiological mediators of hunger. One  critically involved neurochemical is the biogenic amine serotonin  (5-HT), which modulates affect and arousal in vertebrates and  invertebrates alike. In a simple and accessible model system, 5-HT  stimulates readiness to feed acting in the feeding motor network  to enhance specific aspects of neuron excitability. Evidence  suggests that 5-HT stimulates production of nitric oxide (NO), a  critical modulator of neural activity in many animals. This  proposal outlines plans to elucidate the role and mechanisms of  action of 5-HT in regulating the enzyme that makes NO, and thereby  hunger/satiation state. These studies combine behavioral and  electrical measures with analysis of 5-HT and NO-related chemical  compounds in single cells. These studies approach the basic  organization of the feedback loops regulating nutritional  homeostasis in all motile animals and can lead to a fuller  understanding of mechanisms of hunger/satiation. They relate  directly to health issues of weight-control in anorexia and  obesity. Knowledge of these factors is likely to be significant to  the development of autonomous robots capable of making least-  probable-error decisions in a noisy environment, and to the  evolution of artificial intelligence for whose optimal function  motivation-based processes can provide the critical regulation of  goal related activity, just as they do in real intelligence  systems."
1620022,Collaborative Research:   Algorithms for Large-Scale Stochastic and Nonlinear Optimization,DMS,"OE Operations Engineering, COMPUTATIONAL MATHEMATICS",8/1/2016,6/17/2016,Jorge Nocedal,"Nocedal, J","Nocedal, J",IL,Northwestern University,Standard Grant,Leland M. Jameson,7/31/2019,"$270,000.00 ",,nocedal@eecs.northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,MPS,"006Y, 1271","071E, 072E, 073E, 077E, 078E, 9102, 9263",$0.00 ,normalFunding,"The promise of artificial intelligence has been a topic of both public and private interest for decades. Starting in the 1990s the field has been benefited from the rapidly evolving and expanding field of machine learning. The intelligent systems that have been borne out of machine learning, such as search engines, recommendation platforms, and speech and image recognition software, have become an indispensable part of modern society.  Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on increasingly powerful computing platforms and the availability of very large datasets.  One of the pillars of machine learning is mathematical optimization, which, in this context, involves the computation of parameters for a system designed to make decisions based on yet unseen data. The goal of this project is to develop new optimization algorithms that will enable the continuing rise of the field of machine learning.<br/>  <br/>The research consists of two projects, which are thematically related and address the solution of optimization problems that are nonlinear, high dimensional, stochastic, involve very large data sets and in some cases are non-convex. Two families of algorithms will be developed to garner the benefits of both stochastic gradient methods and batch methods, while avoiding their shortcomings. One of these algorithms uses a gradient aggregation approach that re-uses gradient values computed at previous iterations. The challenge is to design an algorithm that is efficient in minimizing testing error, not just training error. The second approach employs adaptive sampling techniques to reduce the noise in stochastic gradient approximations as the optimization progresses. An important aspect of this research is the design of an efficient strategy for incorporating second-order information that captures curvature of the optimized loss function, even in the case when Hessian estimates are based on inaccurate gradients. In all cases, the goal is research is to design and implement algorithms in software, and test them on realistic machine learning applications."
1549522,STTR Phase I:  Independent Science Learning through Serious Games with Expert Avatars and Complementary Stories,IIP,STTR PHASE I,1/1/2016,12/10/2016,Peter Solomon,"Solomon, P","Solomon, P|Kirkley, S|Vesel, J",CT,THEBEAMER LLC,Standard Grant,Ben Schrag,6/30/2017,"$269,946.00 ","Sonny Kirkley, Judy Vesel",prsolomon@comcast.net,87 Church St,East Hartford,CT,61083720,8602125071,ENG,1505,"079E, 1505, 163E, 8031, 8032, 8039",$0.00 ,normalFunding,"This STTR Phase I project  will develop and test a learning platform to facilitate independent, personal and enjoyable science education. The platform combines an engaging book, whose characters employ a fictional virtual environment to solve a mystery, with a complementary computer-based virtual environment to support games, explorations, and interviews with Expert Avatars (XAs), such as Albert Einstein and Henrietta Leavitt, that appear in the book. The goal is to increase the interest in science for children in grades 5-8, where there is a shortage of science teachers, and where educational tools must compete with the high level of technology to which young people are attracted, like games with talking avatars and virtual personal assistants to answer their questions. Increasing students' interest in science careers can help fill the projected worker shortage for high tech industries and provide desperately needed science teachers. Filling these jobs is expected to increase America's GDP (and tax revenues) and high tech exports. This project will develop the initial offering in a projected series to facilitate independent learning of science, mathematics, engineering, history, the arts and other subjects through interesting stories and exciting virtual environments populated with XAs for the leaders in their fields.<br/><br/>The project will build on the successful application in education of computer-based virtual environments and games by adding two important features. First, the digital content will be complemented by the book, whose characters use a fictional virtual environment to solve the same STARDUST MYSTERY posed in the game. What is STARDUST? Where, when and how did it form? How did it get into George Washington and from him to you? The book provides an introduction, user's guide, scaffolding and sales channel for the game. Second, the virtual environment and game, developed with Unity 3-D, will be populated by XAs for some of the great minds in science. The game will support virtual explorations, such as a trip back through time to the Big Bang and virtual visits with the XAs. The XA's will be backed by an artificial intelligence (AI) system to support a conversation where students' can get answers to questions about the XA's contributions, their lives and their period in history. Responses will be generated using customized knowledge bases for each XA and a hybrid, cloud-based AI system.  The project will include a formative evaluation of the game combined with book excerpts to assess the benefits of, and receptivity to, the game, book and XA combination."
1663360,Collaborative Research: Computational Design of Metal-Organic Framework Materials,CMMI,Design of Eng Materials (DEMS),6/15/2017,6/13/2017,Peter Greaney,"Greaney, P","Greaney, P",CA,University of California-Riverside,Standard Grant,Richard Malak,5/31/2020,"$269,245.00 ",,agreaney@engr.ucr.edu,Research & Economic Development,RIVERSIDE,CA,925210217,9518275535,ENG,8086,"024E, 067E, 073E",$0.00 ,normalFunding,"This award supports research in computational methods for the automatic exploration of the search space of metal-organic frameworks to obtain desired combinations of mechanical, thermal and chemical properties. A metal-organic framework is a repeating three-dimensional crystal lattice with a large open space-frame structure composed of organic linking molecules bonded to inorganic nodal units. The interconnected pore-spaces in these materials endow them with a rich variety of unusual properties that can be exploited for gas storage, gas separation, and catalysis. Given the constraints of chemical bonds and bond angles, one cannot easily customize the lattice for a particular size and shape. Thankfully there is an astronomically large number of permutations for combining various atomic elements together. However, human designers are confounded on how to find one for their particular problem domain. What is needed is a computational process to search the space for a best solution. By formalizing the molecular design as a decision tree, the developed computer algorithms will invent new materials whose functional behavior is defined by its chemical makeup and the resulting geometry and movement of the lattice structure. As part of testing the design approach, the project will address two technologically important problems:  designing new metal organic frameworks optimized for gas storage, and materials for separating isomers in industrially important chemical feed stocks. STEM outreach activities to high school students and teachers will also be performed.<br/><br/>Specifically, the project seeks materials that exhibit highly chemically selective adsorption or permeability of gases through mechanisms that arise from chemical, steric, and vibrational behavior of the frameworks. The computational search for this incorporates a unique graph transformation approach that mimics correct stoichiometric reactions and leads to a large search tree that is amenable to recent advances in artificial intelligence planning algorithms. Furthermore, machine learning methods will establish a link between the structure and function of organic frameworks by leveraging data from complex molecular simulations. This will lead to more efficient search of the decision tree so that meaningful results can be obtained. Through detailed simulations of the resulting metal organic frameworks, the researchers will publish how their new materials can be used to tackle challenging problems in energy storage, high-tech manufacturing, and the creation of new sensitive sensor equipment."
552802,REU Site: Design Tech - Sparking Research in Interactive Visual Design,CCF,,3/1/2006,3/13/2008,Benjamin Watson,"Watson, B","Watson, B|Healey, C",NC,North Carolina State University,Continuing grant,Tracy J. Kimbrel,2/28/2010,"$268,763.00 ",Christopher Healey,bwatson@ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,"T370, T787, V916","7736, 9216, 9250, HPCC",$0.00 ,normalFunding,"The site is supported by the Department of Defense in partnership with the NSF REU Program.<br/><br/>Digital technology has already moved from the machine room to the desktop, and is now embedding<br/>itself fully in our daily lives, becoming a designed artifact. Todays undergraduates love designed<br/>technology, and with justification: the outsourcing of purely technical work is more common every day,<br/>while creative technical design work remains truly value-added and secure. Yet oddly, there are few<br/>educational and research programs that train future professionals for this environment.<br/><br/>The three-summer Design Tech program will begin to address this lack, inviting exceptional<br/>undergraduate students in computer science and design to an interactive visual design hothouse. The<br/>program is organized around several principles common to design and technology: celebrating creativity<br/>feeding the spark that motivates successful designers and researchers; embracing critique <br/>encouraging bold thinking and original work by making critique less threatening; focus on product <br/>increasing the understandability of design and technical theory by placing it in an applied context; social<br/>creativity  emphasizing the group dialog of successful creativity to improve teamwork and diversity;<br/>interdisciplinary teamwork  using cross-disciplinary teams to improve research and design quality; team<br/>diversity  bettering designed technology with broader ethnic and cultural participation.<br/><br/>Design Tech students will be recruited from local womens and historically black colleges, pass<br/>through an orientation, be formed into project-centered teams, and work with investigators in semi-weekly<br/>meetings. Less frequent critique sessions inspired by design pedagogy will encourage independent and<br/>critical thought. Projects will target delivery at a final session Showcase open to the public. Research<br/>topics will emphasize interactive visual design, and be drawn from the existing research agendas of the<br/>four investigators, who are experts in graphics, visualization, artificial intelligence and design.<br/><br/>Intellectual Merit<br/>By bringing together the design and interactive computing communities in a<br/>research and educational environment, Design Tech will generate powerful intellectual ripples. Obviously,<br/>the research successfully performed by the undergraduates will have value, as will their learning about<br/>research and design. As researchers and designers work together on these research problems, they will<br/>find new solutions and perhaps more important, generate new problems. Similarly, as they cooperate on<br/>pedagogy, they will synthesize new techniques for making better designers out of researchers, and better<br/>researchers out of designers.<br/><br/>Broader Impacts<br/>With its emphasis on diversity, Design Tech will have a broad impact on the<br/>technical education of women and minorities. The investigators will publish their pedagogical successes<br/>and failures on the web and in print, disseminating the results of their experiment. PI Watson is already<br/>organizing a new SIGGRAPH course on graphics and design as well as an ACM campfire on interactive<br/>visual design; his experiences in Design Tech will shape the thoughts he brings to and the content<br/>disseminates at those events."
535182,Formal Framework for Analysis of Adaptation in Multi-Agent Systems (ADAPT2),IIS,"Cyber-Human Systems (CHS), COLLABORATIVE SYSTEMS",6/15/2006,5/11/2007,Kristina Lerman,"Lerman, K","Lerman, K",CA,University of Southern California,Continuing grant,William Bainbridge,5/31/2009,"$268,000.00 ",,lerman@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,"7367, 7496","9102, 9216, HPCC",$0.00 ,normalFunding,"This research will develop a general framework for mathematical analysis of collective behavior of adaptive multi-agent systems. Adaptation is an essential requirement for autonomous multi-agent systems functioning in uncertain dynamic environments, for example, distributed robot teams, modules in an embedded system, nodes in a sensor network, or software agents. Adaptation allows agents to change their behavior in response to changes in the environment or actions of other agents. Mathematical analysis of adaptive systems will enable researchers to design more robust systems, and to predict, control and understand their behavior. <br/><br/>The research will study agents that make decisions autonomously based on local information, which comes either from interactions with other agents or from the local environment. In particular, this project will examine different classes of adaptive behavior, such as adaptation through reinforcement and adaptation through communication via spatially extended fields. Reinforcement learning is a powerful framework where an agent learns optimal actions through a trial and error exploration of the environment and by receiving rewards for good actions. Collective adaptation can also take place in systems in which agents are coupled through external fields, for example, through markers they deposit in the environment. <br/><br/>Although adaptation and learning have long been the focus of the artificial intelligence community, there is relatively little work examining how a group of adaptive agents will act. The difficulty arises from the fact that agents adapt in the presence of other adaptive agents. Often it is not a priori clear how the system will act or even if adaptation will achieve the desired goals. In addition, the designer has very little guidance about what individual agent characteristics are required to guarantee the desired collective behavior. The lack of a formal understanding of these problems has prevented researchers from taking full advantage of this powerful design paradigm. The mathematical analysis to be performed in this research will help answer these questions. <br/><br/>There is a critical need for better foundations and tools for analyzing multi-agent behavior and verifying control mechanisms for multi-agent systems. The lack of such tools stands in the way of wider deployment of such systems, especially robots and embedded systems. Experiments and simulations that are necessary to validate control algorithms are time consuming and costly. Quantitative understanding provided by the mathematical models to be developed in this project will lead to more robust and efficient control algorithms and greater deployment of such systems in the field.<br/>"
431725,CAREER:  Support Vector Methods for Functional Genomic Analysis,IIS,ARTIFICIAL INTELL & COGNIT SCI,4/1/2004,2/8/2005,William Noble,"Noble, W","Noble, W",WA,University of Washington,Continuing grant,Douglas H. Fisher,2/28/2007,"$266,000.00 ",,noble@gs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6856,"1045, 1187, 9216, HPCC",$0.00 ,normalFunding,"As the Human Genome Project nears completion the need grows for functional genomic analyses which in addition to the primary genomic sequence involve other types of data such as gene expression measurements from microarray hybridization experiments. Research in functional genomics involves a range of computational problems including visualization, clustering, classification, regression, knowledge representation, and predictive modeling.   This project will touch on each of these areas, but the primary focus will be on developing machine learning techniques that learn to place genes into discrete functional categories in order to simplify and render more tractable the problem of inferring gene function from genomic data.  To the end the PI will build on his prior work which showed that a support vector machine (SVM) can be successfully trained using DNA microarray expression data to recognize various gene functional categories, and will develop methods for combining coding sequence, promoter region, gene expression, and other types of genomic data in SVM-based learning algorithms.   The research will lead to improved understanding of the ability of various machine learning techniques to recognize different types of gene functional classes, and will also yield new techniques for learning simultaneously from multiple types of data.  Learning from heterogeneous data sets is a core issue in artificial intelligence and machine learning;  the ability to combine knowledge from various types of genomic data is critical for understanding the cell at the molecular level, and should lead to important insights into gene function."
1025453,CMG Collaborative Research: Non-assimilation Fusion of Data and Models,DMS,OPPORTUNITIES FOR RESEARCH CMG,8/1/2010,8/26/2010,Leonid Piterbarg,"Piterbarg, L","Piterbarg, L",CA,University of Southern California,Standard Grant,Junping Wang,7/31/2014,"$265,841.00 ",,piter@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,MPS,7215,"1303, 7215, 7232",$0.00 ,normalFunding,"The PIs will develop a methodology for improving estimate and prediction of the state of a dynamical system, with particular focus on analyzing ocean dynamics. The primary goals of this project are thus to develop innovative approaches for representation and manipulation of data uncertainty and model error using a fuzzy set formulation and to then apply these approaches for the data and model fusion formulated as the global optimization problem. Convenient and fast numerical algorithms will be developed to solve the problem using high-performance parallel computing. Such an approach differs from usual statistical estimates but with advantages and drawbacks of its own. The general mathematical theory will be applied to a long-standing but important problem of improving estimates and prediction of the state of the ocean. In particular, the proposed study targets a synthesis of submesoscale/mesoscale fronts, jets and eddies by fusing satellite observations, float and shipboard data of lower resolution, as well as ROMS simulation results for Central California. The theory should provide new tools to be applied in oceanography, meteorology, climatology, artificial intelligence, computer science, control engineering, decision theory, expert systems, operational research and pattern recognition. As the first step in using these tools for broader oceanography community goals, the fusion approach will be applied to different data bases to understand and quantify heat storage and carbon content of the North Atlantic in collaboration with scientists from Great Britain and Germany and to allow junior scientists to obtain excellent training and learning in cross disciplinary/multi-disciplinary areas of great scientific and practical importance. <br/><br/>The PIs will address a long-standing but important problem involved with improving the estimation and prediction of the state of the ocean. The primary goals of this project are to develop an innovative approach for representation and manipulation of uncertainty coming from a wide variety of sources such as sensor outputs, model outputs, aggregating expert opinions as well as merging different databases and data even when distinct pieces of information are contradictory, and to suggest methods to fuse this information in decision making goals. The study will provide new mathematical theory and tools relevant for this problem, but also for more general applications in oceanography, meteorology and climatology. Mathematically the approach uses a fuzzy set formulation which originated in pure mathematics and which will be adapted for representing and manipulating data uncertainty and ocean model error. Results of the work will advance development of new forecast metrics in terms of fuzzy sets as well as new methods for quantification of model predictability through data-model and model-model comparisons at weather and climatic scales. As the first step in using these tools for broader oceanography community goals, the approach will be applied to different data bases which relate to quantifying heat storage and carbon content of the North Atlantic. The PIs will collaborate with scientists from Great Britain and Germany. Junior scientists involved in the project will obtain excellent training and learning in cross disciplinary/multi-disciplinary areas of great scientific and practical importance."
1704932,"RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making",IIS,ROBUST INTELLIGENCE,8/1/2017,7/27/2017,Judea Pearl,"Pearl, J","Pearl, J",CA,University of California-Los Angeles,Standard Grant,Weng-keen Wong,7/31/2020,"$265,000.00 ",,judea@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,"7495, 7924",$0.00 ,normalFunding,"Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project also helps to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project studies identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project considers the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project further aims to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project considers the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
83287,Collaborative Research: Interactive Level-Set Modeling for Visualization of Biological Volume Datasets,CCF,ADVANCED COMP RESEARCH PROGRAM,10/1/2000,5/15/2002,David Breen,"Breen, D","Breen, D",CA,California Institute of Technology,Continuing grant,Xiaodong Zhang,3/31/2004,"$264,999.00 ",,david@cs.drexel.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,CSE,4080,"9216, HPCC",$0.00 ,normalFunding,"As scientific data becomes larger and more complex, the problem of presenting data effectively is joined by another, potentially more difficult one - how to extract presentable data from the flood of raw information. This problem is equally difficult for results from large simulations and data from high-resolution instruments. Thus, the field of scientific visualization becomes intimately tied to more traditional studies of data analysis, including image processing, pattern recognition, artificial intelligence, and computer vision. However, in contrast to those fields, visualization explicitly includes the user in the process of filtering, extracting, and rendering meaningful data. The goal of this project is to make level-set modeling - a useful but computationally expensive visualization technique - interactive for use in 3-D visualization of biological data sets.<br/><br/>Technically, the project has three components. The first is the design and implementation of a hardware and software system for interactive level-set surface model computation and display. This system will use off-the-shelf PC hardware and graphics boards and new algorithms and software to reach its interactivity goals. The second component will create the human-computer interface that allows users to interact with the level-set models. This will require mapping user input onto the mathematical descriptions controlling surface motion and deformation in the models. Finally, the third component will be the application of the techniques to visualize large biological data sets by researchers in this project.<br/><br/>This is a collaborative project between California Institute of Technology and the University of Utah.<br/>"
1433765,Computer-Assisted Imaging for Structural Damage,CMMI,Structural and Architectural E,8/1/2014,6/24/2014,David Lattanzi,"Lattanzi, D","Lattanzi, D",VA,George Mason University,Standard Grant,Y. Grace Hsuan,7/31/2018,"$264,942.00 ",,dlattanz@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,ENG,1637,"036E, 039E, 040E, 1057, CVIS",$0.00 ,normalFunding,"After a disaster, such as an earthquake, inspectors are tasked with assessing the integrity of affected buildings and structures. Depending on the scale of the disaster, the number of required inspections can range into the thousands. There are both public safety and economic pressures to consider, and so rapid and accurate assessments of buildings and structures are vital. The goal of this research project is to develop a method using digital image analysis and artificial intelligence to assess the integrity of civil structures after a natural disaster. Fully realized, this technology will enable post-disaster inspectors to rapidly and accurately estimate structural damage using only a digital camera and portable computer. <br/><br/>Research in a comprehensive method of computer vision-based structural assessment will be pursued, one that is flexible enough to operate in highly varied and challenging field environments. To be truly comprehensive, such a methodology must be hierarchical, first recognizing the system-level context of structural components observed in an image and then leveraging that information to augment localized descriptions of damage extracted from segmentation routines. In this research program, the visual and instrumentation records of NEES experiments, available through the NEESHub, will be mined and analyzed to validate the algorithm. The research program will advance understanding as to how visually observable damage correlates to structural performance, and will provide insights into the suitability of hierarchical learning techniques for use in the field of computer vision-based structural assessment. More broadly, the project will result in an extensible method of visual, non-contact structural assessment that will provide a foundation for future structural monitoring system."
1218156,"RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications",IIS,"INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE",9/1/2012,3/26/2013,Haibin Ling,"Ling, H","Ling, H",PA,Temple University,Standard Grant,Jie Yang,8/31/2016,"$264,928.00 ",,hbling@temple.edu,1801 N. Broad Street,Philadelphia,PA,191226003,2157077547,CSE,"7364, 7495","7495, 7923, 9251",$0.00 ,normalFunding,"Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair.  On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br/><br/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms."
624695,BIC: Genetically-Engineered Bacteriorhodopsin Proteins for Holographic Associative Memories,CCF,"BIOLOGY & INFORMATION TECHNOLO, EMERGING MODELS & TECHNOLOGIES",1/1/2006,8/4/2006,Jeffrey Stuart,"Stuart, J","Stuart, J",CT,University of Connecticut,Continuing grant,Mitra Basu,8/31/2008,"$264,235.00 ",,jeffrey.stuart@uconn.edu,438 Whitney Road Ext.,Storrs,CT,62691133,8604863622,CSE,"1705, 7353","9184, 9216, 9218, BIOT, HPCC",$0.00 ,normalFunding,"The increasing demands of modern computation require innovative solutions to data storage and processing. Conventional architectures are often limited not by processor speed, but by the ability to efficiently handle large amounts of data. Optical architectures for these applications promise potential gains in speed, data throughput, & storage density. In addition, an entirely new class of materials has emerged that is expected to provide practical solutions to these demanding applications; these materials include not only conventional optical & holographic materials, but also of those of biological origin. Bacteriorhodopsin (BR) was among the first proteins to attract attention as a viable component in molecular electronics & nanotechnology. In the native organism, Halobacterium salinarum, the protein acts as a photosynthetic sunlight to chemical energy transducer. Through billions of years of evolution, nature has produced a protein that is remarkably rugged and responds quickly and efficiently to light. The protein's unique properties make it an appealing candidate for a number of devices that use light to record or process information, including holography and optical computer memory storage.<br/><br/>Despite bacteriorhodopsin's unique properties, it still lacks the efficiency necessary for commercialization. Fortunately, advanced techniques in molecular biology can be used to optimize the protein for specific device architectures. Through techniques such as random mutagenesis, semi-random mutagenesis, and directed evolution, researchers can custom-tailor protein properties in ways never before possible. The use of directed evolution techniques to produce BR variants for optical recording materials will result in reusable holographic media that require no processing or fixing, and are capable of real-time operation. The goal of this research effort is to develop a new class of fully write-read-erasable dynamic holographic recording media based on genetically-engineered bacteriorhodopsin variants. Each new material will be evaluated to determine which is the most efficient, with respect to a number of standard holographic benchmarks.<br/><br/>The targeted application we hope to develop is a bacteriorhodopsin-based holographic associative memory, which simulates the way the human brain works. Associative memory architectures are not new, but their utility has been limited by the absence of materials that facilitate highly efficient implementation (i.e., the lack of truly reusable media). Associative memories allow computers to identify objects and concepts faster and more efficiently- applications include any technology that requires autonomous general-pattern recognition and/or fast & efficient large-scale database search capabilities. Information processing techniques such as data mining, data reduction, and large-scale complex database searches will be enhanced through the successful development of these architectures. Furthermore, this technology has the potential to play a critical role in the development of artificial intelligence (AI)-successful implementation of AI architectures will require a fast & efficient large-scale database search capability. Incorporation of dynamic write-read-erase materials into pre-existing associative architectures will introduce a level of flexibility not previously possible.<br/><br/>To summarize, the proposed effort uses advanced molecular biological techniques to produce genetically-engineered bacteriorhodopsin (BR) proteins for holographic associative memories. The technical merit & broader impacts of this technology must therefore be considered at multiple levels, including (1) development of novel holographic materials & (2) the ramifications of viable associative memories. The former will impact any holographic technology that will benefit from a real-time reusable media (e.g., optical memory & non-destructive testing architectures), while the latter will facilitate any technology that will benefit from the ability to utilize fast & efficient large scale database capabilities (e.g., artificial intelligence, proteomics, and the human genome project). Perhaps the most basic impact of this technology will be the demonstration of random mutagenesis and directed evolution as viable techniques for the production of custom-tailored proteins to be used in a variety of applications."
9357707,NSF Young Investigator: New Directions in Computational Learning Theory,CCF,THEORY OF COMPUTING,7/15/1993,3/5/1998,Sally Goldman,"Goldman, S","Goldman, S",MO,Washington University,Continuing grant,Yechezkel Zalcstein,12/31/1999,"$262,500.00 ",,sg@cs.wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,CSE,2860,"9216, 9297, 9227, HPCC",$0.00 ,normalFunding,"Building machines that learn from experience is an important research goal of artificial intelligence. Recently, considerable research attention has been devoted to the theoretical study of machine learning. This project focuses on several new directions designed to enhance the current learning models to more accurately model real-life learning situations. Most work in the area of concept learning assumes there is a well-defined border that divides all objects into those that are instances of the concept and those that are not. In reality, though, categorization of objects is often not so clear cut: an algorithm designed to read handwritten cheques will likely encounter many handwritten characters that look somewhat like a `4,` and somewhat like a `9.` In these situations, one possible goal for the learner is to determine which objects are unclassifiable (i.e., the classification is not clear cut) as well as determining the classifications of objects which are classifiable. Another possibility is to require only that the learner determine a categorization so that no object is incorrectly categorized. Thus, for this second goal, the learner can arbitrarily categorize those objects that can go either way. This project defines and studies learning models for both possibilities. Also this project continues the PI's work initiated on developing and studying formal models of teaching to understand how a teacher with knowledge of the target concept and the learner can reduce the training time needed by the learner. As well as being of theoretical interest, there are potential applications of the research to improving automated manufacturing environments."
1704352,"RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making",IIS,ROBUST INTELLIGENCE,8/1/2017,7/27/2017,Jin Tian,"Tian, J","Tian, J",IA,Iowa State University,Standard Grant,Weng-keen Wong,7/31/2020,"$260,169.00 ",,jtian@iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,CSE,7495,"7495, 7924",$0.00 ,normalFunding,"Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project will also help to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project will study identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project will consider the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project will further aim to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project will consider the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
9158473,"PYI:  Real-Time AI, Cooperative Problem Solving, and        Intelligent Systems",IIS,"CISE RESEARCH INFRASTRUCTURE, DIGITAL SOCIETY&TECHNOLOGIES",8/1/1991,8/13/1997,Edmund Durfee,"Durfee, E","Durfee, E",MI,University of Michigan Ann Arbor,Continuing grant,C. Suzanne Iacono,7/31/1998,"$257,500.00 ",,durfee@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,"2885, 6850","9216, 9227, HPCC",$0.00 ,normalFunding,"This is the first year base amount funding of a five-year PYI                   continuing award.  This PYI will continue his research on                       distributed artificial intelligence (AI) with an emphasis on                    building intelligent computing systems for dynamic, multiagent                  applications.  The research uses blackboard systems and other                   integrating architectures that allow an agent's perception,                     reasoning, communication, and motor components to collectively                  control an agent's behavior.  The PI is also pursuing work in                   real-time artificial intelligence.  He is working on developing                 preliminary theories of real-time reasoning that account for both               meeting deadlines and for negotiating to change deadlines.  This                work on techniques for negotiating ties into his additional                     research interest in uncovering the  general principles                         underlying coordination between intelligent agents.  The goal is                to build interdisciplinary theories of coordination, drawing on                 concepts from management science and operations research as well                as AI, and to embody these theories in practical mechanisms for                 coordinating multiple intelligent computing systems.  The near                  term plan is to develop a core of interdisciplinary concepts                    using a hierarchy of behavioral specifications as a common                      representation, with the long-term objective of developing                      fundamental theories of a science of coordination.  The                         researcher is also interested in applying techniques for                        coordinating AI systems to problems in human-human and human-                   computer interactions."
98180,Approximation of NP-Hard Problems: Algorithms and Complexity,CCF,THEORY OF COMPUTING,8/1/2001,8/17/2001,Sanjeev Arora,"Arora, S","Arora, S",NJ,Princeton University,Standard Grant,David Du,7/31/2004,"$256,952.00 ",,arora@cs.princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,2860,"9216, HPCC",$0.00 ,normalFunding,"Approximation of NP-hard problems: Algorithms and Complexity<br/>Sanjeev Arora<br/>Princeton University<br/><br/>The broad goal of  the project is a study of the approximation properties of<br/>NP-hard problems. NP-hard problems are those that do not have any efficient<br/>algorithms if the classes P and NP are different, as is widely-believed. They arise in a variety<br/>of application areas in science and technology, including scheduling, VLSI<br/>design, artificial intelligence, design of optimum networks, etc. <br/>Since we do not expect to solve these problems optimally, there is a need to <br/>design efficient approximation algorithms for them: algorithms that compute a <br/>solution whose cost is within a small factor of the optimum. The PI has been<br/>involved in designing approximation algorithms during the past decade. He has<br/>also been part of an ongoing research program that shows that for many of these problems,<br/>computing approximate solutions is no easier than computing optimum<br/>solutions. (In other words, approximation is also NP-hard.) These<br/>inapproximability results shed important light on the problems as well.<br/><br/>The project takes a two-pronged approach, combining a search for good<br/>approximation algorithms with a search ---using the theory of probabilistically <br/>checkable proofs (PCPs)--- for inapproximability results. The project focusses<br/>on a collection of important algorithmic problems, including: learning mixtures<br/>of distributions (a problem important in AI and data  mining/analysis),<br/>learning bayes nets and markov random fields  (useful in speech recognition,<br/>machine vision, medical diagnoses systems etc.), lattice problems (useful in<br/>cryptography and cryptanalysis), and graph coloring (a central problem in complexity theory).<br/>Progress, especially algorithmic progress, on any of these problems has<br/>important consequences."
9704232,Real-Time Probabilistic Inference,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/15/1997,11/8/1999,Bruce D'Ambrosio,"D'Ambrosio, B","D'Ambrosio, B",OR,Oregon State University,Continuing grant,Ephraim P. Glinert,8/31/2001,"$255,141.00 ",,bruce.dambrosio@gmail.com,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"The goal of this research is to stretch the computational limits of Bayesian inference  with focus on embedded, real-time problems.  Bayesian probability, as both a theoretical  framework and as a representational and computational method, is having a profound  impact on artificial intelligence research and practice.  However, limitations is  available computational methods still hamper widespread application, especially in real-  time and embedded systems.  This research builds from a core focus on search-based  approximation methods, using real-time decision evaluation as its experimental tool, and  extends to scaling issues including compilation (including reinforcement-learning) and  control of communication in distributed systems.  Results of this research will include  improved methods for real-time monitoring and assessment for industrial, medical and  consumer applications."
1554783,CAREER: Phase Transitions in Some Discrete Random Models and Mixing of Markov Chains,DMS,"PROBABILITY, Division Co-Funding: CAREER, EPSCoR Co-Funding",7/1/2016,4/1/2016,Nayantara Bhatnagar,"Bhatnagar, N","Bhatnagar, N",DE,University of Delaware,Continuing grant,Tomek Bartoszynski,6/30/2021,"$253,761.00 ",,nayantara.bhatnagar@gmail.com,210 Hullihen Hall,Newark,DE,197162553,3028312136,MPS,"1263, 8048, 9150","1045, 9150",$0.00 ,normalFunding,"Water turning into ice at its freezing point or the magnetization of iron are examples of phase transitions in physical systems. At the transition point, the properties of the system such as the volume or heat capacity may change discontinuously. The aim of our research is to study phase transitions in mathematical models using probabilistic tools in the following three directions. (1) The longest increasing subsequence (LIS) of a permutation is the length of a maximal subsequence of the permutation in which the elements increase. How long is the LIS for a uniformly random permutation? This question has been studied in connection with practical applications such as sorting sequences, disk drive scheduling and airplane boarding times. The mathematical study of the LIS has revealed deep and unexpected connections of the problem with areas such as the theory of random matrices, analytic combinatorics and random polymer models.  The proposed research aims to study the LIS when the permutation is drawn from certain non-uniform distributions and associated phase transitions. (2) Many computational problems can be phrased as constraint satisfaction problems (CSPs) where one wants to find a solution to a number of variables with a set of constraints imposed on them. CSPs were first studied in computer science motivated by applications to artificial intelligence. To study the difficulty of finding solutions in typical rather than worst case scenarios, researchers study random CSPs. Using sophisticated heuristics, physicists have made detailed predictions about the location and nature of phase transitions in random CSPs. The accuracy of these heuristic predictions motivates the importance of discovering the rigorous mathematical foundations of these techniques. (3) Interacting particle processes are used to model large, randomly evolving interacting systems of agents that arise in the natural sciences including in physics and in biology. The exclusion and interchange random walks are examples of such interacting particle processes. In the symmetric case the long term mixing behavior of the random walk and the nature of phase transitions is well studied. The goal of this research is to understand the mixing properties of natural asymmetric and weighted versions of these processes. While achieving these three goals, the principal investigator will create exciting research opportunities for graduate and undergraduate students in probability, mentoring programs with the goal of retention of women in mathematics, and the development of online curricular material.<br/><br/>The main aim of this project is to develop new theory and analysis for phase transitions in certain discrete probabilistic models. The first problem is to study the limiting distribution of the LIS in non-uniformly random permutations by way of analyzing the fluctuations of the LIS as the parameter of the distribution is varied. The distribution is known to be Gaussian in one regime of the parameter and Tracy-Widom in another and we aim to study this transition. The second problem is to study the condensation and clustering transitions in random CSPs such as the hardcore model on random graphs. The research aims to identify the location of the reconstruction threshold more precisely in these models and to explore the connection to the clustering transition. Finally, the proposal will consider Markov processes such as asymmetric exclusion and interchange and attempt to relate the mixing times and spectral gaps of these processes to the corresponding quantities for a single particle and to understand the cutoff phenomenon for these processes."
9626361,Research in Algorithms Complexity and Database Theory,CCF,"THEORY OF COMPUTING, INFORMATION & KNOWLEDGE MANAGE",7/1/1996,8/26/1996,Christos Papadimitriou,"Papadimitriou, C","Papadimitriou, C",CA,University of California-Berkeley,Standard Grant,Yechezkel Zalcstein,6/30/2000,"$253,710.00 ",,cp3007@columbia.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,"2860, 6855","9216, 9218, HPCC",$0.00 ,normalFunding,"  The PI and his collaborators have been involved in: (a) some of the  subfields of theory that have witnessed impressive recent advances  (approximation algorithms, on-line algorithms), (b) a subfield that  has been very successful and relevant, but is facing new challenges  (database theory), and(c) ``exporting'' complexity-theoretic ideas  to other disciplines (e.g., Game Theory, Economics, and Artificial  Intelligence).   The goals of this project include: (1) The  deepening and broadening of recent advances in approximation  algorithms and on-line algorithms, by attacking fundamental problems  such as the Euclidean traveling salesman problem and the k-server  conjecture; (2) The study of alternative models and metrics, for  example, in relation to on-line algorithms for storage allocation,  that are closer to reality and to computational practice; (3) The  introduction of approximation and on-line problems that in a small  way contribute to our understanding of the computational  requirements of a global information environment; (4) The study of  database-theoretic problems that are posed by novel media and  heterogeneity; (5) The continuation of PI's research program that  considers problems from other disciplines (such as, Game Theory,  Genetics, and Artificial Intelligence) from a complexity-theoretic  point of view.***"
9800070,Logic-Based Approaches to Learning and Knowledge Discovery,CCF,THEORY OF COMPUTING,8/15/1998,8/4/1998,Gyorgy Turan,"Turan, G","Turan, G|Sloan, R",IL,University of Illinois at Chicago,Standard Grant,Robert Sloan,7/31/2002,"$253,001.00 ",Robert Sloan,gyt@uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,2860,"9216, HPCC",$0.00 ,normalFunding,"Logic forms a basic framework for artificial intelligence,  including machine learning and knowledge discovery in  databases. Predicate logic, which is used by several machine  learning systems, poses both open problems of learning  complexity and questions that do not arise in other  approaches to learning. There are algorithmic approaches to  knowledge discovery in databases that suggest several open  problems for propositional and predicate logic, and  complexity theory. Some of the learnability issues specific  to predicate logic that will be studied are the role of  background knowledge, the efficiency of the algorithmic  techniques of logic learning, such as least general  generalizations, the complexity of learning multiple  predicates, and types of noise that either are specific to  predicate logic, or appear to behave differently for  predicate logic. The first two issues will be studied using  the producthomomorphism method.  This technique, introduced  by one of the PI's and developed further by both PI's,  enables the use of combinatorial tools in constructing  learning algorithms.  One extension to be studied is  learning certain broader classes of logic programs, which  are useful for practical applications.  The complexity of  the general product-homomorphism problem will also be  investigated. In the area of noise-tolerance, one topic to  be studied is the complexity of learning Boolean  conjunctions in noise models that are more difficult for the  learner than random classification noise.  This could lead  to extensions of previous work of the PI's on learning noisy  logic programs. Expanding the scope of learning problems  studied in learning theory, the project will construct  algorithms for relations definable in a finite model by  restricted classes of formulas, such as formulas with a  bounded number of variables.  This continues the model  theoretic approach to learning, studied earlier by one of  the PI's.  Another, related family of problems involves  classes of atomic f ormulas satisfying first-order  constraints. In knowledge discovery in databases, a logic-  based approach is to find the theory of the database, which  means identifying all interesting statements that hold in  the database, using an appropriate notion of interesting  statement.  Algorithmically, this requires polynomial-delay  listing algorithms for different classes of objects, such as  the maximal frequent sets of a 0-1 matrix.  The project will  study the possibilities of gaining efficiency by taking into  account the structure of the database.  This leads to  questions about restricted classes of threshold circuits,  and generalized versions of the minimal hitting set listing  problem. The methods to be used are primarily combinatorial,  such as products and homomorphisms of graphs, and model-  theoretic games. This project will contribute to the  understanding of the limits of efficient learnability in  predicate logic.  It will also develop new algorithms that  may be useful for practical machinelearning systems, and  contribute to the methodology for tolerating noisy data.  The overall goal of this work is to gain a better  understanding of the computational complexity aspects of  learning using logic."
9820885,Maximum Likelihood Estimation and Other Probabilistic Algorithms,CCF,THEORY OF COMPUTING,9/1/1999,2/9/2001,Sampath Kannan,"Kannan, S","Kannan, S",PA,University of Pennsylvania,Continuing grant,David Du,8/31/2003,"$252,817.00 ",,kannan@central.cis.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,2860,"9216, HPCC",$0.00 ,normalFunding,"CCR-9820885<br/>Kannan, S.<br/><br/>This project pursues research in a number of areas with the common theme being the design and analysis of probabilistic algorithms.<br/><br/>Maximum Likelihood Estimation is a classical and important technique in statistics.  Specific versions of this general problem are defined by considering specific stochastic processes that generate the sample data.  This problem has generally been thought to be computationally intractable for most interesting applications.  However, this project seeks to create very efficient algorithms that find approximately the most likely solutions.  Specifically such algorithms are sought for important problems in computational biology such as phylogeny construction and multiple alignment.  The project also investigates similar approaches for the problem of inferring Belief Nets, a popular stochastic model in artificial intelligence.<br/><br/>The problem of contention is concerned with message transmission over an ethernet where messages arrive according to a stochastic process such as a Poisson process.  Each message uses a protocol whereby it attempts to transmit itself at each time instant with some probability.<br/><br/>A central open question is whether there is a protocol that ensures that the system is ""stable.""  The PI proved that the answer is ""no"" for a number of ""natural"" classes of protocols and is working on extending these proofs to all acknowledgement-based protocols.  Finally, the project investigate new models and problems in the area of program checking which again involves the design of randomized algorithms. <br/>"
518147,Causal Models of Decision Making: Choice as Intervention,SES,DECISION RISK & MANAGEMENT SCI,9/15/2005,10/21/2008,Steven Sloman,"Sloman, S","Sloman, S",RI,Brown University,Continuing grant,Jacqueline R. Meszaros,8/31/2009,"$251,442.00 ",,Steven_Sloman@brown.edu,BOX 1929,Providence,RI,29129002,4018632777,SBE,1321,"0000, 9150, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"Decision makers are actively trying to understand their environments. They are busy constructing and using causal models that (hopefully) accurately predict the effects of their choices on themselves, on others, and on the world around them. The purpose of this research is to develop a cognitive theory of this causal knowledge that will explain how people's causal models get translated into action. The theory will be developed using a framework known as causal Bayesian networks that is being developed in the fields of statistics and artificial intelligence. Many of the ideas were originally developed by philosophers who observed that the traditional view that optimal decision making involves maximizing the probability of obtaining the most resources (evidential expected utility theory) fails to explain how people take the causes and effects of their actions into account when they make decisions. The key idea is that choice is not merely a selection of an option from a set of alternatives, but an intervention that changes not only the state of the world, but also the model we should use to represent how the world works. The key psychological claims of the theory are that people represent the world by decomposing it into autonomous mechanisms that support interventions and that choice suspends some of those mechanisms in the causal model relevant to a decision. Experiments will (i) test people's sensitivity to causal structure as well as the hypothesis that choice is an intervention; (ii) examine the proposed model by framing it in terms of causal expected utility and contrasting it to a more standard model of evidential expected utility in the context of both simple scenarios and two-player games; (iii) examine what people can learn about the world and about choice strategies from observing one's own and others' choices; and (iv) examine various actual and apparent boundary conditions on the theory such as the role of self-deception in choice. The research has implications for how people should make all kinds of decisions (personal, medical, policy, strategy, etc.). It also has implications for how to improve decision-making, specifically, by first understanding the causal structure of a situation before attempting to make decisions in it."
92480,CAREER: Role of Spatiotemporal and Identity Continuity in Object Constancy,BCS,"HUMAN COGNITION & PERCEPTION, PERCEPTION, ACTION & COGNITION",8/1/2001,6/5/2003,Anne Hillstrom,"Hillstrom, A","Hillstrom, A",TX,University of Texas at Arlington,Continuing grant,Guy Van Orden,5/31/2004,"$251,235.00 ",,ahillstr@gmu.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,SBE,"1180, 7252","0000, 1045, 1187, OTHR",$0.00 ,normalFunding,"Philosophers, artists, and scientists for centuries have thought about how people organize the continuous flow of information reaching our sensory organs into discrete, individuated perceptual objects.  As advances have been made in understanding vision, this topic has reemerged in cognitive psychology, artificial intelligence, and neuroscience.  An object is individuated when the observer (1) perceives its features as belonging to a connected unit, (2) perceives its features as separate from things that are not part of the object, and (3) perceives that it is or is not something that was present sometime in the recent or distant past.  An object that is believed to be the same even when it undergoes changes exhibits what is called object constancy.  Much of what we know about object individuation and constancy in adult perception has been based on self-report methods.  This research will explore the nature of object individuation and object constancy in tasks in which observers are attending to an object but are unlikely to be reasoning about its individuality or constancy.  The research will employ a variety of tasks that have been developed in recent years to demonstrate ways in which attention to objects differs from attention to the space that objects occupy.  The research will determine whether attention to objects is affected by disruptions to identity continuity or spatiotemporal continuity (i.e., the degree to which it is consistently present and moves through space in a physically possible way).  By exploring which discontinuities disrupt attention to objects, the research will establish which continuities are critical to object constancy.  In real scenes, spatiotemporal and identity discontinuity rarely are independent of each other.  In contrast, this research will take advantage of media special effects that can dissociate them.  For example, spatiotemporal discontinuity will sometimes be accomplished by an identifiable object disappearing unexpectedly and reappearing abruptly, and identity discontinuity will sometimes be accomplished by one object morphing smoothly into another.  One part of the project will build on previous findings that once one part of an object is attended, it is easier to detect a subsequently presented target feature when it is elsewhere within the attended object rather than equidistant from the attended location but in another object.  This project will investigate what disrupts this same-object benefit.  For instance, spatiotemporal changes or identity discontinuities will be introduced to the cued or uncued object between the time the cue is presented and the time the target is presented, to see if the same-object benefit is disrupted.  The research will also look for disruptions in speed and accuracy of responses to the display.  Finally, it will also explore how eye movements are affected by the discontinuities.  The direct goal of this research is to understand the fundamental nature of object constancy and individuation.  However the results of the research will also have implications for engineering robotic systems that use machine vision to guide manipulation of dynamic objects.  Such robotic systems need to differentiate which parts of visual information belong to coherent objects and which belong to different objects.  In a different realm, knowledge of what sorts of changes distract people who are processing dynamic displays will aid designers of videos understand how special effects can be used to guide people's attention."
9619447,Automatic Learning of Admissible Heuristic Evaluation       Functions,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/15/1997,5/10/2001,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Continuing grant,William Bainbridge,4/30/2002,"$250,839.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"The  objective  of this project is to develop  a  robust  set  of  algorithms  for  automatically learning admissible  heuristics  -  that   is,   functions   that  identify  optimal   solutions   to  combinatorial problems and give a lower bound on the actual  cost  of  a  solution.  The more accurate the heuristic  function,  the  more  efficiently  an optimal solution can be  found,  or  if  an  optimal  solution is not required the more quickly  a  lower-cost  solution  can found.  This research is developing ways  to  learn  these  heuristics in a domain-independent manner  by  applying  a  technique  that has proved useful in automatically learning  more  accurate  admissible heuristic functions that take more  time  to  compute,  but  make  up for it in the time  they  save   for  the  algorithm  using  the heuristic.  This work will  provide  better  solutions  of  combinatorial problems of artificial  intelligence  which will be increasingly cost-effective as computers get faster  and larger problems are presented for solution."
9023979,Faculty Awards for Women Scientists and Engineers: (FAW),HRD,FACULTY AWARDS FOR WOMEN,11/1/1991,1/27/1997,Alice Parker,"Parker, A","Parker, A",CA,University of Southern California,Continuing grant,Margrete S. Klein,1/31/1998,"$250,000.00 ",,parker@eve.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,EHR,9292,"0000, 4710, 9179, OTHR, SMET",$0.00 ,normalFunding,"The focus of this research system level design tools, and it is being conducted within the ADAM project at USC. Tools include a partitioner, a simulator-verifier, a multi-processor synthesizer, software for making hardware-software tradeoffs, memory hierarchy design tools, bus selection software, and a system-wide scheduler. The first research task is to make available to the CAD design community recently developed system level tools. To do this, user interfaces are being constructed, and the tools integrated into a CAD framework. Second is to explore new research topics: a high level synthesis tool to configure neural chips from specified behavior, use of artificial intelligence techniques to meet conflicting design goals and constraints, and a study of the mechanical-electrical interface. Third, formal models of the system design process are being explored. This grant is made under the Faculty Awards for Women Scientists and Engineers Program."
523643,Bayesian Support Vector Machines for the Prediction of Molecular-Genetic Network Motifs Across Organisms,CCF,BIOLOGY & INFORMATION TECHNOLO,8/1/2005,7/26/2005,Alpan Raval,"Raval, A","Raval, A|Ray, A|Gupta, A",CA,Keck Graduate Institute,Standard Grant,Mitra Basu,7/31/2008,"$249,999.00 ","Animesh Ray, Amarnath Gupta",Alpan_Raval@kgi.edu,535 Watson Drive,Claremont,CA,917114817,9096079313,CSE,1705,"9184, BIOT",$0.00 ,normalFunding," <br/>Progress in the biological sciences in the post-genomic era depends on our ability to make sense of genome-scale information.  The genome and the proteome together establish an intricate network of interactions that exhibits many similarities to social and political networks. This interaction network forms a simple, conceptual representation of the molecular machinery in the living cell.  Knowledge of individual interactions and patterns of interaction therefore significantly enhances our understanding of the mechanisms of biological function. <br/> <br/>Unfortunately, experimental determination of molecular interactions at the scale of the entire genome is often error-prone: many interactions revealed by such high-throughput experiments are false, and conversely, many of the actual interactions are not revealed at all. It is important, therefore, to establish rigorous computational methods that utilize high-throughput data from a variety of sources to predict the existence (and lack thereof) of an interaction, and to assign confidence levels to each prediction in a systematic manner.  Our project utilizes state-of-the-art predictive methods from the field of Artificial Intelligence-Bayesian support vector machines-to predict molecular interactions at the whole-genome level. The project is initiated by an exhaustive data collection effort involving a variety of data sources that supply putative predictors for the presence or absence of interactions among protein/protein or gene/protein pairs.  Dominant predictors among these will be isolated, and the prediction system will be applied to the genomes of several organisms, including the budding yeast, worm, and fly.  The accuracy of the method will be tested and refined by computational and biological means.  Successful completion of this project will significantly enhance our ability to decipher genomic information and apply these findings to discover novel functional pathways of biological, agricultural, and medical importance. <br/> <br/>All methods and results will be publicly disseminated, the former with stand-alone executable programs, and the latter via publications and web pages.  The project will support interdisciplinary training of graduate and postdoctoral students, and should provide research opportunities for undergraduate students.<br/><br/> <br/>"
196015,Development of Educational Materials for Undergraduate Online Programs in Information Engineering Technology,DUE,CCLI-EDUCATIONAL MATERIALS DEV,6/1/2000,6/21/2002,Vladimir Uskov,"Uskov, V","Uskov, V|Saad, A|Erwin, J|Blocher, K|Geonetta, S|Waldrop, L|Donley, J",IL,Bradley University,Standard Grant,Kenneth Lee Gentili,12/31/2004,"$249,838.00 ","Ashraf Saad, John Erwin, Karen Blocher, Sam Geonetta, Larry Waldrop, Jan Donley",uskov@bradley.edu,1501 West Bradley Avenue,Peoria,IL,616250001,3096767611,EHR,7427,"7427, 9178, SMET",$0.00 ,normalFunding,
200729,New Directions in Computational Algebraic Geometry,DMS,"ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS",7/1/2002,4/14/2004,Bernd Sturmfels,"Sturmfels, B","Sturmfels, B",CA,University of California-Berkeley,Continuing grant,Tomek Bartoszynski,6/30/2005,"$249,651.00 ",,bernd@math.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,MPS,"1264, 1271","0000, OTHR, 9263",$0.00 ,normalFunding,"This project develops new algorithms and new applications for<br/>computational algebraic geometry. If focusses on the following<br/>four specific topics: Computing amoebas, toric algebra of graphical<br/>models, semi-definite programming and the real Nullstellensatz.<br/>It involves tools from combinatorics, commutative algebra and<br/>symbolic computation, specifically the method of Grobner bases.<br/>The investigator also writes two books, one on Solving Systems of <br/>Polynomial Equations, and the other on Combinatorial Commutative Algebra.<br/><br/>This project develops new algorithms and new applications for<br/>computational algebra. The research in this project is partly<br/>collaborative with researchers<br/>in other fields, and it has applications to Statistics, Bioinformatics<br/>and Computer Science. The use of algebraic methods plays an increasingly <br/>important role for the analysis of the U.S. census data provided by the<br/>National Institute for Statistical Sciences, and this project provides<br/>foundational research for this application. In Computer Science, these<br/>techniques are used in machine learning and artificial intelligence."
624283,Collaborative Research:  DHB: Human Dynamics of Robot-Supported Collaborative Work,IIS,HSD - DYNAMICS OF HUMAN BEHAVI,12/15/2006,12/11/2006,Pamela Hinds,"Hinds, P","Hinds, P|Rock, S",CA,Stanford University,Standard Grant,William Bainbridge,11/30/2010,"$247,595.00 ",Stephen Rock,phinds@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7319,"7319, 9102, 9215, 9218, HPCC",$0.00 ,normalFunding,"This is a project to understand and test theories of how three aspects of human-robot interaction independently and interactively affect collaborative work: robot social behavior, mutual understanding in human-robot communication, and the impact of robotic assistants on group dynamics.  With advances in computing technology and artificial intelligence, autonomous robots are becoming viable in such critical domains as search and rescue, military battle, mine and bomb detection, scientific exploration, law enforcement, and hospital care. Robotic assistants ranging from museum guides to forestry scouts are being developed to interact with people ""in person"" or remotely, as agents that collaborate with the work team. This project is targeted at little understood but critical aspects of robot-supported collaborative work. <br/><br/>The research involves three kinds of studies: (1) fundamental laboratory research on behavioral characteristics of robots performing social tasks, especially as these characteristics reflect lifelikeness, (2) controlled experiments and field studies of interpersonal communication and the development of mutual understanding between robot and human, and (3) studies of robots in work groups. The studies are designed to motivate and test theory, as well as to explore both direct and secondary or indirect social effects of robot-supported collaborative work. The fieldwork will be carried out in hospitals and scientific exploration settings. <br/><br/>This research will advance our understanding of the possibilities and problems of mutual adaptation in human-robot interaction over time, and will help us anticipate changes in the group dynamics of collaborative work. It also will extend our basic knowledge of communication and group dynamics in environments that incorporate robotic technology.  It will improve our ability to make principled design decisions about robots that work with people, and better understand the societal impact of robots. In particular, this research will give us a foundation for understanding and designing collaborative work with robots in critical environments like mines, hospitals, households with elderly or disabled residents, in challenging scientific settings, and in situations in which the robot is remote. The work also will contribute to public and student awareness of the human side of robotics, and help motivate students' interests in science and engineering.<br/>"
725762,"Collaborative Research: Identifying and Interpreting the Dynamics of Interpersonal Deception from Video, Audio and Text.",BCS,"HSD - DYNAMICS OF HUMAN BEHAVI, HSD - GENERAL, ",10/1/2007,7/9/2009,David McNeill,"McNeill, D","McNeill, D",IL,University of Chicago,Standard Grant,Rita A. Teutonico,9/30/2010,"$247,497.00 ",,dmcneill@uchicago.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,SBE,"7319, 7326, S005","7319, 9178, 9215, 9251, HPCC, SMET",$0.00 ,normalFunding,"Deception is a pervasive feature of social life yet often goes undetected because deceivers capitalize on features of the interpersonal communication process. They adjust their verbal and nonverbal behavior over the course of an interaction in ways that evade detection. To uncover the complexities and dynamics of the communication processes that make successful deception or detection possible, collaborative research will be conducted by a multidisciplinary team of communication, linguistics, psychology, computer science, and management information systems researchers from the University of Arizona, University of Chicago, Michigan State University, and Rutgers University. They will be joined by international experts from the University of Cologne, Imperial College London, and University of Iceland. The project will develop a theoretical model of interpersonal deception that shifts emphasis from stable individual behaviors to dynamic interaction patterns. It will create five test beds by measuring the verbal and nonverbal features from video-recorded interpersonal communication experiments. The five experiments are a cheating experiment, a mock theft experiment, deceptive interviews, a group collaboration task, and a narration task. Measurement will consist of extensive automated and human-annotated measurement of visual, vocal, and verbal features. As part of the annotation work, the team will refine and validate software for automated measurement of nonverbal and verbal features. Theory-driven hypothesis tests and exploratory tests will be conducted on the measured communication behaviors to identify dynamic adaptation patterns using time-series, Bayesian-based Theme analyses, and artificial intelligence data mining techniques. The project will advance the scientific infrastructure for studying deception by forming the largest international and multidisciplinary research team of deception experts of its kind, integrating the knowledge and methods of multiple disciplines, refining computer-aided analysis of human communication, making progress in automating deception detection, and educating new investigators through laboratory exchanges. Society will benefit from a more valid picture of deception that can guide training and detection efforts in public, business, government, and security settings."
1616619,Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering,MCB,Systems and Synthetic Biology,8/1/2016,7/30/2016,Yinjie Tang,"Tang, Y","Tang, Y",MO,Washington University,Standard Grant,Devaki Bhaya,7/31/2019,"$245,474.00 ",,yinjie.tang@seas.wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,BIO,8011,"144E, 1757, 7465",$0.00 ,normalFunding,"Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization.  Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors;  the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings."
9876332,CAREER: Mathematical Foundations of Computer Graphics,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT",4/1/1999,7/22/2002,James Arvo,"Arvo, J","Arvo, J",CA,California Institute of Technology,Continuing grant,Robert B Grafton,9/30/2005,"$243,744.00 ",,arvo@uci.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,CSE,2865,"1045, 9216, HPCC",$0.00 ,normalFunding,"The objective of this research is to strengthen the theoretical <br/>foundations of computer graphics by carefully formulating its <br/>mathematical underpinnings, applying formal methods of computer <br/>science, and exploring fundamental connections with other disciplines.  The work plan is organized into four categories: 1) mathematical underpinnings, 2) numerical methods, 3) <br/>computational complexity, and 4) formal methods.  Within each category several specific projects are described.<br/>Work done under this grant will depart from previous work in both the tools applied and in the areas investigated.  Among the novel tools to be applied are mathematical methods from functional analysis (e.g. measure theory), information-based complexity (e.g. radius of information), and formal <br/>methods of computer science (e.g. refinement calculus); these tools will be applied to fundamental problems of computer graphics, such as deriving and clarifying radiometric <br/>principles, placing a priori limits on the accuracy of image-based rendering, and differentiating images of non-Lambertian scenes.  These projects are firmly rooted in previous work performed by the author.<br/><br/>Among the novel areas to be investigated are proving the <br/>correctness of rendering algorithms, ""inverting"" rendering <br/>algorithms in response to user queries, and formalizing the use <br/>of default assumptions, ambiguity, and contradiction in <br/>human-computer interaction.<br/> The fundamental educational objectives of this work are to infuse computer graphics with appropriate mathematical structure, to train future graphics researchers in the <br/>art of constructing rigorous proofs and formally verifiable <br/>algorithms, and to integrate the tools and fundamental <br/>concepts of computer graphics into the core computer science curriculum.  These goals cannot be attained through the introduction of a single course, but will instead require exposing students to the necessary concepts at many levels.  Toward this end, elements of computer graphics will be <br/>introduced into an existing sophomore-level course on the theory of computation, and an advanced graduate-level course will be devised that explores the interplay of computer graphics, human-computer interaction, and artificial intelligence, <br/>while emphasizing the role of mathematical abstraction and formal verification.<br/><br/> <br/><br/>"
1740184,E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays,CCF,Energy Efficient Computing: fr,9/15/2017,7/11/2018,Jeehwan Kim,"Kim, J","Kim, J",MA,Massachusetts Institute of Technology,Continuing grant,Sankar Basu,8/31/2020,"$243,624.00 ",,jeehwan@MIT.EDU,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,015Y,7945,$0.00 ,normalFunding,"In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform innovative and interdisciplinary research to address many limitations in today?s resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today?s binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ?NeuroSim?. With vertical innovations across material, device, circuit and architecture, tremendous potential and research needs will be pursued towards energy-efficient artificial intelligence in ubiquitous resource-constrained hardware systems."
89915,Collaborative Research: Interactive Level-Set Modeling for Visualization of Biological Volume Datasets,CCF,ADVANCED COMP RESEARCH PROGRAM,10/1/2000,5/15/2002,Ross Whitaker,"Whitaker, R","Whitaker, R",UT,University of Utah,Continuing grant,Xiaodong Zhang,9/30/2004,"$242,584.00 ",,whitaker@cs.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,CSE,4080,"9216, HPCC",$0.00 ,normalFunding,"As scientific data becomes larger and more complex, the problem of presenting data effectively is joined by another, potentially more difficult one - how to extract presentable data from the flood of raw information. This problem is equally difficult for results from large simulations and data from high-resolution instruments. Thus, the field of scientific visualization becomes intimately tied to more traditional studies of data analysis, including image processing, pattern recognition, artificial intelligence, and computer vision. However, in contrast to those fields, visualization explicitly includes the user in the process of filtering, extracting, and rendering meaningful data. The goal of this project is to make level-set modeling - a useful but computationally expensive visualization technique - interactive for use in 3-D visualization of biological data sets.<br/><br/>Technically, the project has three components. The first is the design and implementation of a hardware and software system for interactive level-set surface model computation and display. This system will use off-the-shelf PC hardware and graphics boards and new algorithms and software to reach its interactivity goals. The second component will create the human-computer interface that allows users to interact with the level-set models. This will require mapping user input onto the mathematical descriptions controlling surface motion and deformation in the models. Finally, the third component will be the application of the techniques to visualize large biological data sets by researchers in this project.<br/><br/>This is a collaborative project between the University of Utah and the California Institute of Technology .<br/>"
9619957,REU: Research Experiences for Undergraduates in Experimental Computer Science,CNS,"CISE RESEARCH INFRASTRUCTURE, HUMAN COMPUTER INTER PROGRAM",3/1/1997,3/25/1999,James Cremer,"Cremer, J","Cremer, J|Kearney, J|Fleck, M",IA,University of Iowa,Continuing grant,Lawrence Burton,2/29/2000,"$241,295.00 ","Joseph Kearney, Margaret Fleck",cremer@cs.uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,"2885, 6845","0000, 9139, 9178, 9250, HPCC, OTHR, SMET",$0.00 ,normalFunding,"9619957  Cremer, James   University of Iowa    Research Experiences for Undergraduates at the University of Iowa in Experimental Computer Science    This Research Experiences for Undergraduates (REU) Site project supports 12 students per year in programs carried out during the summers, for three years.  The students participate in a variety of computer science research projects, with emphasis on experimental and applied research.  Students are recruited nationally and matched with active faculty members in research areas including: virtual environments, real-time simulation, graphics, computer vision, computational geometry, distributed systems, and artificial intelligence.  Substantial effort is placed on recruiting minority students and students from non-research institutions.  The program provides a coherent experience involving close interaction between faculty, graduate students, and REU students, hands-on experience with state-of-the-art software and computing facilities, and work on challenging and important research problems."
501451,Adaptive Critics for Nonlinear Continuous-Time Systems,ECCS,"CONTROL, NETWORKS, & COMP INTE",7/15/2005,7/15/2005,Frank Lewis,"Lewis, F","Lewis, F",TX,University of Texas at Arlington,Standard Grant,Pinaki Mazumder,6/30/2009,"$239,931.00 ",,lewis@uta.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,ENG,1518,"0000, 7238, OTHR",$0.00 ,normalFunding,"Intellectual Merit: The PI proposes to work on continuous-time versions of Adaptive Dynamic Programming (ADP), an emerging novel class of designs which offers hope of brain-like capabilities in the (approximately) optimal management of large complex systems subject to random disturbance, nonlinearity and a need for foresight. He will work on stability proofs, convergence analysis and new designs, together. Specific research goals involve neural network ADP for output feedback and nonlinear filtering, neurocontrol with entropy and nonstandard value functionals, model-based continuous time ADP and small-time-step approximate tuning for model-free continuous time ADP.<br/>Neural networks provide a way to approximate unknown nonlinear functions, needed as part of general ADP, with greater accuracy than traditional approximators for a limited number of parameters.<br/><br/>Broader Impacts: The PI plans to write a textbook on ADP in engineering, which is needed very greatly at the present time. The related books currently available are either collections of papers less accessible to the average student (such as the Handbook of Learning and Approximate Dynamic Programming, IEEE Press, 2004) or textbooks which focus on methods of reinforcement learning developed for psychology or artificial intelligence, which do not scale well to large engineering tasks. The PI will also insert the new designs/algorithms into the practical applications worked on  at the Automation and Robotics Research Institute (ARRI), into undergraduate courses, and into his program for high school students in Hands-On Design and Learning for Intelligent Control Systems. <br/>"
218594,Digital Representation of Structural Response for the Reliability Assessment of Complex Systems,CMMI,STRUCTURAL MATERIALS AND MECH,9/1/2002,8/9/2002,michel ghosn,"ghosn, m","ghosn, m|Golub, G",NY,CUNY City College,Standard Grant,Perumalsamy N. Balaguru,8/31/2006,"$239,929.00 ",Gene Golub,ghosn@ce.ccny.cuny.edu,Convent Ave at 138th St,New York,NY,100319101,2126505418,ENG,1635,"1057, CVIS",$0.00 ,normalFunding,"DIGITAL REPRESENTATION OF STRUCTURAL RESPONSE <br/>FOR <br/>THE RELIABILITY ASSESSMENT OF COMPLEX SYSTEMS<br/><br/>ABSTRACT<br/><br/>Current research efforts in structural engineering are geared toward the development of performance based design and safety evaluation criteria that take into consideration the various uncertainties in estimating system behavior and future loading conditions. System reliability methods provide the means to address these important points. However, most existing analytical reliability techniques have one or more limitations in their ablity to: a) accurately model structural behavior at high loads, b) consider different performance criteria, c) identify multiple equally important failure modes, and d) account for load combinations. The application of simulation techniques in conjunction with general purpose finite element packages provides methods with a strong potential for resolving many of these outstanding issues. The purpose of this research is then to develop a simulation-based method for the reliability assessment of structural systems, which would realistically model their behavior at high loads, be implementable in practical situations, and provide accurate solutions for complex structures using efficient algorithms. <br/><br/>The first tool required to perform a simulation-based reliability analysis of a structural system consists of an accurate and efficient nonlinear analysis program capable of modeling the behavior of the structure for a specific (deterministic) set of conditions. The second tool is a systematic search algorithm that can identify probabilistically dominant failure modes accounting for the randomness of loads and material properties. Closed-form solutions for the response of complex nonlinear structures are difficult to obtain and only a digital representation of their behavior is possible through the application of the finite element method. Point estimates of the response under different load intensities and material properties are usually obtained from variations on the Newton-Raphson algorithm. These point estimates may often misidentify the ultimate capacity and may not accurately model the softening part of the loading curve due to the accumulation of numerical errors and because of the properties of the stiffness matrix in these ranges. In this study, the Singular Value Decomposition, SVD, method in combination with the Lanczos algorithm will be used to accurately trace the response of a structure at high loads. The efficiency, robustness, and stability of the proposed method will be demonstrated. <br/><br/>Due to the random nature of the problem, the safety assessment of a structure can only be established using reliability techniques. Since the behavior of a structure with several failure modes is best represented in digital form, modern heuristic techniques may provide the most appropriate tools to assess its reliability. In particular, Genetic Algorithms, GA, have been shown to provide robust techniques for the reliability analysis of structures with multiple failure modes but may be inefficient due to the shotgun search strategy that they are based upon. To improve the efficiency of GA, a filtration operator will be introduced based on the principle of genetic elitism. The modified GA will provide an efficient method to estimate the reliability of complex structures, as well as identify its dominant failure modes and controlling random variables. <br/><br/>This project will introduce advanced tools of computational mathematics into the field of structural mechanics. The study will stress the application of the proposed methods for the simulation based design of civil engineering structures although they will be applicable to fields as varied as electronic circuit design and Micro-Electro-Mechanical-Systems. Training of students in the subjects of matrix computational methods, artificial intelligence, and statistical computing will be a primary goal. Such training will provide future generations of structural engineers with the well-rounded education needed to make decisions and provide solutions to real life complex problems under uncertainty."
9258114,NSF Young Investigator:  Computer-Aided Automation of       Design and Manufacturing Processes,CMMI,INTEGRATION ENGINEERING,9/1/1992,7/1/1996,James Oliver,"Oliver, J","Oliver, J",IA,Iowa State University,Continuing grant,george hazelrigg,2/28/1999,"$239,254.00 ",,oliver@iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,ENG,1463,"9146, 9148, 9297, MANU",$0.00 ,normalFunding,"     This research is aimed at computer-aided automation of design              and manufacturing processes with particular emphasis on products                modeled with parametric sculptured surfaces.  Over the next five                years, research will proceed concurrently in two primary thrusts:               (1) investigation of novel techniques for conceptual design of                  sculptured surface models, and (2) the development of methods to                facilitate the manufacturing processes associated with such                     products.  The recently developed surface synthesis technique will              be expanded by investigating the development of functional design               constraints based on objective performance measures such as                     aerodynamics, hydrodynamics, or kinematics, as well as on                       subjective characteristics such as surface aesthetics.  Research                in the second category will focus on automated generation and                   verification of numerically controlled (NC) machine programs.                   Given a geometric model of the part to be produced and the                      kinematic capabilities of a candidate machine tool, techniques                  based on spherical geometry will be investigated to determine                   workpiece orientations which are optimal with respect to process                time and dimensional accuracy.                                                       Sculptured surface models are among the most commonly utilized             geometric representations, and their creation, modification and                 fabrication can incur substantial capital investment.  Thus this                research may have a profound effect on product development                      efficiency for a wide range of industrial and consumer products."
1354297,Innovations in Electroacoustics and Computing: Print Disablity and as a Model for Technology Innovation and Transfer,SES,"Cyber-Human Systems (CHS), SCIENCE, TECH & SOCIETY",5/15/2014,5/5/2014,Mara Mills,"Mills, M","Mills, M",NY,New York University,Standard Grant,Frederick M Kronz,4/30/2017,"$239,138.00 ",,mmills@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,SBE,"7367, 7603","1353, 7603",$0.00 ,normalFunding,"Through archival research and interviews with innovators, the PI will produce a history of electronic reading technologies for blind and print-disabled people, and their co-evolution with mainstream reading practices. Beyond the introduction of new formats such as audiobooks and electronic books, print access efforts in the twentieth century gave rise to numerous technical innovations that transferred to other branches of electroacoustics and computing. Innovations in long-playing records,pitch-shifting with magnetic tape, scanning, optical character recognition (OCR), and synthetic speech ultimately retooled reading for both humans and machines. The project will contribute to the history of computing through attention to the overlooked topics of optical character recognition (OCR) as a mode of data input, and pattern-matching as a technique for artificial intelligence.<br/><br/><br/>Based on these historical examples, this communications scholar develops new tools for understanding and stimulating innovative technology design and transfer. The work will contribute to the subfield of disability and STS, will train two disabled students, and will help destigmatize the category of assistive technology by tracing the ways these devices intervene into media policy, are repurposed for broad use, or in fact are marketed to multiple audiences. In addition to a monograph, the project will result in a website that will preserve and make publicly-available examples from several historical reading formats (e.g. Talking Books, text-to-tone, and text-to-speech systems). The website will model best practices of electronic accessibility."
421000,"MRI:     Acquisition of a Desktop, High-Resolution, Three-Dimensional X-Ray Computed Tomography (CT) System",ECCS,MAJOR RESEARCH INSTRUMENTATION,9/1/2004,8/2/2004,Shreekanth Mandayam,"Mandayam, S","Mandayam, S|Polikar, R|Sukumaran, B|Schmalzel, J",NJ,Rowan University,Standard Grant,Radhakisan S. Baheti,8/31/2006,"$238,698.00 ","Robi Polikar, Beena Sukumaran, John Schmalzel",shreek@rowan.edu,Office of Sponsored Programs,Glassboro,NJ,80281701,8562564057,ENG,1189,"0000, 1189, OTHR",$0.00 ,normalFunding,"This proposal seeks support to acquire the SkyScan 1072 compact, desk-top X-Ray microtomograph system for the non-destructive, high spatial resolution (1.8mm/pixel), three-dimensional reconstruction of objects. Research applications include particle characterization (sand, toner, etc.) and imaging of stress-corrosion cracks in gas pipelines.<br/><br/>The proposed acquisition enhances the existing imaging capabilities in the nondestructive evaluation laboratory (NDE Lab) at Rowan University. Presently, we are able to image test objects using the following sensor modalities - magnetic, ultrasonic, thermal, acoustic, optical and 2-D X-Ray. We are developing digital image processing and artificial intelligence (AI) algorithms for predicting 3-D object profiles. These profiles are then visualized using the Virtual Reality (VR) system. However, currently, we do not have the capability to validate the accuracy of the sensor methods and the AI algorithms in predicting these 3-D profiles. The proposed X-Ray computed tomography (CT) system will provide us with exactly that capability; and serve as a validation ""gold"" standard.<br/><br/>Intellectual merit of the proposed activity<br/>The acquisition and use of a CT system that provides 3-D reconstruction of object shapes as a validation ""gold"" standard significantly benefits the design of artificial neural network algorithms that are employed to predict 3-D shapes from conventional and emergent 2-D imaging techniques. This procedure allows us to develop novel NDE imaging methods that can explicitly demonstrate the various trade-offs that are involved in accurate 3-D characterization of object shapes.<br/><br/>Broader impacts of the proposed activity<br/>The NDE Lab in the Rowan University College of Engineering is a multi-disciplinary, collaborative research and teaching laboratory that supports the R&D efforts faculty, students (both graduate and undergraduate) and industrial partners. The proposed acquisition will positively impact research activities among other faculty not only in the College of Engineering, but also across Campus. Collaborations that are underway include the development of smart-sensors and bio-sensors -the reliability of these devices<br/>will be tested using the proposed CT scanner.<br/><br/>Previously funded research projects in the NDE Lab have demonstrated significant educational impact. To date, the Lab has employed 32 undergraduate research assistants and 10 graduate research assistants. The Lab has supported an average of three multidisciplinary Engineering Clinic projects every semester since Fall 1999, impacting approximately 120 students. So far, 9 Faculty from three engineering disciplines (ECE, ME, CEE) have collaborated on research and education projects. We anticipate that 10 undergraduate students and 2 graduate students will use the proposed instrument every semester.<br/><br/>"
712836,CAREER: Evolving and Self-Managing Data Integration Systems,IIS,"INFORMATION & KNOWLEDGE MANAGE, INFO INTEGRATION & INFORMATICS",8/31/2006,6/16/2009,AnHai Doan,"Doan, A","Doan, A",WI,University of Wisconsin-Madison,Continuing grant,Xiaoyang Wang,5/31/2010,"$238,115.00 ",,anhai@cs.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,CSE,"6855, 7364","1045, 9218, HPCC",$0.00 ,normalFunding,"Data integration systems provide a uniform access to a multitude of data sources. They have the potential to revolutionize the way we access data, and provide a basis on which to build even more advanced information processing architectures. However, today such systems are still extremely hard to build and costly to maintain. They must be told in tedious detail how to interact with data sources, and must be constantly modified to deal with changes at the sources. To address this problem, the project envisions building data integration systems that learn to evolve and self-manage over time, with minimal human intervention. To make fundamental contributions toward realizing this vision, the project employs database and artificial intelligence (especially machine learning) techniques to attack the following central challenges: (a) effectively automating key labor-intensive tasks, including schema matching, global schema creation, and duplicate detection, (b) detecting system failures due to changes at the sources, with minimal human intervention, and (c) further reducing the tremendous data integration burden of the system administrators by spreading the burden thinly over the mass of users. <br/><br/>The education plan leverages the research to prepare students and the broader community for the novel data management challenges raised by the Internet world. In terms of intellectual merit, the project takes a next logical step in data integration research. It brings conceptually novel solutions to fundamental issues underlying virtually any data integration or sharing efforts. The project results have the potential for autonomic-computing applications. In terms of broader impacts, the project will facilitate the widespread deployment of data integration systems, thus resulting in more effective information management and access for society. It plays an integral part in educating next-generation professional workers and researchers. The research will also help integrate data for rural Illinois fire fighters, and train them in access and use of the integrated information systems. The project information will be disseminated via publications, workshops, tutorials, and the Web site http://www.cs.wisc.edu/~anhai/projects/career.html that will include the resulting research results, data and system artifacts."
432151,BIC: Genetically-Engineered Bacteriorhodopsin Proteins for Holographic Associative Memories,CCF,"BIOLOGY & INFORMATION TECHNOLO, EMERGING MODELS & TECHNOLOGIES",9/1/2004,8/4/2005,Jeffrey Stuart,"Stuart, J","Stuart, J|Birge, R|Marcy, D",NY,Syracuse University,Continuing grant,Pinaki Mazumder,4/30/2006,"$237,000.00 ","Robert Birge, Duane Marcy",jeffrey.stuart@uconn.edu,OFFICE OF SPONSORED PROGRAMS,SYRACUSE,NY,132441200,3154432807,CSE,"1705, 7353","9184, 9216, BIOT, 9107, 9251, HPCC",$0.00 ,normalFunding,"The increasing demands of modern computation require innovative solutions to data storage and processing. Conventional architectures are often limited not by processor speed, but by the ability to efficiently handle large amounts of data. Optical architectures for these applications promise potential gains in speed, data throughput, & storage density. In addition, an entirely new class of materials has emerged that is expected to provide practical solutions to these demanding applications; these materials include not only conventional optical & holographic materials, but also of those of biological origin. Bacteriorhodopsin (BR) was among the first proteins to attract attention as a viable component in molecular electronics & nanotechnology. In the native organism, Halobacterium salinarum, the protein acts as a photosynthetic sunlight to chemical energy transducer. Through billions of years of evolution, nature has produced a protein that is remarkably rugged and responds quickly and efficiently to light. The protein's unique properties make it an appealing candidate for a number of devices that use light to record or process information, including holography and optical computer memory storage.<br/><br/>Despite bacteriorhodopsin's unique properties, it still lacks the efficiency necessary for commercialization. Fortunately, advanced techniques in molecular biology can be used to optimize the protein for specific device architectures. Through techniques such as random mutagenesis, semi-random mutagenesis, and directed evolution, researchers can custom-tailor protein properties in ways never before possible. The use of directed evolution techniques to produce BR variants for optical recording materials will result in reusable holographic media that require no processing or fixing, and are capable of real-time operation. The goal of this research effort is to develop a new class of fully write-read-erasable dynamic holographic recording media based on genetically-engineered bacteriorhodopsin variants. Each new material will be evaluated to determine which is the most efficient, with respect to a number of standard holographic benchmarks.<br/><br/>The targeted application we hope to develop is a bacteriorhodopsin-based holographic associative memory, which simulates the way the human brain works. Associative memory architectures are not new, but their utility has been limited by the absence of materials that facilitate highly efficient implementation (i.e., the lack of truly reusable media). Associative memories allow computers to identify objects and concepts faster and more efficiently- applications include any technology that requires autonomous general-pattern recognition and/or fast & efficient large-scale database search capabilities. Information processing techniques such as data mining, data reduction, and large-scale complex database searches will be enhanced through the successful development of these architectures. Furthermore, this technology has the potential to play a critical role in the development of artificial intelligence (AI)-successful implementation of AI architectures will require a fast & efficient large-scale database search capability. Incorporation of dynamic write-read-erase materials into pre-existing associative architectures will introduce a level of flexibility not previously possible.<br/><br/>To summarize, the proposed effort uses advanced molecular biological techniques to produce genetically-engineered bacteriorhodopsin (BR) proteins for holographic associative memories. The technical merit & broader impacts of this technology must therefore be considered at multiple levels, including (1) development of novel holographic materials & (2) the ramifications of viable associative memories. The former will impact any holographic technology that will benefit from a real-time reusable media (e.g., optical memory & non-destructive testing architectures), while the latter will facilitate any technology that will benefit from the ability to utilize fast & efficient large scale database capabilities (e.g., artificial intelligence, proteomics, and the human genome project). Perhaps the most basic impact of this technology will be the demonstration of random mutagenesis and directed evolution as viable techniques for the production of custom-tailored proteins to be used in a variety of applications."
9526004,Optimization of Real-Time Rule-Based Expert Systems,IIS,INFORMATION & KNOWLEDGE MANAGE,6/15/1996,6/9/2000,Albert Cheng,"Cheng, A","Cheng, A",TX,University of Houston,Continuing grant,Maria Zemankova,5/31/2001,"$236,313.00 ",,cheng@cs.uh.edu,4800 Calhoun Boulevard,Houston,TX,772042015,7137435773,CSE,6855,"9216, HPCC",$0.00 ,normalFunding,"This research focuses on developing the scientific foundation and implementing practical tools for optimizing and synthesizing rule-based expert systems to meet specified response time constraints.  Real-time rule-based expert systems are embedded artificial intelligence systems increasingly used in safety-critical applications such as airplane avionics, medical monitoring instruments, smart robots, and space vehicles.  In addition to functional correctness, these systems must also satisfy  stringent timing constraints.  The result of missing a deadline in these systems may be catastrophic.  If a given rule-based system cannot deliver an adequate performance in bounded time, then it has to be optimized or resynthesized.  The first part of the project investigates several approaches (state-space-based and semantics-based) for optimizing the rule base of expert systems.  The second part of the project investigates the optimization of the match phase, which has a highly unpredictable runtime.  The development of a systematic methodology to tackle the optimization problem opens up new avenues to further enhance the runtime performance of rule-based systems in time-critical environments.  This technology will play a key role in tomorrow's complex information and computing systems such as multimedia tools, virtual reality systems, smart robots, and high-bandwidth networks, where an intelligent interface is essential and time becomes an increasingly critical resource."
9406998,Marker-Propagation Networks:  A Quantitative Analysis,CCF,COMPUTER SYSTEMS ARCHITECTURE,12/1/1994,12/20/1996,Dan Moldovan,"Moldovan, D","Moldovan, D",TX,Southern Methodist University,Continuing grant,Anand R. Tripathi,11/30/1998,"$235,000.00 ",,moldovan@utdallas.edu,6425 BOAZ,Dallas,TX,752750302,2147682030,CSE,4715,"9216, HPCC",$0.00 ,normalFunding,"  Marker-propagation networks (MPNs) represent a powerful  computational model especially suitable for artificial  intelligence and other  applications where information is often  uncertain and incompletely specified.  MPNs refer to networks of  active nodes and labeled links.  The power and  novelty of this  model derives from the fact that the processing instruments are  programmable data patterns of flexible length called markers.  Node processing  is activated by the arrival of markers.  Marker  propagations through the  network are not driven by destination  addresses, instead, they depend on local  conditions in the nodes,  network topology and the information programmed in  each marker.  This is a major difference between MPNs and other parallel  processing models, and it is the reason why MPNs are capable of  handling weakly  or incompletely specified applications.    Previous work in the area of  marker--propagation processing  assumed much simpler models.  The model studied  in this project  operates asynchronously, and is highly programmable.  Some of  the  critical issues related to the implementation of MPNs on existing  parallel  computers are possible programming paradigms, sources of  parallelism, load  balancing, design tradeoffs, and others.    The approach taken in this project  is a quantitative one, meaning  that the model is implemented on several  parallel computers,  performance is measured and the results compared.    The  MPN model offers scalability and has the potential of being a  preferred  architecture for future supercomputers dedicated to  knowledge processing  applications."
9907419,"Collaborative Research:  Constraint Satisfaction, Database Query Evaluation, and Information Integration",IIS,"WESTERN EUROPE PROGRAM, INFORMATION & KNOWLEDGE MANAGE",10/1/2000,11/7/2002,Phokion Kolaitis,"Kolaitis, P","Kolaitis, P",CA,University of California-Santa Cruz,Continuing grant,Gia-Loi Le Gruenwald,9/30/2005,"$233,388.00 ",,kolaitis@ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,"5980, 6855","5914, 9178, 9216, 9251, HPCC, SMET",$0.00 ,normalFunding,"This interdisciplinary research is carried out in a collaboration between Professors Phokion Kolaitis at the University of California, Santa Cruz and Moshe Vardi at Rice University. Constraint satisfaction and conjunctive query evaluation are two fundamental and ubiquitous problems in artificial intelligence and database systems, respectively. Since these problems are known to be computationally intractable in the worst case, researchers in artificial intelligence and database systems have sought to discover tractable cases of constraint satisfaction and conjunctive query evaluation, as well as to design heuristic algorithms for solving these problems. Thus far, however, these studies have been largely carried out in parallel and with relatively little or no interaction between the two areas. Recent research work has established that there are strong and exact connections between constraint satisfaction and conjunctive query evaluation. The main goal of this project is to further explore the connections between constraint satisfaction and conjunctive query evaluation, and to examine the applicability of techniques developed for each of these problems to the other problem. To this effect, a novel game-theoretic framework is being developed to unify seemingly unrelated results, identify additional tractable cases of these two problems, and design heuristics for the general case. Moreover, algorithms and heuristics developed by the artificial intelligence community are being evaluated in regards to their efficacy in conjunctive query evaluation, and vice versa. Results obtained in the course of this project will enhance the interaction between artificial intelligence and database systems, and will advance knowledge transfer between these two areas."
1616216,Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering,MCB,Systems and Synthetic Biology,8/1/2016,7/30/2016,Forrest Sheng Bao,"Bao, FS","Bao, FS",OH,University of Akron,Standard Grant,Devaki Bhaya,9/30/2018,"$232,523.00 ",,fsb@iastate.edu,302 Buchtel Common,Akron,OH,443250001,3309722760,BIO,8011,"144E, 1757, 7465",$0.00 ,normalFunding,"Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization. Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors; the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings."
1458272,IRES: Avatar-based Adaptive Context System,OISE,IRES Track I: IRES Sites (IS),6/15/2015,6/3/2015,Avelino Gonzalez,"Gonzalez, A","Gonzalez, A",FL,University of Central Florida,Standard Grant,Charles H. Estabrook,5/31/2019,"$231,974.00 ",,gonzalez@ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,O/D,7727,"5936, 5980, 7727",$0.00 ,normalFunding,"Part 1<br/>This interdisciplinary partnership between the University of Central Florida and the Fraunhofer Institute for Digital Media Technology (FIDMT) in Ilmenau, Germany is focused on adaptive conversational avatars, the rapidly emerging field crossing computer engineering, computer science, education, communications, and social science.  Immediate applications of this research field include artificial intellegence and national security (including cyber-security), interactive robotics, improvement of quality of life for disbaled, and health and caretaking for children and elderly.<br/>This project will place students from the University of Central Florida under the mentorship of the PI (Dr. A. J. Gonzalez) and of Dr. Klaus Jantke, the counterpart at FIDMT in Ilmenau, Germany. Dr. Jantke is the director of the Children's Media Department of FIDMT located in Erfurt, Germany and has a long and illustrious history in research in computing media. The international aspect of innovative and advanced research is essential in modern research hence the PIs will work with three cohorts of students, one during each year of the project's existence. Each cohort will include one graduate student and either two undergraduates (the first year) or four (in each of the subsequent years).  The research period for each cohort will be 16 weeks - eight weeks in the US and eight weeks in Germany for each year of the grant period.<br/>This research project is motivated by an ancient art of storytelling. In our pursuit of an artificially intelligent computer agent, the IRES project seeks to build a capability to autonomously synthesize possible scenarios for the system development and to modify them dynamically upon listener request. More specifically, the topic of the research in this project is the creation of an avatar-based system that can synthesize and adapt a scenario according to the user's request in real time and without any pre-scripted pathways. Good storytellers were treasured in medieval times, given the lack of other media through which to relate a story to a mostly illiterate population. Therefore, the project seeks to embody the storyteller in a lifelike avatar that resembles an actual person. This avatar will tell the story to the listener in spoken natural language, and interact with her/him when the latter requests changes to the story. <br/><br/>Part 2<br/>Storytelling media have evolved over time, from oral stories to modern E-books. Since the development of the computer, storytelling systems have become a science of their own, and have evolved from simple systems that can only generate a single short story to systems that respond to the listener's actions by modifying the story dynamically in real time. Digital storytelling has therefore become a growing field within artificial intelligence. The project seeks to take this evolution of storytelling media one step further by doing research to create a virtual storyteller who tells a dynamic story. The story is modifiable through a request by the listener (typically a child, a student, or an elderly person), yet will seek to remain realistic as well as interesting. Every story has a story space. That is, only so many things can happen in a story. We use contextual reasoning to represent the story space. In the real world, courses of action are influenced by the current context, making some conversational avatars very attractive while others unattractive when addressing the current situation within the story space. In a similar manner, the situation faced by the protagonist in the dynamic scenario will limit the choices of actions that he/she would otherwise have, thereby taking the story in various directions, none of which need be specifically pre-scripted.  The PIs base the proposed research on the use of formal methods to manipulate the story space within the main theme of the story. By formal methods the PIs mean that one represents the story knowledge formally in terms of strings, interaction sequences such as storyboards and graphs, formulas (for conditions), and the like. Formal methods, therefore, will give the ability to reason with formal methods (string comparison, unification, anti-unification and the like) in the story space. Formal methods have been used in the literature to manipulate contextual information."
1554123,"CAREER: Locally Adaptive Nonparametric Estimation for the Modern Age - New Insights, Extensions, and Inference Tools",DMS,"STATISTICS, Division Co-Funding: CAREER",7/1/2016,5/23/2018,Ryan Tibshirani,"Tibshirani, R","Tibshirani, R",PA,Carnegie-Mellon University,Continuing grant,Gabor J. Szekely,6/30/2021,"$231,216.00 ",,ryantibs@cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,MPS,"1269, 8048",1045,$0.00 ,normalFunding,"Nonparametric modeling---which means, roughly, flexible modeling of smooth trends without specific assumptions about their form or shape---finds diverse applications in many areas such as epidemiology, astrophysics, finance, and artificial intelligence. It is also a field ripe for modern statistical development, since nonparametric models are in a sense even more appealing in the ""big data"" era, as it is precisely in data-rich settings that the increased flexibility of these models will begin to show real rewards in terms of statistical accuracy. The proposed work will develop nonparametric methods (and affiliated software) that will be useful to data scientists who model smooth, nonlinear trends in areas like those mentioned above, as well as many others. A specific scientific emphasis will be the forecasting of influenza and dengue fever. Such forecasts will help policy makers design and implement more effective countermeasures towards these diseases. The proposal puts forward two main ideas for educational training, closely related to the research aims to be pursued. The first is a set of short videos on nonparametric smoothing, intended as supplements to an undergraduate level course called Advanced Methods for Data Analysis. They will be integrated with an interactive quiz system, and will be made freely available (on YouTube) so that others outside the class may watch too. The second idea is a statistical computation training group, for PhD students from Statistics and Computer Science.<br/><br/>""Locally adaptive"" nonparametric methods offer more fine-grained flexibility than traditional nonparametric methods, in that they can simultaneously represent different amounts of smoothness at different parts of the function domain. Currently, locally adaptive nonparametric methods are not often used in big, modern data sets, likely because of their computational inefficiency, and the general inavailability of locally adaptive methods in many modern problem settings. The proposed work seeks to change this, and to push the state of the art in modern locally adaptive nonparametric estimation. The research aims are to: deepen the theoretical understanding of existing locally adaptive methods for univariate problems; efficiently scale these methods and extend these theories to problems where data are collected in high dimensions and over graphs; and develop inferential tools for all of these locally adaptive procedures. The specific contributions will be balanced between the theoretical (statistical theories that describe the underpinnings of the methods in question) and computational (practical algorithms that describe implementation of these methods at scale) perspectives. A final more applied research aim is to use the proposed methods to improve and extend a forecasting system for major epidemics such as influenza and dengue fever."
9504316,Higher level Reasoning for Constraint Satisfaction,IIS,ARTIFICIAL INTELL & COGNIT SCI,12/15/1995,11/5/1997,Eugene Freuder,"Freuder, E","Freuder, E",NH,University of New Hampshire,Continuing grant,Ephraim P. Glinert,11/30/1999,"$231,057.00 ",,ecf@cs.unh.edu,51 COLLEGE RD SERVICE BLDG 107,Durham,NH,38243585,6038622172,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"IRI-9504316  Freuder, Eugene  University of New Hampshire  $78, 415-12 mos    Higher Level Reasoning for Constraint Satisfaction    Constraint satisfaction is an important reasoning paradigm in  artificial intelligence, with many applications, extending to  more general computing domains outside of AI. As constraint  satisfaction addresses larger and more practical problems, it  will become increasingly necessary to bring to bear advanced  artificial intelligence techniques for higher level reasoning.  Higher level reasoning steps back from the immediate need to find  a solution to a problem and reasons about such interests as:  Interactive constraint satisfaction (How to acquire, update, and  explain constraint knowledge), Abstraction and reformulation (How  to simplify problems by removing constraints without trivializing  them), Metaknowledge (How to use knowledge about constraint  management, substitutability of constraints, and relation of  constraints to problem structure effectively), Knowledge  compilation (Achieving efficiency by preprocessing bodies of  constraints), and Subproblem decomposition (Extraction of useful  subproblems and their constraint representations)."
1821828,Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering,MCB,Systems and Synthetic Biology,10/5/2017,8/6/2018,Forrest Sheng Bao,"Bao, FS","Bao, FS",IA,Iowa State University,Standard Grant,Devaki Bhaya,7/31/2019,"$230,672.00 ",,fsb@iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,BIO,8011,"144E, 1757, 7465",$0.00 ,normalFunding,"Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization. Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors; the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
928092,New Model and Methodology for Signal Estimation and Decoding,CMMI,"DYNAMICAL SYSTEMS, ENG DIVERSITY ACTIVITIES, BROAD PARTIC IN ENG (BRIGE)",9/1/2009,6/30/2011,Jing Li,"Li, J","Li, J",PA,Lehigh University,Continuing grant,Irina Dolinskaya,9/30/2014,"$230,000.00 ",,jingli@ece.lehigh.edu,Alumni Building 27,Bethlehem,PA,180153005,6107583021,ENG,"7478, 7680, 7741","034E, 1057, 9102, CVIS",$0.00 ,normalFunding,"This project aims to apply nonlinear dynamics to the study of (iterative) statistical inference, an important class of algorithms with well-proven applications in communications, signal processing and artificial intelligence. Existing models and methodologies for iterative analysis, coming largely from an information theoretical perspective, are inadequate in predicting and controlling the individual (rather than the ensemble-average) time-evolution behavior of a large-dimension and highly-dynamic signal sequence. On the other hand, estimating nonlinear dynamical systems, especially the challenging case of chaos, has not taken advantage of the powerful tool of statistical inference nearly as much as it could have. A wide spectrum of activities are planned to bring together the important ideas and tools from these two fields, to supply each other with new perspectives and new approaches, and to hopefully generate a whole new engineering methodology for unifying classical signals and chaotic signals. Specific focus will be set on understanding the cause and impact of chaotic behavior in statistical inference, developing ways to control chaos and transient chaos, and using statistical inference on appropriate models, such as Markov random fields and factor graphs, to predict and synchronize chaotic systems. <br/><br/>In view of the very pervasive scope of the practical applications associated with statistical inference algorithms and nonlinear dynamical theory, the research work in the proposed direction will have significant societal and scientific impacts. The potential application is broad, including many communication systems and discrete dynamical systems, such as cellular networks, wireless sensor and ad-hoc networks, digital data recording systems, radar systems, weather and tornado prediction, ecology, and population estimation. The proposed research also integrates a meaningful education and outreach component, which includes opening a series of seminars, supplying undergraduate and graduate students with theses projects, developing a new graduate level course, and engaging under-represented students in research.<br/>"
1661755,CAREER: A New Neat Framework for Statistical Machine Learning,IIS,ROBUST INTELLIGENCE,9/1/2016,1/24/2017,Pradeep Ravikumar,"Ravikumar, P","Ravikumar, P",PA,Carnegie-Mellon University,Continuing grant,Weng-keen Wong,8/31/2019,"$229,400.00 ",,pradeepr@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,7495,1045,$0.00 ,normalFunding,"The pendulum in Artificial Intelligence (AI) research has periodically swung from so called ""neat"" or mathematically rigorous approaches, and ""scruffy"" or more adhoc approaches. In recent years, real-world data across varied fields of science and engineering are increasingly complex, and involve a large number of variables, which has resulted in a surge of scruffier methods. This proposal develops a general ""neat"" framework for such modern settings by leveraging state of the art developments in two of the most popular subfields of machine learning methods: graphical models and high-dimensional statistical methods. These developments have in common that a complex model parameter is expressed as a superposition of simple components, which is then leveraged for tractable inference and learning.<br/><br/>Our unified framework results not only in a unified picture of these developments but also provides newer methods to work with such high-dimensional data. The research thus impacts problems across science and engineering wherever statistical machine learning approaches are being used (such as genomics, natural language processing and image analysis, to name a few). The work on a unified framework for statistical machine learning problems is highly coupled with a push for imparting training to students on what we call ""comptastical"" thinking. This combines both computational and statistical thinking required for addressing the problems of limited computation and limited data inherent in modern statistical AI application domains. The proposal also develops an infrastructure for component-based courses with relationally organized lecture module components."
924988,"How Flowcharts Got into the Brain: Diagramming Brains, Minds and Computers Together",SES,"SCIENCE, TECH & SOCIETY",10/1/2009,7/24/2013,Joseph Dumit,"Dumit, J","Dumit, J",CA,University of California-Davis,Standard Grant,Frederick M Kronz,9/30/2014,"$228,427.00 ",,dumit@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,SBE,7603,"0000, 6866, 7567, OTHR",$0.00 ,normalFunding,"This project, supported by the Biology & Society initiative between the Science, Technology & Society Program and the BIO directorate at NSF, examines the role of flowcharts in neurosciences.  Flowcharts are commonly used today in computer science, psychology, and neuroscience. Despite the near ubiquity of diagrams like flowcharts in the development of computers and the founding of neural nets, artificial intelligence, and cognitive psychology and neuroscience, there has been almost no attention paid to the history and uses of those diagrams.  This project examines the impact that visual diagrams and flowcharts had on the development of computers, psychology and neuroscience from the 1940s and 1970s. Published reports and archival research provide the basis for this study of the interactions between programming diagrams, flowcharts, neural models, and brain modules, as their conceivers borrowed and built upon visual metaphors and analogies. Engaging with scholarship on the importance of drawing and visual ways of thinking in the growth of science, this project investigates whether and how these diagrams and models enabled and constrained theories and experiments in cognitive neuroscience and artificial intelligence research.<br/><br/>This project will augment our understanding of the historical development of computers, brains, artificial intelligence, and cognitive psychology by demonstrating their sometime dependence and interaction with flow diagrams. It promises a richer, more comprehensive and balanced historical grasp of several aspects of the mind-brain-computer nexus than has hitherto been available, potentially clarifying a key episode in the history of modern science and technology. The project documents the variety of flowchart techniques, as well as alternate ways of reading and interacting with the diagrams that may be worth revisiting. If successful, contemporary cognitive scientists, neuroscientists and AI researchers may benefit directly from rethinking the meaning and use of their diagrams. <br/><br/><br/>"
1552097,CAREER: Pursuing New Tools for Approximation Algorithms,CCF,ALGORITHMIC FOUNDATIONS,3/1/2016,5/7/2018,Shayan Gharan,"Gharan, S","Gharan, S",WA,University of Washington,Continuing grant,Rahul Shah,2/28/2021,"$227,932.00 ",,shayan@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7796,"1045, 7926",$0.00 ,normalFunding,"Many of the large-scale industries are now employing sophisticated algorithms to solve variants of fundamental optimization problems. For example, Amazon uses a variant of the Traveling Salesman Problem (TSP) known as the vehicle routing problem for routing Amazon-Fresh Trucks. Uber solves a variant of TSP to route its shared-ride services. Many of the social networks including Facebook and Google+ solve variants of constraints satisfaction problems for their social targeting tasks. These optimization problems have ubiquitous applicability but they are computationally challenging in the sense that many are known to be NP-hard. This means that under standard assumptions they cannot be solved optimally by algorithms which terminate in reasonable time. The field of approximation algorithms attempts to develop efficient algorithms that find solutions close to the optimum. These approximation algorithms have found many applications in the real world. The project will advance state-of-the-art in approximation algorithms which will not only have impact on industry but also contribute to our fundamental understanding of P vs NP issue, which is at the core of computer science.<br/><br/>This project aims to develop new tools and techniques to obtain improved approximation algorithms for fundamental optimization problems, including the TSP and Constraint Satisfaction problems. The project intends to prove new algebraic properties of stable polynomials and use them to study graphs from an algebraic point of view. These tools will lead to design a new class of approximation algorithms. These new tools coming out of this project will be incorporated in the next generation of courses in approximation algorithms that focus on algebraic techniques. Although grounded in computer science theory, the project will also attract many graduate students outside of theory from applied fields like machine learning and artificial intelligence forming basis for interdisciplinary research."
725685,Collaborative Research: Interactive Deception and its Detection through Multi-modal Analysis of Interviewer-Interviewee Dynamics,BCS,"HSD - DYNAMICS OF HUMAN BEHAVI, ",10/1/2007,9/18/2007,Timothy Levine,"Levine, T","Levine, T|Park, HS|Biocca, F",MI,Michigan State University,Standard Grant,Amber L. Story,9/30/2011,"$227,902.00 ","Hee Sun Park, Frank Biocca",levinet@msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,SBE,"7319, S005","7319, 9215, HPCC",$0.00 ,normalFunding,"Deception is a pervasive feature of social life yet often goes undetected because deceivers capitalize on features of the interpersonal communication process. They adjust their verbal and nonverbal behavior over the course of an interaction in ways that evade detection. To uncover the complexities and dynamics of the communication processes that make successful deception or detection possible, collaborative research will be conducted by a multidisciplinary team of communication, linguistics, psychology, computer science, and management information systems researchers from the University of Arizona, University of Chicago, Michigan State University, and Rutgers University. They will be joined by international experts from the University of Cologne, Imperial College London, and University of Iceland. The project will develop a theoretical model of interpersonal deception that shifts emphasis from stable individual behaviors to dynamic interaction patterns. It will create five test beds by measuring the verbal and nonverbal features from video-recorded interpersonal communication experiments. The five experiments are a cheating experiment, a mock theft experiment, deceptive interviews, a group collaboration task, and a narration task. Measurement will consist of extensive automated and human-annotated measurement of visual, vocal, and verbal features. As part of the annotation work, the team will refine and validate software for automated measurement of nonverbal and verbal features. Theory-driven hypothesis tests and exploratory tests will be conducted on the measured communication behaviors to identify dynamic adaptation patterns using time-series, Bayesian-based Theme analyses, and artificial intelligence data mining techniques. The project will advance the scientific infrastructure for studying deception by forming the largest international and multidisciplinary research team of deception experts of its kind, integrating the knowledge and methods of multiple disciplines, refining computer-aided analysis of human communication, making progress in automating deception detection, and educating new investigators through laboratory exchanges. Society will benefit from a more valid picture of deception that can guide training and detection efforts in public, business, government, and security settings."
1742656,Image-Data-Driven Deep Learning in Geosystems,CMMI,Geotechnical Engineering and M,9/1/2017,7/30/2017,Zhen Liu,"Liu, Z","Liu, Z|Hu, S",MI,Michigan Technological University,Standard Grant,Richard J. Fragaszy,8/31/2019,"$227,367.00 ",Shiyan Hu,zhenl@mtu.edu,1400 Townsend Drive,Houghton,MI,499311295,9064871885,ENG,1636,"036E, 037E, 038E, 1057, CVIS",$0.00 ,normalFunding,"Breakthroughs in deep learning in 2006 triggered numerous cutting-edge innovations in text processing, speech recognition, driverless cars, disease diagnosis, and so on.  This project will utilize the core concepts underlying the recent computer vision innovations to address a rarely-discussed, yet urgent issue in engineering: how to analyze the explosively increasing image data including images and videos, which are difficult to analyze with traditional methods. These concepts will be employed to explore the possibility of accurately assessing the safety of retaining walls with image data.  This effort aims at setting up a paradigm for connecting engineering disciplines to artificial intelligence and enhancing the safety of geosystems as an essential infrastructure component by enabling their analysis with image-data-driven deep learning.  The project will help revitalize traditional artificial intelligence sub-areas in geotechnical and other engineering areas, just as deep learning rekindled the interest in artificial neural networks and machine learning, and turned them into leading players in STEM research and innovations.  The project may also change engineers' opinions regarding how to create knowledge with a revolutionary way attributed to deep learning, i.e., learning directly from data instead of indirectly from models established based on the data.  Innovative education and outreach effort will be made by means of developing a mobile app to disseminate the idea and products of the project.  The project will contribute to education by outreaching to K-12 students, underrepresented groups, and geotechnical engineering researchers and practitioners with the project products including the app at various events at the PIs' institution and professional conferences. <br/><br/>The goal of this study is to understand the image-data-driven deep learning in geosystems with an exploratory investigation into the stability analysis of retaining walls.  To achieve the goal, the recent breakthroughs in computer vision, which were later used as one of the core techniques in the development of Google's AlphaGo, will be studied for its capacity in assessing the stability of a typical geosystem, i.e., retaining walls.  The core concept enabling machines to surpass humans in visual classification capacity, i.e., convolutional neural nets (CNN), will be used to process the big data in geotechnical engineering, which primarily consist of still and live images (videos), that cannot be readily analyzed using traditional geotechnical engineering methods.  Conventional neural nets will be used to analyze images for retaining walls to tell whether a wall is safe or failed.  For quantitative analysis, 2D and 3D images for retaining walls will be generated using stochastic methods and analyzed using traditional limit analysis and numerical methods for labeling.  These labeled image data will be used as input to train convolutional neural nets for supervised learning. The trained nets will be tested against another independent set of data generated in the same way as the training data. Three research tasks will be conducted in this project: 1) understanding the data science for image-data-driven geotechnical engineering research, 2) investigating the connections between those image patterns in deep learning and the physical mechanisms, and 3) revealing the robustness and extrapolation capacity of the deep learning approach in the stability analysis of retaining walls."
9978567,Efficient Query Processing for Data Integration,IIS,INFORMATION & KNOWLEDGE MANAGE,10/1/1999,7/5/2001,Alon Halevy,"Halevy, A","Halevy, A",WA,University of Washington,Continuing grant,Maria Zemankova,9/30/2002,"$226,000.00 ",,alon@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6855,"9216, HPCC",$0.00 ,normalFunding,"This goal of this research project is to develop efficient query optimization and query execution methods for data integration systems. Data integration systems provide uniform access to a multitude of autonomous data sources within an enterprise or on the World-Wide Web. Unlike in traditional database applications, a query execution engine for data integration must be able to cope with limited availability of statistics on the underlying data and with unexpected network delays during query execution. The approach consists of developing an adaptive query execution engine for data integration. Two kinds of adaptivity are considered: (1) interleaving of query optimization and execution, and (2) developing novel query execution operators that are tailored to data integration. In the first part, algorithms for determining appropriate points at which to suspend query optimization are considered. For the second part, novel join implementations are considered (e.g., the double-pipelined join), as well as operators that are needed only in the data integration context (e.g., dynamic collectors performing unions over large collections of sources). In addition, issues involving the integration of semi-structured data (e.g., XML) are also addressed. The results of the research include the implemented Tukwila data integration system, which will be made available to other researchers in the field. The impact of the research will be to remove the performance bottleneck that hinders fielding data integration systems in the WWW and enterprise contexts. We will be able to process data integration queries involving 10's of MB of data coming from external sources in real time.<br/>http://data.cs.washington.edu/integration/tukwila<br/>"
9702306,CAREER: Optimization Methods for Higher-Order               Learning Machines,IIS,ARTIFICIAL INTELL & COGNIT SCI,6/1/1997,6/15/2000,Kristin Bennett,"Bennett, K","Bennett, K",NY,Rensselaer Polytechnic Institute,Continuing grant,William Bainbridge,5/31/2002,"$225,022.00 ",,bennek@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,6856,"1045, 1187, 9216, HPCC",$0.00 ,normalFunding,"This  research investigates optimization methods for constructing  higher-order learning machines to solve very large classification  problems  such  as  those  found in  data  mining  and  character  recognition.    In  higher-order  learning  machines,  the  input  vectors  are  mapped nonlinearly into a higher-dimensional  space  and  then  a  linear discriminant is constructed in  the  higher-  dimensional space. The resulting discriminant function may  be  a  polynomial, neural  network, radial basis function classifier, or  decision  tree.    Vapnik's Statistical Learning Theory  is  used  within  the  problem formulation to avoid over-fitting  or  over-  parameterizing  the   discriminant  function.    To   solve   the  resulting  minimization problem, innovative optimization  methods  are  developed.    This work will have both  an  educational  and  research  impact.   The optimization methods  for  classification  problems will also be used within computer-based course materials  for  teaching concepts of mathematical programming and as a basis  for  research  projects for undergraduates.  The research  impact  will   be   the   development  of   novel,  fast,  and   accurate  classification  methods  based on  statistical  learning  theory.  These   methods   will  be  applied  to   very  large   practical  applications  in a diverse set of fields, for example:  character  recognition  in  engineering,   cancer  diagnosis   in  medicine,  database  marketing  in  business,  and  prediction  of  mortgage  prepayment in finance."
1622256,SBIR Phase I:  Cloud Based Artificial Intelligence for Trend Analysis Using Sensor Data,IIP,SMALL BUSINESS PHASE I,7/1/2016,6/20/2016,Laura Kassovic,"Kassovic, L","Kassovic, L",CA,MbientLab,Standard Grant,Richard Schwerdtfeger,6/30/2017,"$225,000.00 ",,laura@mbientlab.com,848 Girard St,San Francisco,CA,941341920,4084069149,ENG,5371,"033E, 152E, 5371, 8033",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase 1 project is to address the problem of data interpretation, one of the most important and fastest growing issues caused by the influx of wearable technologies. As with all technology, wearable devices are increasing in popularity and decreasing in cost every day. Businesses rushing to catch this wave of technology paradigm are met with the complex problem of how to interpret the data gathered in a way that is accurate and useful to consumers. Many of these businesses are companies with products that were previously completely unrelated with computer or smartphone technologies. As such, they do not have the in-house expertise to not only correctly gather such data, but then analyze it for patterns that could be deemed useful in identifying behavior or conditions for the consumer. By providing a boxed solution that makes machine learning based data analysis possible for the average engineer, our project is aimed to help these businesses cross that hurdle.<br/><br/>This Small Business Innovation Research (SBIR) Phase 1 project seeks to bring Artificial Intelligence and Machine Learning systems for use in the hands of non-data/computer scientists. While machine learning and AI techniques are widely used these days in many applications ranging from Google search to Uber rides, they remain fairly esoteric topics with a high learning curve just to understand, let alone apply. We plan to address this issue differently from previous competitors by building a highly intuitive web UI on top of our existing hardware sensor platform. This allows us to leverage the data gathering and processing consistency of our hardware, along with our proprietary SDKs to ensure properly labelled and clean data. As a result, we will have a much easier time developing basic digital processing filters as well as applying machine learning techniques to the data in order to solve generic classification problems."
1722432,"SBIR Phase I:  Compact, Low-cost, Automated 3D Ultrasound System for Regular and Accessible Breast Imaging",IIP,SMALL BUSINESS PHASE I,7/1/2017,8/27/2018,Maryam Ziaei-Moayyed,"Ziaei-Moayyed, M","Ziaei-Moayyed, M",CA,"iSono Health, Inc.",Standard Grant,Henry Ahn,3/31/2019,"$225,000.00 ",,maryam@isonohealth.com,177 Townsend St.,San Francisco,CA,941075910,5105411320,ENG,5371,"5371, 8038",$0.00 ,normalFunding,"This SBIR Phase I project introduces a new paradigm for early monitoring and detection of breast cancer: the Quantified Self Exam. In the United States over 300,000 women are diagnosed and 40,000 women die from breast cancer every year. Breast cancer has a 99% survival rate if detected early, but limitations in cost, sensitivity, accessibility, and convenience of existing screening technologies result in one third of breasts cancers getting missed at early stages. Since treatment for early stage cancer is an order of magnitude less costly than treatment for stage 3 and 4 cancers, there is a clear economic and societal benefit for the development of better breast cancer monitoring and screening tools. To address this challenge, the technology proposed in this project leverages the proven benefits of ultrasound imaging and the newfound power of cloud-based artificial intelligence to provide a regular and accessible self-monitoring tool that can quantify and track suspicious changes in breast tissue. The device portability, low cost, 2 minute scan time, and automated analysis of breast image data will greatly increase the accessibility of breast cancer monitoring for women, which in turn stands to decrease the cost burden of this disease for the US healthcare system. <br/><br/>This SBIR Phase I project proposes to develop a new tool for early detection and monitoring of breast cancer: the Quantified Self Exam (QSE) that combines a low-cost, compact 3D ultrasound device and positioning accessory with artificial intelligence to empower women and their physicians with appropriate and actionable data.  The QSE technology proposed in this project operates independent of user skill and captures 3D volumetric images of the whole breast in 2 minutes.  The system architecture allows for simplified and low-cost ultrasound hardware that connects wirelessly to a smart phone/tablet and transfers captured data to secure cloud for advanced image processing and storage. The ultrasound scanner attaches to a positioning accessory for repeatable imaging that enables longitudinal 3D monitoring of abnormal growth using machine learning-based image analysis. The proposed Phase I R&D efforts focus on four objectives: (i) optimize electrical hardware and low-level imaging software for spatial resolution and image quality; (ii) build a QSE scanner that maximizes field of view and volumetric integrity; (iii) build a positioning accessory for positioning of the QSE scanner; (iv) demonstrate the longitudinal repeatability of QSE imaging by validating the alignment of 3D ultrasound volumes on a breast phantom."
916046,RI: Small: Collaborative Research: Word Sense and Multilingual Subjectivity Analysis,IIS,ROBUST INTELLIGENCE,9/1/2009,8/21/2009,Janyce Wiebe,"Wiebe, J","Wiebe, J",PA,University of Pittsburgh,Standard Grant,Tatiana D. Korelsky,8/31/2013,"$225,000.00 ",,wiebe@cs.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,7495,"7495, 9102, 9215, HPCC",$0.00 ,normalFunding,"Approaches to subjectivity and sentiment analysis often rely on<br/>manually or automatically constructed lexicons. Most such lexicons are<br/>compiled as lists of words, rather than word meanings (""senses"").<br/>However, many words have both subjective and objective senses as well<br/>as senses of different polarities, which is a major source of<br/>ambiguity in subjectivity and sentiment analysis.  The proposed work<br/>addresses this gap, by investigating novel methods for subjectivity<br/>sense labeling, and exploiting the results in sense-aware subjectivity<br/>and sentiment analysis.  To achieve these goals, three research<br/>objectives are targeted. The first is developing methods for assigning<br/>subjectivity labels to word senses in a taxonomy. The second is<br/>developing contextual subjectivity disambiguation techniques to<br/>effectively make use of the word sense subjectivity annotations. The<br/>third is applying these techniques to multiple languages, including<br/>languages with fewer resources than English.  The project will have<br/>broader impacts in both research and education.  First, it will make<br/>subjectivity and sentiment resources and tools more widely available,<br/>in multiple languages, to the research community, which will help<br/>advance the state of the art in automatic subjectivity analysis, which<br/>in turn will benefit end applications.  Second, several educational<br/>goals will be pursued: training graduate and undergraduate students in<br/>computational linguistics; augmenting artificial intelligence courses<br/>with projects based on the proposed research, which will offer<br/>students hands-on experience with natural language processing<br/>research; and reaching out to women and minorities to increase their<br/>exposure to text processing technologies and access to research<br/>opportunities."
9876136,"CAREER: A Software Development Framework That Integrates Learning, Probabilistic Reasoning, And Any-Time Computation",IIS,ARTIFICIAL INTELL & COGNIT SCI,3/1/1999,8/16/2002,Sebastian Thrun,"Thrun, S","Thrun, S",PA,Carnegie-Mellon University,Continuing grant,William Bainbridge,2/28/2003,"$225,000.00 ",,thrun@stanford.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,6856,"1045, 9216, HPCC",$0.00 ,normalFunding,"<br/>An increasing number of today's computers are equipped with sensors and actuators, so that they can interact directly with people and the outside world. Specific examples include software agents that interact with people and other software agents through the Internet, and consumer products, which interact with people and the physical world. Such computers, often called ""embedded,"" face a variety of challenges. For example, sensor limitations might make it impossible to sense the state of the environment accurately; thus, embedded computers must be able to cope with uncertainty. The environments of embedded computers might be dynamic, in which case there is a need to adapt to changes therein. Additionally, embedded computers might have to meet real-time constraints, as their environments tend not to wait for the termination of their programs. While many of these issues have been researched in the field of artificial intelligence (AI), computer science still lacks a sound methodology for software development in embedded computers. Existing programming languages and toolkits do not address issues such as uncertainty, adaptation, and on-time computing.<br/><br/>The PI's career objective it to change the way embedded computers are programmed. To pursue this goal, he proposes research towards a new programming language, specifically designed for embedded computer systems. This language will introduce three new ideas currently not found in existing programming languages:<br/><br/>I.  Probabilistic data types and operators. Probabilistic data types and operators will enable programmers to compute with uncertain information just as if it was certain. Probabilistic data types represent information by probability densities. They generalize existing data types (e.g., float, int) in that they represent multiple values at a time, weighted by numerical probabilities. From the programmer's view, probabilistic computation will be analogous to conventional computation, with the added benefit of increased robustness to uncertainty.<br/><br/>2.  Adaptation. The PI will develop mechanisms that support data-driven adaptation of program code. language will possess built-in learning algorithms (e.g., neural networks, reinforcement learning) and a mechanism for proper credit assignment. This will support the design of adaptable software, capable of automatically adapting to changes in the environment. It will also enable programmers to ""teach"" their code, as a supplement to current software development practice.<br/><br/>3.  Any-time execution. To accommodate the need for timely responses, the new language will provide run-time support for any-time computation. Any-time programs can be queried for a result at (almost) any time; the quality of their solutions, however, increases over time. To obtain any-time characteristics, the execution system will process probabilistic variables selectively, in decreasing order of the probability of individual values. A special mechanism will be provided that permits the event-driven termination of any-time computation.<br/><br/>If this research is successful, programmers of embedded systems will be able to utilize the results-with minimal overhead, effectively enabling them to develop better software with significantly less effort, when compared to today's best practice.<br/><br/>To better achieve his career goal, the PI will also engage in a collection of educational activities. He plans to revise the curriculum of CMU's introductory programming class, by including a course segment on embedded computation. He will also develop a new graduate-level course on embedded computation, which will integrate material from a variety of currently separate disciplines. For both courses, the programming language will be used as a vehicle: By using this language, students will gain a much deeper understanding of the various issues involved in embedded computation and their theoretical foundations. Additionally, feedback of advanced students will guide the basic research proposed here. All course materials, the language, its implementation and documentation, and all related research papers will be made available to the research community at large using the Web, so that others can contribute to and benefit from this project.<br/><br/><br/><br/>"
1721595,SBIR Phase I:  Wearable Technology to Prevent Decompression Sickness Underwater by Continuously Monitoring Bubble Presence in the Bloodstream and Tissues,IIP,SMALL BUSINESS PHASE I,7/1/2017,7/10/2017,William Garcia,"Garcia, W","Garcia, W",PR,SIL Technologies LLC,Standard Grant,Henry Ahn,2/28/2019,"$225,000.00 ",,william.garcia@siltechnologies.company,2539 Calle 14,Rincon,PR,6772461,5182217114,ENG,5371,"5345, 5371, 8018, 8042, 9150",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to enable the development of a unique wearable scuba-diving device that will eliminate the risk of Decompression Sickness (DCS), by monitoring in real time the formation of nitrogen bubbles in the body of the user while in the dive. The risk to develop DCS while conducting underwater activities occurs during the ascension phase, when the changing pressure may yield the formation of nitrogen bubbles in tissues and body. The presence of bubbles triggers a variety of serious injuries with long term consequences and even death. Any professional and licensed recreational scuba training makes trainees aware about the risks associated to DCS. Divers are instructed to follow ascent rates and safety stops according with criteria established from statistical considerations of empirical data. Nevertheless, DCS is suffered by rule-abiding divers during 3% of the immersions, requiring costly and distressing evacuation and treatment with hyperbaric chambers. The wearable device will alert the scuba-diver before the sickness develops, reducing the risk to suffer DCS, making underwater activities simpler and safer. <br/><br/>The proposed project plans to demonstrate an innovative ultrasonic resonant concept adapted from the acoustic chamber notion. Acoustic chambers are structures which are belted by piezoelectric arrangements which are set to deform expanding and compressing when subjected to oscillating electric voltages. The frequency of oscillations can be set to match the modes of vibration of the media entering in resonance. Under such conditions the setup is extremely sensitive to minor changes in the elastic properties of the system, such as those induced by the presence of compressible bubbles. This project will execute a plan to produce a wearable design of the piezoelectric array. Artificial intelligence as well as conventional methods will be employed to analyze the electrical disturbances, and relate them to the bubbles sizes in real time. The computing, data acquisition and power requirements will be determined. Ultimately, these results will determine the feasibility to integrate all the required components in an autonomous wearable DCS risk detection device by a scuba diver."
1621712,SBIR Phase I:  Virtual Learning Assistants for Constructed Response Assessment,IIP,SMALL BUSINESS PHASE I,7/1/2016,6/22/2016,Dharmendra Kanejiya,"Kanejiya, D","Kanejiya, D",MA,"Cognii, Inc.",Standard Grant,Ben Schrag,6/30/2017,"$225,000.00 ",,dharm@cognii.com,745 Atlantic Ave 331,Boston,MA,21112735,6178991744,ENG,5371,"5371, 8031, 8032, 8039",$0.00 ,normalFunding,"This SBIR Phase I project focuses on creating scalable Virtual Learning Assistant (VLA) technology for constructed response assessment. The best pedagogies responsible for improving learning outcomes generally involve (i) constructed response assessments and (ii) one-to-one tutoring. Students learn the best when they are given an opportunity to construct answers in their own words (instead of selecting from multiple choices) and when they receive immediate guidance and coaching in a one-to-one conversation with a human tutor. However, the costs and time associated with the constructed response assessment and one-to-one tutoring are significant, making them very difficult to scale. The proposed project will apply the most advanced technologies such as Artificial Intelligence and Natural Language Processing to solve both these problems. Students will benefit from the interactive formative assessment that engages them in a natural language conversation. This innovation is applicable across the grade levels in K-12, higher education, and adult learning and across the subjects areas such as English language arts, STEM and humanities. It will facilitate implementation of more rigorous academic standards and make online education more effective. This innovation will improve students' learning outcomes, save teachers' time and reduce the cost of delivering high quality engaging education on a large scale. <br/><br/>This project will create a new type of virtual assistant technology that is exclusively focused on education. The proposed Virtual Learning Assistant (VLA) will advance the conversational AI technology to create pedagogically rich learning and assessment environments for any topic in a content area. The VLA is uniquely distinct from general purpose virtual assistants in its ability to evaluate an answer instead of merely serving information. This project will investigate and create various algorithms for processing natural language input arising in an educational setting across different subjects or topics. The resulting web based product will allow teachers to create new high quality assessment items with minimal input and assign them to their students. When a student answers a question, the VLA will analyze it instantly for linguistic syntax and semantics using statistical and deterministic knowledge representations. The VLA will generate not only a numerical score reflecting the accuracy of the answer, but also a qualitative feedback that will guide the student towards conceptual mastery of the topic. As part of this Phase I research, a pilot study will be conducted involving teachers and students to study the efficacy of the VLA and to verify its usability and feasibility."
1620992,SBIR Phase I:  From Search to Research with Fast Patent-document Correlations,IIP,SMALL BUSINESS PHASE I,7/1/2016,6/22/2016,Monte Shaffer,"Shaffer, M","Shaffer, M",KY,Entrepreneurial Innovation,Standard Grant,Ben Schrag,6/30/2017,"$225,000.00 ",,monte.shaffer@gmail.com,921 Beasley Street #210,Lexington,KY,405091583,5095927592,ENG,5371,"5371, 8031, 8032, 8039, 9150, 9180",$0.00 ,normalFunding,"This SBIR Phase I project attempts to address a fundamental question for innovators: is my idea already patented?  This do-it-yourself-initially service will empower small-business enterprises with synthesized research of over 10 million patent documents within 10 minutes based on the concepts contained within the idea. Such a comprehensive, real-time, low-cost offering is currently unavailable for small-business entrepreneurs.  Current search tools do not synthesize the results into an executive summary, do not allow an entire document to be entered as the search input, and do not perform real-time concept/correlation computations.  This proposed innovation will enable the inventor to submit an entire document (the idea) as the search query; then, utilizing network mathematics and artificial-intelligence algorithms, this service will synthesize search results in real-time summarizing what patent documents are most related to the idea based on natural-language processing.  Such a service for small-business entrepreneurs would enable them to initially ascertain the novelty of their idea and give them an on-the-go education about the natural language used in patent documents in comparison to their idea.  This meta-innovation would objectively ascertain the intellectual-property merit of any proposed technology, enable small-business innovators, and foster the acceleration of innovation development in the United States.<br/><br/>The development of latent semantic analysis (LSA) has enabled algorithm development to extract latent (or hidden) semantic structure from documents addressing two important word-sense ambiguity issues that text-matching search cannot: polysemy (single term with multiple meanings; i.e., strike as to hit [verb], to start up [verb], or to cease working [noun]) and synonymy (multiple terms with single meaning; i.e., car and automobile).  Albeit robust, this concept-search approach for large document collections is not tractable due to the high-complexity computational requirements for performing matrix singular value decomposition (SVD) necessary for LSA.   Approximation techniques that use subset approaches necessarily introduce some amount of systematic error.  To ascertain the most relevant documents in a large collection for a given focal document, this proposed innovation (search-subset LSA) will subset using proprietary search methodologies without any systematic error, reducing both the number of documents to compare and the number of terms to analyze thereby making real-time document correlations possible.  The aims of this research are: to identify the optimal subset approach for comprehensive nomological capture of top-correlation candidates, to ascertain optimal input parameters for the focal query document, and to develop a statistical test to confirm that no systematic bias is present in this approach."
1622905,"STTR Phase I: Science, Technology, and Bullying Prevention in an App: Students to School Change",IIP,STTR PHASE I,7/1/2016,6/21/2016,Kenneth Bain,"Bain, K","Bain, K|Leff, S",NC,"Mobile Cinema Park, INC.",Standard Grant,Glenn H. Larsen,12/31/2016,"$225,000.00 ",Stephen Leff,kenneth.bain@mobilecinemapark.com,4045 Payne Road,High Point,NC,272651227,3367400530,ENG,1505,"118E, 1505, 8031, 8032, 8039, 9177",$0.00 ,normalFunding,"This STTR Phase I project aims to transform bullying prevention for middle school students through a revolutionary bullying prevention app. Bullying is the most common form of aggression and almost all states are mandating schools provide programming or policies. This project builds on the strong foundation of a one-of-a-kind, scientifically-grounded 90-minute 3D, interactive bullying prevention assembly for middle school students. The assembly is portable, easy to run and scalable, and evaluations demonstrated large immediate positive effects in students' desire to make changes to school climate and in their problem-solving skills, empathy, and confidence in handling bullying. This project addresses the challenge of ensuring that these immediate gains are translated into changes over time through the development of a novel app through community-based participatory research which combines empirically-based strategies with feedback from students, teachers, and administrators. This app will allow students to practice strategies learned from the assembly in a manner consistent with the growing demand for game-based mobile learning. Multiple teams will be hired throughout the US thus generating income for tax revenue and jobs.<br/><br/>The high-risk, high reward technological innovation challenge in phase 1 is aimed to develop new technological platforms that will enable each user to build his own set of events from different scenarios, all through simple touch screen capabilities and build an artificial intelligence machine learning system that will understand the student's free language. In order to achieve this goal, the organization will work with a technological consultant and develop the content using scriptwriters, focus groups, and community-based participatory research. This will create the first student-driven, downloadable bullying prevention app for use in concert with a scientifically grounded bullying prevention show. The app will build upon the 90 minute multi-media show for 7th and 8th graders in which there is a powerful 3D narrative, video illustrations for how to deal successfully with bullying situations, and an audience interactive component through handheld voting devices. Together the show and app will positively impact a school's academic and social-emotional climate. In addition, the show and student-motivated app are significantly more feasible than the teacher time- and cost-intensive models of other bullying prevention programs."
1721926,STTR Phase I:  Smart and Fast Atomic Force Microscope for Imaging and Characterization,IIP,STTR PHASE I,7/1/2017,7/30/2018,Larry Janness,"Janness, L","Janness, L|Hanna, D",MI,RHK Technology Inc,Standard Grant,Ben Schrag,2/28/2019,"$225,000.00 ",Darrin Hanna,janness@rhk-tech.com,1050 E. Maple Road,Troy,MI,480832813,2485775426,ENG,1505,"1505, 8034",$0.00 ,normalFunding,"This Small Business Technology Transfer Phase I project represents a change in concept and technical paradigm for Atomic Force Microscopy (AFM) technology, and as such shall significantly impact research and development in both industry and academia.  As discussed in the Technical Merits below, the proposed AFM is fast, smart, and more powerful in terms of imaging and probing local mechanics.  The company has a track record of commercializing AFM controllers that are compatible with most all types of scanners, commercial and home-constructed.  Current AFM users can purchase the new scanner and/or controller to attain the enhanced performance. In addition, new AFM users are also anticipated especially in the areas of nanomaterials, devices and sensors, and multidimensional devices and materials where both high spatial and temporal resolutions are paramount.  Further, the combined high spatial resolution in conjunction with fast speed shall result in immediate advances in the fields of material development, surface coating, nanomaterial and nanodevice inspection and quality control, nanolithography, and tissue engineering.  Based on current market trends, sales are anticipated to reach $25M within the first three years.  The amount is likely higher given the forecasted growth of the global microscopy market. <br/><br/>The intellectual merit of this project includes three cutting edge improvements to current AFM: (1) faster image acquisition speed; (2) automated and rapid feature finding and tracking; (3) 1-2 orders of magnitude of improvement in speed and efficiency in nanomechanical imaging.  The ultra-high speed will be achieved by implementing a novel reconfigurable processor optimized for AFM into a unique hybrid, low-noise controller architecture, which is highly versatile and compatible with various known configurations of AFM microscopes from many different vendors.  In addition, the automatic feature finding and tracking functions will be accomplished using artificial intelligence directly in hardware and a novel scan pattern, completely different from current ?trace-retrace? scanning trajectory in current AFM.  These new and ?smart? approaches further speed up scanning and tracking speed.  Finally, the AFM will be able to produce nanomechanical images with high speed and accuracy using multifrequency spectroscopy. This concept has been proposed, and individual aspects have been demonstrated in isolation through simulations or lab prototypes over the past five years or more.  The faster and more powerful electronic controller shall enable the test and implementation of multifrequency spectroscopy technology in its full potential."
1448848,STTR Phase I:  A Social and Data-Driven Platform for Searching Healthcare Providers,IIP,STTR PHASE I,1/1/2015,1/11/2016,Matthew Wiley,"Wiley, M","Wiley, M|Christidis, E",CA,SmartDocFinder LLC,Standard Grant,Peter Atherton,7/31/2016,"$225,000.00 ",Evangelos Christidis,mwiley63@gmail.com,3499 10th St,Riverside,CA,925013617,3057818044,ENG,1505,"1505, 8032",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase I project results from it providing a novel way to more effectively match patients to healthcare providers. Patients will be able to use the developed system to discover and compare the most suitable and experienced healthcare providers for their unique health needs, instead of just viewing a directory of providers in their area. For example, the proposed system will recommend to a patient searching for ""knee replacement surgery"" orthopedic surgeons with experience in this or similar procedures, positive health outcomes and high past patients satisfaction levels. The patient may then compare these surgeons by expertise, relative cost, location and several other attributes. By helping patients select the best healthcare providers, the proposed system not only has the potential to improve health outcomes, because providers will see the patients more relevant to their expertise, but may also reduce the number of ""shopping-around"" visits which may lead to a reduction in overall healthcare costs.<br/><br/>This Small Business Technology Transfer (STTR) Phase I project will study methods to exploit Big Data, ranging from government-published health metrics and surveys to public social media data, to better match patients to healthcare providers. A key challenge is that many of these sources include free text, which must be analyzed to extract medically significant information. Further, different sources refer to the same medical terms in different ways; for example ""myocardial infarction"" vs. ""heart attack"", or ""doctor knows her stuff"" vs. ""doctor is knowledgeable"". Data mining and artificial intelligence techniques will be leveraged to identify which provider properties - medical school, years of experience, affiliated hospitals, and so on - should be used when searching for providers and how these properties should be best weighted and combined, given the healthcare needs of a patient."
1721381,SBIR Phase I:  Fast Creation of Photorealistic 3D Models using Consumer Hardware,IIP,SMALL BUSINESS PHASE I,7/1/2017,6/28/2017,Jeevan Kalanithi,"Kalanithi, J","Kalanithi, J",CA,Openspace,Standard Grant,Peter Atherton,6/30/2018,"$225,000.00 ",,zoinks@gmail.com,3802 23rd St,San Francisco,CA,941143321,4159947035,ENG,5371,"5371, 8032",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be large: a successful project would transform the construction industry, making it far more efficient by reducing legal conflicts, schedule slips and poor decision making; the project has the potential to make real estate sales and marketing more efficient by allowing buyers and sellers to accurately represent properties online, reducing the need for on-site visits. The proposed work will enable the fast and easy creation of 100% complete visual documentation of a physical space; this documentation can be generated many times throughout the course of construction. In so doing, the proposed project will allow professionals in the construction industry to track progress and communicate with their teams far more efficiently than ever before. A second exciting effect of the proposal will be the creation of vast, detailed, never before seen datasets of construction projects and real estate, allowing technical innovations in artificial intelligence and computer vision to impact one of the largest industries in the nation and the world. For example, systems could be trained to automatically spot safety concerns, augmenting the efforts of safety managers and keeping workers safer than ever before.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project will develop a fast, easy to use and cheap method to create photorealistic 3D models using off the shelf consumer hardware. Technical hurdles include validating the quality and efficacy of models generated with consumer hardware, near instantaneous creation of 3D models on device, and automatic creation of routes through the 3D space without human annotation. With these hurdles cleared, advanced work might include automated analytics between and among 3D models of the same site captured over time. Because of the system's ease of use, it will enable the collection of large, totally novel datasets. The goal of the research is to produce a prototype that a layperson can use to create a 3D model of a physical site in order to document it. The plan to reach these goals includes iterative software development against the hurdles listed above, as well as continuous user feedback to guide and refine development."
1721739,SBIR Phase I:  IoT Smart Water Management System,IIP,SMALL BUSINESS PHASE I,6/1/2017,6/9/2017,Matthew Cusack,"Cusack, M","Cusack, M",NY,"Mobius Labs, Inc",Standard Grant,Richard Schwerdtfeger,5/31/2018,"$224,949.00 ",,cusackmatthewj@gmail.com,37 Vischer Ferry Rd,Rexford,NY,121481617,3477662487,ENG,5371,"5371, 8033",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to provide a simple to use ""smoke alarm"" for water appliances coupled with a level of insight into water consumption and failures that has never existed before. What was once a reliance on water meter data for the sum of all appliances is now a detailed understanding for each individual water fixture. This unprecedented access to water usage data at an individual appliance level will provide the opportunity for increased data analytics research, predictive analytics for failure modes and maintenance scheduling, and better understanding of human consumption habits to identify and solve problems that allow organizations to meet aggressive sustainability goals.  Only recently has there been an ability for hospitals to aggregate their medical information to aid research efforts to treat and cure chronic diseases and illnesses.  Mobius is looking to do the same for any building owner for water, as the growing concern to continued, reasonable costing fresh water becomes even greater.<br/><br/>The proposed project will provide the opportunity for the development of an IoT Smart Water Management System (SWMS). It will use artificial intelligence and machine learning to both identify leaks so they can be corrected before wasting precious water and energy, and provide predictive analytics for actionable insights. This will significantly improve water appliance maintenance and prevent costly water damage to properties. Further, at a macro level, it provides municipality level insight for maintenance and crisis management. The vision is to easily install these SWMS devices into any existing water fixture. It will take less than 60 seconds to install and connect to the Internet. The design goal is to be cost-effective from the start. The SWMS provides an affordable and easy way to adopt data driven decision making into current operations. The critical objectives set forth in this proposal are centered on achieving a simple ""smoke alarm"" like warning of a fault coupled with a robust analytics platform.  Finally, these will be designed as highly durable IoT devices that require little or no maintenance."
917170,RI: Small: Collaborative Research: Word Sense and Multilingual Subjectivity Analysis,IIS,ROBUST INTELLIGENCE,9/1/2009,8/21/2009,Rada Mihalcea,"Mihalcea, R","Mihalcea, R",TX,University of North Texas,Standard Grant,Tatiana D. Korelsky,8/31/2013,"$224,796.00 ",,mihalcea@umich.edu,1155 Union Circle #305250,DENTON,TX,762035017,9405653940,CSE,7495,"7495, 7923, 9102, 9215, HPCC",$0.00 ,normalFunding,"Approaches to subjectivity and sentiment analysis often rely on<br/>manually or automatically constructed lexicons. Most such lexicons are<br/>compiled as lists of words, rather than word meanings (""senses"").<br/>However, many words have both subjective and objective senses as well<br/>as senses of different polarities, which is a major source of<br/>ambiguity in subjectivity and sentiment analysis. The proposed work<br/>addresses this gap, by investigating novel methods for subjectivity<br/>sense labeling, and exploiting the results in sense-aware subjectivity<br/>and sentiment analysis. To achieve these goals, three research<br/>objectives are targeted. The first is developing methods for assigning<br/>subjectivity labels to word senses in a taxonomy. The second is<br/>developing contextual subjectivity disambiguation techniques to<br/>effectively make use of the word sense subjectivity annotations. The<br/>third is applying these techniques to multiple languages, including<br/>languages with fewer resources than English. The project will have<br/>broader impacts in both research and education. First, it will make<br/>subjectivity and sentiment resources and tools more widely available,<br/>in multiple languages, to the research community, which will help<br/>advance the state of the art in automatic subjectivity analysis, which<br/>in turn will benefit end applications. Second, several educational<br/>goals will be pursued: training graduate and undergraduate students in<br/>computational linguistics; augmenting artificial intelligence courses<br/>with projects based on the proposed research, which will offer<br/>students hands-on experience with natural language processing<br/>research; and reaching out to women and minorities to increase their<br/>exposure to text processing technologies and access to research<br/>opportunities.<br/>"
927921,Secure Systems Engineering Grand Challenge Problem Workshop,CNS,,10/1/2009,9/18/2009,Martha Austin,"Austin, M","Austin, M",NH,Dartmouth College,Standard Grant,carl landwehr,9/30/2010,"$224,624.00 ",,martha.f.austin@dartmouth.edu,OFFICE OF SPONSORED PROJECTS,HANOVER,NH,37551404,6036463007,CSE,I232,"9218, HPCC",$0.00 ,normalFunding,"<br/><br/>Proposal Number:  08927921<br/>PI:   Austin, Martha<br/>Institution:   Dartmouth College<br/>Proposal Title: Secure Systems Engineering Grand Challenge <br/>                       Problem Workshop<br/><br/><br/>The overall goal of this project is to run a workshop that will set the stage for a competition in secure systems design.  <br/>Drawing on the very successful DARPA Vehicle Grand Challenges, which enabled significant advances in artificial intelligence applied to autonomous vehicle control in a  setting replete with road hazards and then in a urban setting, the PI wants so set up a competition where system designs will be tested against attempts to show that they contain vulnerabilities that threaten their security.<br/>Through the workshop, new paths leading towards sustainable improvement in information assurance practices will investigated.  The primary results from the workshop will be the definition of one or more open multidisciplinary competitions to identify and demonstrate practical, effective approaches to improving the overall level of information assurance for the public and private sectors in specific application domains. <br/>Since these kind of competitions are new to the field of computer security, it is necessary to hold a workshop to energize the community and to define just what would constitute effective competitions.<br/>"
1647600,SBIR Phase I:  A Cocktail Party Technology: Real-Time Conversation Separation from Background Voices and Sounds,IIP,SMALL BUSINESS PHASE I,12/1/2016,4/13/2017,Shey-Sheen Chang,"Chang, SS","Chang, SS",CT,Yobe Inc,Standard Grant,Peter Atherton,8/31/2017,"$224,588.00 ",,sam.chang@yobeinc.com,745 Atlantic Av,Boston,CT,21110000,2032041158,ENG,5371,"5371, 8032",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is that it will for the first time make it possible to create voice technologies whose performance in speech and speaker recognition does not significantly degrade due to the presence of interfering voices or environmental sounds. This issue has kept many voice technologies out of both the mobile and IoT markets. It is expected that the company's unique artificial intelligence platform will deliver a fully scalable, real-time software solution. Solving this challenge will make the currently noisy world of smartphones more realistic for voice technologies (like voice authentication) that to date have avoided the space. <br/><br/>This Small Business Innovation Research Phase I project concerns a novel technology that is the result of innovatively combining advanced signal processing, broadcast studio methodologies, and artificial intelligence techniques to perform aggressive separation of voice from background voices and sounds. It also automatically repairs the biometrics of the separated voice signals on the basis of empirically formulated signal-dependent rules. The technology has already been demonstrated through informal tests to be significantly better than existing technologies in separating two-person conversations from highly overlapped background voices and sounds captured on a pair of closely spaced (few centimeters) omnidirectional microphones. This SBIR Phase I project seeks to firmly establish the clear superiority of this technology over any other existing voice separation technology. The ultimate goal of the project is to demonstrate that when the proposed technology is properly optimized as a frontend to state-of-the-art automatic speech recognition or state-of-the-art automatic speaker recognition, the recognition error rates in noisy multi-voice environments are comparable to those obtained in noiseless single-voice environments."
1346484,STTR Phase I: Serious Game for Energy Science,IIP,STTR PHASE I,1/1/2014,11/7/2013,Monica Trevathan,"Trevathan, M","Trevathan, M|Willis, J",TX,"Tietronix Software, Incorporated",Standard Grant,Glenn H. Larsen,12/31/2014,"$224,497.00 ",Jana Willis,Monica.Trevathan@tietronix.com,1331 Gemini Av.,Houston,TX,770582794,2814619300,ENG,1505,"1505, 8031, 8032, 8043, 9177",$0.00 ,normalFunding,"This STTR Phase I project, Serious Game for Energy Science (SGES), proposes to address the question 'Can a serious game in Science, Technology, Engineering and Math (STEM), with artificial intelligence and teacher controls, engage the learner, impact student problem-solving abilities, increase interest in STEM-related activities/fields, and positively impact student learning outcomes in science, math, and reading comprehension?' Educational institutions have seen increased demand for technologies impacting learning outcomes and promoting STEM interest. As gaming becomes more broadly accepted, there is greater demand for Serious Games - games built specifically to enhance learning. This research innovation will develop two components to be modeled in STEM serious game development: (1) artificial intelligence, and (2) instructional management tool for teachers. SGES will accomplish this innovation as well as contribute to, and advance, the body of knowledge in Serious Game development. SGES research objectives are to determine the effects of a serious game in Energy Science on students: engagement, problem-solving abilities, interest in STEM-related activities and fields, and learning outcomes in science, math, and reading comprehension. Students will be inspired to learn about energy science, energy production, and environmental impacts by being immersed in an interactive world with interesting characters and engaging story objectives.<br/><br/>The broader/commercial impact of Serious Game for Energy Science (SGES) is an expandable model adaptable to learning objectives across grades levels and content areas. This research will establish models for artificial intelligence and teacher controls in serious games, and support teaching science, math, and reading comprehension with gaming. This will impact the commercialization of serious games in any science, technology, engineering and mathematics (STEM) topic. With the increase use of serious games in learning, development of this projects' research-based model will increase the economic competitiveness of the United States in the serious games market sector. Innovative serious games like SGES can potentially increase knowledge/interest in STEM related skills/careers addressing national needs for STEM graduates in the workforce. SGES will enhance math, science, environmental literacy, and reading comprehension through student exploration of energy science, energy production, and environmental impact using problem-solving, critical thinking, communication, and collaboration skills. The project research results will impact the number of students entering STEM related careers or graduating with STEM degrees by engaging them through game play. The SGES project aims to improve STEM education for all grade levels and improve educator development by providing educators with an effective use of technology in the classroom."
113618,ITR/AP (CISE) Collaborative Research: Best-First Search Algorithms for Sequence Alignment Problems in Computational Biology,IIS,ITR SMALL GRANTS,10/1/2001,9/21/2001,Weixiong Zhang,"Zhang, W","Zhang, W|Stormo, G",MO,Washington University,Standard Grant,frank olken,9/30/2006,"$224,039.00 ",Gary Stormo,zhang@cse.wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,CSE,1686,"1655, 9218, HPCC",$0.00 ,normalFunding,"Abstract<br/>Zhang 0113618<br/>Korf 0113313<br/><br/>Best-First Search Algorithms for Sequence Alignment Problems in Computational<br/>Biology<br/><br/>Molecular biologists are currently faced with very challenging computational problems.  For example, a draft of the human genome has been completed, a sequence of about three billion base pairs.  A draft of the mouse genome soon will be completed.  We know that mice and men share over 90% of their genetic material.  What we don't know is exactly which parts of the human and mouse genomes are common to both species.  This information can be used to identify human genes, and to translate results from mouse studies to studies of human health and disease.  The problem of identifying the common elements between these two DNA sequences is an example of sequence alignment, which is a computational problem.  Other examples of sequence alignment problems include gene identification, and RNA and protean structure prediction.  Current computer algorithms are either too slow, or require too much memory, to directly solve a problem as large as the human-mouse genomic sequence alignment.  We propose to develop new algorithms for various sequence-alignment problems, based on heuristic search algorithms in artificial intelligence.  Our goal is to provide much more efficient sequence-alignment algorithms for use by molecular biologists.<br/><br/>"
113313,ITR/AP (CISE) Collaborative Research: Best-First Search Algorithms for Sequence Alignment Problems in Computational Biology,IIS,ITR SMALL GRANTS,10/1/2001,9/21/2001,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Standard Grant,Sylvia J. Spengler,9/30/2005,"$224,000.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,1686,"1655, 1686, 9218, HPCC",$0.00 ,normalFunding,"Abstract<br/>Zhang 0113618<br/>Korf 0113313<br/><br/>Best-First Search Algorithms for Sequence Alignment Problems in Computational<br/>Biology<br/><br/>Molecular biologists are currently faced with very challenging computational problems.  For example, a draft of the human genome has been completed, a sequence of about three billion base pairs.  A draft of the mouse genome soon will be completed.  We know that mice and men share over 90% of their genetic material.  What we don't know is exactly which parts of the human and mouse genomes are common to both species.  This information can be used to identify human genes, and to translate results from mouse studies to studies of human health and disease.  The problem of identifying the common elements between these two DNA sequences is an example of sequence alignment, which is a computational problem.  Other examples of sequence alignment problems include gene identification, and RNA and protean structure prediction.  Current computer algorithms are either too slow, or require too much memory, to directly solve a problem as large as the human-mouse genomic sequence alignment.  We propose to develop new algorithms for various sequence-alignment problems, based on heuristic search algorithms in artificial intelligence.  Our goal is to provide much more efficient sequence-alignment algorithms for use by molecular biologists.<br/><br/><br/>"
9977981,Effective Planning Using Compact Problem Representations,IIS,"HUMAN COMPUTER INTER PROGRAM, ARTIFICIAL INTELL & COGNIT SCI",10/1/1999,7/12/2001,Robert Givan,"Givan, R","Givan, R",IN,Purdue Research Foundation,Continuing grant,William Bainbridge,9/30/2002,"$223,437.00 ",,givan@purdue.edu,,West Lafayette,IN,47907,3174946200,CSE,"6845, 6856","9216, HPCC",$0.00 ,normalFunding,"<br/>IIS-9977981<br/>Robert L. Givan<br/>Purdue University<br/>$77,529 - 12 mos<br/><br/><br/>Effective Planning Using Compact Problem Representations<br/><br/><br/>This is the first year funding of a three year continuing award. This project examines new techniques for solving very large planning problems in stochastic domains.  In many realistic domains, where the effects of actions cannot be deterministically given, Markov Decision Processes (MDPs) are a natural formal representation.  Many important problems in both industrial applications (e.g., Federal Express package routing) and cognitive modeling (e.g., problem-solving in uncertain domains, route finding, naive human planning) are naturally represented using the MDP formalism.   The operations research literature has provided effective methods for solving problems represented as MDPs for domains in which the number of possible states of the system is relatively small (less than 100,000 or so).  However, most industrial and artificial intelligence domains do not meet this restriction.  Recent AI research has shown that it is possible to exploit propositional structure in the state space in order to compactly represent and solve larger MDPs than was previously possible.   Traditional AI planning research has concentrated on deterministic planning domains, and has relied heavily on compact, logical representations for such domains.  This project aims to apply many of the lessons learned in deterministic planning to the stochastic setting by designing new compact representations for MDP problems while retaining the effectiveness of traditional MDP solution techniques.  Use of such representations would allow the description and effective solution of much larger MDP problems than is currently possible, resulting in the automated near-optimal solution of many practical planning and optimization tasks that currently require heuristic solution by hand<br/>"
1658042,Collaborative Research: Combining models and observations to constrain the marine iron cycle,OCE,CHEMICAL OCEANOGRAPHY,7/1/2017,3/3/2017,Thomas Weber,"Weber, T","Weber, T",NY,University of Rochester,Standard Grant,Simone Metz,6/30/2020,"$221,390.00 ",,t.weber@rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,GEO,1670,,$0.00 ,normalFunding,"Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
1627906,Bounded Cognition in Decision-Making,SES,ECONOMICS,7/1/2016,7/7/2016,Jawwad Noor,"Noor, J","Noor, J",MA,Trustees of Boston University,Standard Grant,Kwabena Gyimah-Brempong,6/30/2018,"$219,723.00 ",,jnoor@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,SBE,1320,,$0.00 ,normalFunding,"At the heart of decision-making lie cognitive processes through which an understanding of the decision context is acquired and decision-relevant evaluations made. These processes can be cognitively costly and in particular may be bounded by limited cognitive resources. The PIs propose to analyze the behavior that might arise from such bounded cognition and to subsequently construct choice models. This would provide a path for possible applications of cognitive science in economics. Cognitive science is a multi-disciplinary field spanning psychology, neuroscience, artificial intelligence, linguistics, etc. and the proposal is a step in the direction of exploring the richness of its possible connections with economics.<br/><br/><br/>    As a first step, the PIs propose to study an agent in an intertemporal choice context who evaluates any given consumption stream by drawing on limited cognitive resources to think about the consequences of the stream for his future selves. They posit that the optimality of the use of cognitive resources should be reflected behaviorally in greater patience when dealing with larger stakes. Moreover, the existence of capacity constraints should lead to non-separabilities in the evaluation of consumption streams. They will proceed to find a utility representation for such behaviors that is interpretable in terms of bounded cognition. The project makes use of the approach of axiomatic decision theory."
2918,Industry/University Cooperative Research Center for Power System Engineering Research Center (PSerc),IIP,"INDUSTRY/UNIV COOP RES CENTERS, ",5/1/2001,3/3/2006,Marcelo Simoes,"Simoes, M","Simoes, M",CO,Colorado School of Mines,Continuing grant,Rathindra DasGupta,4/30/2007,"$219,204.00 ",,msimoes@mines.edu,1500 Illinois,Golden,CO,804011887,3032733000,ENG,"5761, W242","0000, 9139, 9178, 9231, 9251, HPCC, OTHR, SMET",$0.00 ,normalFunding,"EEC-0002918<br/>Shoureshi<br/><br/><br/>The goal of the Pserc Center at the Colorado School of Mines will be to integrate advances from power systems, control theory, artificial intelligence, diagnostics, new sensor-technologies, etc. to assist the electric utility industry in facing these new challenges.<br/><br/>The research, which is complementary to those of the other Pserc sites, will focus on the following topics:<br/><br/>Development of Intelligent Substation; Advanced Power Generation Control with Integrated Economics, Variable Demands and Short-Term Load Forecast; Development of Advanced Sensors and Sensory Feedback Systems for Increased Reliability and Lower Maintenance Cost; Predictive Maintenance for Reduction of Operating Cost; Development of Remote Health Assessment Techniques T&D; and EMAT Based Diagnostics of Overhead Transmission Lines.<br/>"
9421326,Perceptual Representations in Conceptual Tasks,BCS,HUMAN COGNITION & PERCEPTION,2/1/1995,11/18/1996,Lawrence Barsalou,"Barsalou, L","Barsalou, L",IL,University of Chicago,Continuing grant,Jasmine V. Young,1/31/1998,"$218,759.00 ",,barsalou@emory.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,SBE,1180,"0000, 1092, 9178, 9251, OTHR, SMET",$0.00 ,normalFunding,"The aim of the proposed work is to determine whether perceptual representations enter significantly into conceptual processing.  Subjects will perform conceptual tasks that have traditionally been explained with propositional, non-perceptual theories of knowledge, e.g., feature listing (what features are typically true of a chair) and property verification (e.g., does a chair have a seat).  Of interest will be whether subjects use perceptual representations in these tasks, even though the task contexts do not require or demand that they do.  The use of perceptual representations will be detected in two ways:  instructional equivalence and perceptual work.  Instructional equivalence occurs when subjects who receive no imagery instructions (`neutral subjects`) perform similarly to subjects explicitly asked to use imagery (`imagery subjects`).  Perceptual work occurs when performance of both neutral and imagery subjects is affected by perceptual variables.  Initial experiments on feature listing and property verification provide strong evidence for both instructional equivalence and perceptual work, indicating that neutral subjects use perceptual representations.  Further studies will replicate and extend these findings.  For feature listing, various experiments examine the roles of perceptual representations in conceptual combination, event concepts, abstract concepts, gesture, and production modes.  For property verification, various experiments use distractor relatedness, preparation time, part expectancy, and perspective to examine the role of perceptual representations.  In an additional project on modality-specific interference, several experiments test the prediction that perceptual representations of conceptual knowledge should produce specific patterns of attentional interference.  Should these projects provide evidence that perceptual representations play central roles in conceptual processing, theories of cognition and intelligence would require significant reformulation.  Most existing theories assume that intelligent behavior reflects the processing of an abstract, amodal, and arbitrary language of thought, much like the symbolic computer languages used widely in electronic computation.  According to existing theories, perceptual experience is transduced into a set of conceptual symbols that bear no perceptual resemblance to their referential origins.  An alternative, and much less explored view, is that conceptual symbols are fragments of perceptual states, extracted directly from these states via selective attention.  The resulting conceptual representations are not static holistic 'pictures in the head,' but instead are systems of perceptual symbols that combine productively to produce infinite conceptual structures.  Additionally, these perceptual symbols are analytic, schematic, multimodal, and dynamic, offering a rich expressive system for representing a wide variety of concepts, not just those for concrete objects.  Intuitively, such perceptual symbol systems resemble modern multimedia computing much more than traditional non-analogue computing. Evidence continuing to indicate the presence of a perceptual symbolic system in humans, has strong implications for understanding and applying intelligence as well as theories of the brain's operation and visions of artificial intelligence.  Rather than viewing intelligence as the manipulation of arbitrary amodal symbols, it would come to be viewed as arising from a productive system of perceptual symbols."
9421098,Deductive Composition of Software from Component Libaries,CCF,SOFTWARE ENGINEERING AND LANGU,4/15/1995,6/13/1997,Richard Waldinger,"Waldinger, R","Waldinger, R",CA,SRI International,Continuing grant,Frank D. Anger,3/31/1998,"$218,139.00 ",,waldinger@ai.sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,CSE,2880,"9216, HPCC",$0.00 ,normalFunding,"This award supports research in deductive methods, applied to automate the synthesis of software built from component libraries. Software is constructed from relatively large-scale components, rather than from the primitive instructions of a programming language. Theorem-proving techniques are invoked to identify the relevant components and to compose them to solve the problem at hand. The goal is to put computing power in the hands of a broader segment of the population and to increase the productivity and accuracy of the expert practitioner. The software is constructed to meet specifications expressed in a logical or graphical notation. Specifications are elicited from the user via a dialog with a graphical user interface. The specification is phrased as a mathematical theorem, which is proved by an automatic deduction system. The proof is conducted in an application domain theory, which describes the components in the software library, the constructs of the specification language, and the background knowledge necessary to glue the components together to meet the specification. The theorem is proved by the automatic deduction system Snark, which has been implemented for applications in software engineering and artificial intelligence. A program that meets the original specification is extracted from the proof and translated into the desired target language. Software is produced with high assurance of correctness---it is verified by the proof from which it is extracted. This research is expected to make subroutine libraries, component libraries, and software reuse libraries accessible to users who are largely ignorant of the contents of the libraries, their conventions and terminology, or even the target programming language."
855707,Computing Equilibria for Large Sequential Games,CMMI,OPERATIONS RESEARCH,8/1/2009,7/15/2009,Javier Pena,"Pena, J","Pena, J",PA,Carnegie-Mellon University,Standard Grant,Sheldon Jacobson,7/31/2012,"$215,664.00 ",,jfp@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,ENG,5514,"073E, 9147, MANU, 6890","$215,664.00 ",normalFunding,"This award is funded under the American Recovery and Reinvestment Act of 2009. <br/><br/>A sequential game is a mathematical model of the interaction of multiple self-interested players in dynamic stochastic environments with limited information. The long-term goal of this research project is to design and implement specialized algorithmic tools for the computation of the main solution concept for these games, namely Nash equilibria. The initial phase of the project will concentrate on two-person zero-sum sequential games. The Nash equilibria formulation for this special class of sequential games can be stated as a highly structured saddle-point problem and is amenable to modern smoothing and interior-point techniques for convex optimization. Advanced phases of the project will tackle the more challenging problems of computing equilibria for games with more than two players as well as refinements of Nash equilibria such as sequential, perfect and quasi-perfect equilibria.<br/><br/>The algorithmic advances of this research project have immediate application in the design of automatic game players, which is a topic of major interest in artificial intelligence. At a more fundamental level, the availability of algorithmic technology for equilibria computation will provide new tools for rational decision making in complex dynamic environments such as those encountered in financial markets, multi-user computing networks, political negotiations, and military operations."
9511270,Constraint Use In Language Comprehension,BCS,"HUMAN COGNITION & PERCEPTION, LINGUISTICS",9/1/1995,6/8/1998,Maryellen MacDonald,"MacDonald, M","MacDonald, M",CA,University of Southern California,Standard Grant,Catherine N. Ball,8/31/1999,"$215,000.00 ",,mcmacdonald@wisc.edu,University Park,Los Angeles,CA,900890001,2137407762,SBE,"1180, 1311","9178, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"     This research is designed to investigate syntactic ambiguity  resolution in normal, adult language comprehension. The study of  ambiguity resolution can illuminate the architecture of the  language comprehension system and can evaluate the  psycholinguistic and linguistic theories concerning the nature of  linguistic mental representations.       The theoretical framework of the investigation is a lexical,  ""constraint-based"" framework in which syntactic ambiguity is seen  as a type of lexical ambiguity, such that syntactic ambiguity  resolution has the same properties as the resolution of lexical  semantic ambiguities. This approach has been applied profitably  to the analysis of several ""classic"" syntactic ambiguities in  English that had previously been taken as evidence for a  radically different processing architecture.        The experiments use self-paced reading methods and eye  fixation monitoring to study ambiguity resolution and constraint  use. A large amount of normative data is also collected  concerning the strength of the constraints, and regression  methods are used to determine the extent to which difference  constraints affect comprehenders' interpretations at different  points in time.       The research is significant in that it advances a unified  account of language comprehension in which representation at all  levels (phonological, lexical, syntactic, discourse, etc.) are  governed by the same basic properties, including frequency  sensitivity and activation of representations via constraint  satisfaction. A unified account of language representation  affects not only theories of human language use, but also work in  artificial intelligence, which to date has generally reflected  the more traditional theories of human language comprehension.  Our understanding in the unified approach of human ambiguity  resolution could therefore have substantial impact on computer  natural language comprehension research, particularly the very  difficult problem of ambiguity resolut ion in these systems."
1724753,Inductive learning of nonlocal phonological interactions,BCS,LINGUISTICS,8/1/2017,8/8/2017,Gillian Gallagher,"Gallagher, G","Gallagher, G|Gouskova, M",NY,New York University,Standard Grant,William J. Badecker,1/31/2021,"$214,541.00 ",Maria Gouskova,geg4@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,SBE,1311,"1311, 9179",$0.00 ,normalFunding,"Language is a fundamental and universal aspect of human cognition. Linguistic research over the past five decades has established that language structure is governed by detailed rules. These rules constrain meanings, sentences, words, and sound patterns--the focus of the proposed research. For many years, sound structure was investigated primarily by theorizing. More recently, linguists have begun to test these theories using experiments and computational models. Computational models are valuable because they can only be created based on a complete and explicit understanding of the underlying rules. If the model succeeds in learning human-like rules when given the same data that is available to human learners, then it can shed some light on the rules that constitute the human knowledge of language and how humans learn these rules. In addition to helping scientists understand the human mind, computational models and the datasets they use are invaluable in developing applied computational tools for machine language translation, language identification, and artificial intelligence.<br/><br/>The rules that govern sound patterns differ in nuanced ways between languages, and they can be divided into two kinds. First, all languages have rules that restrict how sounds interact with sounds that immediately precede or follow them: for example, in English, words can begin in ""pr"" but not ""pn"", whereas in Greek, words can begin in either sequence. But some languages also have rules that restrict the interactions of sounds that are not adjacent (nonlocal). Languages such as Hungarian and Turkish have vowel harmony, which means that all the vowels in a word tend to share certain features of their pronunciation. Navajo (Southwestern United States) has consonant harmony--consonants have to match in certain features. In languages such as Quechua (spoken in South America) and Amharic (Africa), certain features of consonants have to mismatch. Linguists have known about these patterns for a long time, and there are many theories of how they are cognitively represented. But these nonlocal rules continue to stymie computational models, because in order to notice them, the computer has to consider many more possibilities than it would for rules on adjacent sounds. This is similar to how much more difficult it is for a computer to crack a password the longer it gets. The proposed research builds a computational model of nonlocal rules that identifies certain clues to their existence in a language. The project will compile corpora to test the model's ability to find nonlocal rules (Quechua, Shona, Hungarian, Russian, Aymara, Sundanese). The model's performance will be compared with experiments with native speakers of several languages. The model, the corpora, and the experimental data will be made freely available to the scientific community and the public. Workshops will disseminate the research in Bolivia. The project will provide training for students in computational analysis and corpus building."
301993,Simulation and Function Approximation Based Iterative Approach To Process Control,CBET,"Proc Sys, Reac Eng & Mol Therm",4/15/2003,4/9/2003,Jay Lee,"Lee, J","Lee, J",GA,Georgia Tech Research Corporation,Standard Grant,Maria Burka,3/31/2007,"$214,247.00 ",,jay.lee@chbe.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,ENG,1403,"0000, OTHR",$0.00 ,normalFunding,"Research:<br/><br/>The PI plans to investigate a simulation and function approximation-based strategy for bringing an evolutionary improvement to a control policy. The investigation is motivated by some inherent limitations of the current model-based predictive control formulation with respect to handling systems of large-scale complex dynamics, and large amount of uncertainty. The development will be rooted in an approach developed in the field of artificial intelligence - referred to by various names such as Neuro-Dynamic Programming and Reinforced Learning - which has shown great success in handling highly complex multi-stage discrete decision problems like backgammon playing, elevator dispatch problem, and job-shop scheduling. The approach, when extrapolated to the problem of process control, begins by performing closed-loop simulations with a given suboptimal control policy for an extensive set of possible operating conditions. The simulation results are then used to generate data for state versus ""cost-to-go"" or ""reward"" function, typically by fitting a neural network to the data. The approximation is improved by additional off-line calculations, either by ""value iteration"" based on iterating the Bellman Equation or by ""policy iteration"" based on iterating between policy evaluation and policy improvement. The improved approximation of the ""cost-to-go"" function can be used to implement optimal control in a computationally efficient way, either by reducing a large-horizon problem into an equivalent short-horizon problem or by allowing an off-line parameterization of the improved control law. <br/><br/>To make the approach practicable for process control a number of issues need to be resolved. The success of the approach will depend on the ability to obtain an accurate and robust approximation of the cost-to-go function. An immediate question to ask is what types of function approximators are best suited for the approximation. Also, the level of confidence in the neural network's cost predictions through interpolation and extrapolation need to be taken into account in the control calculations. The PI plans to investigate these and other fundamental issues to arrive at systematic and practically useful answers. The PI will collaborate with industrial partners Weyerhauser, Owens Corning, LG Chemicals, and Aspen Technology, to test the developed tools on real industrial process and to incorporate them into commercial process control software packages. The application portion of the project will be carried out by students and visitors supported by these companies.<br/><br/>Broader Impact:<br/><br/>The Chemical Process Industries (CPI) are replete with nonlinear control problems involving significant uncertainties, which can benefit from this work. In addition to process control, the strategy fits naturally to planning and scheduling problems under uncertainty as well as supply chain operation problems."
9357731,NSF Young Investigator,IIS,HUMAN COMPUTER INTER PROGRAM,8/1/1993,7/11/1996,Bonnie Dorr,"Dorr, B","Dorr, B",MD,University of Maryland College Park,Continuing grant,Gary W Strong,1/31/1998,"$212,500.00 ",,bdorr@ihmc.us,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,6845,"0000, 9216, 9218, 9297, HPCC, OTHR",$0.00 ,normalFunding,"9357731 Stein NYI - Embodiment Informs Cognition (Supplement) This is a supplement to the above mentioned NYI award for the purpose of holding a small workshop to cover the cost of participation of a small number of college and university faculty members involved in teaching introductory AI courses. This supplement addresses the desire to provide improved educational and research opportunities to bridge the gap between the capacities of current artificially intelligent agents and human-like cognitive abilities, both issues to be discussed from a point of view of classical undergraduate or first year graduate AI education, indicating how a symbolic (linguistic) approach evolves from the interpretation of arbitrary signals in terms of the human experiences. The goals of the workshop consist of providing information exchange relating to the nature of the introductory course, and addressing new curricula issues and questions including the one related to the Stein award mentioned above, but others as well such as the use and selection of instructional programming tools, and other software repository issues related to Artificial Intelligence education. A report or publication is part of the results of the workshop."
1550179,CAREER: New Directions for Metric Learning,IIS,ROBUST INTELLIGENCE,1/7/2015,9/22/2015,Kilian Weinberger,"Weinberger, K","Weinberger, K",NY,Cornell University,Continuing grant,Weng-keen Wong,2/28/2018,"$211,313.00 ",,kilianweinberger@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7495,"1045, 7495",$0.00 ,normalFunding,"Quantifying similarity is a fundamental challenge in artificial intelligence and machine learning which - if performed perfectly - would reduce many tasks to a trivial nearest neighbor search. For example, determining whether an email were spam would be as simple as searching a labeled database of emails and assigning it the same label (spam or not) as the email considered most similar to it. But how can one measure the similarity of two email messages? Does the same measurement still apply when comparing medical images? How does our understanding of similarity depend on the problem specification? Metric learning optimizes distance functions specifically for a given task, taking into account both the learning problem and the data. Initial successes with linear metrics show great improvements on many ""k-nearest neighbors""-based learning tasks. <br/><br/>This project pursues four research directions that strengthen the theoretical understanding of metric learning within the research community, broaden its impact and significantly improve the current state-of-the-art: <br/><br/>1. Are there non-linear transformations that lead to equally elegant and efficient optimization problems as existing linear metrics? As data sets grow and become increasingly complex, linear metrics are no longer sufficient to capture similarity relations. By exploring the use of non-linear metrics, this research can substantially improve the impact of metric learning and the accuracy of similarity relations. <br/><br/>2. Can the impact of metric learning be extended to machine learning frameworks beyond nearest neighbors? Designing new metric learning algorithms that explicitly optimize distances for a broad variety of machine learning algorithms will significantly increase the number of applications and learning methods that can directly benefit from metric learning. <br/><br/>3. Can metrics be learned from weak supervision? Removing the dependency on labeled data will reduce the cost of metric learning and increase its applicability. <br/><br/>4. Can one develop a solid theoretical framework to explain preliminary empirical successes and to direct future research? This will strengthen the theoretical understanding of metric learning within the research community. <br/><br/>Successful resolution of the proposed problems will lead to novel learning methods which will be immediately applicable to ongoing high-impact medical research collaborations of the principal investigator. In conjunction with these research directions, the principal investigator will also pursue educational goals, including the co-development of a K-12 curriculum module estimated to impact 2,500 high-school students. Many topics in the proposed research plan have components ideal for introducing the research process to undergraduate and graduate students, and the principal investigator plans to use his research as a vehicle to instruct and inspire future computer scientists and next-generation researchers."
1734082,D3SC and EAGER: Using Deep Learning to Find Algorithms for Optimizing Chemical Reactions,CHE,"Chem Struct,Dynmcs&Mechansms B",9/1/2017,6/9/2017,Richard Zare,"Zare, R","Zare, R",CA,Stanford University,Standard Grant,Tingyu Li,8/31/2019,"$209,734.00 ",,zare@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,MPS,9102,"7433, 7916, 8084",$0.00 ,normalFunding,"With support from the Chemical Structure, Dynamics and Mechanisms - B Program in the Division of Chemistry and in response to the Data-Driven Discovery Science in Chemistry (D3SC) Dear Colleague Letter, Professor Richard N. Zare at Stanford University is working on optimizing chemical reactions in microdroplets with deep reinforcement learning.  Unoptimized reactions are expensive because they waste time and reagents.  A common way for chemists to explore reaction optimization is to change one variable at a time while all other variables remain fixed. This method, however, might not find the best conditions, that is the global optimum.  Another way is to search across all combinations of reaction conditions by using batch chemistry. This approach gives a better chance to find the global optimal condition, but it is time-consuming and expensive. Deep reinforcement learning is believed to be a superior approach in which the computer analyzes a large data set and recognizes the pattern of features that lead to best reaction outcomes.  It is like training a dog: suppose we want the dog to pick up a ball.  If the dog does what we want, we say ""Good dog!""; if it does not, we say ""Bad dog!"". Similarly, Professor Zare uses a machine learning method to give the system a positive reward if the reaction reaches a better result than previous ones, or a negative reward if it does not.  A repeated process will eventually result in a set of best reaction conditions for certain reactions.  Professor Zare and his group apply this approach to microdroplet chemistry, where many reactions can be carried out in small droplets and be accelerated by factors of one thousand to one million compared with the same reaction happening in bulk solution. Combining the efficient deep reinforcement learning method with accelerated microdroplet reactions, Professor Zare and his group are seeking to find optimal reaction conditions in a fast way.  This combined approach can represent a significant step for enabling artificial intelligence to be used to optimize chemical reactions, which should have benefits in chemical production, drug screening, and materials discovery.  The students in the Zare group enjoy the unique opportunity to experience micro-droplet chemical synthesis, fast chemical characterization, and deep learning-based complex data analysis.<br/><br/>A reaction can be thought of as a system having multiple inputs (parameters) and providing one or more outputs. Example inputs include: temperature; solvent composition; pH; catalyst; droplet size; and time. Example outputs include: product yield; selectivity; purity; and cost. The goal of reaction optimization described here is to select the best inputs to achieve a given output, which can be formulated as a reinforcement learning system. In order to find the optimal reaction conditions, Professor Zare is searching for critical reaction condition to try at the next step based on previous reaction conditions and product yields. A recurrent neural network is used to model the policy for reaction optimization. The reinforcement learning system is trained on mock reactions (random functions) and then real reactions for better performance.  The approach, if successful, could help better understanding of fundamental features of reactivity and enable important industrial applications."
9703307,CAREER/EPSCoR:  Cooperative Agents for Conceptual           Search and Browsing of World Wide Web Resources,IIS,"DIGITAL SOCIETY&TECHNOLOGIES, INFORMATION & KNOWLEDGE MANAGE, EPSCoR Co-Funding",8/15/1997,8/6/2001,Susan Gauch,"Gauch, S","Gauch, S",KS,University of Kansas Center for Research Inc,Continuing grant,Maria Zemankova,7/31/2002,"$208,095.00 ",,segauch@gmail.com,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,CSE,"6850, 6855, 9150","1045, 9139, 9150, 9178, 9251, HPCC, SMET",$0.00 ,normalFunding,"The goals of this project are four-fold: (1) to investigate ways to support distributed searching agents for the Web; (2) to evaluate the effectiveness of ontology-based Web browsing agents; (3) to study the use of of visualization agents for the Web; and (4) to keep a record of changes to the ontology to study how information changes on the Web. This approach has the following advantages: First, distributing the search process makes more equitable use of computing and network resources and allows search agents to be customized to reflect local interests and preferences. Second, an ontology-based browsing agent allows for more serendipitous access to Web resources. Unlike the current browsing structures (e.g., Yahoo), these browsing agents associate appropriate resources with each concept automatically. The ontology may adapt over time at individual sites, allowing the browsing structure to evolve as the Web itself evolves. Third, the ability to visualize large portions of the Web in a more abstract way allows users to quickly get an impression of what type of information is available. Fourth, by keeping a history of changes to the local ontologies, the ebb and flow of the importance of concepts locally and globally can be presented. Finally, undergraduate and graduate students are being exposed to a truly interdisciplinary research through their involvement in a long term project that combines expertise from several fields, primarily computer graphics, artificial intelligence, distributed processing and information science. The World Wide Web (WWW) offers the promise of unlimited access to electronic information. However currently, the reality is electronic access to unlimited anarchy. This project is addressing the use of conceptual ontologies to bring order to the chaos."
9908435,"Collaborative Research:  Constraint Satisfaction, Database Query Evaluation, and Information Integration",IIS,INFORMATION & KNOWLEDGE MANAGE,10/1/2000,7/11/2002,Moshe Vardi,"Vardi, M","Vardi, M",TX,William Marsh Rice University,Continuing grant,Gia-Loi Le Gruenwald,9/30/2005,"$208,083.00 ",,vardi@rice.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,CSE,6855,"9216, HPCC",$0.00 ,normalFunding,"This interdisciplinary research is carried out in a collaboration between Professors Phokion Kolaitis at the University of California, Santa Cruz and Moshe Vardi at Rice University. Constraint satisfaction and conjunctive query evaluation are two fundamental and ubiquitous problems in artificial intelligence and database systems, respectively. Since these problems are known to be computationally intractable in the worst case, researchers in artificial intelligence and database systems have sought to discover tractable cases of constraint satisfaction and conjunctive query evaluation, as well as to design heuristic algorithms for solving these problems. Thus far, however, these studies have been largely carried out in parallel and with relatively little or no interaction between the two areas. Recent research work has established that there are strong and exact connections between constraint satisfaction and conjunctive query evaluation. The main goal of this project is to further explore the connections between constraint satisfaction and conjunctive query evaluation, and to examine the applicability of techniques developed for each of these problems to the other problem. To this effect, a novel game-theoretic framework is being developed to unify seemingly unrelated results, identify additional tractable cases of these two problems, and design heuristics for the general case. Moreover, algorithms and heuristics developed by the artificial intelligence community are being evaluated in regards to their efficacy in conjunctive query evaluation, and vice versa. Results obtained in the course of this project will enhance the interaction between artificial intelligence and database systems, and will advance knowledge transfer between these two areas."
1651565,CAREER: Modeling and Inference for Large Scale Spatio-Temporal Data,IIS,ROBUST INTELLIGENCE,3/15/2017,2/13/2018,Stefano Ermon,"Ermon, S","Ermon, S",CA,Stanford University,Continuing grant,Kenneth C. Whang,2/28/2022,"$207,034.00 ",,ermon@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7495,"1045, 7495",$0.00 ,normalFunding,"Key sustainability challenges, such as poverty mitigation, climate change, and food security, involve global phenomena that are unique in scale and complexity. Our global sensing capabilities - from remote sensing to crowdsourcing - are becoming increasingly economical and accurate. These recent technological developments are creating new spatio-temporal data streams that contain a wealth of information relevant to sustainable development goals. Actionable insights, however, cannot be easily extracted because the sheer size and unstructured nature of the data preclude traditional analysis techniques. This five-year career-development plan is an integrated research, education, and outreach program focused on developing new AI techniques to extract actionable insights from large-scale spatio-temporal data. These techniques have the potential to yield accurate, inexpensive, and highly scalable models to inform research and policy.<br/><br/>The research goal of this project is to develop new modeling and algorithmic frameworks to help address global sustainability challenges involving spatio-temporal data. This research will develop new predictive models of complex spatio-temporal phenomena integrating in unique ways ideas from graphical models and representation learning, improving their overall performance. New approaches to learn from unlabeled data exploiting various forms of prior domain knowledge, including spatio-temporal dependencies and relationships between different data modalities, will be developed. To learn models and make predictions at scale, this project will also develop new scalable probabilistic inference methods based on the use of random projections to reduce the dimensionality of probabilistic models while preserving their key properties. The techniques developed will be made available to both academia and industry through open-source software, and will enable computationally feasible approaches for analyzing large spatio-temporal datasets and for modeling global scale phenomena. Predictions and data products produced by this project will enable new analyses and advance sustainability disciplines. Results will be disseminated widely through scientific articles, research seminars, and conference presentations to maximize the benefits to the scientific community. Educational and outreach efforts will include the involvement of undergraduate students undertaking independent research projects, a website describing research bridging computation and, and a summer outreach program aimed at introducing under-represented high-school students to computer science and artificial intelligence."
1120578,RUI: MPS-BIO: Collaborative Research: Design and Construction of Second-Generation Bacterial Computers,MCB,"CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY, Systems and Synthetic Biology",9/15/2011,2/27/2013,A. Malcolm Campbell,"Campbell, AM","Campbell, AM|Heyer, L",NC,Davidson College,Standard Grant,Susanne von Bodman,8/31/2014,"$206,559.00 ",Laurie Heyer,macampbell@davidson.edu,Box 7149,Davidson,NC,280357149,7048942644,BIO,"7275, 7334, 7454, 8011","1228, 7744, 8007, 9178, 9183, 9229",$0.00 ,normalFunding,"Bacteria can be modified, through synthetic biology approaches, to function as biological computers. They can be programmed with DNA sequences, interact naturally with other cells and the environment, power themselves from food sources, and respond to directed evolution. Biological computing is not yet widespread, and this project will develop second-generation bacterial computers capable of addressing mathematical problems in graph theory, probability, theory of computation, and artificial intelligence. The project will identify problems that are scalable and generalizable, develop a system of classifying the bacterial computational complexity of mathematical problems, and construct mathematical models and computer simulations to assess the design feasibility of new bacterial computer programming languages. Proven and novel bacterial computing mechanisms will be used to program bacterial computers to solve the selected mathematical problems. <br/><br/>Broader Impacts. This project will provide multidisciplinary education and research training for undergraduate students (including members of groups under-represented in science) at the interface of mathematics, synthetic biology and computer science. Students will pose research questions, develop testable hypotheses, collect and analyze data, and communicate results through publications and at scientific meetings. <br/><br/>This project is supported jointly by the Networks and Regulation and Mathematical Biology Programs."
9977969,Developing and testing a computer tool that critiques survey questions,SES,"ECONOMICS, SOCIOLOGY, METHOD, MEASURE & STATS",1/1/2000,9/27/1999,Arthur Graesser,"Graesser, A","Graesser, A",TN,University of Memphis,Standard Grant,Cheryl L. Eavey,12/31/2003,"$205,990.00 ",,a-graesser@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,SBE,"1320, 1331, 1333","0000, 1614, OTHR",$0.00 ,normalFunding,"The validity and reliability of answers to questions on a survey critically depend on whether the respondents understand the meaning of the questions.  This project develops and tests a computer tool that assists survey designers in improving the comprehensibility of questions.  The computer tool will have particular modules that diagnose each question in a survey on various levels of language, discourse, and world knowledge.  For example, the critique identifies questions with low frequency words, vague or ambiguous terms, unclear relative terms, complex syntax, high working memory load, misleading presuppositions, and content that appears to be unrelated to the survey context.  The computer tool will incorporate empirical findings and computational architectures in the fields of cognitive science, artificial intelligence, computational linguistics, discourse processing, and psychology.  Some of these modules are so complex, technical, or subtle that they are invisible to the unassisted human eye, including experts in survey methodology, questionnaire design, and computational linguistics.  This motivates the need for a computer tool to assist the research methodologist in revising questions and in learning about the complex mechanisms that underlie each component.<br/><br/>The computer tool will be useful to the extent that it provides an accurate and reliable diagnosis of problematic questions.  The project will therefore evaluate the performance of the computer tool on several measures.  Each module determines whether or not a particular question has a problem (e.g., unfamiliar technical term, working memory overload).  These decisions will be compared with the decisions of experts.  Other performance measures are needed because trained expert judges may miss subtle computational mechanisms.  These other measures will assess whether the computer output can predict the behavior of respondents when they answer the questions: (a) behaviors of respondents that indicate they are having difficulty comprehending the question in a conversational interview (such as clarification questions of respondents) and (b) test-retest reliability of answers to questions when respondents answer a question on multiple occasions.  Performance measures also will be compared for original questions, questions revised by survey methodologists who do not use the computer tool, and questions revised by survey methodologists who have had the benefit of using the tool. This research is supported by the Methodology, Measurement, and Statistics Program and a consortium of federal statistical agencies under the Research on Survey Methodology Funding Opportunity.<br/><br/><br/>"
650074,CAREER:     Statistical Methods for Dimensionality Reduction in Machine Learning,IIS,"ARTIFICIAL INTELL & COGNIT SCI, ROBUST INTELLIGENCE, Science of Learning Activities",6/30/2006,8/18/2008,Lawrence Saul,"Saul, L","Saul, L",CA,University of California-San Diego,Continuing grant,Sven G. Koenig,6/30/2010,"$205,072.00 ",,saul@cs.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,"6856, 7495, 7704","1045, 1187, 9215, 9218, HPCC",$0.00 ,normalFunding,"This research addresses the problem of dimensionality reduction, discovering low dimensional structure hidden in high dimensional data.  It arises in many fields of information processing, and poses a particular challenge to researchers attempting to build machines that emulate feats of human perception, such as recognizing faces and understanding speech. It also plays an increasingly prominent role in many applications of statistical and scientific computing. With the advent of widespread information technologies, it has become possible to collect and manipulate ever-increasing amounts of experimental data. Thus, scientists interested in the exploratory analysis and visualization of large multivariate data sets face similar challenges in information processing as our perceptual systems.<br/><br/>This research focuses on two recently proposed algorithms for dimensionality reduction. The two algorithms address the ""curse of dimensionality"" as it arises in two different settings of machine learning: (1) unsupervised learning, where the dimensionality reduction is performed without any feedback from the learning environment, and (2) supervised learning, where the dimensionality reduction is performed with the benefit of labeled examples.<br/><br/>The first algorithm to be studied is Locally Linear Embedding (LLE), an unsupervised learning algorithm that computes low dimensional, neighborhood preserving embeddings of high dimensional data. The data, assumed to lie on a nonlinear manifold, is mapped into a single global coordinate system of lower dimensionality. The mapping is derived from the symmetries of locally linear reconstructions, and the actual computation of the embedding reduces to a sparse eigenvalue problem. Notably, the optimizations in LLE (though capable of generating highly nonlinear embeddings) are simple to implement, and they do not involve local minima. LLE has applications to exploratory data analysis, scientific visualization, and computer vision.<br/><br/>The second algorithm is Multiplicative Margin Maximization (M3), a supervised learning algorithm for nonnegative quadratic programming in support vector machines (SVMs). Support vector machines currently provide state-of-the-art solutions to many problems in machine learning, particularly those involving data sets of high dimensionality. Solving the quadratic programming problem in SVMs, however, remains a significant bottleneck in their implementation. The M3 algorithm is designed to alleviate this bottleneck. Its update rules have a simple closed form, and they converge monotonically to the solution of the maximum margin hyperplane. Moreover, they do not involve any heuristics such as choosing a learning rate or deciding which variables to update at each iteration. They optimize the traditionally proposed objective function for SVMs and can be applied to problems in classification, regression, and novelty detection.<br/><br/>The algorithms to be studied in this research are easy to implement, but the problems they solve are quite complex. Compared to previous approaches, they are distinguished not only by their novel simplicity and well-behaved optimizations, but also by the unexpected connections they make to other areas in mathematics, computer science, and statistics. The work will not only develop the theoretical foundations of these algorithms, but also attempt to scale them up to increasingly large problems in machine learning.<br/><br/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century.  The research is expected to have a broad impact across many areas of science and engineering, by overcoming the challenges posed by data sets of extremely high dimensionality. Software toolkits will be published, so that researchers everywhere will have access to state-of-the-art methods for dimensionality reduction. The educational innovations will include new undergraduate and graduate courses in artificial intelligence, machine learning, statistical computing, and sensory processing.<br/>"
9701508,CAREER: Distributed Deduction with Contraction and Foundation of Strategy Analysis,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT, CISE RESEARCH RESOURCES",9/1/1997,3/16/2001,Maria Paola Bonacina,"Bonacina, MP","Bonacina, MP",IA,University of Iowa,Continuing grant,William Randolph Franklin,8/31/2002,"$205,000.00 ",,bonacina@cs.uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,"2865, 2890","1045, 1187, 2891, 9216, HPCC",$0.00 ,normalFunding,"This project has two parts, one in distributed deduction and one  in the theory of theorem-proving strategies.  Distributed  deduction couples the traditional aim of making computation  faster by parallelization, with the aim of investigating new  forms of automated reasoning, that may arise from the combination  of deductive computing and distributed computing.  The research  will consider the coarse-grain parallelization of contraction-  based strategies, that are among the most successful strategies  available, especially on equational problems.  The objective is  to design new techniques to subdivide a theorem-proving problem  among concurrent deductive processes, in such a way that each of  them has less work than a sequential process, and a proof may be  found faster.  This part of the work will consist in the  definition and implementation of distributed strategies with  these features.    Theorem-proving strategies are evaluated usually by testing their  implementations. The long-term goal of the theoretical part of  this research is to make possible some complexity analysis of  theorem-proving strategies prior to implementation, so that  useful features may be recognized sooner.  Recent work by the  proponent shows that progress in this direction is feasible.  This project will develop a methodology of analysis, that covers  both forward reasoning and backward reasoning, sequential and  parallel strategies.  As part of the project the methodology will  be applied to analyze selected features of strategies, such as  contraction, lemmaizing/caching and forms of parallel search.  The two parts of the project are deeply connected, because the  methodology for strategy analysis is based on a model of the  search space and search process, which is used also as a  fundamental tool of analysis to achieve the objectives in  distributed deduction.    The educational component of this project comprises two  objectives in course development.  The first one is the evolution  of an undergraduate cour se in programming language concepts into  a course where the concepts are learnt in functional and logic  programming.  The purpose is to offer to the students some  exposure to paradigms that are underrepresented in the  curriculum.  This is important, since long-lasting programming  maturity requires the flexibility fostered by the practice of  multiple paradigms.  The second one is the development of a  graduate course in artificial intelligence. It will be a course  in logical methods for artificial intelligence, with an emphasis  on fully automated deduction.  The students will acquire a solid  understanding of some of the most important concepts in the  logical foundations of computer science, together with the  preparation for seminars or research projects in deduction. Both  lectures and assignments will emphasize the practical  consequences of the theory, and students will conduct experiments  with state-of-the-art theorem provers."
9624058,CAREER:  Evaluation as the Basis for AI Agent Design,IIS,"CISE RESEARCH RESOURCES, ARTIFICIAL INTELL & COGNIT SCI",8/15/1996,6/8/1999,Adele Howe,"Howe, A","Howe, A",CO,Colorado State University,Continuing grant,Ephraim P. Glinert,7/31/2001,"$204,604.00 ",,howe@cs.colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,CSE,"2890, 6856","1045, 2891, 6856, 9216, HPCC",$0.00 ,normalFunding,"Many software developers view evaluation as a burden both because  it   currently   takes  significant  effort  and   because   most  programmers  are not trained in it.  In the context of  the  PI's  area  of  expertise  (planning and  agent  design  in  Artificial  Intelligence), the purpose of this project is to address two gaps  in  current  methodology and pedagogy: the dearth  of  evaluation  methods  for AI software agents and the absence of empirical  and  evaluation  methods  in the undergraduate and  graduate  computer  science  curricula.  Towards these ends, the  research  component  creates  new methods for evaluation that support AI agent  design  and development in the context of two agent projects: a simulated  robot  and  an  information gathering  agent  for  the  WWW.  The  teaching   component  integrates  evaluation  methods  into   the  undergraduate and graduate CS curriculum by incorporating modules  into  existing courses where possible and designing  new  courses  where  necessary.  Each  component  exploits  existing  and   new  research   projects  for  exploring  issues  of   evaluation   in  motivating design. The expected results are not only new software  evaluation  methods, documented examples of  their  use  and  two  thoroughly  evaluated software agents, but also experienced,  new  practitioners."
1218177,"RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications",IIS,ROBUST INTELLIGENCE,9/1/2012,6/17/2013,Jingyi Yu,"Yu, J","Yu, J",DE,University of Delaware,Continuing grant,Jie Yang,8/31/2015,"$204,431.00 ",,yu@cis.udel.edu,210 Hullihen Hall,Newark,DE,197162553,3028312136,CSE,7495,"7923, 9150",$0.00 ,normalFunding,"Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair.  On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br/><br/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms."
328712,Pre College Outreach in Electrical Engineering,ECCS,"ELECT, PHOTONICS, & MAG DEVICE",7/15/2003,5/17/2006,Peter Bofah,"Bofah, P","Bofah, P",DC,Howard University,Standard Grant,Rajinder P. Khosla,12/31/2006,"$204,000.00 ",,pbofah@Howard.edu,2400 Sixth Street N W,Washington,DC,200599000,2028064759,ENG,1517,"0000, 9102, OTHR",$0.00 ,normalFunding,"The Howard University Pre-College program, called the Energy Expert Systems Institute (EESI), is a 5-week residential program aimed at attracting high school students, with special emphasis on underrepresented students, to choose a career in electrical engineering.<br/><br/>Intellectual merits:<br/><br/>Extensive hands-on and research training to expose students to current and relevant topics in electrical engineering such as power and energy systems, communications, the application of system and network theory, material sciences, topics from civil engineering and computer science. Basic computation lectures in electrical engineering fundamentals and problem solving techniques.<br/>Lectures aimed at developing the oral and written communication skills of the students.<br/>Exposure to laboratory programming tools like MATLAB, PSPICE, Electronic Workbench, etc, and programming software packages like Artificial Intelligence, Fuzzy Logic, etc to improve the students technical skills.<br/>Tutorials on modern technology such as nano-technology, Microelectromechanical Systems (MEMS), Distributed Generation (DG), and Wavelet (WL).<br/><br/>Broader Impact:<br/><br/> The Pre-College program is aimed at 11th and 12th grade high school students from the Metropolitan area (Washington DC, Virginia, Maryland) and other parts of the country. The program will expose them to electrical engineering fundamentals and its application to new emerging technologies through lectures and various research projects performed during the program. The activities proposed will enhance the students interest and appreciation for electrical engineering leading to increased enrollment in engineering programs and awards of engineering degrees. The program will also reach out to undergraduates and high school teachers from urban schools to allow them to gain a broader experience and understanding of technology. The experiences gained by teachers will impact effective teaching and learning of modern tools and technology in the high schools."
1439005,XPS: FULL: DSD: Collaborative Research: Rapid Prototyping HPC Environment for Deep Learning,CCF,Exploiting Parallel&Scalabilty,8/1/2014,8/5/2014,Andrew Ng,"Ng, A","Ng, A",CA,Stanford University,Standard Grant,Vipin Chaudhary,7/31/2017,"$202,500.00 ",,ang@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,8283,,$0.00 ,normalFunding,"The impact of Big Data is all around us and is enabling a plethora of commercial services. Further it is establishing the fourth paradigm of scientific investigation where discovery is based on mining data rather than from theories verified by observation. Big Data has established a new discipline (Data Science) with vibrant research activities across several areas of computer science. This ?Rapid Python Deep Learning Infrastructure? (RaPyDLI) project advances Deep Learning (DL) which is a novel exciting artificial intelligence approach to Big Data problems, which also involves a sophisticated model and a corresponding ?big compute? needing high end supercomputer architectures. DL has already seen success in areas like speech recognition, drug discovery and computer vision where self-driving cars are an early target. DL uses a very general unbiased way of analyzing large data sets inspired by the brain as a set of connected neurons. As with the brain, the artificial neurons learn from experience corresponding to a ?training dataset? and the ?trained network? can be used to make decisions. Trained on voices, the DL network can enhance voice recognition and trained on images, the DL network can recognize objects in the image. A recent study by the Stanford participants in this project trained 10 billion connections on 10 million images to recognize objects in an image. This study involved a dataset that was approximately 0.1% the size of data ?learnt? by an adult human in their lifetime and one billionth of the total digital data stored in the world today. Note the 1.5 billion images uploaded to social media sites every day emphasize the staggering size of big data. The project aims to enhance by DL by allowing it to use large supercomputers efficiently and by providing a convenient DL computing environment that enables rapid prototyping i.e. interactive experimentation with new algorithms. This will enable DL to be applied to much larger datasets such as those ?seen? by a human in their lifetime. The RaPyDLI partnership of Indiana University, University of Tennessee, and Stanford enables this with expertise in parallel computing algorithms and run times, big data, clouds, and DL itself.<br/>RaPyDLI will reach out to DL practitioners with workshops both to gather requirements for and feedback on its software. Further it will proactively reach out to under-represented communities with summer experiences and DL curriculum modules that include demonstrations built as ?Deep Learning as a Service?.<br/>RaPyDLI will be built as a set of open source modules that can be accessed from a Python user interface but executed interoperably in a C/C++ or Java environment on the largest supercomputers or clouds with interactive analysis and visualization. RaPyDLI will support GPU accelerators and Intel Phi coprocessors and a broad range of storage approaches including files, NoSQL, HDFS and databases. RaPyDLI will include benchmarks as well as software and will offer a repository so users can contribute the high level code for a range of neural networks with benefits to research and education."
1704656,AF: Large: Collaborative Research: Nonconvex Methods and Models for Learning: Towards Algorithms with Provable and Interpretable Guarantees,CCF,ALGORITHMIC FOUNDATIONS,6/1/2017,4/20/2018,Rong Ge,"Ge, R","Ge, R",NC,Duke University,Continuing grant,Rahul Shah,5/31/2022,"$202,246.00 ",,rongge@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7796,"7925, 7926, 9251",$0.00 ,normalFunding,"Artificial Intelligence along with Machine Learning are perhaps the most dominant research themes of our times - with far reaching implications for society and our current life style. While the possibilities are many, there are also doubts about how far these methods will go - and what new theoretical foundations may be required to take them to the next level overcoming possible hurdles. Recently, machine learning has undergone a paradigm shift with increasing reliance on  stochastic optimization to train highly non-convex models -- including but not limited to deep nets. Theoretical understanding has lagged behind, primarily because most problems in question are provably intractable on worst-case instances. Furthermore, traditional machine learning theory is mostly concerned with classification, whereas much practical success is driven by unsupervised learning and representation learning. Most past theory of representation learning was focused on simple models such as k-means clustering and PCA, whereas  practical work uses vastly more complicated models like autoencoders, restricted Boltzmann machines and deep generative models. The proposal presents an ambitious agenda for extending theory to embrace and support these practical trends, with hope of influencing practice. Theoretical foundations will be provided for the next generation of machine learning methods and optimization algorithms. <br/><br/>The project may end up having significant impact on  practical machine learning, and even cause a cultural change in the field -- theory as well as practice -- with long-term ramifications. Given the ubiquity as well as  economic and scientific implications of machine learning today, such impact will extend into other disciplines, especially in (ongoing) collaborations with researchers in neuroscience. The project will train a new generation of machine learning researchers, through an active teaching and mentoring plan at all levels, from undergrad to postdoc. This new generation will be at ease combining cutting edge theory and applications. There is a pressing need for such people today, and the senior PIs played a role in training/mentoring several existing ones.<br/> <br/>Technical contributions will include new theoretical models of knowledge representation and semantics, and also frameworks for proving convergence of nonconvex optimization routines. Theory will be developed to explain and exploit the interplay between representation learning and supervised learning that has proved so empirically successful in deep learning, and seems to underlie new learning paradigms such as domain adaptation, transfer learning, and interactive learning. Attempts will be made to replace neural models with models with more ""interpretable""  attributes and performance curves.  All PIs have a track record of combining theory with practice. They  are also devoted to a heterodox research approach, borrowing from all the past phases of machine learning: interpretable representations from the earlier phases (which relied on logical representations, or probabilistic models), provable guarantees from the middle phase (convex optimization, kernels etc.), and an embrace of nonconvex methods from the latest deep net phase. Such eclecticism is uncommon in machine learning, and may give rise to new paradigms and new kinds of science."
1526350,III: Small: Collaborative Research: RUI: Adaptive Integration of Textual and Geospatial Information for Mining Massive Map Collections,IIS,"INFO INTEGRATION & INFORMATICS, EPSCoR Co-Funding",9/1/2015,8/18/2015,Jerod Weinman,"Weinman, J","Weinman, J",IA,Grinnell College,Standard Grant,Maria Zemankova,8/31/2019,"$202,140.00 ",,jerod@acm.org,1121 Park Street,Grinnell,IA,501121690,6412694983,CSE,"7364, 9150","7364, 7923, 9150, 9229",$0.00 ,normalFunding,"Libraries and archives are digitizing historical maps for widespread online access. Without technology for searching them, large map collections relevant to a given problem or question may remain obscure even in online archives. If all of the text in a map can be read automatically by computer, a wealth of information becomes quickly available -- location names, geographic features, and often statistics. This project will increase capacity for search and analysis of historical maps by automatically recognizing place names and other text in these digitized artifacts while simultaneously aligning them with modern geography. The improvements this project will make to current text recognition methods will facilitate more powerful uses of humanity's trove of old maps -- for example, by allowing scientists and policymakers to establish changes in land usage, waterways, or borders over time. By creating free, open-source tools for studying historical maps, this project will increase public engagement with science and technology and empower any Internet user to explore the intersection of technology and history. This research will train a diverse group of graduate and undergraduate students in constructing, learning, and making predictions with adaptive models featuring heterogeneous yet highly interdependent entities.<br/><br/>Although many institutions are digitizing hundreds of thousands of historical maps, most digitized map images are poorly annotated, limiting their usefulness. Manual annotation and metadata association is highly laborious. This project's primary objectives are (1) to fully automate text and shape-based georeferencing (aligning map images to the known global geography) while (2) indexing words and place names (for search) by enhancing text detection and recognition methods in these complex artifacts. These innovations will address the shortcomings of manual georeferencing and current automated text recognition algorithms. The researchers will employ an iterative interpretation process for solving problems including text/graphics separation, text recognition, and georeferencing. For example, the fact that all members of a given class of text entities on a map (e.g., county names) are typically rendered in the same text style can be used to inform predictions about difficult members of the category with information derived from more easily-recognized members. The researchers will use a dataset of annotated maps containing over 12,000 words in 9,000 place names as benchmark data for testing the algorithms developed in the project. Software, data, and benchmarks will be broadly distributed on the project website (http://www.cs.grinnell.edu/~weinman/research/maps.shtml). Findings will be shared with the research community through journals and conferences in the computer vision, artificial intelligence, and GIS communities."
453604,SUPERB (Summer Undergraduate Progam in Engineering Research at Berkeley),CCF,RSCH EXPER FOR UNDERGRAD SITES,2/15/2005,9/22/2006,Edward Lee,"Lee, E","Lee, E",CA,University of California-Berkeley,Continuing grant,Eun K. Park,1/31/2009,"$200,910.00 ",,eal@eecs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,1139,"9125, BIOT",$0.00 ,normalFunding,"The overall goal of this research is to demonstrate new architectural solutions for the converged information and communication networks of the next century in nontraditional applications.<br/><br/>Intellectual Merit<br/>This project focuses on the societal impact of engineering systems and technologies. We have developed various collaborative technologies (tele-immersive laboratory, experimental economics), to explore how humanists and social scientists may take advantage of the vast digital information and interactive capabilities that the Internet offers in communication.<br/><br/>Broader Impact<br/>Students will be able to do research in every area of CS-IT: algorithms, complexity theory, computer graphics and vision, artificial intelligence, robotics, networks, wireless communications, software engineering, operating systems, human computer interaction, computational biology, programming languages, and computer architecture, under the supervision of faculty with outstanding qualifications, who are committed to undergraduate research."
350356,SLC Catalyst: Perceptual Learning and Brain Plasticity,SBE,SCIENCE OF LEARN CTR-CATALYSTS,10/1/2003,9/25/2003,Daniel Kersten,"Kersten, D","Kersten, D|Rieser, J|Kanwisher, N|Bulthoff, H",MN,University of Minnesota-Twin Cities,Standard Grant,Maria Kozhevnikov,9/30/2006,"$200,838.00 ","John Rieser, Nancy Kanwisher, Heinrich Bulthoff",kersten@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,SBE,7277,"0000, OTHR",$0.00 ,normalFunding,"The aim of this SLC Catalyst activity is to develop plans for an interdisciplinary multi-institutional center devoted to translating contemporary research on perceptual learning and brain plasticity into educational and rehabilitation outcomes, with special emphasis on the needs of the 3+ million Americans with impaired vision. The Center will be composed of a partnership among teams of researchers at five leading sites for vision research: University of Minnesota, Vanderbilt University, Boston (MIT, Harvard, and Shepens Eye Research Institute), UCLA, and the Max Planck Institute for Biological Cybernetics (Tubingen, Germany) . These teams combine interdisciplinary expertise in perceptual development, impaired vision and special education, computational vision, neuroscience, and behavior. <br/><br/>The key idea behind the proposed center is that learning and adaptation take place within the visual and other perceptual pathways. Understanding the principles of learning at this early input stage of information processing is a critical prerequisite for understanding human capacities that rely on sensory input.<br/><br/>The following planning activities will be completed: 1) Identify the most important educational and rehabilitation needs related to perceptual learning and brain plasticity in reading, recognition and spatial navigation. 2) Identify the existing research barriers to solving them, and potential research solutions. 3) Hold a workshop to arrive at a consensus for a center's educational and rehabilitation priorities. 4) Incorporate these plans into a full Center proposal.<br/><br/>Because of its intrinsic importance to human nature, vision is a model system for researchers interested in development, neuroscience, cognition and behavior, and artificial intelligence. Vision is also a topic of primary concern to educators and rehabilitation specialists with visually impaired students or clients, and to engineers and computer scientists who design adaptive technology for visually impaired people. For the most part, these two communities -- vision researchers, and vision educators and engineers -- have had little interaction, leaving unfulfilled opportunities for translating the huge body of research findings into improved quality of life for visually impaired people. Three burgeoning areas of vision research provide the basis for bridging this gulf -- perceptual learning, brain plasticity, and machine learning. Recent advances in these three areas has overturned the prevailing view that human vision is frozen in structure following a brief early critical period. There is a sea change in thought in which the visual system (and presumably other neural systems) is beginning to be regarded as modifiable throughout the human lifespan. Just how modifiable, on what time scale, and at what level of specificity are key unresolved issues to be addressed."
725607,Collaborative Research:  Interactive Deception and its Detection through Multimodal Analysis,BCS,"HSD - DYNAMICS OF HUMAN BEHAVI, ",10/1/2007,9/18/2007,Dimitris Metaxas,"Metaxas, D","Metaxas, D",NJ,Rutgers University New Brunswick,Standard Grant,Antoinette WinklerPrins,9/30/2011,"$200,001.00 ",,dnm@cs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,SBE,"7319, S005","7319, 9215, HPCC",$0.00 ,normalFunding,"Deception is a pervasive feature of social life yet often goes undetected because deceivers capitalize on features of the interpersonal communication process. They adjust their verbal and nonverbal behavior over the course of an interaction in ways that evade detection. To uncover the complexities and dynamics of the communication processes that make successful deception or detection possible, collaborative research will be conducted by a multidisciplinary team of communication, linguistics, psychology, computer science, and management information systems researchers from the University of Arizona, University of Chicago, Michigan State University, and Rutgers University. They will be joined by international experts from the University of Cologne, Imperial College London, and University of Iceland. The project will develop a theoretical model of interpersonal deception that shifts emphasis from stable individual behaviors to dynamic interaction patterns. It will create five test beds by measuring the verbal and nonverbal features from video-recorded interpersonal communication experiments. The five experiments are a cheating experiment, a mock theft experiment, deceptive interviews, a group collaboration task, and a narration task. Measurement will consist of extensive automated and human-annotated measurement of visual, vocal, and verbal features. As part of the annotation work, the team will refine and validate software for automated measurement of nonverbal and verbal features. Theory-driven hypothesis tests and exploratory tests will be conducted on the measured communication behaviors to identify dynamic adaptation patterns using time-series, Bayesian-based Theme analyses, and artificial intelligence data mining techniques. The project will advance the scientific infrastructure for studying deception by forming the largest international and multidisciplinary research team of deception experts of its kind, integrating the knowledge and methods of multiple disciplines, refining computer-aided analysis of human communication, making progress in automating deception detection, and educating new investigators through laboratory exchanges. Society will benefit from a more valid picture of deception that can guide training and detection efforts in public, business, government, and security settings."
1120558,RUI: MPS-BIO: Collaborative Research: Design and Construction of Second-Generation Bacterial Computers,MCB,"CROSS-EF ACTIVITIES, MSPA-INTERDISCIPLINARY, MATHEMATICAL BIOLOGY",9/15/2011,9/9/2011,Todd Eckdahl,"Eckdahl, T","Eckdahl, T|Poet, J",MO,Missouri Western State University,Standard Grant,Susanne von Bodman,8/31/2013,"$200,001.00 ",Jeffrey Poet,eckdahl@missouriwestern.edu,4525 Downs Drive,St. Joseph,MO,645072246,8162714364,BIO,"7275, 7454, 7334","1228, 8007, 9178, 9183, 9229",$0.00 ,normalFunding,"Bacteria can be modified, through synthetic biology approaches, to function as biological computers. They can be programmed with DNA sequences, interact naturally with other cells and the environment, power themselves from food sources, and respond to directed evolution. Biological computing is not yet widespread, and this project will develop second-generation bacterial computers capable of addressing mathematical problems in graph theory, probability, theory of computation, and artificial intelligence. The project will identify problems that are scalable and generalizable, develop a system of classifying the bacterial computational complexity of mathematical problems, and construct mathematical models and computer simulations to assess the design feasibility of new bacterial computer programming languages. Proven and novel bacterial computing mechanisms will be used to program bacterial computers to solve the selected mathematical problems. <br/><br/>Broader Impacts. This project will provide multidisciplinary education and research training for undergraduate students (including members of groups under-represented in science) at the interface of mathematics, synthetic biology and computer science. Students will pose research questions, develop testable hypotheses, collect and analyze data, and communicate results through publications and at scientific meetings. <br/><br/>This project is supported jointly by the Networks and Regulation and Mathematical Biology Programs."
9624739,CAREER:  Intelligent Systems and Advanced Computation in    Molecular Biology,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/1/1996,4/25/2000,Richard Lathrop,"Lathrop, R","Lathrop, R",CA,University of California-Irvine,Continuing grant,Ephraim P. Glinert,8/31/2000,"$200,000.00 ",,rickl@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,6856,"1045, 9139, 9216, HPCC",$0.00 ,normalFunding," The aim of this project is to integrate research and education in advanced computation and artificial intelligence as applied to problems in molecular biology.  The underlying research theme is the relation of structure to function in complex systems.  The specific application focus is on enhanced protein structure prediction capability and its subsequent relation to function.  Structural models and empirical objective functions are extracted from the existing scientific databases, thereby capitalizing on an enormous scientific investment compiled over decades.  Structural predictions for novel protein sequences are made by aligning the sequence to the models so as to optimize the objective function.  A novel branch and bound algorithm permits the true global optimum alignment to be found even though the underlying search problem is NP-hard.  The education program creates a collaborative setting wherein computer scientists and biologists both can interact within an interdisciplinary research program.  Students from both disciplines can get hands-on experience ``learning by doing'' research on real and important problems.  The research will lead to improvements in our ability to predict protein structure and function from sequence, a crucial step toward design of novel pharmaceutical compounds, realizing the full potential of the human genome project, and understanding fundamental life processes."
1049719,EAGER:  Self-Assembly of Complex Systems,CCF,BIO COMPUTING,1/1/2011,8/24/2010,Russell Deaton,"Deaton, R","Deaton, R",AR,University of Arkansas,Standard Grant,Mitra Basu,1/31/2013,"$200,000.00 ",,rjdeaton@memphis.edu,210 Administration Building,FAYETTEVILLE,AR,727011201,4795753845,CSE,7946,"7916, 9150, 9218, HPCC",$0.00 ,normalFunding,"Abstract for EAGER: Self-Assembly of Complex Systems <br/>Intellectual Merit:  <br/>Self-assembly is a model for how individual components arrange themselves through local interactions to form organized structures. It originated as a model for construction of nanotechnology. The theory of complex systems describes many phenomena in nature, from human intelligence and evolving communities of organisms to human social networks, economies, and cultures. In these systems, complexity emerges in ways that is not immediately obvious from an understanding of the component parts and the relationships between them. In this project, self-assembly will be investigated as a mechanism for creation of complex systems. Self-assembly can be shown to be equivalent to other models of complex systems. In addition, it can be programmed like a computer. A goal of this project is to develop efficient ways to program self-assembly to produce interesting complex systems, which have practical applications. As a beginning to this, we have developed a mapping of self-assembly onto graphs that enables us to use an efficient algorithm to determine the system that is constructed. Thus, self-assembly should be able to generate complex systems and to provide efficient and realistic simulation of those types of systems. In the project, the self-assembly algorithms will be applied to automatic content generation for games, in which the self-assembly automatically creates situations and non-player characters with which players of the game interact. The conjecture is that this will provide more dynamic and realistic game environments, and moreover, will be an interesting test-bed for investigation of the relationship between self-assembly and complex systems.<br/>Broader Impacts:  <br/>This research integrates ideas from chemistry, physics, biology, and computer science to relate self-assembly to complex systems, and to produce potentially transformative tools that will not only improve understanding of complex systems, but also form the basis for innovative complex systems in a variety of application domains. These include nanotechnology, artificial intelligence, art, literature, and computer games. There are many natural phenomena (i.e. human intelligence, living systems) for which traditional symbolic models of computation are only able to capture a part of their essential capabilities and characteristics.  Human language is an example. This research conceivably could result in software that is able to produce target systems that capture some of the capability, adaptability, and complexity that is observed in nature.  If successful, the project could result in a new paradigm for realistic and complex behavior through computer programs, and would potentially impact not only nanotechnology, but also applications that require automatic generation of realistic content. Moreover, our models of self-assembly can generate this content in tractable ways. In addition, under the direction of the investigator, graduate and undergraduate students will work together in a team on this project, and will be educated in the unique multidisciplinary approach that has been proposed."
757646,Pilot: Computational Metaphor Identification for Supporting Creativity in Science Education,IIS,CreativeIT,4/1/2008,3/28/2008,William Tomlinson,"Tomlinson, W","Tomlinson, W|Richland, L",CA,University of California-Irvine,Standard Grant,Pamela L. Jennings,3/31/2011,"$200,000.00 ",Lindsey Richland,wmt@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7788,"7655, 9215, HPCC",$0.00 ,normalFunding,"An important aspect of creative thinking in science education is the set of metaphors that students use to understand and conceptualize material. Previous research has shown that metaphorical and analogical thinking are key components in creative processes and play an integral role in academic creativity. An important part of encouraging creativity through metaphor is raising a student's awareness of the conceptual metaphors they already use. However, identifying the metaphors that students use in their learning has previously been labor intensive, requiring a great deal of time and attention from a human instructor. Previous work in computational linguistics has enabled the automatic extraction of metaphor from bodies of written text. This project improves the state of the art in computational metaphor identification (CMI) through the use of large corpora, through the employment of typed dependency parsing, and through a comparison of several selectional preference learning techniques. The result will be a technological tool kit that supports human creativity by automatically identifying metaphors in bodies of text. This research makes a significant contribution to the fields of computer science and computational linguistics by improving existing metaphor extraction techniques through the integration of current research in selectional preference learning and dependency parsing. In the area of education research, the project will evaluate the impact of CMI on both students' thinking and teachers' teaching, as well as examining the perceived utility of CMI by both groups. This research will allow these metaphors to be used to anchor instruction. This project has the potential to improve creative thinking in science instruction by helping students and their teachers perceive more effectively the ways in which students are thinking about science concepts. In addition, the research may provide insight into how this type of system could enhance creativity and learning across a wide range of other disciplines. Finally, the ability to perform computational metaphor identification may have a variety of other potential applications, from automated search and information retrieval to knowledge representation and artificial intelligence."
1730044,CompCog:  Collaborative Research:  Learning Visuospatial Reasoning Skills from Experience,BCS,Science of Learning,8/15/2017,8/16/2017,Maithilee Kunda,"Kunda, M","Kunda, M|Rittle-Johnson, B",TN,Vanderbilt University,Standard Grant,Soo-Siang Lim,7/31/2019,"$200,000.00 ",Bethany Rittle-Johnson,mkunda@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,SBE,004Y,059Z,$0.00 ,normalFunding,"This project uses methods from artificial intelligence (AI) to better understand how people learn visuospatial reasoning skills like mental rotation, which are a critical ingredient in the development of strong math and science abilities.  In particular, this project proposes a new approach to quantify the learning value contained in different visual experiences, using wearable cameras combined with a new AI system that learns visuospatial reasoning skills from video examples.  Results from this project will not only advance the state of the art in AI but also will enable researchers to measure how valuable different real-world visual experiences are in helping people to learn visuospatial reasoning skills.  For example, certain types of object play activities might be particularly valuable for helping a child to learn certain visuospatial reasoning skills.  Ultimately, this new measurement approach could be used to identify early signs of visuospatial reasoning difficulties in children and could also help in the design of new visuospatial training interventions to boost children's early math and science development.<br/><br/>The core scientific question that this project aims to answer is: How are visuospatial reasoning skills learned from first-person visual experiences?  This question will be answered through computational experiments with a new AI system---the Mental Imagery Engine (MIME)---that learns visuospatial reasoning skills, like mental rotation, from video examples.  Training data will include first-person, wearable-camera videos from two different settings that are both important for human learning:  unstructured object manipulation by infants and visuospatial training interventions designed for children.  Results from experiments with the MIME AI system will advance the state of the art in both AI and the science of human learning by helping to explain how visuospatial reasoning skills can be learned from visual experiences, and, in particular, how having different kinds of visual experiences can affect the quality of a person's learning outcomes in different ways."
1347075,EAGER: Human-Centric Predictive Analytics of Cyber-Threats: a Temporal Dynamics Approach,CNS,Secure &Trustworthy Cyberspace,9/1/2013,8/15/2013,H. Brinton Milward,"Milward, HB","Milward, HB|Breiger, R|Rozenblit, J|Lazos, L",AZ,University of Arizona,Standard Grant,deborah shands,8/31/2016,"$200,000.00 ","Ronald Breiger, Jerzy Rozenblit, Loukas Lazos",milward@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,8060,"7434, 7916",$0.00 ,normalFunding,"Cybersecurity is paramount to protecting national interests in domains that include but extend well beyond defense and finance. However, current state-of-the-art cyber-defenses have severely limited predictive and attribution capabilities. Detecting and understanding cyber attacks is not sufficient--we can liken that to ""studying symptoms instead of a disease.""<br/>           <br/>This research carries out a synergistic approach to integrating cyber data forensics with human-centric social network analysis under a common framework. The three major activities of this project are as follows: (a) comprehensive models of cyber-attack characteristics are developed using feature extraction techniques on diverse data sources, (b) adversarial groups are classified according to their feature similarities, and (c) group classification is enhanced using analytic techniques from social network science.<br/>           <br/>To accomplish these activities: (1) different models for constructing joint representations of computer and social networks are investigated within a multi-mode graph framework; (2) data reduction and feature extraction techniques are developed for associating large datasets with this unified graph model; (3) an existing system is leveraged to discover invisible and missing links between adversarial networks of individuals; and (4) social network models and tools, as well as case studies, are applied to infer adversarial group typology.<br/>           <br/>This research is expected to benefit computer science, cyber security, and social sciences by improving detection methods for cyber attacks. Applying time-series analysis in creative ways to multi-mode networks should contribute to the field of artificial intelligence. This joint work should apply also in fields such as health care, marketing, or forecasting technology adoption trends."
1131404,GOALI: Study of Advance Rate of Hard Rock Tunnel Boring Machines (TBMs) and the Impacts of Ground Conditions and Machine Specifications,CMMI,"GRANT OPP FOR ACAD LIA W/INDUS, GEOMECHANICS & GEOMATERIALS",9/1/2011,8/15/2011,Jamal Rostami,"Rostami, J","Rostami, J|Rogstad, WD|Home, L",PA,Pennsylvania State Univ University Park,Standard Grant,Richard J. Fragaszy,8/31/2015,"$200,000.00 ","W. D. Rogstad, Lok Home",rostami@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,ENG,"1504, 1634","036E, 037E, 1057, 1504, 172E, CVIS",$0.00 ,normalFunding,"The objective of this Grant Opportunity for Academic Liaison with Industry (GOALI) project is to develop a model for estimation of Tunnel Boring Machine (TBM) utilization and advance rate based on the machine specifications and ground conditions.  Accurate estimation of the penetration, utilization, and daily advance rate of hard rock TBM has been a challenge due to the complexity of the machine rock interaction and the influence of operational and management issues on machine production.  Having a reasonably accurate estimate is crucial in justification of the project, as well as planning and cost estimation.  The errors in the estimates have caused many technical and legal problems and have engaged much of resources in construction claims.  A quick review of the literature shows that much of research has focused on the estimation of rate of penetration (ROP) of certain machine types in a given geology.  Yet, the estimation of machine utilization and analysis of downtime has not been treated in a systematic way, although downtime is the largest proportion of time spent in any tunneling operation involving TBMs.  The limited amount of research in this area is outdated and does not reflect the advances in machine manufacturing techniques.   The controlling parameters for TBM utilization and advance rate include the geological setting, machine type and specifications, operational parameters, the machine backup system and auxiliary equipment, and finally site management.  This study will look at the case histories of recent TBM application to evaluate the impact of various geological parameters on machine performance.  An existing TBM field performance database will be updated with additional data for statistical analysis and seeking new relationships between controlling parameters.  The study will also develop activity based models of the tunneling operation and will establish correlation between time required to perform each activity and ground conditions to allow for more accurate estimate of machine utilization and advance rate.  Also, the feasibility of using artificial intelligence methods for estimation of the machine performance will be evaluated based on the available data to complement the proposed models.  This project will be performed with the participation and contributions by the Robbins Company, the largest manufacturer of tunnel boring machines in the US (and one of the largest in the world), and Frontier Kemper, a leading tunneling contractor in North America.  Both companies will assist the research project by providing field data and expertise to expand the database of TBM field performance and realistic activity time models.  The proposed work will improve the accuracy of the existing performance prediction models and offer means to achieve more efficient operation.  <br/><br/>With a more reliable estimation of TBM advance rate, more accurate cost estimation for hard rock tunneling can be achieved and many of unnecessary construction claims can be avoided.  This study can also lead to an objective evaluation of machine backup system and impact of various components on machine utilization, which can lead to a systematic evaluation of ground conditions for selection of proper machine and backup system to avoid long delays in tunneling operation.  Overall, the result of this study leads to more efficient and cost effective tunneling with reduced delays, improved safety, and prospects for better risk management for tunnel construction using TBM.  The main beneficiary of the study will be the general public through the cost savings on the construction of critically needed civil infrastructure upgrades such as water, sewer, rail, subway, and road tunnels."
514155,Computational Complexity Theory and Circuit Complexity,CCF,THEORY OF COMPUTING,6/15/2005,3/6/2007,Eric Allender,"Allender, E","Allender, E",NJ,Rutgers University New Brunswick,Continuing grant,Richard Beigel,5/31/2009,"$200,000.00 ",,Allender@cs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,2860,"9218, HPCC",$0.00 ,normalFunding,"This proposal is for support of continuing research on problems in computational complexity theory. It presents detailed plans of attack on the following specific topics:<br/><br/>Algorithmic Randomness: Recent progress in the field of derandomization gives tools to convert randomized algorithms into deterministic ones. This yields new connections between \Algorithmic Information Theory"" (or \Kolmogorov Complexity"") and circuit complexity as an unexpected side-product. This may yield novel and useful characterizations of complexity classes; some initial theorems of this sort have been obtained.<br/><br/>Constant-Depth Circuits: The complexity class ACC0 (consisting of problems computed by bounded-depth circuits of And, Or, and Modm gates) is of great interest to theoreticians, because (a) it is the smallest class of circuits not known to be unable to compute every problem in NP, and (b) in contrast, it seems to be very closely related to classes of circuits known to be unable to compute some very simple functions. Because<br/>of recent results that give new graph-theoretic characterizations of ACC0, and because of new results that relate arithmetic complexity to Boolean complexity, it is proposed that renewed attention be placed on the problem of trying to prove lower bounds for ACC0, and on the problem of extending the recent characterizations to more complexity classes.<br/><br/>Constraint Satisfaction Problems: Many important problems in artificial intelligence and in database theory (and elsewhere) can be expressed as constraint satisfaction problems. One of the fundamental theorems about these problems is that, up to polynomial-time equivalence, there are only two kinds of problems. Either they are in P, or they are NP-complete. Recent work with collaborators suggests that if one considers<br/>the natural reducibilies that are used to investigate subclasses of P, then there is no longer a dichotomy, but instead a partition into six classes of equivalent problems.<br/><br/>Intellectual merit of the proposed activity: The goal of this activity is to clarify the relationship among complexity classes, which is the best tool currently available for understanding the computational complexity of real-world computational problems. Some of these problems are notoriously dificult, but recent progress justifies some optimism that additional useful insight about these complexity classes can be obtained.<br/><br/>Broader impacts resulting from the proposed activity: An important part of this proposal is a request for support for a graduate student. In addition to helping obtain research results, this support would have the effect of training a new researcher and educator. This support would also help the student to participate in professional meetings and workshops, and help strengthen those institutions, which are the principal forums for dissemination of these research results. The long-term goals of research in computational complexity, if finally achieved, will have profound impact on society (for instance, by providing firm mathematical underpinnings to public-key cryptography, which currently rests upon many unproven conjectures). The proposed research offers concrete plans for incremental progress toward this long-range goal."
309537,Development and Feasibility Study of an Integrated High-speed Photonic Search Engine with Applications to Information Technology,CCF,ITR SMALL GRANTS,8/15/2003,8/6/2003,Ahmed Louri,"Louri, A","Louri, A",AZ,University of Arizona,Standard Grant,Sankar Basu,7/31/2007,"$199,999.00 ",,louri@email.gwu.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,1686,"9215, HPCC",$0.00 ,normalFunding,"Searching is a fundamental and pervasive operation in information processing. It can be expressed in a variety of forms such as (a) equivalence search (exact match search, not-equal-to search, similar-to search) (b) magnitude comparison search (smaller than, greater than, not-smaller-than, not-greater-than), (c) between limits search (search within a range or outside a range), (d) ordered retrieval search (ascending order, descending order), (e) extreme search (finding the maximum, the minimum, and the median), and (f) lookup search. These types of searches can be found in many information technology (IT) applications including database processing, artificial intelligence, pattern matching, security, and communications. In addition to its widespread use in information processing, searching plays a major role in data communication and routing where it serves as the basis for routing table lookup and classification necessary for packet routing. Conventional processors are often designed for numerical processing and search operations are delegated to software.  Consequently, and for many applications, search operations are the most time consuming and create a major performance bottleneck.<br/><br/>In this research project, we propose to investigate the development and detailed analysis of novel photonic search engines, that can implement search operations in hardware as directly as possible, and thereby as efficiently as possible. This will not only provide for minimum execution time but will also increase efficiency in other areas. These engines can be used as co-processing assists within a larger electronic processing node for computation and/or communication or as stand-alone search accelerators. We propose a novel approach that will combine device technology with architectural innovations in an efficient and practical manner with the aim of achieving a significant improvement in performance as well as reduction in system size. Our approach differs significantly from any on-going research on the subject.  It represents a paradigm shift where search functions are directly executed in hardware instead of coded as lengthy subroutines using low-level instructions.  It is anticipated that this approach will provide parallel search engines with low-power operation, high-speed processing (in the Terabits/second range), high degree of parallelism (due to the exploitation of several degrees of freedom in optics), and small monolithically integrated system size. The proposed research will have a broader impact on information technology. It is likely that a new field of study, multi-wavelength guided-wave integrated optical processing, will emerge for designing smaller processing systems while providing even more computing power than before. <br/><br/>"
9876181,CAREER: Object Identification in Intelligent Systems,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/1/1999,7/31/2002,Timothy Huang,"Huang, T","Huang, T",VT,Middlebury College,Continuing grant,Edwina L. Rissland,4/30/2005,"$199,998.00 ",,huang@middlebury.edu,14 OLD CHAPEL ROAD,MIDDLEBURY,VT,57536000,8024435000,CSE,6856,"1045, 1187, 9216, HPCC",$0.00 ,normalFunding,"Object identification -- the task of deciding that two observed objects are in fact one and the same object -- is a fundamental requirement for any intelligent system or situated agent that reasons about individuals.  An approach to this problem has been developed in recent years based on a Bayesian framework that determines the probability for an object's expected appearance at subsequent observations, given its current appearance.  The theory has been successfully applied to the task of recognizing cars observed by cameras at widely separated sites in a freeway network. This research will build upon and extend theoretical results involving object identification and data association, and will show how to apply these results to real-world problems.<br/><br/>This research has three primary thrusts.  One aim is to integrate and generalize work from the data association community, which has focused on tracking independently moving objects whose state can be modeled by multivariate Gaussians, with work from the uncertainty in artificial intelligence community, which has produced a variety of compact state representations and associated inference algorithms.  The goal is to present a unified framework with broader applicability than current theory.  A second aim is to develop improved heuristic algorithms for approximating solutions to intractable problems that arise when the theory is applied to real-world domains.  The goal is  to develop new algorithms and demonstrate improved performance over existing ones. The third aim is to apply the theory to other real-world tasks, such as maintaining consistency and eliminating duplicate entries in databases.  The goal is to illustrate the patterns of reasoning involved in moving from domain-independent theory to domain-specific problems. These research activities form part of a more general effort within the AI community to develop models and algorithms for reasoning in uncertain environments with noisy and imprecise sensors. <br/><br/>The PI's education plans will strengthen the computer science program at Middlebury College in particular, and at liberal arts institutions in general, in two ways:  through innovative,  inter-disciplinary approaches to presenting introductory computer science concepts so as to increase the interest among first and second year college students in this field at a time when many of them might otherwise stop taking courses in mathematics or science;  and through early involvement of students in undergraduate research projects.  The project's ultimate goal is to provide a model for others to follow in ways to integrate research and education activities at undergraduate liberal arts institutions.<br/><br/><br/><br/>"
617883,SGER:  Scalable adversary resistant routing,CNS,ITR-CYBERTRUST,9/15/2006,9/13/2006,Baruch Awerbuch,"Awerbuch, B","Awerbuch, B",MD,Johns Hopkins University,Standard Grant,Karl Levitt,8/31/2008,"$199,967.00 ",,baruch@cs.jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,7456,"7254, 9218, 9237, HPCC",$0.00 ,normalFunding,"Proposal Number: 0617883<br/>PI:  Baruch Awerbuch       <br/>Institution:   Johns Hopkins University       <br/>Title:   SGER: Scalable adversary-resistant routing               <br/><br/><br/>Abstract<br/><br/>This research advocates a concept of reputation-based  routing as a way to achieve secure routing without compromising scalability. None of the existing work guarantees such strong properties.<br/><br/>In order for this research to succeed, novel mathematical and algorithmic ideas are necessary. Accomplishing our research objective is an extremely high-risk and required multi-disciplinary  approach accomplishing breakthroughs in  many fields, such as Applied Networking, Artificial Intelligence and Theoretical Computer Science.<br/><br/>This proposal is based on a sequence of preliminary results of the author that show that efficient collaboration in context of weeding out adversarial actions in the network routing setting is possible<br/>even under completely adversarial circumstances.<br/><br/>The key differentiator between this work and rest of the published work on similar topics is our insistence of solid mathematical foundations, that will not use unjustified assumptions. The reason for this is that unproven heuristics are not a viable approach in an adversarial setting.<br/><br/>On the other hand, there is an acute need laying the foundation for the area of adversary-tolerant routing.  Without such a foundation, we cannot possibly have confidence in ability of Internet to properly function in face of adversarial attacks. Lack of confidence in our cyber-structure casts a doubt on the stability of our society as a whole.<br/><br/><br/>"
450770,SGER:     An Architecture of Diversity for Common Sense Reasoning,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/1/2004,7/15/2005,Walter Bender,"Bender, W","Bender, W",MA,Massachusetts Institute of Technology,Standard Grant,Kenneth C. Whang,11/30/2005,"$199,948.00 ",,walter@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,6856,"9218, 9237, HPCC",$0.00 ,normalFunding,"Artificial Intelligence research has made limited progress towards computational understanding of human reasoning: we have failed to emphasize the creation of programs with ""resourcefulness"" in the face of unfamiliar problems. In computing theory and applications the emphasis has largely been on specific algorithms and mathematical techniques; complex systems have rarely yielded reproducible results or fundamental insights into a theory of system construction. Resourceful programs will require the application of multiple reasoning techniques, a layered architecture for coordinating activity whereby higher-order, reflective processes can diagnose failures in lower-order, deliberative processes.<br/><br/>Scenarios requiring ""commonsense reasoning"" provide an anvil of sufficient scope that only highly-resourceful programs will meet the requirements. Two projects support these aims: Roboverse establishes a virtual world where humanoid characters engage in complex, multi-realm scenarios, applying common sense to physical, social and mental activities; Panalogy is a specification for interconnect among multiple representations, combining diverse reasoning techniques such as analogy, case-based reasoning, statistical analysis and logical inference. An early version of Panalogy instantiates a set of meta-management components, demonstrating different ways to coordinate and repair baseline reasoning processes.<br/><br/>These resources enable wider research-community involvement by providing motivating demonstrations of new theoretical principles and evaluation tools and methodologies for experimental reproduction and comparison. We aim, through workshops, publications and direct engagement to encourage broader support from corporate and governmental sources. This increased effort in resourceful computing research leads the way towards programs that engage readily with humans in the search for solutions to complex problems of importance to science and society.<br/>"
1634627,Actor-Critic-Like Stochastic Adaptive Search Algorithms for Simulation Optimization,CMMI,OE Operations Engineering,9/1/2016,8/2/2016,Jiaqiao Hu,"Hu, J","Hu, J",NY,SUNY at Stony Brook,Standard Grant,Georgia-Ann Klutke,8/31/2019,"$199,923.00 ",,jiaqiao.hu.1@stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,ENG,006Y,"071E, 072E, 073E, 077E, 078E",$0.00 ,normalFunding,"Many systems arising in applications from engineering design, manufacturing, and health care require the use of simulation optimization techniques to improve their performance. However, despite significant progress in recent years, simulation optimization remains an area with many theoretical and practical challenges. This research project aims to expand the current knowledge in this field by investigating a novel approach that integrates theories and tools from reinforcement learning (a subarea of artificial intelligence) within a class of adaptive search algorithms called the model-based methods to solve simulation optimization problems. Because of the generality of these methodologies, the resulting techniques will have broad applicability in a wide array of industry and science sectors. In particular, through collaboration with power engineers, the developed algorithms will be tested and applied to voltage control problems in electric power systems, potentially benefiting both utility companies and energy consumers. The research plan will be closely integrated with the education and training of students in engineering by incorporating new developments into the graduate courses the investigator teaches and recruiting  female and underrepresented minority students to the project.<br/><br/>The goal of this research is to advance theoretical underpinnings of new model-based algorithms that can be orders of magnitude more efficient than the state-of-the-art. This will be accomplished by exploring the connections between model-based methods and policy gradient-based reinforcement-learning algorithms. Specifically, the investigator will examine how to use the insights from actor-critic algorithms in the reinforcement learning framework to effectively reduce the sampling variance of model-based methods. If successful, the approach will integrate function approximation techniques within a model-based optimization setting to provide algorithms with low-variance performance estimates in searching for improved solutions. This research may change the manner in which these algorithms are implemented and applied, leading to faster and more efficient algorithms for solving a broad class of optimization problems, especially in settings that require expensive function evaluations or simulations for performance estimation."
1215302,ICES: Small: Artificial Human Agents for Virtual Economies,CCF,"ECONOMICS, Inter Com Sci Econ Soc S (ICE)",8/15/2012,8/9/2012,Yixin Chen,"Chen, Y","Chen, Y|Levine, D",MO,Washington University,Standard Grant,Tracy J. Kimbrel,7/31/2015,"$199,823.00 ",David Levine,chen@cse.wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,CSE,"1320, 8052","7923, 7932",$0.00 ,normalFunding,"The goal of the project is to be able to replace human agents with<br/>artificial agents in studying two-player games. This project, if<br/>successful, will greatly enhance the ability of economists to test<br/>economic theories by partially replacing laboratory experiments with<br/>simulations. Over the last decades laboratory studies have proven<br/>invaluable both for the validation (and invalidation) of economic<br/>theories, and for the practical purpose of testing mechanisms (such as<br/>auctions) in the laboratory prior to practical implementation. The<br/>ability to use simulations with artificial agents in place of<br/>laboratory experiments with live human beings will both reduce the<br/>cost of validation and testing, and make it possible to explore<br/>quickly a much wider range of theories and policy alternatives. It<br/>will also enhance our understanding of human behavior and enrich our<br/>knowledge of the connection between human and artificial intelligence.<br/><br/>Agent-based modeling is an emerging and attractive approach to<br/>validating economic theories. Existing research has focused on simple<br/>and naive agents. This project proposes as the next step to develop<br/>artificial human (economic) agents capable of mimicking the behavior<br/>of human laboratory subjects in the context of two player simultaneous<br/>move games. Substantial and detailed data is available on human play<br/>under these conditions. Existing algorithms fall only slightly short<br/>of the ability to mimic human play but do not yet implement fully<br/>autonomous agents. Based on hidden Markov models, the PIs propose to<br/>develop and investigate a framework of belief learning that is broad<br/>enough to encompass many existing learning algorithms including<br/>reinforcement learning, fictitious play, and smooth fictitious play.<br/>Moreover, based on this framework, the PIs propose to derive more<br/>sophisticated learning methods to fully develop artificial agents. This<br/>research will pursue two important directions. First, the PIs will<br/>introduce the initial calibration of priors based on available<br/>information and a cognitive hierarchy model. Second, the PIs will allow for<br/>the reconsideration of the existing model when ""surprises"" occur. The<br/>project will lead to the next stage of research in both economics and<br/>computer science in broadening the class of artificial agents to<br/>attack broader and more economically important tasks. It will also<br/>enrich the research on graphical model learning for artificial<br/>intelligence."
9988784,NSF-CNPq Collaborative Research: Combining Cognitive & Utilitarian Coordination in a Layered Agent Architecture,IIS,"SPECIAL PROJECTS - CISE, CISE RESEARCH INFRASTRUCTURE, DIGITAL SOCIETY&TECHNOLOGIES",10/1/2000,6/19/2002,Victor Lesser,"Lesser, V","Lesser, V",MA,University of Massachusetts Amherst,Continuing grant,C. Suzanne Iacono,9/30/2004,"$199,682.00 ",,lesser@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"1714, 2885, 6850","9216, HPCC",$0.00 ,normalFunding,"This CNPq research project will enable a research group at the University of Massachusetts, Amherst to cooperate with a research group at the Artificial Intelligence Group at the University of Rio Grande do Sul in Brazil. Together they will create a two-level multi-agent framework. At the higher level, a subsystem that reasons about symbolic information will be developed. Its activities pertain to domain-specific coordination tasks. At the lower level, a subsystem will be developed that reasons about quantitative information. Its activities pertain to feasibility and implementation operations. The two layers comprise interdependent activities that operate asynchronously. The lower layer provides feedback to the upper layer; the upper layer responds to the feedback by altering its tasks or performance objectives where necessary. Such an architecture will make it easier for multi-agent systems to function in open environments, such as the Internet, where the goals to be achieved, the resources available and the other interacting agents are dynamically changing. <br/><br/>"
918055,EAGER: A Self-Healing Approach for Smart Assembly Systems,CMMI,MANFG ENTERPRISE SYSTEMS,2/15/2009,2/12/2009,Jaime Camelio,"Camelio, J","Camelio, J",VA,Virginia Polytechnic Institute and State University,Standard Grant,Russell Barton,1/31/2012,"$199,451.00 ",,jcamelio@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,ENG,1786,"071E, 7916, 9102, 9147, 9148, MANU",$0.00 ,normalFunding,"ABSTRACT<br/><br/>This grant provides funding to conduct preliminary research in a new paradigm in quality improvement for manufacturing systems. This paradigm is based on a smart self-healing system that increases production quality by autonomously correcting faults or applying compensation actions during the assembly process. The smart self-healing systems will replicate key characteristics of bio-organisms such as awareness, adaptation, redundancy, and decentralization by using artificial intelligence. The applicability of biological mechanisms in designing a control system will be explored by developing a controllable assembly testbed. The proposed testbed will integrate state-of-the-art sensor-actuator networks to replicate the assembly of compliant or flexible parts. The proposed algorithms will integrate three sources of data: system predictive models, process data, and human knowledge. This project focuses on a new quality method for complex assembly systems found in the automotive, heavy equipment, appliance, and aerospace industries. The self-healing mechanisms will hierarchically attack faults at three different levels: component, station, and system.<br/>The development of a paradigm-shifting self-healing approach to quality improvement will provide faster and more precise fault prevention, detection, identification, and correction. Material waste and the number of defective parts will be reduced, the quality of assembled products will be improved, and efficiency and production capacity will be increased through diminished manufacturing downtime. The work aims to advance the current knowledge in three areas: 1) predictive assembly variation models for complex nonlinear systems; 2) monitoring-detection-diagnosis methods for information fusion-based assembly systems; and 3) mathematical framework for a self-healing assembly system using a bio-inspired approach."
757454,Pilot: A Robust Distributed Intelligent System for Telematic Applications,IIS,CreativeIT,4/1/2008,3/27/2008,Jonas Braasch,"Braasch, J","Braasch, J|Oliveros, P",NY,Rensselaer Polytechnic Institute,Standard Grant,Pamela L. Jennings,3/31/2011,"$199,276.00 ",Pauline Oliveros,braasj@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,7788,"7655, 9215, HPCC",$0.00 ,normalFunding,"Complex communication for co-located performers within telepresence applications across networks is still impaired compared performers sharing one physical location. This impairment must be significantly reduced to allow the broader community to participate in complex communication scenarios.  To achieve this goal, an avatar in the form of a musical conductor with forms of artificial intelligence will coordinate between co-located musicians. Improvised Contemporary Live Music of a larger ensemble, serving as a test bed, is arguably one of the most complex scenarios one could think of, because it requires  engaged communication between individuals within a multiple-source sound field that also has to be considered as a whole.  The results are expected to inspire solutions for other communication tasks. <br/> <br/>The avatar system will actively coordinate co-located improvisation ensembles in a creative way. To achieve this goal, Computational Auditory Scene Analysis (CASA) systems, to allow robust feature recognition, and Evolutionary algorithms, for the creative component, will be combined, to  form the first model of its kind. The research results are expected to be significant by themselves and are not bound to telematic applications. With regard to the latter, the proposed system will have a clear  advantage over a human musician/conductor, while intelligent algorithms are clearly lacking behind human performance in most other applications, especially when it comes to creativity. <br/><br/>"
1649972,CAREER: Adversarial Artificial Intelligence for Social Good,IIS,ROBUST INTELLIGENCE,3/1/2017,2/14/2018,Yevgeniy Vorobeychik,"Vorobeychik, Y","Vorobeychik, Y",TN,Vanderbilt University,Continuing grant,Reid Simmons,2/28/2022,"$198,977.00 ",,Yevgeniy.Vorobeychik@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,7495,"1045, 7495",$0.00 ,normalFunding,"The success of AI technologies has resulted in their widespread deployment, with algorithms for reasoning under uncertainty, such as machine learning, having a particularly high impact.  A challenge that is often ignored, however, is the adversarial nature of many domains, in which social, economic, and political interests may try to manipulate intelligent systems into making costly mistakes.  While AI has a long history in playing adversarial games, such as chess and poker, the approaches have not been appropriate for many real-world situations.  The goal of the proposed research is to develop a general framework for adversarial AI that is far broader in scope and applicability, building on insights from game theory, AI planning, and cybersecurity.<br/><br/>A key modeling insight of the proposed research is that attacks across a broad array of settings can be modeled as planning problems, so that robust algorithms can be fundamentally viewed as interdicting attack plans.  Our research will develop new foundational techniques for scalable plan interdiction under uncertainty, building off of the framework of Stackelberg games. Proposed techniques will leverage a combination of abstraction, factored representation of state, and value function approximation.  In addition, novel scalable algorithms will be developed for multi-stage interdiction problems, modeled as sequential stochastic games, considering both perfect and imperfect information. Moreover, the research will make novel modeling and algorithmic contributions in multi-defender and multi-attacker interdiction games.  Finally, in the more applied arena, the research will make significant intellectual contributions in applying advances in adversarial AI to model problems exhibiting important adversarial aspects, such as privacy-preserving data sharing, access control and audit policies, and vaccine design.<br/>"
9625255,CAREER:  Machine Learning  for Autonomous Process           Management,IIS,ARTIFICIAL INTELL & COGNIT SCI,6/1/1996,7/20/1999,Andrew Moore,"Moore, A","Moore, A",PA,Carnegie-Mellon University,Continuing grant,Ephraim P. Glinert,5/31/2000,"$198,467.00 ",,awm@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,6856,"1045, 9146, MANU",$0.00 ,normalFunding,"This investigation builds new statistical artificial intelligence  and    reinforcement   learning   techniques   for    large-scale  manufacturing  operations.  The primary  scientific  question  it  attacks  is:  How  can machine learning be used to  automate  the  decisions   that   a  process  engineer  makes   in   monitoring,  optimizing,  and  fine tuning processes?   The  products  of  the  research   are   new   algorithms  for   memory-based   learning.  Innovations  include Bayesian locally weighted  regression,  Fast  real-time  learning response by means of multiresolution  memory-  base  structures,  novel model-selection search  algorithms,  and  experiment  design methodologies for memory-based  approximators.  In  parallel with their development, these algorithms  are  being  tested  and  deployed through several joint projects between  the  principal investigator's research group at CMU and two  large  US  manufacturing  companies. The economic impact  of  this  research  will   be   processes  and  factories  that  analyse  their   own  datastreams in real time, develop increasingly improved models of  themselves, and exploit those models."
9732705,"Machine Learning, On-Line Decision Making, and Algorithms   for Computationally Hard Problems",CCF,THEORY OF COMPUTING,9/1/1998,5/22/1998,Avrim Blum,"Blum, A","Blum, A",PA,Carnegie-Mellon University,Standard Grant,Robert Sloan,8/31/2001,"$198,407.00 ",,avrim@ttic.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,2860,"9216, HPCC",$0.00 ,normalFunding,"The focus of this research is on developing efficient  combinatorial algorithms for key problems in Artificial  Intelligence and Optimization, as well as providing an improved  understanding of the inherent nature of these problems.  This  project involves three areas in particular:  machine learning, on-  line decision-making, and the study of algorithms for  computationally hard problems.  In the area of machine learning,  one main component of this work is the design of better  algorithms for learning  in large feature spaces.  This includes  questions of how to best combine a large number of low-quality  sources of advice that may be available (e.g., via the internet),  as well as a number of questions with close relations to  crytography.  In the area of on-line algorithms and on-line  decision making, this research will investigate new approaches  for the Weighted-Caching problem, as well as the potential for  using methods from machine learning (for instance, algorithms for  combining sources of advice) to produce improved solutions to a  number of problems in this area.  In the study of methods for  solving computationally hard problems, this project will continue  exploration of approximation algorithms, as well as a new  approach to general purpose planning based on representing  planning problems in a compact graph structure, and then bringing  in tools and ideas from graph algorithms.  This planning method  was first demonstrated in the Graphplan planner, and empirically  appears to be substantially faster than more traditional planning  algorithms in a wide variety of settings."
1318427,Computation of crowded geodesics on the universal Teichmueller space for planar shape matching in computer vision,DMS,"APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS",8/1/2013,5/30/2014,Akil Narayan,"Narayan, A","Narayan, A|Heryudono, A",MA,"University of Massachusetts, Dartmouth",Continuing grant,Leland M. Jameson,10/31/2015,"$198,300.00 ",Alfa Heryudono,akil@sci.utah.edu,285 Old Westport Road,North Dartmouth,MA,27472300,5089998953,MPS,"1266, 1271",9263,$0.00 ,normalFunding,"Quantifying the (dis)similarity between two shapes is a central problem in computer vision. One distance metric on the space of planar shapes is realized by identifying this space as a subset of the Universal Teichmueller Space, and equipping it with the Weil-Petersson metric. This results in a metric that is scale- and translation-invariant on shapes, and has unique geodesic flow between two shape endpoints. The work of this proposal develops robust computational methods for the computation of metric distances and geodesics between shapes on this space. The major difficulty lies in computations involving ""crowded"" shapes, i.e., those with elongated, winding, or extended protrusions. Such shapes stymie finite-precision computations because direct algorithms suffer from severe roundoff error. The major thrusts of this proposal develop algorithmic methodologies to address roundoff error and related issues: The Zipper conformal mapping algorithm will be augmented to produce accurate conformal maps for crowded shapes. The velocity field representation on a geodesic will be rewritten into a form that is resistant to roundoff error. The geodesic equation will be transformed into a expression that takes advantage of the aforementioned velocity field transformation, and can effectively flow between crowded shapes. The final phase of this project will demonstrate accurate geodesic flow and distance computations between crowded shapes. The methods developed under this project can be applied to several related problems in scientific computing: solutions to differential equations on irregular geometries through conformal mapping, conservative integration methods with ill-conditioned particle systems, and moving-mesh kernel approximations.<br/><br/>The work of this project can contribute to far-reaching applications in scientific and computer vision problems: automated object recognition (e.g. projectile identification), outline classification (determination of an animal's species), medical imaging (usage of MRI to diagnose dementia and related diseases), and artificial intelligence (visual recognition and interpretation) to name a few. All computational deliverables (computer code, example simulations, documentation) will be made publicly available. Through the engagement of students in related research tasks, this project will contribute to the educational development of future engineers, mathematicians, and computer scientists."
1658436,Collaborative research: Combining models and observations to constrain the marine iron cycle,OCE,CHEMICAL OCEANOGRAPHY,7/1/2017,3/3/2017,Seth John,"John, S","John, S",CA,University of Southern California,Standard Grant,Simone Metz,6/30/2020,"$197,957.00 ",,sethjohn@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,1670,,$0.00 ,normalFunding,"Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
712199,STTR Phase I: Providing Access to Science and Math for Disabled Students Using MathSpeak,IIP,"STTR PHASE I, SMALL BUSINESS PHASE I",7/1/2007,12/4/2007,David Schleppenbach,"Schleppenbach, D","Schleppenbach, D",IN,"GH, LLC",Standard Grant,Ian M. Bennett,12/31/2008,"$197,466.00 ",,engage@ghbraille.com,1305 Cumberland Ave.,West Lafayette,IN,479061075,7657753776,ENG,"1505, 5371","1654, 9139, HPCC",$0.00 ,normalFunding,"This Small Business Technology Transfer Research (STTR) Phase I research project investigates the improvement of the quality of the synthetic speech rendering generated by the conversion mechanism and to subsequently demonstrate Phase II commercialization feasibility via efficacy tests with targeted consumer groups. The first objective will be to remove distortions and mechanical sounding expressions. Observations suggest that the distortions arise from the lack of logical insertion of pauses (i.e., based on a model of real speech) between elements in the synthetic speech stream. This objective will be accomplished by developing an algorithm based on recordings of math educators speaking mathematical expressions that will be incorporated into the synthetic speech conversion mechanism. The second objective will involve efficacy testing for the reduction of distortions and mechanical sounding expressions. Distortion reduction testing will require participants to listen expressions and to exactly (verbatim) report the expressions they heard. The third objective will involve an efficacy test to test the capacity of the pause algorithm to enhance disambiguation.<br/><br/>Broader impacts include the following: an overriding goal is to increase the accessibility to science, technology, engineering, and mathematical fields by under-represented groups. This goal is consistent with the objectives of the NSF and the Department of Educations incentive to further develop and implement the National Instructional Accessibility Standard (NIMAS), which would facilitate an increase in accessibility via the development of flexible alternatives to print as a primary objective. Additionally, the project advances discovery and understanding not only of the specifics aspects of the wording of spoken language that contribute to misinterpretations but also investigates the more subtle nuances of the non-verbal information such as the intervals between word and their influences on accurate acquisition of information. These findings have educational implications for the optimization of learning strategies and models for teaching and training. Further, the basic protocol for algorithm development has potential paradigmatic significance for development and improvement of synthetic speech across multiple fields that synthetic speech such as artificial intelligence, augmentative and alternative communication, and computer and communication sciences."
1526189,AF: Small: Exact algorithms for the quantum satisfiability problem,CCF,ALGORITHMIC FOUNDATIONS,9/1/2015,6/8/2015,Sevag Gharibian,"Gharibian, S","Gharibian, S",VA,Virginia Commonwealth University,Standard Grant,Dmitry Maslov,12/31/2018,"$196,593.00 ",,sgharibian@vcu.edu,P.O. Box 980568,RICHMOND,VA,232980568,8048286772,CSE,7796,"7923, 7928",$0.00 ,normalFunding,"Among the most fundamental problems in theoretical computer science is the k-SATISFIABILITY problem (k-SAT), which roughly asks: Given a set of Boolean constraints of a special form, each acting on k out of n bits, does there exist an assignment to all n bits which simultaneously satisfies every constraint? This problem has far-reaching applications in areas ranging from artificial intelligence to electronic design automation to theorem proving, thus underscoring its significance. <br/><br/>More recently, a quantum generalization of k-SAT has arisen, known as k-QSAT, which finds applications in areas such as quantum error-correcting codes. Moreover, k-QSAT is physically well-motivated, as it can be thought of as modeling how quantum systems in nature are governed by local quantum constraints. Unlike k-SAT, however, much less is known about k-QSAT. The aim of this project is precisely to close this fundamental knowledge gap. In particular, this project broadly asks: In what cases can non-trivial algorithms be developed for solving k-QSAT? <br/><br/>The resolution of this question will yield deep insights into which properties of quantum systems can be computed efficiently by a classical computer. Moreover, the results obtained will be disseminated through a variety of avenues, including conferences, new course materials, and high school workshops aimed at exposing young computer scientists to the frontiers of research."
642732,SGER: The Robotic Vision Semantic Challenge,IIS,"COMPUTER VISION, ROBUST INTELLIGENCE",8/15/2006,3/27/2008,Paul Rybski,"Rybski, P","Rybski, P|Efros, A",PA,Carnegie-Mellon University,Standard Grant,Paul Yu Oh,1/31/2009,"$196,240.00 ",Alexei Efros,prybski@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7339, 7495","7495, 9215, 9216, 9237, HPCC",$0.00 ,normalFunding,"SGER: The Robotic Vision Semantic Challenge<br/><br/>The web contains vast collections of unstructured image databases that could be exploited to generated useful models for image recognition. Search engines currently only use keywords found in image filenames rather than the image data itself. However, the thousands of images retrieved in such a search could be used to <br/>generate models for recognizing specific objects. The goal of this research project is to develop the infrastructure for a new research competition designed to push the state of the art in image understanding and automatic acquisition of knowledge from large unstructured databases of images, such as those generally found <br/>on the web. This competition will be held at the AAAI (American Association for Artificial Intelligence) Mobile Robot Competition and Exhibition which has been co-located with the AAAI conference for the past ten years. By providing the necessary infrastructure for organizing and managing such a competition, there is a strong chance to attract the best and the brightest in the computer vision, robotics and AI research fields to push the envelope of the state of the art in image and video understanding technologies. Competitions such as these provide a standardized testbed on which researchers can compare the results of their research. At the end of the competition, the PIs will hold a workshop so that the specific technical aspects of each entry can be presented and discussed. In addition, the competitors will have to share their code under an open source license, so that newcomers of 2008 will stand on the shoulders of the winning teams of 2007.<br/><br/>Project URL: http://www.cs.cmu.edu/prybski/AAAI RVSC"
948123,EAGER:  Understanding Social Behavior in Real-Time Strategy Games,IIS,Cyber-Human Systems (CHS),9/1/2009,9/8/2009,Jennifer Golbeck,"Golbeck, J","Golbeck, J|Kuter, U",MD,University of Maryland College Park,Standard Grant,William Bainbridge,8/31/2012,"$196,199.00 ",Ugur Kuter,jgolbeck@umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,7367,"7367, 7916, 9215, HPCC",$0.00 ,normalFunding,"This is a study of  how people make decisions in dynamic, social environments, achieving a methodological innovation by using online real-time strategy (RTS) games as laboratories for studying human behavior.  Investigation into social interactions has been discussed in the context of virtual worlds and online role-playing games, but not in RTS games, nor have researchers yet developed the data-collection techniques or theoretical principles for doing research in this important sector of human-centered computing. In addition to their entertainment value, RTS games have emerged to become virtual platforms that simulate real-world, real-time physics, scenarios, characters, and strategies. Particularly, multi-player online RTS games are providing a new model of human interaction that is in line with decision theory, game theory, planning, learning, and other concepts from research fields such as Computer Science, Artificial Intelligence, Economics, and Behavioral Sciences.<br/><br/>This research will study users' social strategies in RTS games in three major ways: developing a gaming environment, a user study with experiments, and an automated learning approach.  The game will present users with a series of missions to be accomplished, and users will receive points for successful completion. In early stages these missions can be accomplished alone and with little effort, but as the player progresses they will require alliances with others.  The first phase of user studies will involve a qualitative analysis of user behaviors, identifying specific points in the game when users must make decisions where the social relationships will be important factors.  This qualitative analysis will be followed by a quantitative analysis of the players' performance, developing techniques for measuring the payoffs from each action.  Once players begin developing strong alliances, a set of experiments will analyze their reasoning when making strategic decisions. This will include measurements of social tie strength, structural social network features, the past history of interactions, and evolutionary simulations of strategies.  The final phase of research will involve controlled experiments with users, presenting them with situations where they have to make a decision that requires consideration of the social structure.<br/><br/>This project will make software, test suites, documentation, and teaching materials freely available on the Internet. Decision making is an important problem in artificial intelligence, and effective decision-making is important in all kinds of organizations and real-world applications. This research could provide the theoretical and experimental basis for developing practical algorithms and applications for social decision making, to make it easier for the organizations and the users of such applications in their decision-making process.<br/>"
9414239,Visual Communication and Species Recognition,IOS,IBN ANIMAL BEHAVIOR,9/15/1994,8/24/1998,Bruce Jayne,"Jayne, B","Jayne, B",OH,University of Cincinnati Main Campus,Standard Grant,John A. Byers,8/31/1999,"$196,044.00 ",,bruce.jayne@uc.edu,"University Hall, Suite 530",Cincinnati,OH,452210222,5135564358,BIO,1160,"9169, 9178, 9251, ENVI, SMET",$0.00 ,normalFunding,"                Animals use a variety of signals to communicate with each  other, and evolution has resulted in an enormous diversity  of species-specific recognition mechanisms.  Species  recognition is critical, especially in mating, because  mistakes can result in loss of reproductive effort, or (in  the case of predatory animals) even death.  This research  concerns the question of how animals recognize members of  their own species and discriminate them from other species  using visual signals during courtship and mating.  A newly  developed video imaging technique will be used to understand  how visual signals function in the mating process of wolf  spiders, and how differences between species evolve.  Because spiders are potentially cannibalistic, species  recognition mechanisms are critical to survival as well as  reproductive success.  As a consequence, recognition is  innate and based on simple behavioral cues.  In the planned  experiments, visual signals of courting males (body  ornaments and behaviors) will be altered using computer  digitization and video animation, then presented to female  spiders on microtelevision screens.  Responses of females to  video images of their own species and those of other  species, and combinations of video images with audio  recordings of spider courtship vibration ""songs"", will test  hypotheses about the cues involved in species recognition.  Results of this research will allow a better understanding  of the mechanisms involved in species recognition in  animals.  This research will also contribute to the growing  knowledge about spiders, an ecologically important group of  invertebrate predators whose basic biology is less known  than other taxa.  Additionally, this research involves the  continuing development of a computer-assisted technique for  studying behavior which may be applicable to other species  and research questions in animal behavior (mate choice,  agonistic behavior, visual perception, neuroethology) and  other fields (image recogn ition, artificial intelligence)."
1049363,RAPID:  Gulf Coast Oil Spill Biodiversity Tracker. A Volunteer-based Observation Network to Monitor the Impact of Oil on Organisms along the Gulf Coast,DBI,Global Systems Science,9/1/2010,8/17/2010,Steven Kelling,"Kelling, S","Kelling, S",NY,Cornell University,Standard Grant,Julie Dickerson,8/31/2012,"$195,595.00 ",,stk2@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,BIO,7978,"1165, 5987, 7914, 9183, 9184, BIOT",$0.00 ,normalFunding,"In response to the Deep Horizon oil spill in the Gulf of Mexico, Cornell University is awarded a RAPID grant to develop information infrastructure that enhances our ability to provide information on the impact of the oil spill.  The project uses Internet and information technologies to engage volunteers in providing critically needed data to assess the impact of the oil spill on wildlife and the environment through time. The Biodiversity Tracker will expand the capabilities currently provided by eBird (www.ebird.org), which uses a network of volunteers to survey beaches and marshes for birds. These data are displayed on real-time, interactive maps showing locations of reported birds in relation to current and forecasted oil slick locations. Expanded capabilities will include online data forms and maps to collect and display information on oiled birds, other wildlife affected by the oil spill, and beach conditions; outreach support to engage more participants; and open access to all data through the Avian Knowledge Network (www.avianknowledge.net) and DataONE (dataone.org).<br/><br/><br/>The oil spill disaster in the Gulf of Mexico will affect the region's biodiversity and ecology for years to come. Understanding this impact requires documenting the spill's effects on wildlife and the environment throughout the entire region, yet traditional biodiversity monitoring and inventorying approaches are inadequate to gather the vast amounts of data needed. The Gulf Coast Oil Spill Biodiversity Tracker engages citizen-science participants in gathering these data and makes the information publicly accessible through interactive online maps and databases. These data will enable quick responses for scientific and conservation efforts and will provide a fundamental data resource needed to monitor ongoing impacts from the disaster."
1552238,Computation of crowded geodesics on the universal Teichmueller space for planar shape matching in computer vision,DMS,"APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS",6/30/2015,9/15/2015,Akil Narayan,"Narayan, A","Narayan, A",UT,University of Utah,Continuing grant,Leland M. Jameson,7/31/2017,"$195,562.00 ",,akil@sci.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,MPS,"1266, 1271","9150, 9263",$0.00 ,normalFunding,"Quantifying the (dis)similarity between two shapes is a central problem in computer vision. One distance metric on the space of planar shapes is realized by identifying this space as a subset of the Universal Teichmueller Space, and equipping it with the Weil-Petersson metric. This results in a metric that is scale- and translation-invariant on shapes, and has unique geodesic flow between two shape endpoints. The work of this proposal develops robust computational methods for the computation of metric distances and geodesics between shapes on this space. The major difficulty lies in computations involving ""crowded"" shapes, i.e., those with elongated, winding, or extended protrusions. Such shapes stymie finite-precision computations because direct algorithms suffer from severe roundoff error. The major thrusts of this proposal develop algorithmic methodologies to address roundoff error and related issues: The Zipper conformal mapping algorithm will be augmented to produce accurate conformal maps for crowded shapes. The velocity field representation on a geodesic will be rewritten into a form that is resistant to roundoff error. The geodesic equation will be transformed into a expression that takes advantage of the aforementioned velocity field transformation, and can effectively flow between crowded shapes. The final phase of this project will demonstrate accurate geodesic flow and distance computations between crowded shapes. The methods developed under this project can be applied to several related problems in scientific computing: solutions to differential equations on irregular geometries through conformal mapping, conservative integration methods with ill-conditioned particle systems, and moving-mesh kernel approximations.<br/><br/>The work of this project can contribute to far-reaching applications in scientific and computer vision problems: automated object recognition (e.g. projectile identification), outline classification (determination of an animal's species), medical imaging (usage of MRI to diagnose dementia and related diseases), and artificial intelligence (visual recognition and interpretation) to name a few. All computational deliverables (computer code, example simulations, documentation) will be made publicly available. Through the engagement of students in related research tasks, this project will contribute to the educational development of future engineers, mathematicians, and computer scientists."
958576,"II-NEW: Acquiring infrastructure for Artificial Intelligence, Natural Language Processing and Information Retrieval",CNS,COMPUTING RES INFRASTRUCTURE,5/1/2010,3/3/2010,Jugal Kalita,"Kalita, J","Kalita, J|Hines, L|Stavrositu, C",CO,University of Colorado at Colorado Springs,Standard Grant,Vijayalakshmi Atluri,4/30/2012,"$195,051.00 ","Lisa Hines, Carmen Stavrositu",jkalita@uccs.edu,"1420, Austin Bluffs Parkway",Colorado Springs,CO,809183733,7192553153,CSE,7359,"9218, HPCC",$0.00 ,normalFunding,"This proposal seeks to obtain funding to acquire computing<br/>infrastructure to perform cross-disciplinary research in artificial<br/>intelligence, natural language processing, bioinformatics, social<br/>networks and related fields. In particular, the projects that will<br/>be supported by the infrastructure acquired include developing algorithms<br/>and architectures for large-scale ontology alignment, particularly in<br/>the biomedical domain; mining Wikipedia and similar Web-based sources<br/>for geographical, temporal and ontological information; performing<br/>named entity recognition in biomedical and other domains; performing<br/>computational motivational and content analysis of socially generated<br/>content such a blogs and micro-blogs; undertaking corpus-based computational<br/>linguistics research in under-studied and possibly endangered languages from<br/>India and other locations; developing better-performing algorithms for gene<br/>expression analysis; and developing, implementing and comparing algorithms<br/>for protein structure prediction, particularly proteins that contain<br/>coiled-coil structures. These projects deal with large amounts of data<br/>and information and processing such data and information requires large<br/>amounts of computing power. Our proposal seeks to acquire adequate and<br/>flexible computing hardware to facilitate problem-solving in these and other<br/>areas, so that current and future problems can be solved felicitously. <br/><br/>The infrastructure acquired will enable cutting-edge research by Ph.D.,<br/>Masters and undergraduate students, including REU site students, in a<br/>variety of cross-disciplinary topics that employ ideas and innovations<br/>in artificial intelligence, machine learning and information retrieval.<br/>For example, the results of our research may enable creations of systems<br/>that discover overlaps and matches among large medical ontologies so that<br/>painstakingly created domain-specific information can be fused, compared<br/>and utilized better; and may assist in creating programs that assist in<br/>automatically understanding and/or visualizing content of socially-generated<br/>Websites such as Wikipedia and Twitter.<br/><br/>For further information see the project web site at the URL:<br/>http://www.cs.uccs.edu/~kalita."
1757520,SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention,IIS,Smart and Connected Health,8/18/2017,9/20/2017,Peter Pirolli,"Pirolli, P","Pirolli, P",FL,"Florida Institute for Human and Machine Cognition, Inc.",Standard Grant,Sylvia J. Spengler,9/30/2018,"$192,193.00 ",,ppirolli@ihmc.us,40 S. Alcaniz St.,Pensacola,FL,325026008,8502024473,CSE,8018,"8018, 8062, 9251",$0.00 ,normalFunding,"Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br/><br/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups.  Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br/><br/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory."
1142510,"Collaborative Research: EAGER: Network for Science, Engineering, Arts and Design (NSEAD)",IIS,Cyber-Human Systems (CHS),8/1/2011,7/14/2011,Carol LaFayette,"LaFayette, C","LaFayette, C",TX,Texas A&M Research Foundation,Standard Grant,Kevin Crowston,7/31/2013,"$190,050.00 ",,lurleen@viz.tamu.edu,"400 Harvey Mitchell Parkway, S",College Station,TX,778454321,9798458600,CSE,7367,"7367, 7916",$0.00 ,normalFunding,"The Network to support Science, Engineering, Arts and Design (NSEAD) will support transformative research and pedagogy that are only possible through the combined expertise of diverse knowledge domains and disciplines. For example, as physicists and engineers developed new imaging techniques, visual artists experimented with the new expressive potentials they enabled, often influencing development of the technologies. Visual artists and musicians have created and continue to create computer languages and algorithms while pushing technologies for composing and recording in fields of software engineering, artificial intelligence, graphics and visualization. Students who are involved in the arts have higher math, verbal, and composite SAT scores than students who are not involved in the arts. (Vaughn and Winner, 2000). There is a growing movement by higher education academic institutions in the United States to integrate the Arts and STEM disciplines to educate the whole student while leveraging creative cognitive skills for solving complex problems in science and technology disciplines. And finally, diverse ecosystem of academic programs in pre-K to gray formal and informal STEM learning; scientific research conferences; exhibitions, and cultural institution programs continues to emerge as new information technologies, creativity support and social networking tools become pervasive in our society. This project envisions a network that addresses fundamental challenges including the need to align academic pedagogies with 21st century thinking skills; to promote diversity of perspectives, approaches, and people in the creative information technology economy; and to benchmark best practices that create critical thinkers and leaders for the ever-changing technology-driven job market. The development of such a network will provide a platform to disseminate and generate public dialogue about the intellectual, cultural, and economic potential of intersections of science, technology and creativity. <br/><br/>NSEAD will be a platform to support the burgeoning research community of Computer Scientists, Engineers, Artists and Designers engaged in integrative research and pedagogy across these disciplines. NSEAD will provide a bridge for academic institutions, non-profit organizations, industry liaisons, and resource providers to collaborate, share best practices in research and pedagogy, and build stronger affinities. It will serve as a junction for elements such as: 1) research community development; 2) collaboration and project matchmaking opportunities; 3) skills expertise referrals; 4) inter-institutional collaborations; 5) forums to share best practices in pre-K to gray STEM learning and creative enrichment; and 6) strategies for network leadership and resource sustainability."
424919,CAREER: Role of Spatiotemporal and Identity Continuity in Object Constancy,BCS,"HUMAN COGNITION & PERCEPTION, PERCEPTION, ACTION & COGNITION",1/20/2004,5/26/2005,Anne Hillstrom,"Hillstrom, A","Hillstrom, A",VA,George Mason University,Continuing grant,Amber L. Story,7/31/2006,"$189,500.00 ",,ahillstr@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,SBE,"1180, 7252","0000, 1045, 1187, OTHR",$0.00 ,normalFunding,"Philosophers, artists, and scientists for centuries have thought about how people organize the continuous flow of information reaching our sensory organs into discrete, individuated perceptual objects. As advances have been made in understanding vision, this topic has reemerged in cognitive psychology, artificial intelligence, and neuroscience. An object is individuated when the observer (1) perceives its features as belonging to a connected unit, (2) perceives its features as separate from things that are not part of the object, and (3) perceives that it is or is not something that was present sometime in the recent or distant past. An object that is believed to be the same even when it undergoes changes exhibits what is called object constancy. Much of what we know about object individuation and constancy in adult perception has been based on self-report methods. This research will explore the nature of object individuation and object constancy in tasks in which observers are attending to an object but are unlikely to be reasoning about its individuality or constancy. The research will employ a variety of tasks that have been developed in recent years to demonstrate ways in which attention to objects differs from attention to the space that objects occupy. The research will determine whether attention to objects is affected by disruptions to identity continuity or spatiotemporal continuity (i.e., the degree to which it is consistently present and moves through space in a physically possible way). By exploring which discontinuities disrupt attention to objects, the research will establish which continuities are critical to object constancy. In real scenes, spatiotemporal and identity discontinuity rarely are independent of each other. In contrast, this research will take advantage of media special effects that can dissociate them. For example, spatiotemporal discontinuity will sometimes be accomplished by an identifiable object disappearing unexpectedly and reappearing abruptly, and identity discontinuity will sometimes be accomplished by one object morphing smoothly into another. One part of the project will build on previous findings that once one part of an object is attended, it is easier to detect a subsequently presented target feature when it is elsewhere within the attended object rather than equidistant from the attended location but in another object. This project will investigate what disrupts this same-object benefit. For instance, spatiotemporal changes or identity discontinuities will be introduced to the cued or uncued object between the time the cue is presented and the time the target is presented, to see if the same-object benefit is disrupted. The research will also look for disruptions in speed and accuracy of responses to the display. Finally, it will also explore how eye movements are affected by the discontinuities. The direct goal of this research is to understand the fundamental nature of object constancy and individuation. However the results of the research will also have implications for engineering robotic systems that use machine vision to guide manipulation of dynamic objects. Such robotic systems need to differentiate which parts of visual information belong to coherent objects and which belong to different objects. In a different realm, knowledge of what sorts of changes distract people who are processing dynamic displays will aid designers of videos understand how special effects can be used to guide people's attention."
1744077,XPS: DSD: Collaborative Research: NeoNexus: The Next-generation Information Processing System across Digital and Neuromorphic Computing Domains,CCF,Exploiting Parallel&Scalabilty,5/1/2017,5/23/2017,Hai Li,"Li, H","Li, H",NC,Duke University,Standard Grant,Yuanyuan Yang,8/31/2018,"$189,019.00 ",,hai.li@duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,8283,,$0.00 ,normalFunding,"The explosion of ""big data"" applications imposes severe challenges of data processing speed and scalability on traditional computer systems. The performance of traditional Von Neumann machines is greatly hindered by the increasing performance gap between CPU and memory, motivating the active research on new or alternative computing architectures. By imitating brain's naturally massive parallel architecture with closely coupled memory and computing as well as the unique analog domain operations, neuromorphic computing systems are anticipated to deliver superior speed for applications in image recognition and natural language understanding.<br/><br/>The objective of this research is to establish the fundamental framework and design methodology for NeoNexus -- the next-generation information processing system inspired by human neocortex. It integrates neuromorphic computing accelerators with conventional computing resources by leveraging large scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays. The computation and data exchange will be carefully coordinated and supported by the innovative interconnect architecture, i.e., a hierarchical network-on-chip (NoC). The software-hardware co-design platform will be developed to address the various design challenges. The project will help computer architecture and high-performance computing communities to overcome the ever-increasing technical challenges of traditional architectures and accelerate the fusion between conventional computing technology and cognitive computing model. It will also promote the applications of artificial intelligence technology advances in modern computer architectures and motivate the inventions at both software and hardware levels. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce."
351442,Computational Properties of Human Auditory Cortex,BCS,COGNEURO,6/1/2004,8/28/2004,John Belliveau,"Belliveau, J","Belliveau, J|Ahveninen, J",MA,Massachusetts General Hospital,Standard Grant,Michael E. Smith,5/31/2005,"$187,890.00 ",Jyrki Ahveninen,jack@NMR.MGH.Harvard.EDU,Research Management,Somerville,MA,21451446,8572821670,SBE,1699,"0000, OTHR",$0.00 ,normalFunding,"One's ability to extract relevant sounds from naturally overflowing acoustic stimulation requires efficient analysis of their identity and spatial origin. For example, concentrating on a particular spoken message in a noisy environment, filled with distracting sounds of other conversations, would be impossible without these essential brain functions. With National Science Foundation funding, Dr. John W. Belliveau is conducting research towards better understanding of how the human auditory system processes sound identity (""what"") and location (""where"") information. He is investigating how selective attention to sound identity or location modulates the putative ""what"" and ""where"" processing pathways in the human auditory system. To accomplish these goals, the researchers utilize spatiotemporal modeling of human brain activity, which combines spatially specific functional magnetic resonance imaging (fMRI) with temporally accurate magnetoencephaolographic/electroencephalographic (MEG/EEG) measures of brain function.<br/><br/>The broader impacts of this project include free distribution of developed software/algorithms, and advanced training of researchers in the field of cognitive neuroimaging. Empirical information on the auditory-cortex 'what' and 'where' pathways will be incorporated into computational models of human auditory processing. Advanced models of brain function may ultimately benefit biological cybernetics, artificial intelligence, and robotics applications."
963451,Collaborative Research: Measuring Collective Intelligence,IIS,Cyber-Human Systems (CHS),1/1/2010,1/11/2010,Anita Woolley,"Woolley, A","Woolley, A",PA,Carnegie-Mellon University,Standard Grant,Ephraim P. Glinert,12/31/2012,"$187,633.00 ",,awoolley@cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,7367,"9215, HPCC",$0.00 ,normalFunding,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research. But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence. One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College. The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems. For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups. Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups. Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups. A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems. This research will provide powerful new tools for managing and designing such systems. Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors. Imagine that this test could predict the team's future performance on a wide range of important tasks. And imagine that the test could also help suggest changes to the team that would improve its flexibility. Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks. From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently. This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts: With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it. With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems. The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
1726047,Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students,DUE,IUSE,9/1/2017,7/21/2017,Kimberly Talley,"Talley, K","Talley, K",TX,Texas State University - San Marcos,Standard Grant,Heather Watson,8/31/2022,"$184,034.00 ",,kgt5@txstate.edu,601 University Drive,San Marcos,TX,786664616,5122452314,EHR,1998,"8209, 8238, 8244, 9178",$0.00 ,normalFunding,"Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
1159008,IRFP: Deep Neural Networks for Perception and Action Integration in Robotic Control,OISE,IRFP,6/1/2013,5/27/2015,Alan Lockett,"Lockett, A","Lockett, A",TX,Lockett                 Alan           J,Fellowship,Cassandra M. Dudka,7/31/2016,"$183,808.00 ",,,,Austin,TX,787490000,,O/D,5956,"5950, 5956",$0.00 ,normalFunding,"The International Research Fellowship Program enables U.S. scientists and engineers to conduct nine to twenty-four months of research abroad. The program's awards provide opportunities for joint research, and the use of unique or complementary facilities, expertise and experimental conditions abroad. <br/><br/>This award will support a twenty-four-month research fellowship by Dr. Alan Lockett to work with Professor Juergen Schmidhuber at the Instituto dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA) in Lugano, Switzerland. <br/><br/>This project explores methods for training deep neural networks to control a physical robot with humanoid hands and arms. The recent development of new methods for training deep artificial neural networks has resulted in breakthroughs on a number of benchmarks in artificial intelligence. Deep neural networks currently hold the record for benchmark predictive tasks including handwriting recognition (MNIST) and object recognition (NORB, CIFAR-10). <br/><br/>This project is developing methods for training deep neural network controllers with thousands or millions of parameters using an array of massively multiprocessor GPUs with over 4,096 processors. Deep network controllers in this research are trained using neuroevolution, reinforcement learning, and combinations of the two. Such controllers are being used to train a humanoid iCub robot to manipulate objects for the AAAI Small-Scale Manipulation Challenge.<br/><br/>The research is being performed at the Instituto dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA) in Lugano, Switzerland in conjunction with Professor Juergen Schmidhuber. IDSIA is a leading research institution in the study of deep neural networks, artificial evolution, reinforcement learning, and robotic control. <br/><br/>This research seeks to advance our understanding of robotic control in general. The focus on deep neural networks that integrate hierarchical perception and action modules has the potential to result in breakthroughs in control of complex robotic systems that would enable the deployment of computer and robotic systems that operate with greater autonomy than is currently possible.<br/><br/>The deployment of robotic technologies over the course of the next century is likely to mirror the rapid introduction of computer technology in the past century.  Behind the success of these robots will be deep hierarchical control systems that integrate perception and action at a high level of abstraction, as studied in this research. This research examines technologies that hold the potential to transform and improve our lives in innumerable ways. In the future, self-driving cars will co-ordinate with each other and with an active roadway to minimize accidents and improve efficiency. Advanced autopilot technology will finally make personal flying vehicles a reality. Autonomous robotic miners will reduce risk to humans while improving access to raw materials and resources. Robotic surgeons will perform complex operations with new levels of precision. Each of these technologies depends critically on the availability of deep integration of perceptual analysis and hierarchical controllers. The use of deep neural networks like the ones studied in the proposed research constitutes a promising approach to bringing these new technologies out of the lab and into our daily lives."
1657598,CRII: AF: Characterization and Complexity of Information Elicitation,CCF,"CRII CISE Research Initiation, ALGORITHMIC FOUNDATIONS",6/1/2017,5/29/2018,Rafael Frongillo,"Frongillo, R","Frongillo, R",CO,University of Colorado at Boulder,Standard Grant,Tracy J. Kimbrel,5/31/2019,"$182,300.00 ",,raf@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,"026Y, 7796","7796, 7932, 8228, 9251",$0.00 ,normalFunding,"The way one judges the accuracy of predictions can greatly impact what predictions people or computers make.  For example, Glenn Brier argued in 1950 that the way meteorologists were evaluated would actually give them an incentive to distort the true probability of rain.  Brier's study inspired a growing body of work in statistics, economics, and now computer science, which studies evaluation metrics that incentivize accurate reports from people or machines.  These evaluation metrics are also used in machine learning, a branch of artificial intelligence, where a designer implicitly tells the computer what statistic to predict by providing only the evaluation metric itself.  This project seeks to mathematically characterize this link between statistics and evaluation metrics, and moreover, to understand the computational and statistical difficulty of evaluating different statistics.  A precise understanding of this link would provide new evaluation metrics with the potential to increase predictive power across a vast array of applications such as climate simulations and smart cities.  In particular, metrics for statistics that quantify uncertainty or risk could improve decision making in many fields, including healthcare, engineering, and finance.<br/><br/>A dominant algorithmic paradigm in machine learning, encompassing most regression techniques and classification algorithms, is that of empirical risk minimization (ERM): choosing a model from some class that best fits the data, according to some evaluation metric called a loss function.  A thread of research in theoretical machine learning called property elicitation gives a mathematical formalism to describe the link between loss functions and their corresponding statistics.  In these terms, this project seeks to characterize the statistics which have calibrated loss functions, and determine how many regression parameters or data points are required for the calibration to hold.  These questions are particularly relevant to machine learning when restricting attention to certain classes of loss functions which can be easily optimized or which have desirable statistical learning guarantees.  The class of statistics from mathematical finance known as risk measures, which are used to regulate banks, form an important focus of the project."
9357851,NYI:  High Performance Automated Reasoning and its          Applications,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT, CISE RESEARCH RESOURCES",8/1/1993,2/14/2000,Hantao Zhang,"Zhang, H","Zhang, H",IA,University of Iowa,Continuing grant,William Randolph Franklin,1/31/2001,"$180,285.00 ",,hzhang@cs.uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,"2865, 2890","2865, 2891, 9216, 9297, HPCC",$0.00 ,normalFunding,"9357851  Zhang  Reasoning algorithms are used in many application areas of  computer science and artificial intelligence, and high  performance of reasoning algorithms is indispensable to the  successes of these applications.  The objectives of this research  are to develop high performance reasoning algorithms, and to  apply these algorithms in formal verification of hardware and  software designs.  This research will substantially improve the  performance of a software system called RRL (Rewrite Rule  Laboratory) by adding new reasoning algorithms into it, and by  building new applications on the top of it.    The research will focus on redundance control of automated  deduction and mathematical induction, and efficient  representation of data structures.  The topics include restricted  inference rules, powerful simplification rules, unnecessary  computation detection, induction schemata formulation, induction  hypotheses handling, and efficient implementations of all the  involved algorithms.  Practical verification problems will be  chosen from software and hardware design as test problems for RRL  and RRL will be enhanced to meet the need of large-scale  applications by providing failure-resistant and user-friendly  interfaces.  Special effort will be made on distributing RRL  world-wide to the people who are interested in using RRL as  either a research tool or a teaching tool in automated reasoning.  ***"
643266,Semantic and Contextual Composition: Processing and Neurological Underpinnings,BCS,LINGUISTICS,3/15/2008,1/17/2013,Maria Pinango,"Pinango, M","Pinango, M|Constable, R",CT,Yale University,Continuing grant,Joan Maling,2/28/2014,"$180,000.00 ",Robert Constable,maria.pinango@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,SBE,1311,"0000, OTHR",$0.00 ,normalFunding,"Through a series of psychological and neuroimaging studies Dr. Maria M. Pinango will investigate how and where the brain decodes the information of a sentence in real-time, that is, as the sentence unfolds. Two experimental lines will be carried out: a psychological line and a neuroimaging line. Through the psychological line she will determine how the comprehension system reveals the processing of the different kinds of information contained in a sentence: syntactic, semantic and conceptual. Pinango's research model predicts that information about sentence structure (syntactic) is done immediately and with no cost, whereas information about the meaning information (semantic) takes time to develop and demands more computation. Finally, Pinango's model predicts that the process of placing the content of a sentence (conceptual information) into the larger context of what speakers know about the world is yet a costlier process as it requires the comprehension system to leave the language system and place the meaning of the sentence into the larger and richer conceptual system. Through the neuroimaging (functional magnetic resonance imaging) line it will be determined how and where in the brain this parallel decoding of syntactic, semantic and conceptual information takes place. <br/><br/><br/><br/>This research connects to important questions in linguistics, artificial intelligence, cognitive neurology and neuroscience. On the medical side, the research has implications for the study of brain pathologies as it seeks to answer the question of why on the one hand, special populations such as Alzheimer's patients, Schizophrenia patients have what appear to be intact linguistic ability yet are unable to fully comprehend sentences and, why on the other, cerebro-vascular patients such as Broca's aphasic patients have true linguistic impairments yet are able to show normal-like sentence comprehension. The project provides a unique opportunity for undergraduate students to receive intensive training in the demanding task of investigating a model of linguistic organization from the perspective of brain organization. In doing so it supports the crucial collaboration between researchers in linguistics and neuroscience at Yale University."
1548781,SBIR Phase I: A Novel Experiential Learning Toy Teaching Robotics and Automation to K-12 Students,IIP,SMALL BUSINESS PHASE I,1/1/2016,6/9/2016,Woo Ho Lee,"Lee, WH","Lee, WH",TX,TechComb LLC,Standard Grant,Glenn H. Larsen,12/31/2016,"$179,999.00 ",,wooholee@icloud.com,8220 Snow Goose Way,Fort Worth,TX,761182004,9728416758,ENG,5371,"079E, 5371, 8031, 8032, 8039",$0.00 ,normalFunding,"This SBIR Phase I project is to raise awareness and enthusiasm for Science, Technology, Engineering, and Mathematics (STEM) education among young children through experiential learning enabled by novel and interactive robotic toys. U.S. Department of Labor's recent survey reports that only 5% of U.S. workers are employed in science and engineering fields, yet they are responsible for more than 50% of the sustained economic expansion. Over the past few decades the U.S. contribution to the number of scientists and engineers worldwide has reduced from 40% to 15%. Interestingly, there is a high interest among young students for the STEM fields but approximately 40% of them end up switching to non-STEM careers by the time they graduate from college - according to the President's Council of Advisors on Science and Technology. This project brings a radical change in this trend by aptly stimulating the curiosity and challenging the intelligence, the key catalysts for continued interest, in K-12 students. Through innovative and intelligent hardware and software modules, this project delivers an enhanced learning experience on next generation robotics and automation technologies in the classroom as well as at home, leading towards a much richer and secure prospect for the future tax payers.<br/><br/>This SBIR Phase I project develops an interactive and reconfigurable robotics-learning system comprised of smart positioning modules and interconnects. The key innovations include: a zero nuts-and-bolts architecture for quick and easy system setup, distributed artificial intelligence for interactive plug-n-play operations, and personalized gaming and learning feature to engage different age groups, experience levels, and study areas. This gaming and learning system aids in understanding various concepts of new age manufacturing, shaped by rapidly evolving economic constraints, including but not limited to: challenges in flexible/lean manufacturing for low cost and rapid turnaround production; effects of source agnostic automation, where robots/tools from different manufacturers are combined, on overall manufacturing metrics; and difficulties associated with robot cooperative control with limited feedback in complex operations. Such knowledge, gained through hands-on learning, better prepares the future scientists and engineers to not only adapt in the highly demanding manufacturing environment of the future but also explore innovative solutions to complex technical problems. This project envisions to significantly surpass the learning experience offered by contemporary educational toys, including passive building sets, jigsaw puzzles, rule-based interactive toys and so on, by delivering a highly immersed, actively encouraging, and truly exploratory experience for the makers of tomorrow."
1441291,"EXP: Collaborative Research: PerSketchTivity- Empowering and Inspiring Creative, Competent, Communicative, and Effective Engineers through Perspective Sketching",IIS,Cyberlearn & Future Learn Tech,9/1/2014,8/22/2014,Julie Linsey,"Linsey, J","Linsey, J|Li, W",GA,Georgia Tech Research Corporation,Standard Grant,Elliot Douglas,8/31/2018,"$179,999.00 ",Wayne Li,julie.linsey@me.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,8020,"8045, 8244, 8841",$0.00 ,normalFunding,"The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by building examples and studying their possibilities for fostering learning as well as challenges to using them well. This project examines whether technology can support learning to freehand sketch. Sketching has been demonstrated to play an important role in a number of domains, including engineering, and the ability to quickly sketch has been shown to improve creativity by making it easier for engineers to generate ideas and communicate them. This project will modify artificial intelligence tools that support recognizing sketches to directly help teach undergraduate engineers how to sketch well. Research studies will examine whether the tool helps students learn sketching skills, and importantly how it influences their spatial reasoning ability. Thus, if successful this research will not only create tools to allow people to learn to sketch better, but also will advance our understanding of how spatial reasoning and sketching are linked, and could eventually lead to more effective engineering education.<br/><br/>The project proposes two interconnected strands of work: developing the software tool and conducting research studies in the context of undergraduate engineering courses. The software tool will use a heterogenous set of classifiers to help provide feedback to learners as they perform a sequence of sketching exercises on tablets. The design process will iterate on the tool to explore what types of feedback are most helpful and how different classifiers can be used to detect different levels of sketching skill. The program of research will include studying whether sketching training leads to advances in spatial reasoning skills, whether it affects design self-efficacy and attitudes towards sketching, transfer of spatial skillsets to design activities in other courses, and how sketching skills correlate to success on spatial reasoning tasks.  In addition, through iterative development including user-centered design processes, design principles for sketching based tools will be derived. Data sources will include both qualitative and quantitative data such as pre- and post-test spatial reasoning tasks, structured interviews, surveys, and artifact analysis. Additionally, students (N=approximately 30-40) using the new tool in class will be compared to control cohorts of approximately 30 students who either use traditional engineering curricula (little free-hand sketching and some isometric drawing) and a sketching curriculum without the AI tool."
1520594,SBIR Phase I: An augmented learning platform for mobile devices,IIP,SMALL BUSINESS PHASE I,7/1/2015,12/10/2015,Tarun Pondicherry,"Pondicherry, T","Pondicherry, T",CA,"LightUp, Inc.",Standard Grant,Glenn H. Larsen,6/30/2016,"$179,999.00 ",,founders@lightup.io,5208 Lodestar Way,Elk Grove,CA,957586724,7327051198,ENG,5371,"163E, 5371, 8031, 8032, 8039, 9180",$0.00 ,normalFunding,"This SBIR Phase I project will develop and test the software foundation for a novel augmented learning platform enabled by today's mobile devices. While research has shown that project-based learning is crucial for children to understand science, technology, engineering and math (STEM) topics, it currently requires knowledgeable facilitators providing guidance to be effective. This greatly limits the feasibility of project-based learning in schools, homes and informal learning environments. Augmented learning platforms hold the potential to change this, but are not widely deployed because they typically require expensive and unwieldy table top displays. The technology being developed in this project turns any mobile device into an augmented learning platform, transforming ordinary hands-on learning environments into interactive experiences by enhancing them with digital information. This project aligns with the National Science Foundation's mission to support science and engineering education at all levels by developing a novel educational platform that opens up STEM topics to all children, regardless of their prior experience or learning environment. The smart education and learning market is valued at $122 billion (2014), meaning that the commercial success of this U.S.-based company selling through U.S. schools and retailers will positively impact both domestic tax revenue and jobs.<br/><br/>The augmented learning platform that will be developed in this project will enable project-based learning at an unprecedented scale. The platform will perform three tasks. It will employ computer vision to detect electronic circuits and convert them into a graph data structure. Then, it will use artificial intelligence and simulation to analyze the resulting graph data structure. Finally, it will provide feedback to users with an augmented reality overlay within a few milliseconds. The goal of the research is to develop and test this platform with the company's current users by integrating it into an electrical engineering tutor app and evaluating their engagement and learning outcome compared to pure hardware or software systems that teach engineering concepts. The system will initially be tested with data from automated mobile analytics tools from a wide-scale deployment to current users of the electrical engineering tutor app. In the future, the underlying technology can work with any subject that produces a graph data structure for analysis. The novel platform in this project enables every mobile device to be a learning platform, giving millions access to project-based learning."
1451571,EAGER: CortiCore - Exploring the Use of An Automata Processor as an MISD Accelerator,CCF,"ROBUST INTELLIGENCE, SOFTWARE & HARDWARE FOUNDATION",8/15/2014,6/14/2016,Kevin Skadron,"Skadron, K","Skadron, K|Skadron, K|Stan, M",VA,University of Virginia Main Campus,Standard Grant,Almadena Y. Chtchelkanova,12/31/2017,"$179,995.00 ","Kevin Skadron, Mircea Stan",skadron@cs.virginia.edu,P.O.  BOX 400195,CHARLOTTESVILLE,VA,229044195,4349244270,CSE,"7495, 7798","7916, 7941, 7942, 7943, 7944, 8091, 8206",$0.00 ,normalFunding,"A novel computational accelerator architecture - the Automata Processor -has recently been introduced by Micron, that extends the computational paradigm of non-deterministic finite automata with important new capabilities. This architecture is particularly well suited for tasks involving  pattern matching.  Preliminary results suggest speedups as high as 1000X are possible, especially applications that entail combinatorial search, i.e., searching among many possible patterns to find the best match.  This project evaluates the suitability of this novel architecture for accelerating combinatorial search, using cortical learning algorithms (i.e., algorithms for machine learning that are inspired by observations and/or theories of how the brain works) as a case study. Until now, cortical learning algorithms have primarily been implemented only in software, which leads to solutions that are slow, large, expensive and power hungry, and thus limits their applicability. In particular, this project initially focuses on accelerating hierarchical temporal memory, a cortical learning algorithm that has recently been shown to be highly effective for analysis and integration of high-data-rate, multi-modal sensor and video data. It embodies many characteristics of a variety of combinatorial search tasks, combining and extending techniques from Bayesian networks, clustering, and decision trees.  This project is the first to evaluate the ability of the ""enhanced automata"" paradigm to accelerate cortical learning algorithms, and one of the first to explore the capabilities of the Automata Processor. In the process of evaluating the best way to accelerate cortical learning algorithms, this project will yield insights into the suitability of the Automata Processor for other artificial intelligence algorithms. It will also lead to development of new algorithms, software libraries, programming guidelines, and a new programming interface, to help speed the mapping of other applications to the Automata Processor and future accelerators. It will also yield techniques to improve the performance, flexibility, and energy efficiency of future accelerators, and new insights into the design and programming of heterogeneous systems with diverse accelerator hardware units.<br/><br/> This project has potential to lay the foundations for a novel acceleration framework that enables efficient solutions to a large set of intractable problems, with orders-of-magnitude improvements in performance and energy efficiency, and to guide development of future accelerators. As a consequence of these acceleration capabilities, portable, low-power artificial intelligence solutions could become ubiquitous.  This project creates tools that facilitate research and product development involving accelerator-based computing.  This project contributes to education and outreach through new course materials and assignments, hands-on research and training opportunities in cutting-edge acceleration paradigms, and new academic-industry collaborations."
942454,"CCLI: Enhancing Expertise, Sociability and Literacy through Teaching Artificial Intelligence as a Lab Science",DUE,"S-STEM:SCHLR SCI TECH ENG&MATH, CCLI-Type 1 (Exploratory)",9/15/2010,6/30/2016,Stephanie August,"August, S","August, S",CA,Loyola Marymount University,Standard Grant,Victor P. Piotrowski,8/31/2016,"$179,897.00 ",,saugust@lmu.edu,One LMU Drive,Los Angeles,CA,900452659,3103384599,EHR,"1536, 7494","9178, SMET",$0.00 ,normalFunding,"Computer Engineering (32)<br/><br/>This proposal develops a new approach of teaching introductory Artificial Intelligence (AI) concepts through a laboratory experimentation approach.  Each topic includes several components that range from ""the concept in the real world"" through detailed code implementation.  The laboratory setting supports communication skills as well as software engineering and process understanding, and the laboratories cover a wide range of AI applications. The laboratory approach supports students who learn better in a social setting, including women students, or who learn better by reading and developing mental models.<br/><br/>The project has several components, including developing laboratory materials to be used in a sequence of lab exercises as the student works through the laboratory (including the basic concept, some applications of the concept, sample processing concepts, design description, code hints, test suites, experiments, full source code, and a complexity analysis).  It extends beyond that available through current repositories of AI materials. The project includes three workshops, which are primarily assessment activities where participants review course materials.  <br/><br/>The project develops a repository linked to an appropriate element of the NSDL and appropriate development of metadata is included.  Along with the repository, a mix of papers, conference presentations, and conference workshops make this available to the broader community."
821640,"MRI:    Acquisition of Instruments for Interaction, Learning, and Perception in Virtual Environments",CNS,MAJOR RESEARCH INSTRUMENTATION,8/1/2008,7/21/2008,Robert Bodenheimer,"Bodenheimer, R","Bodenheimer, R|Adams, J|McNamara, T|Rieser, J|Sarkar, N",TN,Vanderbilt University,Standard Grant,Rita V. Rodriguez,7/31/2011,"$179,651.00 ","Julie Adams, Timothy McNamara, John Rieser, Nilanjan Sarkar",bobbyb@vuse.vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,1189,"9150, 9218, HPCC",$0.00 ,normalFunding,"Proposal #: CNS 08-21640<br/>PI(s):  Bodenheimer, Robert E.<br/>  Adams, Julie A.; McNamara, Timothy P.; Rieser, John J.; Sarkar, Nilanjan<br/>Institution: Vanderbilt University <br/>  Nashville, TN 37235-7749<br/>Title:    MRI/Acq.: Instruments for Interaction, Learning, and Perception in Virtual Environments<br/>Project Proposed:<br/>This project, acquiring a high-fidelity instrument designed to facilitate and assess perception, interaction, and learning in immersive environments, pursues an ambitious research agenda dealing with people, their interactions with virtual environments, and the design factors underlying successful environments. The work aims to build a program to develop a better understanding of the cognitive capabilities of humans in immersive virtual environments, to inform the design process of such environments and to understand how humans reason about space. The instrument will be shared among diverse and interdisciplinary groups collaborating in the area of virtual environments, including Computer Science and Engineering (graphics, animation, artificial intelligence, human factors, robotic, etc.) and the Psychological Science (cognitive psychology, child development, rehabilitation engineering, brain sciences, etc.) The component parts of the instrument (comprising optical motion capture equipment, a head-mounted display with binocular eye-tracking, and high-performance wireless data gloves) allow the measurement, tracking, rendering, and animation of subjects in virtual environments (from their overall position, to their posture, to the actions of their hands and fingers) coupled with the measurement of their gaze. The project ranges from low-level research in how people experience virtual environments to user evaluations involving high-level interface and simulation design. Children with autism will also be studied.<br/>Broader Impacts: This project improves the quality of learning in virtual environments, reducing the time and cost of authoring and overcoming likely impediments to their widespread use. The instrument enables courses in robotics currently infeasible with real robots and provides experience for students. The work builds a scientific program to develop a better understanding of the cognitive capabilities of humans in immersive virtual environments and may be applied to understanding the development of children?s abilities to reason about space and to coordinate perceptual-motor skills as they develop. Moreover, it may help to treat autism spectral disorder.<br/>"
1315432,"SBIR Phase I: Virtualization Tolerant, High Performance Computing in Servers, Using Compute Intensive Multicore Accelerators",IIP,SMALL BUSINESS PHASE I,7/1/2013,1/23/2014,Jeff Brower,"Brower, J","Brower, J",TX,"Signalogic, Inc.",Standard Grant,Peter Atherton,6/30/2014,"$178,840.00 ",,dspinfo@signalogic.com,9617 Wendell Rd,Dallas,TX,752435510,2143495551,ENG,5371,"5371, 8032, 8039, 8040",$0.00 ,normalFunding,"The innovation addresses problems of data I/O inefficiency and virtualization in High Performance Computing (HPC). Conventional High Performance Computing (HPC) methods are both inefficient and incompatible with virtualization methods commonly used in servers, creating a roadblock to supercomputing server farms needed for practical AI (Artificial Intelligence) applications. GPU (Graphics Processor Unit) and ""many integrated x86 cores"" (many-x86) accelerators, while offering high performance, generate excessive heat, are physically large, and do not offer direct, high-speed, low-latency I/O. For example, GPU and many-x86 accelerator boards are full-length, double-wide, consume up to 300W, and do not connect high-speed, low-latency I/O directly between their compute cores and external networks. This project describes research and development efforts based on a novel approach combining arrays of high performance, low heat compute intensive multicore CPU accelerators with network I/O connected directly to the cores, and a superset of the popular OpenMP standard for multicore programming. Results will demonstrate the first fundamentally virtualization tolerant accelerator available on the market, using a single 1U server with (a) 2.5 Teraflop acceleration, (b) 450 W total power consumption, and (c) virtualization-compatible, OpenMP based programming model with high degree of ease-of-use and suitable for rapid adoption by AI application developers and programmers.<br/><br/>The broader/commercial impacts of the innovation include increased High Performance Computing (HPC) efficiency and virtualization compatibility in supercomputing server farm applications and enabling new Artificial Intelligence (AI) server farm applications. Commercial examples include practical AI applications that require real-time network data I/O, such as mobile device speech and face recognition, fast and automated analysis of drone and surveillance video (for example detecting human behavior and divining human intent in real-time), financial data modeling and trading network risk checks applied directly at the network edge, and real-time social media data analytics. Breakthroughs in HPC efficiency and virtualization will lead to greater scientific understanding of heterogeneous CPU systems, in this case x86 and ARM server motherboards combined with compute intensive multicore accelerators. The OpenMP programming model will be enhanced to allow compute-intensive, direct I/O cores and general-purpose x86 cores to coexist within a unified platform, under a standards-based model. A practical, scalable server acceleration paradigm will be demonstrated with four (4) compute intensive multicore CPU accelerators inserted in a 1U server, running video analytics and computational finance application examples."
9987898,Music Plus One: A System for Synthetic Musical Accompaniment,IIS,"STATISTICS, HUMAN COMPUTER INTER PROGRAM",8/1/2000,8/16/2001,Christopher Raphael,"Raphael, C","Raphael, C",MA,University of Massachusetts Amherst,Continuing grant,Mary P. Harper,1/31/2003,"$176,305.00 ",,craphael@indiana.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"1269, 6845","9216, HPCC",$0.00 ,normalFunding,"This research focuses on creating a computer system that serves as musical accompanist in non-improvised music for soloist and accompaniment.  The system will ""hear"" the soloist by performing a real-time analysis of the acoustic signal to determine when important musical events take place.  As the piece of music is rehearsed, the system will train a probabilistic model of the soloist's rhythmic interpretation;   it will understand both what it ""knows"" and what it ""doesn't know"" about the soloist's interpretation by modeling both mean behavior and covariance structure.   The predictive power of this model will be combined with the real-time signal analysis to enable the  system both to follow and to anticipate the soloist.   In addition, the system will be presented with expressively played examples of the accompaniment and will train and utilize a model of the accompaniment's musical interpretation based on these.  The goal is to create a system that demonstrates both the technique and musicality necessary to achieve a high level of music-making.   From a modeling point of view, the primary challenge is one of knowledge fusion.  The system is faced with a number of disparate sources of knowledge including the musical score, the real-time analysis of the soloist's acoustic signal, training data from the past rehearsals, and inherent musical  constraints on the accompaniment.  A probabilistic model, a Bayesian Belief Network (BBN), will be developed that incorporates and balances these knowledge sources in a way that is musically believable,  automatically trainable, and computationally efficient.   The resulting system will be an invaluable teaching tool, as well as an aid to musicians preparing for performance.   The approach should be applicable to other domains as well.  Finally, if such an accompaniment system passes the musical equivalent of the ""Turing Test"" it would comprise a new and unexpected data point to be considered in our evolving understanding of the bounds of human and artificial intelligence."
647018,REU Sites: Collaborative Research: Advances of Machine Learning in Theory & Applications (AMALTHEA),IIS,RSCH EXPER FOR UNDERGRAD SITES,3/1/2007,9/26/2013,Georgios Anagnostopoulos,"Anagnostopoulos, G","Anagnostopoulos, G|Kepuska, V",FL,Florida Institute of Technology,Standard Grant,Maria Zemankova,2/28/2014,"$176,172.00 ",Veton Kepuska,georgio@fit.edu,150 W UNIVERSITY BLVD,MELBOURNE,FL,329016975,3216748000,CSE,1139,"9178, 9218, 9250, HPCC, SMET",$0.00 ,normalFunding,"Title: REU Site: Collaborative Research: Advances of Machine Learning in Theory and Applications (AMALTHEA)<br/><br/>PI: Georgios C Anagnostopoulos <br/>Institution: Florida Institute of Technology<br/><br/>PI: Michael Georgiopoulos<br/>Institution: University of Central Florida<br/><br/>AMALTHEA is a collaborative effort between two closely-located universities, Florida Institute of Technology in Melbourne and University of Central Florida in Orlando, Florida. The project seeks to provide top quality educational experiences to a diverse community of learners through research participation in the area of Machine Learning (ML). Machine Learning is nowadays a high-importance, ever- expanding discipline that draws concepts from a variety of fields, including artificial intelligence, cognitive sciences, information theory, statistics, mathematics, physics, philosophy and biology among others. On the other hand, automatic target recognition, earthquake prediction, gene expression discovery, intelligent credit fraud protection and affectionate computing, to mention just a few, are examples of cutting-edge applications of ML in various technological and scientific domains. The project's thrust area is the theory of ML and how it can be integrated and applied to important real-life problems, thus exposing participants to both theory and applications.<br/><br/>AMALTHEA involves ten undergraduate students annually in ML research over ten weeks in the summer. Overall, the project will impact a diverse group of 30 students, as well as 12 graduate students, which will participate in undergraduate teaching and mentoring activities. <br/>The undergraduate students perform supervised research on ML topics that have the potential to impact the field of ML itself, as well as how ML is applied to other scientific disciplines. REU research results are expected to be published in interdisciplinary conferences, and, potentially, technical journals. Additionally, these REU research advances are fed back and integrated into the teaching of ML-related courses at the partnering institutions.<br/><br/>The project involves four faculty who have significant overall experience in ML research and education; they have mentored over 50 undergraduates in research and co-authored over 20 conference and journal papers with them. The project is also supported in its endeavors by an actively participating Advisory Board consisting of industry and government professionals with interest and expertise in ML.<br/><br/>URL: http://my.fit.edu/amalthea"
1565516,CRII: CIF: Fast Algorithms for Learning Graphical Models from Scarce Data,CCF,,3/1/2016,2/16/2016,Guy Bresler,"Bresler, G","Bresler, G",MA,Massachusetts Institute of Technology,Standard Grant,Richard Brown,2/28/2018,"$175,000.00 ",,guy@MIT.EDU,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,026y,"7797, 7936, 8089, 8228",$0.00 ,normalFunding,"Graphical models (GMs) are a powerful framework used to succinctly represent complex high-dimensional phenomena. Statistical dependence between variables is represented combinatorially via edges in a graph, and this allows both model interpretability and computationally efficient inference. For these reasons, GMs are at the core of machine learning and artificial intelligence and have been used in a variety of applied fields, including finance, operations research, biology, signal processing, and social networks. For large complex data with non-obvious structure, the central problem is that of learning an appropriate model. Learning a graphical model presents both a computational and statistical challenge. The combinatorial nature of the problem means that there are a huge number of possible models to explore. At the same time, the high-dimensional nature of modern applications means that the number of data-points is often much smaller than the dimension of the ambient parameter space: learning algorithms must therefore make efficient use of the data, which is scarce relative to the problem size. Existing approaches to learning graphical models achieve either statistical efficiency or computational efficiency, but not both.<br/><br/>This research aims for the best of both worlds: extreme computational and statistical efficiency. While practical applications demand such efficiency, it is unlikely to be attainable in complete generality, for all models. The question is, what features of real-world systems allow for tractable learning? The research entails identifying specific model subclasses of interest and developing algorithms with provable performance guarantees. Concretely, the research provides new information-theoretic lower bounds on the amount of data required to learn, and informed by these lower bounds, gives fast (computationally efficient) algorithms that are statistically near optimal."
9806389,Pseudo-Boolean Functions: Representations and Optimization,DMS,COMPUTATIONAL MATHEMATICS,9/1/1998,8/20/1998,Peter Hammer,"Hammer, P","Hammer, P|Boros, E",NJ,Rutgers University New Brunswick,Standard Grant,John C. Strikwerda,8/31/2001,"$175,000.00 ",Endre Boros,hammer@rutcor.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,MPS,1271,"0000, 9263, OTHR",$0.00 ,normalFunding,"9806389<br/>Peter L. Hammer<br/><br/>Numerous problems in area as diverse as VLSI design, game theory, artificial intelligence, neural networks, operations research, statistics, reliability, and finance can be modeled by using set functions, i.e., mappings of the subsets of a finite set into the reals. It was noticed in the mid-60's by the PI that set functions can be viewed as ""pseudo-Boolean"" functions, i.e., real valued functions with 0-1 variables, and can be represented as multilinear polynomials. It was noticed along the years that beside their polynomial representation, pseudo-Boolean functions admit also other algebraic representations, e.g., as additive posiforms, as logical posiforms, etc. It also turns out that various types of applications may lead naturally to various types of representations. Also, it can be seen that the solution of some of the most important problems concerning pseudo-Boolean problems (finding a global optimum, finding a local optimum, approximating the optimum, finding a good approximation of the functions, finding a good majorant or minorant of the function) depends heavily on the particular representation used. In this proposal the investigators will deal mostly with the optimization of pseudo-Boolean functions with a heavy emphasis on their representation. They will consider separately various problems of optimization, majorization, approximation, etc., for pseudo-Boolean functions given in polynomial form, in additive posiform, as well as in disjunctive posiform representation. Beside investigations concerning the algebraic problems of presentation, the investigators will lay heavy emphasis on the computational aspects of the problem, and plan to elaborate specialized algorithms for exact and heuristic optimization problems of pseudo- Boolean functions in various forms, on local optimization, and on the detection of efficient methods for particular classes of problems.<br/><br/>In numerous real-life situations, optimization problems have to be solved involving decisions and selections between various alternatives. When, for example, locations have to be found for cellular ground stations, emergency facilities, warehouses, etc., the usual mathematical optimization procedures cannot be applied blindly, since they may recommend the location of say half a unit in one place and the other half in another. Therefore, new mathematical techniques are needed to make sure that the solutions can only involve locating either an entire unit in one place or no part of it in that place. Similar problems occur when selections are made between projects to be undertaken, people or equipment to be assigned to various tasks, or much more complex situations where a large company (e.g. an airline) has to assign its equipment (e.g. aircrafts) to its various activities (e.g. flights). In such situations, the mathematical formulation of the problem requires the use of variables which can only take the values of 0 or 1. In spite of its apparent simplicity, this requirement can cause major mathematical and computational difficulties. This project deals to a large extent with the problem of finding various mathematical models describing situations like the above ones and developing optimization techniques for handling them. A substantial amount of computational experimentation is part of the project and will complement the mathematical developments."
9619522,Abstracting Component Interactions to Support               Distributed Software Architectures,CCF,SOFTWARE ENGINEERING AND LANGU,5/15/1997,3/21/1997,Gul Agha,"Agha, G","Agha, G",IL,University of Illinois at Urbana-Champaign,Standard Grant,Frank D. Anger,4/30/2000,"$175,000.00 ",,agha@cs.uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,2880,"9216, HPCC",$0.00 ,normalFunding,"9619522  Computing applications in the real world are generally  distributed and open to interaction with their environment.  Creating an architecture for such systems requires  developing mechanisms for managing complex interactions  between distributed components. As requirements and the  environment change, both the individual components and the  pattern of interactions between them evolve. This implies  that interaction mechanisms may need to be synthesized  during the execution of the system according to the evolving  needs of components. In current software, the implementation  of policies governing interactions between components is  typically represented using a variety of low-level  primitives -- such as message-passing, remote procedure  call, or shared memory -- and is therefore a major source of  code complexity. The project is studying programming  techniques for abstract and modular representation of  interaction patterns. Such programming techniques will allow  code for distributed applications to evolve gracefully --  for example, by reusing components when only their  interaction context changes. The research is based on  Actors, a formal model of concurrent computation in open  distributed systems.  ***"
1565979,CRII: CPS: Towards an Intelligent Low-Altitude UAS Traffic Management System,CNS,CRII CISE Research Initiation,5/15/2016,7/26/2016,Peng Wei,"Wei, P","Wei, P",IA,Iowa State University,Standard Grant,David Corman,4/30/2019,"$174,998.00 ",,pwei@iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,CSE,026Y,"8228, 9150",$0.00 ,normalFunding,"The objective of this project is to provide theoretical foundations for cyber-physical systems to support the increasing autonomy in the presence of other manned/unmanned air traffic. Currently the United States air transportation is facing significant challenges due to the rapid evolution of increasingly autonomous systems such as unmanned aircraft systems (UAS) and their expanding presence. However, there has been little scientific investigation on the cyber-physical systems that supports unmanned aircraft operations operating in the presence of other air vehicles. This research project explores novel strategies of coordinating and managing the UAS traffic to ensure low-altitude airspace safety and efficiency in near future. This will also help to catalyze additional cyber-physical systems research in related areas including aviation infrastructures, navigation and surveillance devices, and unmanned aerial vehicle technologies. The investigator will work with Iowa State University Extension and Outreach Office to promote UAS applications in precision agriculture, aviation safety and responsible uses of UAS.<br/><br/>The theoretical aspect of the research will leverage interdisciplinary methodologies in the fields of optimization, artificial intelligence, and control. The project designs algorithms, implements software and demonstrates proof-of-concept using low-altitude UAS traffic management as a challenge application area. This project establishes an unmanned air system traffic simulation platform, which can be used to validate new methods and tools, and enable collaborations with government, industrial and academic partners. The research outcomes are expected to provide a framework to investigate the feasibility, safety, efficiency and potential benefits of the increasing autonomy in civil aviation."
1657039,CRII: CSR: Rethinking the FTL in SSDs -- a file translation layer instead of a flash translation layer,CNS,CRII CISE Research Initiation,3/15/2017,3/20/2017,Hung-Wei Tseng,"Tseng, HW","Tseng, HW",NC,North Carolina State University,Standard Grant,M. Mimi McClure,2/28/2019,"$174,998.00 ",,htseng3@ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,CSE,026Y,"7354, 8228",$0.00 ,normalFunding,"As data sets for artificial intelligence, network services, and cloud storage grows, so does the demand of quickly and efficiently serving data from the storage device. Using solid state drives (SSDs) based on non-volatile, flash memory technologies is an effective approach to improve the performance of storage devices. However, as the rest parts of the computer system leverage the entrenched interface to communicate with SSDs, the overhead of supporting these abstractions buries the real potential of SSDs. Specifically, the different addressing modes for different system layers result in multiple address translations when accessing a single file and require additional system resource to maintain the mapping. This address translation overhead takes time and limits the bandwidth of SSDs. This project is addressing this problem by proposing an innovative storage interface that minimizes the system overhead but better fits the behaviors of applications in accessing data. The proposed interface will simplify the design of operating systems. This interface will require no modifications to existing applications. <br/><br/>As most file accessing overhead coming from the operating system, simplifying operating systems with the proposed interface will significantly boost the latency and bandwidth when applications access SSDs. This project will implement the proposed design in real SSDs without changes to existing hardware, meaning that the result of this project can immediately facilitate existing computer systems hosting big data applications without additional hardware costs. This project will also encourage researchers to revisit existing hardware/software interfaces for achieving better performance on emerging peripheral devices as well as exploring other benefits, including enhanced security and reduced energy consumption of pursuing this research direction."
1657379,CRII: CHS: Mining Intentions on Social Media to Enhance Situational Awareness of Crisis Response Organizations,IIS,CRII CISE Research Initiation,9/1/2017,3/1/2017,Hemant Purohit,"Purohit, H","Purohit, H",VA,George Mason University,Standard Grant,Dan Cosley,8/31/2019,"$174,965.00 ",,hpurohit@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,026Y,"7367, 8228",$0.00 ,normalFunding,"In large-scale emergencies, people post a lot of information about their status, needs, and abilities to help on social media. In principle, these posts might help emergency management teams get a better picture of the situation and find useful resources, but the number and questionable accuracy of these posts make them less useful than they could be. This project is about developing tools that identify people's intentions related to the emergency, sorting tweets into categories such as requests for help or information, offers of help, announcements of their safety or location, and so on. This problem of intent inference is a key scientific problem in natural language processing and artificial intelligence, with practical uses in a number of areas beyond emergency management, including web search and providing location-aware services. The researchers will attack the intent inference problem by narrowing it to the emergency response domain. First, they will work closely with emergency response teams to identify meaningful categories of intent that align with emergency response needs, in order to guide the collection and labeling of social media posts. Then, they will develop strategies drawn from existing image and natural language processing techniques and informed by the emergency response context to do the categorization work. Finally, they will build and evaluate a tool that uses the categorization algorithms to highlight the social media posts that are most likely to be useful to emergency responders. The work will be used to help develop courses around data science at the lead researcher's school, and the tools will be made publicly available through an open source code and advertised to communities of interest. <br/><br/>To build the set of crisis-specific intent categories, the research team will first analyze existing operational manuals for emergency response including the Incident-Command-System models to extract key processes and initial categories, then refine that set working with experts from the Fairfax Fire and Rescue Department, an advisory committee of social media working group for emergency services at Department of Homeland Security that has members across the country, and members of the project's advisory board.  Intent extraction will be modeled as a multilabel classification problem on two dimensions: type of intent, and topical category; this formulation maps well to characteristics of posts (which might contain multiple intents and topics) and scopes the complexity of general intent inference. Datasets will be gathered from prior crisis events and labeled by crowd workers interested in humanitarian work according to the categories identified from the first phase. Features of posts will be constructed from posts? metadata using natural language processing techniques on textual content, image processing techniques on multimedia content and author profiling techniques. Features will include extracting syntactic-semantic patterns that represent declarative and psycholinguistic knowledge as well as ideas from discourse analysis, while features of authors will be drawn from their provided profile information as well as aggregate inferences from their posts. The team will use a multi-task learning framework as the underlying algorithm to leverage relationships between the different categories to be classified.  Finally, the developed interface will support faceted browsing by intent, topic, location, and response management process, and be evaluated through training exercises with the research team's practitioner partners."
1415912,SBIR Phase I: Automatic Design and Optimization of Novel Drug Candidates,IIP,SMALL BUSINESS PHASE I,7/1/2014,12/9/2014,Shahar Keinan,"Keinan, S","Keinan, S",NC,"Teraffinity, Inc.",Standard Grant,Ruth M. Shuman,6/30/2015,"$174,950.00 ",,skeinan@cloudpharmaceuticals.com,"108 Fawn Dr., Suite 201",Wake Forest,NC,275879717,9103981200,ENG,5371,"163E, 5371, 8038",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) project is to provide a tool for designing new drugs. Designing new drugs that bind to a specified protein target required finding the best molecule in a vast chemical space. The proposed design tool can search this large chemical space much more efficiently and cheaply compared to current methods. It is based on a ""reverse engineering"" method to solve the problem of going from a set of desired properties back to chemical structures that may have these properties. This design tool allows the efficient search of the database to find the best molecule in advance of laboratory work. The envisioned technology is expected to shorten the screening and drug discovery phase from 3 years to 1 year, while saving ~$20 M per target overall, by shifting current practices and enabling a rapid, lower cost, and more novel targeted drug discovery and lead identification. <br/><br/>This project proposes to develop a computational drug discovery platform. This platform uses advanced QM/MM (quantum chemistry and molecular chemistry combined) calculations for binding accuracy combined with an artificial intelligence heuristic search algorithm to find the most appropriate molecule in a vast molecular space. The advances to be accomplished with this SBIR project include adding two novel toolsl to improve the performance of the current ""in silico"" drug design algorithm: 1) a multi-object optimization algorithm to further improve high accuracy, and 2) an automated scaffold design algorithm. These will result in highly selective designs with novel scaffolds that not only bind well to the target, but that also have excellent drug-like properties such as low probability of toxicity and off target effects, as well as greater stability and synthesizability. These advancements should provide higher accuracy of binding affinity prediction results with fewer false positives and better molecule selection, and reduced labor, which allows for greater automation."
1657613,CRII: RI: Inference for Probabilistic Programs: A Symbolic Approach,IIS,CRII CISE Research Initiation,3/1/2017,2/21/2017,Guy Van den Broeck,"Broeck, GVd","Broeck, GVd",CA,University of California-Los Angeles,Standard Grant,Weng-keen Wong,2/28/2019,"$174,639.00 ",,guyvdb@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,026Y,"7495, 8228",$0.00 ,normalFunding,"Probabilistic machine learning and artificial intelligence have revolutionized the world and are present in most aspects of our life. However, the tools used to develop probabilistic machine learning solutions are limited in what they can express. Moreover, they require significant expert knowledge, and are not accessible to scientists in each discipline, let alone everybody else. Probabilistic programming aims to make probabilistic machine learning accessible to all, and as easy to program as a phone application. To make this dream a reality, probabilistic program execution, making probabilistic predictions from observations, has to become as highly efficient and robust as our current non-probabilistic software tools. This project develops general-purpose algorithms to execute probabilistic programs efficiently, using advanced symbolic reasoning techniques from artificial intelligence. Moreover, it does so for probabilistic programs that are significantly more complex than the ones in use today, involving a wide range of programming language features that are both discrete and continuous. This increase in scalability and expressive power will foster novel, increasingly advanced machine learning applications. <br/><br/>More specifically, probabilistic programs subsume classical probabilistic graphical models and are additionally able to capture complex probabilistic dependencies that include arbitrary pieces of executable code. While many expressive probabilistic programming languages have been proposed in recent years, the current bottleneck and barrier to success is the lack of general-purpose reasoning algorithms to perform inference with probabilistic programs efficiently. This research tackles two key problems in probabilistic program inference. First, current sampling-based algorithms have problems reasoning about dependencies between large numbers of discrete random variables and explaining low-probability observations. In one thrust, this project develops new inference algorithms based on knowledge compilation. This technique compiles the program into a symbolic structure that is efficient for probability computation. The algorithm does not compile the entire program, which is generally intractable, but uses importance sampling on partially compiled programs to sample efficient subprograms. This combines the best of approximate program evaluation by sampling with highly efficient compilation techniques for exact inference. Second, symbolic approaches to inference are fundamentally discrete and have problems dealing with continuous and integer variables, which frequently appear in real code. Conversely, algorithms for continuous distributions cannot efficiently handle discrete program structure. In another thrust, this project studies symbolic approaches to probabilistic reasoning in programs with both types of structure, using recent breakthroughs based on satisfiability modulo theories and hashing-based sampling. This project provides a scientific leap at a fundamental level. It also provides a context for training undergraduate and graduate students in subjects spanning machine learning, artificial intelligence, statistics, and programming languages, and targets the integration of probabilistic programming into computer science curricula."
1209714,SoCS: Collaborative Research: A Human Computational Approach for Improving Data Quality in Citizen Science Projects,IIS,SOCIAL-COMPUTATIONAL SYSTEMS,8/1/2012,7/23/2012,Weng-Keen Wong,"Wong, WK","Wong, WK",OR,Oregon State University,Standard Grant,William Bainbridge,7/31/2016,"$174,635.00 ",,wong@eecs.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7953,7953,$0.00 ,normalFunding,"A unique interdisciplinary team of computer scientists, information scientists, ornithologists, project managers, and programmers will develop a novel network between machine learning methods and human observational capacity to explore the synergies between mechanical computation and human computation. This is called a Human/Computer Learning Network, and while the focus is to improve data quality in broad-scale citizen-science projects, the network has the potential for wide applicability in a variety of complex problem domains. The core of this network is an active learning feedback loop between machines and humans that dramatically improves the quality of both, and thereby continually improves the effectiveness of the network as a whole. The Human/Computer Learning Network will leverage the contributions of broad recruitment of human observers and process their contributed data with artificial intelligence algorithms leading to a total computational power far exceeding the sum of their individual parts. This work will use the highly successful eBird citizen-science project as a testbed to develop the Human/Computer Learning Network. eBird engages a global network of volunteers who submit tens of millions of bird observations annually to a central database.<br/>This research addresses three fundamental data quality challenges in citizen-science. These are: 1) reducing errors in identification or classification of objects; 2) identifying and quantifying the differences between individual observers; 3) reducing the spatial bias prevalent in many citizen-science projects. To address these challenges, the project will build on advances in artificial intelligence that now provide the opportunity to study systems through the generation of models that can account for enormous complexity. Preliminary work on observer classification will be extended by developing new multi-label machine learning classification algorithms that provide better ecological interpretations and more accurate predictions. In addition, the research will develop new active learning algorithms by constructing sampling paths that will optimize volunteer survey efforts to maximize overall spatial coverage, and incentivize participation via crowdsourcing techniques. Finally, it will study how participants can improve the quality of their observations based on the feedback and information provided by the artificial intelligence. <br/><br/>Broad-scale citizen-science projects can recruit extensive networks of volunteers, who act as intelligent and trainable sensors in the environment to gather observations. Artificial intelligence processes can dramatically improve the quality of the observational data that volunteers can provide by filtering inputs based on observers' expertise, a judgment that is based on aggregated historical data. By guiding the observers with immediate feedback on observation accuracy and customization of observation worksheets, the artificial intelligence processes contribute to advancing expertise of the observers, while simultaneously improving the quality of the training data on which the artificial intelligence processes make their decisions. The results of the project will have significant benefit for all citizen science and broader impact in an emerging world of ubiquitous computing in which human-machine partnerships will become increasingly common."
963404,Collaborative Research: Measuring and Modeling Collective Intelligence,IIS,Cyber-Human Systems (CHS),1/1/2010,2/18/2015,Christopher Chabris,"Chabris, C","Chabris, C",NY,Union College,Standard Grant,Ephraim P. Glinert,12/31/2015,"$173,908.00 ",,chabrisc@union.edu,807 Union Street,Schenectady,NY,123083103,5183886101,CSE,7367,"9215, HPCC",$0.00 ,normalFunding,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research.  But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence.  One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College.  The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems.  For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups.  Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups.  Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups.   A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems.  This research will provide powerful new tools for managing and designing such systems.  Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors.  Imagine that this test could predict the team's future performance on a wide range of important tasks.  And imagine that the test could also help suggest changes to the team that would improve its flexibility.  Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks.  From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently.  This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts:  With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it.  With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems.  The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
1415653,SBIR Phase I:  Assistive Digital Vision for the Blind,IIP,SMALL BUSINESS PHASE I,7/1/2014,12/17/2014,Arman Ghodousi,"Ghodousi, A","Ghodousi, A",VA,Ghodousi LLC,Standard Grant,Muralidharan S. Nair,6/30/2015,"$172,500.00 ",,arman@g-technologygroup.com,5702 General Washington DR.,Alexandria,VA,223120000,4805443192,ENG,5371,"163E, 5371, 6840, 8035, 9139, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project seeks to implement state-of-the art image processing algorithms designed to identify objects amidst a complex background, which currently require high power computer processing resources, onto an embedded device, which would allow the capability to be used in small, portable, and affordable devices. The project further aims to include an obstacle avoidance algorithm to identify objects within a specific range. This high-risk research promises wide-ranging benefits, with the focus to be on creation of an assistive digital vision technology. The main objectives of the proposed effort include: 1) integrating a camera and sonar onto a commercially available embedded device; 2) development of an obstacle detection/avoidance algorithm for the sonar sensor and successfully implementing it into the embedded device; 3) customization of object identification / recognition algorithms for the camera sensor to implement them into the embedded device. Success will be evaluated by measuring performance of the resultant breadboard device in its ability to detect objects at various distances, and to recognize three common objects against a cluttered background. The goal and expected result is to exceed a probability of detection of 80%.<br/><br/>The broader impact/commercial potential of this project is enabling blind people to develop a more comprehensive mental picture of their surrounding and improving their situational awareness. There are 39 million visually impaired people living around the world. Guide dogs and white canes are the preferred mobility aids, but there is little else available to them that is both user-friendly and affordable. The envisaged technology will be compatible with the white cane and will alert the user to the presence of above ground obstacles, such as traffic and sign poles and overhanging objects. In addition, the object identification will further allow the user to develop a more comprehensive mental picture of his surroundings and improve his mobility. While other navigation support products are in the high hundreds to thousands of dollars, the technology proposed herein is expected to be commercialized in a product available for less than $200, thus allowing it to make a broad impact to the wide population of the visually impaired. The resultant technology that contains embedded camera and sonar technologies in a portable device may also contribute to the field of robotics and artificial intelligence, wherein a better understanding of the environment will support new decision-making algorithms."
1661516,Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution,DBI,ADVANCES IN BIO INFORMATICS,9/1/2017,8/30/2017,Josef Uyeda,"Uyeda, J","Uyeda, J",VA,Virginia Polytechnic Institute and State University,Standard Grant,Peter H. McCartney,8/31/2020,"$172,356.00 ",,josef.uyeda@gmail.com,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,BIO,1165,9150,$0.00 ,normalFunding,"The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
9605028,NSF-CGP Fellowship:  Development of Power System Intelligent Coordinated Control,OISE,JAPAN-U.S. FELLOWSHIPS PROG-RE,7/1/1997,6/18/1997,Kwang Lee,"Lee, K","Lee, K",PA,Pennsylvania State Univ University Park,Standard Grant,Gerald Edwards,6/30/2000,"$170,026.00 ",,Kwang_Y_Lee@baylor.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,O/D,8270,"0000, 5983, OTHR",$0.00 ,normalFunding,"9605028  Lee    This award provides funds to support a long-term research  visit by Dr. Kwang Y. Lee, Intelligent Distributed Controls  Research Laboratory, Department of Electrical and Computer  Engineering, Pennsylvania State University, for collaboration  with Dr. Takashi Hiyama, Department of Electrical and  Computer Engineering, Kumamoto University, Kumamoto, Japan.  Their research is concerned with the development of power  system intelligent coordinated control.  The purpose of  intelligent coordinated control is to improve power  generation reliability, economy, and safety through the  implementation of modern control technologies and artificial  intelligence.    The research will be conducted primarily in the Kumamoto  Electric Power Systems Laboratory at Kumamoto University.  During the visit, Dr. Lee also will be working with the  Kyushu Electric Power Company in experimenting with the power  system intelligent coordinated control concepts in its Power  System Analysis Simulator.  The U.S. and Japanese  collaborators have been engaged independently in parallel  research in this area and share a common interest in training  students and other researchers in the required skills to  develop, test, and implement advanced control techniques in  actual power plants and power systems.  The collaborators  expect the present collaboration to allow them to expand  their current research from the power plant to the power  system level and integrate their various capabilities for  mutual benefit.  This project is supported under the Science  Fellowship Program between the National Science Foundation  and the Japan Foundation Center for Global Partnership.  ***"
341197,Engaging Undergraduates in On-Line Inquiry Learning:  A Case-Based CyberLibrary in Human Biology,DUE,CCLI-EDUCATIONAL MATERIALS DEV,4/1/2004,4/2/2004,Merle Bruno,"Bruno, M","Bruno, M",MA,Hampshire College,Standard Grant,Jeanne Small,3/31/2006,"$170,001.00 ",,mbruno@hampshire.edu,893 West Street,Amherst,MA,10023372,4135595378,EHR,7427,"7427, 9178, SMET",$0.00 ,normalFunding,"This project addresses the need to engage introductory biology students and future teachers in critical thinking and problem solving. The work fosters active learning and provides inquiry-oriented biology materials that make learning biology exciting and relevant for all students.  The products include 1) The Human Biology Case CyberLibrary, a powerful suite of medical case studies for undergraduates; and 2) a set of software tools to support student inquiry.  Medical cases are adapted from cases developed for medical education, including some from Harvard Medical School.  Based on prior funding from the CCLI program and the Department of Education we developed infrastructure software, inquiry tools and one human biology case.  The current project is developing several additional cases and testing the effectiveness of the product and tools on student learning.  We are examining how well the material supports inquiry learning and evaluating usability and changes in student attitudes towards scientific reasoning.  This material is being tagged for the National Science Digital Library (NSDL) and submitted to and reviewed by BioQUEST.   Intellectual merit: The work pushes the state of the art in the use of artificial intelligence, interactive multimedia, and web-based technology in biology education.  Broader impact: The results have the potential to impact publishers, universities, for-profit companies, and individual authors who develop non-print educational materials.<br/><br/>"
1623124,EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL),IIS,Cyberlearn & Future Learn Tech,9/1/2016,8/26/2016,Barbara Grosz,"Grosz, B","Grosz, B",MA,Harvard University,Standard Grant,Amy Baylor,8/31/2019,"$170,000.00 ",,grosz@eecs.harvard.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,CSE,8020,"8045, 8841",$0.00 ,normalFunding,"The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
1711775,Bridging the Gap Between Education and Research through Pre-College Engineering Systems (PCES) Outreach Program,ECCS,"ENERGY,POWER,ADAPTIVE SYS",8/1/2017,7/18/2017,James Momoh,"Momoh, J","Momoh, J",DC,Howard University,Standard Grant,Anil Pahwa,7/31/2020,"$170,000.00 ",,jmomoh@howard.edu,2400 Sixth Street N W,Washington,DC,200599000,2028064759,ENG,7607,"1340, 155E, 9177",$0.00 ,normalFunding,"The purpose of the project is to develop a residential summer research and education Science Technology Engineering and Mathematics (STEM) outreach program targeted at 11th and 12th graders from across the country. The program will advance students' preparation for careers in engineering through integration of research and education. The students in the program will undertake lectures on topics such as advanced mathematics and physics, chemistry, preparatory scholastic aptitude testing, advanced placement courses, and will be exposed to fundamentals of engineering courses and special topics in Electrical and Computer Engineering such as artificial intelligence, communications, nanotechnology, photonics, energy systems and smart grid technologies. These courses will prepare and motivate students for research work in energy management, automation functions for secured critical infrastructures, sensor based systems and safe environment. The background achieved and exposure through hands-on activities will capacity for a future diverse workforce of underrepresented groups and women to pursue careers in engineering.<br/><br/>The research work in the pre-college engineering systems program will include various fields of engineering and science used to help students to appreciate the role of creativity, analytical and hands-on work in conducting engineering projects, processes and systems. The research work will involve needs assessment, constraints, problem formulation and design of algorithms, implementation, testing and validation under different scenarios. The major areas for project ideas include communication and signal processing, photonics/electronics, nanotechnology, materials and energy and power systems, with each area having its own set of specific projects. Under communication and signal processing, specific projects include the solar bag, smart phones, new integrated display board, and others. In photonics/electronics, the specific works include mobile diagnostics for power electronics and smart displays. Nanotechnology and materials projects include design of nano toothpaste, nano skating boots, and a nano tricycle for kids. In the area of energy and power systems, smart city design using renewable energy resources and electric vehicles with self driving properties are specific project areas. Furthermore, wireless sensors, a handmade wristwatch for health monitoring, and automatic fan control will be pursued within the computer engineering projects. Students will work in teams and final products will be presented at the end of the program each year to an audience of faculty, parents and a representative of the funding agency, the National Science Foundation (NSF). Mentoring during and after the program (during the school year) will be in place to track students' continued progress toward life-long pursuit of engineering as a carrier. Lessons learned will be shared with other engineering schools so that the country will benefit from the NSF investment in education and research activities for pre-college students at Howard University."
9807872,Functional Organization of the Auditory System,IOS,SENSORY SYSTEMS,9/1/1998,4/21/1999,Ranjan Batra,"Batra, R","Batra, R",CT,University of Connecticut Health Center,Continuing grant,Avijit Chaudhuri,8/31/2000,"$170,000.00 ",,rbatra@anatomy.umsmed.edu,263 Farmington Ave.,Farmington,CT,60321956,8606793951,BIO,1185,"1096, 9107, BIOT",$0.00 ,normalFunding,"   Hearing involves several centers, called nuclei, located in the brainstem, where auditory information is processed before being passed on to the midbrain and higher centers.  For many auditory signals, aspects of timing are very important.  Complex sounds, for example, often have a periodicity in their waveform that may be heard as a particular pitch, or frequency.  Anatomical studies suggest that one of the brainstem nuclei, called the ventral nucleus of the lateral lemniscus or VNLL, receives a large input from the one ear on the opposite side, from cell types that specifically transmit the temporal pattern of a sound.  This project uses a novel awake preparation for physiological recordings of nerve cells in the VNLL, to test whether the VNLL itself shows an orderly mapping of responses to pitch periodicity.  Results will be important because the VNLL has been so understudied in any mammals except for echolocating bats.<br/>    The impact of this work will be important to understanding the role of this major nucleus in temporal pattern processing, and will also be important to help understand pitch-periodicity perception in humans, which in turn can be important in speech recognition, and could lead to improved electronics for speech processors and artificial intelligence (AI) networks.<br/>  <br/>"
534620,Distributed Implementation:    Collaborative Decision-Making in Multi-Agent Systems with Self-Interest,IIS,DIGITAL SOCIETY&TECHNOLOGIES,11/1/2005,10/18/2005,David Parkes,"Parkes, D","Parkes, D",MA,Harvard University,Standard Grant,William Bainbridge,10/31/2007,"$168,266.00 ",,parkes@eecs.harvard.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,CSE,6850,"7496, 9218, HPCC",$0.00 ,normalFunding,"This is a research project in the field of distributed implementation, in which the goal is to facilitate collaboration between self-interested agents but without centralized computation and without the direct revelation of private information. This generalizes mechanism design, which is inherently centralized, in a way that makes it more relevant for many distributed systems.  The intention is that distributed implementation will facilitate the integration of methods for cooperative problem solving in Distributed Artificial Intelligence (DAI) with the methods to handle self-interest in computational mechanism design. <br/><br/>One often imagines that collaborative systems are those for which the participants have some intrinsic altruism. But in fact, collaboration can also be promoted between participants with intrinsic self-interest. For instance, while participants in a team may share high-level common goals, each individual may prefer that others perform tasks. Careful design can provide appropriate incentives to promote collaborative behavior in many domains, including: automated task allocation amongst a team of workers (e.g. at an airport or a hospital); for collaborative network protocols (e.g. peer-to-peer routing, grid computing); and also in e-commerce domains (e.g. for the automation of logistics such as fleet procurement and scheduling between shippers and carriers).<br/><br/>This project will significantly extend both the theory and practice of distributed implementation, moving beyond overarching principles to the design and analysis of specific (constructive) protocols. One fundamental problem that it will address is that of distributed sequential decision making with self-interested participants. Many systems are dynamic, and as such it seems important to study how to apply recent methods in sequential decision making with a central mechanism in our distributed context. This research will study the problem of distributed (but episodic) constrained optimization, adapting existing algorithmic methods from DAI in order to make them work with self-interest. It will also consider settings in which computation is costly, which raises new tensions. Finally, it will expand the theory to address multi-agent systems with richer agent behaviors, including mixtures of obedient, self-interested, faulty and malicious agents. This will make the theory even more relevant in practical systems.<br/><br/>Advances in distributed implementation will have a direct impact in a number of areas. For distributed computational systems such as grid computing, peer-to-peer, and ad hoc networks, this research can promote optimal and coordinated decision making (for instance on how to allocate resources, store content, route packets) within the system and without requiring some trusted third-party. For e-commerce, it can enable trading with dynamic pricing amongst mobile users with wireless devices in public spaces, such as in shopping malls, on campuses and at ball games. More broadly, distributed implementation can promote collaboration within firms and other organizations, for instance providing automated task allocation to workers in dynamic and complex domains such as airports and hospitals. An important component of the research plan involves the continued integration of these ideas into both undergraduate and graduate curricula at the interface between computer science and economics.<br/>"
958298,Collaborative Research:II-NEW: A Digital/VLSI Test and Reliable Computing Research Laboratory,CNS,"SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE",6/1/2010,4/10/2012,Mohammed Niamat,"Niamat, M","Niamat, M|Jha, R|Alam, M",OH,University of Toledo,Standard Grant,Almadena Y. Chtchelkanova,5/31/2014,"$167,730.00 ","Rashmi Jha, Mansoor Alam",mniamat@utnet.utoledo.edu,"2801 W Bancroft St., MS 218",TOLEDO,OH,436063390,4195302844,CSE,"1714, 7359","7359, 9218, 9251, HPCC",$0.00 ,normalFunding,"Testing represents one of the major manufacturing costs in the semiconductor industry. Designing circuits with testability features significantly reduces testing costs and time. Thus, it is important for designers to be exposed to the concepts in testing which can help them design better and reliable products.<br/>In this collaborative project between the University of Toledo (UT) and Ohio Northern University (ONU), a ""Digital/VLSI Test and Reliable Computing Research Laboratory"" is being established for the development of computationally intensive algorithms and use of commercial CAD tools for testing digital, VLSI, and advanced semiconductor devices.<br/><br/>Some of the research projects being carried out include: Novel Testing Techniques for Quantum Cellular Automata (QCA) circuits; Built In Self Test (BIST) for Embedded SRAMS in System on Chips; Testing Look-Up-Table (LUT) Delay Aliasing Faults in SRAM Based FPGAs Using Half-Frequencies;  Analysis and Testing of Electromigration Failures; Testing and Modeling Soft Errors in FPGAs; Reliability Analysis and Device Failures in Advanced Semiconductor Devices; Reliability Issues Related to Power Consumption in VLSI Chips during Test; and Small Delay Defects and Test Generation.<br/><br/>Educational modules developed from the research carried out in this project are integrated into a number of graduate and undergraduate courses at ONU and UT. Since applications of semiconductor chips are far and wide, many different industries including auto, aerospace, defense and healthcare may benefit from this project."
9906446,"Multi-Modal Communication: Signal Variation, Interaction Between Modes, and Relationship to Fitness Benefits",IOS,"PHYSIOLOG & STRUCTURAL SYS, IBN ANIMAL BEHAVIOR",9/1/1999,7/23/2002,George Uetz,"Uetz, G","Uetz, G",OH,University of Cincinnati Main Campus,Standard Grant,Jerry  O. Wolff,8/31/2004,"$164,604.00 ",,GEORGE.UETZ@UC.EDU,"University Hall, Suite 530",Cincinnati,OH,452210222,5135564358,BIO,"1141, 1160","1160, 9169, 9178, 9251, EGCH, SMET",$0.00 ,normalFunding,"Animals use multiple modes of communication (e.g., sounds, visual and/or chemical cues) to recognize members of their own species and discriminate them from others. The research goal is to understand the role of multi-modal signaling in an invertebrate animal model (spiders). As invertebrates have a limited behavioral repertoire and very little learning ability, species recognition in spiders is innate and based on simple cues. It is therefore possible to experiment with specific aspects of multi-modal signals, and gain insights about the recognition ""program"" encoded within their simple nervous system. Video / audio digitization and playback experiments will examine the relationship between visual and vibration signals produced by (male) ""senders"" and the information they convey to (female) ""receivers"".  In addition, field studies will determine how the<br/>environment affects transmission of different signal modes. <br/><br/> Results will allow a better understanding of mechanisms involved in animal communication, and their adaptive value. The research will also contribute to growing knowledge about ecologically important but poorly-understood invertebrate predators. Additionally, this research involves training students in the use of a powerful computer-assisted technique that could be applied to a variety of research questions in animal behavior, neurobiology and other fields (image recognition, artificial intelligence).<br/><br/>"
1740197,E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays,CCF,Energy Efficient Computing: fr,9/15/2017,7/23/2018,Saibal Mukhopadhyay,"Mukhopadhyay, S","Mukhopadhyay, S",GA,Georgia Tech Research Corporation,Continuing grant,Sankar Basu,8/31/2020,"$162,412.00 ",,saibal@ece.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,015Y,"7945, 8089",$0.00 ,normalFunding,"In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform  interdisciplinary research to address many limitations in today's resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today's binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ""NeuroSim"". With innovations across material, device, circuit and architecture,  research needs will be pursued towards energy-efficient processing in ubiquitous resource-constrained hardware systems."
1721550,Collaborative Research:  Automatic Video Interpretation and Description,DMS,"OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS",9/1/2017,8/20/2017,Wing Hung Wong,"Wong, WH","Wong, WH",CA,Stanford University,Standard Grant,Christopher W. Stark,8/31/2020,"$160,000.00 ",,whwong@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,MPS,"1253, 6892, 8069","1253, 7433, 8004, 8083, 9263",$0.00 ,normalFunding,"Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
1721216,Collaborative Research:  Automatic Video Interpretation and Description,DMS,"OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS",9/1/2017,8/20/2017,Xiaotong Shen,"Shen, X","Shen, X",MN,University of Minnesota-Twin Cities,Standard Grant,Christopher W. Stark,8/31/2020,"$160,000.00 ",,xshen@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,MPS,"1253, 6892, 8069","1253, 7433, 8004, 8083, 9263",$0.00 ,normalFunding,"Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
1307179,Collaborative Research: Transfer Learning for Chemical Analyses from Laser-Induced Spectroscopy,CHE,Chemical Measurement & Imaging,9/15/2013,9/8/2013,Sridhar Mahadevan,"Mahadevan, S","Mahadevan, S",MA,University of Massachusetts Amherst,Standard Grant,Kelsey D. Cook,8/31/2016,"$158,872.00 ",,mahadeva@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,MPS,6880,"7433, 8084",$0.00 ,normalFunding,"With support from the Chemical Measurements and Imaging program, Professors Melinda Dyar of Mt. Holyoke College and Sridhar Mahadevan of University of Massachusetts at Amherst and their students will use laser-induced breakdown spectroscopy (LIBS) measurements, including laboratory investigations of standard materials at varying experimental conditions, to develop numerical methods that will address limitations to the broad application of LIBS imposed by matrix effects and plasma variability. State-of-the-art dimensionality reduction and transfer learning methods from machine learning and statistics will be used to build innovative LIBS-based predictive models. These investigations will extend classical methods in statistics for dealing with multiple paired data sets, such as canonical correlational analysis, to deal with unlabeled data, and extract nonlinear low-dimensional regularities in the data. The project includes the design of a suite of model-building tools that can deal with a range of problems and optimization objectives, including different types of correspondence information available across datasets, diversity of global objectives ranging from preserving local to global geometry, and producing linear or nonlinear mappings to lower-dimensional factors. <br/><br/>Laser-induced breakdown spectroscopy (LIBS) is a chemical analysis tool that uses the light emitted by a sample when a focused laser pulse generates a plasma at the sample surface. LIBS has a number of features that make it particularly useful for field use, including rapid analysis, minimal sample preparation and suitability for stand-off, that is remote, detection. Moreover, LIBS can detect and quantify light elements that are not always measured using other methods. Consequently, LIBS is well-suited to many applications including, defense interests (e.g., military explosive detection, illegal drug detection, airport security), in-situ analysis of archeological sites, field work at hazardous waste sites, and geological resource exploration. However, utilization of LIBS measurements is limited by signal variability with measurement and sample conditions. This project launches an integrated research program to couple state of the art LIBS instrumentation at Mount Holyoke College to equally state of the art numerical methodology in artificial intelligence and machine learning at the nearby University of Massachusetts to increase the utility of LIBS measurements. This project will provide an interdisciplinary training environment that includes undergraduate, graduate and post-doctoral researchers."
1414935,RI:  Small:  Understanding Value-based Multiagent Learning and Its Applications,IIS,ROBUST INTELLIGENCE,7/1/2013,2/19/2014,Michael Littman,"Littman, M","Littman, M",RI,Brown University,Standard Grant,Hector Munoz-Avila,1/31/2016,"$157,019.00 ",,mlittman@cs.brown.edu,BOX 1929,Providence,RI,29129002,4018632777,CSE,7495,"7495, 7923, 9150",$0.00 ,normalFunding,"This project explores the behavior of value-based learning methods in multi-agent environments. Value-based methods make decisions by using experience to estimate the utility impact of alternatives and choosing those with high predicted value. Because they evaluate components of behavior instead of treating behaviors as atomic units, they are computationally and statistically efficient. While these methods have been used in computational experiments for many years, only recently have researchers begun to formally characterize their behavior. Our own preliminary work is finding that some value-based methods exhibit super-Nash behavior, making them particularly worthy of study.<br/><br/>More specifically, we are analyzing, mathematically and experimentally, how value-based algorithms perform in several classes of simulated games of varying complexity from the artificial intelligence community, multi-agent engineering applications drawn from the wireless networking area, and as models of human and animal decision making in collaboration with cognitive neuroscientists. Where possible, we are refining existing value-based algorithms to work more efficiently, robustly, and generally than existing algorithms. We are also designing educational outreach activities, including creating entertaining instructional videos on how to promote cooperative behavior in real-life social dilemmas."
1059577,EAGER:  Modeling and Visualization of Latent Communities,IIS,,9/15/2010,9/14/2010,Peter Brusilovsky,"Brusilovsky, P","Brusilovsky, P",PA,University of Pittsburgh,Standard Grant,Sylvia J. Spengler,12/31/2011,"$155,882.00 ",,peterb@mail.sis.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,J394,"7484, 7916",$0.00 ,normalFunding,"In many areas of human professional and social life, people tend to form more or less clearly defined communities.   The main problem of these hidden or latent communities is that they are really hard to discover since the borders of these communities cut through various professional and organizational borders. The modern social Web, however, provides a huge volume of alternative data sources for discovering latent communities.  The goal of this proposal is to explore a range of promising approaches that can be used to elicit latent communities from various kinds of data about individuals available in the modern social Web and deliver the results for human thinking and interactive exploration through interactive visualizations. The visualization provided will allow humans explore and manipulate the results delivered by the new algorithms.  This will deliver results that are produced by the joint power of human and artificial intelligence. In the course of the project, the team will build several data sets combining data of several social Web systems and use these data sets to develop, evaluate, and compare several elicitation and visualization approaches.  The work will advance the research on latent communities, community and user modeling, and interactive social visualization. At the same time, the work will constitute one of the first attempts to use a variety of social Web data and a variety of approaches for community modeling. To increase the broader impact of the project, the researcher will apply the latent community knowledge to several practical tasks, such as identifying proper academic mentors and forming coherent collaboration groups.  They will also engage a number of students in the research advancing their training into this emerging field."
410719,"Implementation and Enhancement of Internet Based Robotics, Automation, and CAD/CAM/CNC in a New Manufacturing Engineering Technology Curriculum",DUE,CCLI-ADAPTATION AND IMPLEMENTA,8/15/2004,8/24/2004,Richard Chiou,"Chiou, R","Chiou, R|Kwon, Y|Sosa, H",PA,Drexel University,Standard Grant,Kathleen A. Alfano,7/31/2007,"$155,648.00 ","Yongjin Kwon, Horacio Sosa",ryc23@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,EHR,7428,"7428, 9178, SMET",$0.00 ,normalFunding,"Engineering-Engineering Technology (58)  The project is enhancing Drexel's new Manufacturing Engineering Technology (MET) curriculum through the incorporation of state-of-the-art Internet based robotics, automation, and CAD/CAM/CNC technology.  The project is using information and communication technologies to develop real-time control of production processes, which is a key element in creating and deploying global manufacturing enterprises. The project is adapting Internet based technologies that other schools of engineering have developed in robotics, CAD, communication, and information management. Adaptation includes Internet programming, design and production, E-commerce, and advanced manufacturing systems from Industrial Engineering at the University of Iowa; sensor-based intelligent process control, tele-robotics, and machine vision systems and motion control in Mechanical Engineering at Drexel University; E-transactions, and Internet supply-chain and network integration from Industrial Engineering at Arizona State University; Internet based reverse engineering and advanced manufacturing, and artificial intelligence in manufacturing and process optimization from Industrial and Manufacturing at Bradley University; and E-manufacturing, precision, sensor-based manufacturing and automation, and  Internet based collaboration and product design from Manufacturing Sciences at Western Kentucky University.   <br/><br/>Courses are being restructured and new courses developed to support a new Mechatronics laboratory. This is providing students with contemporary practices and hands-on skills for an expanding e-manufacturing sector. The project is integrating Internet based technologies with those at other universities and community colleges in the Greater Philadelphia Region to provide students access to the curriculum that is being develop at Drexel. Distant delivery is enabling students of diverse educational backgrounds to develop technical skills needed to enter the workforce in this emerging technology. The project is targeting women and minority students.<br/>"
853021,International Research Fellowship Program: Probabilistic Models for Reasoning in Natural Language Dialog,OISE,IRFP,10/1/2009,6/8/2009,Luke Zettlemoyer,"Zettlemoyer, L","Zettlemoyer, L",MA,Zettlemoyer Luke,Fellowship,John Snyder,9/30/2011,"$153,900.00 ",,,,Cambridge,MA,21394309,,O/D,5956,"0000, 5946, 5956, 5979, 5980, OTHR, 6890","$153,900.00 ",normalFunding,"0853021<br/>Zettlemoyer<br/><br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>The International Research Fellowship Program enables U.S. scientists and engineers to conduct nine to twenty-four months of research abroad. The program's awards provide opportunities for joint research, and the use of unique or complementary facilities, expertise and experimental conditions abroad.<br/><br/>This award will support a twenty-four month research fellowship by Dr. Luke Zettlemoyer to work with Dr. Mark Steedman at the University of Edinburgh in the UK.<br/><br/>The PI is developing probabilistic models for pragmatic reasoning, the type of context-dependent reasoning that is required for automated systems to participate in natural language conversations. They are investigating whether these new methods will improve performance when used in dialog systems. The focus is on two specific questions. (1) Can we develop methods for learning to recover the context-dependent meanings of a sequence of natural language statements? For each sentence, we want to be able to automatically construct a rich, logical representation of its underlying meaning. In general, later statements can elaborate on, correct, or refer to parts of previous statements, leading to a challenging context-dependent reasoning problem. (2) Can we use probabilistic, game-theoretic models of multi-agent interaction to build effective dialog systems? Such an approach will explicitly model dialog participants jointly interacting in an uncertain world where each conversant has independent beliefs and desires that influence the conversational flow. <br/><br/>Building automated systems that participate effectively in natural language conversations is one of the classic goals of research in artificial intelligence. Such dialog systems have the potential to revolutionize the way we interact with computers. Although probabilistic techniques have been used successfully in a wide range of natural language processing problems, researchers have only recently started to develop them for modeling conversation. The methods we are developing should enable deployed systems to participate in significantly more complex conversations."
9414494,Artificial Intelligence Based Process Synthesis Methodology for In-Plant Waste Minimization,CBET,"Proc Sys, Reac Eng & Mol Therm",8/1/1994,2/24/1998,Yinlun Huang,"Huang, Y","Huang, Y",MI,Wayne State University,Standard Grant,Geoffrey Prentice,8/31/1998,"$151,881.00 ",,yhuang@wayne.edu,5057 Woodward,Detroit,MI,482023622,3135772424,ENG,1403,"9148, 9197, ENVI",$0.00 ,normalFunding,"Huang - Abstract - 9414494 Rapidly changing industrial technologies are often accompanied by the generation of hazardous or toxic wastes. One way to reduce the quantity and toxicity of these wastes is to incorporate waste minimization strategies into process design. This study will focus on the development of a novel and systematic process synthesis methodology for designing/modifying processes that satisfy environmental objectives. The methodology assesses cost and waste minimization simultaneously, and utilizes knowledge representing operation protocols, environmental regulations, and designers' experience of process design and implementation of waste minimization strategies. Because a large amount of extractable knowledge can only be represented in a symbolic form, and because the available process information and data are often imprecise, incomplete, and uncertain, conventional optimization techniques may not be applicable to solving waste minimization problems. Instead, the principle investigator (PI) uses artificial intelligence techniques (AI) in the development of this methodology. The adoption of these techniques will help the identification of economically desirable and operationally stable processes with minimum waste generation. The goal of this research is to develop an intelligent process design system based on AI methodology. This system consists of two subsystems: a decision support subsystem and a process synthesis subsystem. The first subsystem performs preconceptual synthesis. It is capable of identifying waste minimization problems in a process by means of an index of waste minimization, selecting the most efficient technology, determining the necessary unit operations and the interrelationships among processing units, and performing an overall economic evaluation. The second subsystem utilizes the selected technology to synthesize or modify a process which will not only be cost-effective but also environmentally clean. This design tool is not meant to replac e commercial process simulators, but could be used in conjunction with them. The tool will be applied to a variety of processes in the chemical and petrochemical industries which are traditionally major waste generators. The PI will work cooperatively with three companies, M. W. Kellogg, BASF, and Marathon Refining, in order to ensure that the design tool is effective for in-plant waste minimization."
716950,NSWP:  Automated Monitoring and Forecasting of Space Weather using Artificial Intelligence Techniques,AGS,SOLAR-TERRESTRIAL,8/1/2007,5/14/2009,Ju Jing,"Jing, J","Jing, J|Shih, F|Wang, H",NJ,New Jersey Institute of Technology,Continuing grant,Paul Bellaire,7/31/2010,"$151,415.00 ","Frank Shih, Haimin Wang",jj4@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,1523,"9196, EGCH",$0.00 ,normalFunding,"The proposing team will use pattern recognition techniques to predict the occurrence of solar flares, developing a new tool known as the Support Vector Machine (SVM). The proposers intend to develop tools to detect new magnetic flux emergence on the Sun, using circular harmonic component decomposition as a filter for an artificial intelligence classifier. This technique will characterize new flux emergence and establish the probabilities for active regions to become flare productive. They will implement a solar flare detection and characterization algorithm, including a classification scheme using the SVM, active region growth, and edge enhancement techniques. The algorithm will detect flare ribbon separations and help determine the electric currents in magnetic reconnection regions. The PI will also study a large number of CMEs using a characterization routine to establish the relationship between CME speed and magnetic reconnection rate. This will allow the prediction of CME kinetics based on real- time monitoring of magnetic reconnection. <br/><br/>This effort will enhance our understanding and prediction of processes affecting solar activity and the propagation of resulting solar effects to the Earth via the solar wind.  The work is inherently interdisciplinary, involving cutting-edge solar physics and computer science research. The techniques developed here also have potential utility for medical imaging, terrestrial weather forecasting, and pattern recognition for moving targets relevant to military applications. This proposal's education and training component involves the support of a newly graduated post-doctoral researcher and a graduate student. <br/>"
1258305,EAGER:  Toward Automatic Generation of Challenge-Driven Interactive Narratives,IIS,Cyber-Human Systems (CHS),12/1/2012,11/7/2012,Michael Mateas,"Mateas, M","Mateas, M|Wardrip-Fruin, N|Jhala, A",CA,University of California-Santa Cruz,Standard Grant,William Bainbridge,11/30/2014,"$151,044.00 ","Noah Wardrip-Fruin, Arnav Jhala",michaelm@soe.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7367,"7367, 7916",$0.00 ,normalFunding,"This project will conduct the first exploration of a computational system that co-generates intertwined narrative and gameplay progressions. The system will utilize a novel representation called ludo-narrative units (LNUs), representing combinations of narrative, gameplay challenges, and choices. Utilizing audience experience models taking into account phenomena such as player agency, narrative comprehension, and gameplay learning objectives, the system will reason about progressions of narrative choices, narrative exposition, and gameplay challenges, and can dynamically reshape content to match designated goals and audience context. To accomplish this, the project will build an artificial intelligence director to construct interactive scenarios for audiences during their engagement with a game-based narrative.<br/><br/>The dynamic construction of scenarios from a pool of authored LNUs would already comprise more flexibility than currently appears in state-of-the-art scenario driven games and other popular interactive narratives, since LNUs can be selected in multiple orders in response to audience activity. But the envisioned system will provide further flexibility and customization through modification of LNU content using story generation technology. Specifically, it will use a story-planning system based on imaginative recall to dynamically provide this content. Further, global narrative and gameplay structure will be provided by using a constraint-solving algorithm to create full experiences satisfying the various system goals, written using answer set programming techniques. This enables the crucial flexibility that allows the system to reason over an arbitrary number of domains without locking it into pre-planned interfaces and infrastructure.<br/><br/>A high-level impact of this research will be contributing to a deeper understanding of these scenarios, as it defines them with the level of rigor required for generation. At a more technical level, the research will produce the first system that generates mixed interactive narrative and gameplay guided by shared experience goals. One of the high-level motivations for pursuing this work is that it has potentially profound impact for education, allowing next-generation educational software to benefit from the motivating power of scenarios and to be generated specifically for the learning profile, goals, and progress of particular learners. It is also potentially the case that experiences generated in this manner, and based on these models, could more effectively reach audiences that have grown up with games as a primary media form."
1257700,CAREER: Art and Vision: Scene Layout from Pictorial Cues,IIS,ROBUST INTELLIGENCE,4/1/2012,9/18/2012,Stella Yu,"Yu, S","Yu, S",CA,International Computer Science Institute,Continuing grant,Jie Yang,12/31/2013,"$151,027.00 ",,stellayu@berkeley.edu,1947 CENTER ST STE 600,Berkeley,CA,947044115,5106662900,CSE,7495,"1045, 1187, 7495, 9218, HPCC",$0.00 ,normalFunding,"<br/><br/>CAREER: Art and Vision: Scene Layout from Pictorial Cues<br/><br/>PI:  Stella (XingXing) Yu     <br/><br/>Institution: Boston College<br/>Artists are the masters of visual perception. Studying art and vision together can provide new solutions to fundamental problems in computer vision. We focus on inferring scene layout from a single image. This problem has been studied since the earliest days of Artificial Intelligence research, resulting in a host of so-called Shape-from-X methods, where X could be shading, perspective, etc.<br/>Unfortunately, each of these methods works under its own assumptions which often do not hold in real images. How these cues interact and integrate remains elusive. Painters constantly use a combination of four techniques: occlusion, perspective, shading, and form to effectively evoke a 3D percept from a 2D picture. Studying their techniques can lend insights into the computation of recovering scene layout from pixel values. The PI proposes to bring artists and vision scientists together to solve the computational problem of scene layout from pictorial cues. This project realizes it in three areas:<br/>education, experiments and computational modeling.<br/><br/>A new interdisciplinary course, Art and Visual Perception, has been developed at Boston College to give a comprehensive cross-examination of how art contributes to the understanding of vision, and how vision contributes to the generation and viewing of art. Students are actively engaged in both art practice and vision experiments.<br/>Learning art and vision together results in a deeper understanding than studying each discipline separately. Students' assignments also result in valuable datasets for vision research.<br/><br/>The computational approach to scene layout from pictorial cues in this project is to group pixels into spatially organized surfaces from a global integration of multiple pictorial cues in a spectral graph-theoretic framework. The goal is to turn artistic rendering knowledge on how these cues interact into a computational reality.<br/>The PI will study geometry (occlusion and perspective), appearance (brightness and color), and form using eye tracking and psychophysics experiments and computational models. These efforts are organized into two phases that progress from inferring the spatial layout from scenes made of planar surfaces (rooms and streets) to scenes made of curved surfaces (landscape and generic scenes).<br/><br/>Intellectual Merit<br/><br/>What is most remarkable about vision is its ability to perceive 3D spatial layout from a single 2D image. The proposed research replicates this ability in computation from a grouping perspective.<br/>Compared to statistical learning approaches, the grouping method is not only generic and thus scales well with the number of scenes, but can also produce a precise organization of surfaces in the scene.<br/>Compared to traditional Shape-from-X approaches, the grouping method examines each pictorial cue in conjunction with others. The integration of these multiple pictorial cues allows them for the first time to become applicable to real images. The PI has developed the essential grouping machinery in spectral graph theory for depth segregation. Compared to most existing formulations on this topic, it has unparalleled conceptual simplicity, computational efficiency, and guaranteed near-global optimality. The proposed research on brightness and color perception, in connection with Shape-from- Shading and surface organization, will help clarify the role of low- level and high-level mechanisms in the long-standing scientific debate between Hering and Helmholtz on color perception.<br/><br/>Broader Impact<br/><br/>This project bridges the gap between art and science not only in research but also in education by developing a new curriculum that traverses the areas of neuroscience, psychology, computer science, and visual arts, by involving students in art practice and scientific experiments, and by providing a forum for artists and scientists to exchange ideas on visual perception. These interdisciplinary efforts befit the liberal arts education tradition at Boston College. This project will not only benefit from the strong Fine Arts department on campus, but also cultivate computer science awareness and outreach to non-technical people, and promote the growth of the young Computer Science department at Boston College.<br/><br/>URL:  http://www.cs.bc.edu/~syu/artvis/<br/>"
1058925,Collaborative Research: CI-ADDO-NEW: StarExec: Cross-Community Infrastructure for Logic Solving,CNS,SOFTWARE & HARDWARE FOUNDATION,9/1/2011,8/15/2011,Geoffrey Sutcliffe,"Sutcliffe, G","Sutcliffe, G",FL,University of Miami,Standard Grant,Nina Amla,8/31/2016,"$150,295.00 ",,geoff@cs.miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,CSE,7798,"7359, 7944",$0.00 ,normalFunding,"Logic solvers are software programs that can solve complex logical<br/>formulas fully automatically. Problems in many areas of Computer<br/>Science, such as artificial intelligence, program analysis, security,<br/>hardware verification, and cyber-physical systems can be faithfully<br/>translated into logical formulas. Those formulas can then be solved<br/>fully automatically by logic solvers. Over the past two decades, at<br/>least ten different logic-solving communities have emerged, based on<br/>different logical languages and solving techniques. These communities<br/>have independently been building computing infrastructure to aid<br/>development and evaluation of their solvers: libraries of benchmark<br/>formulas, cluster-backed web services, annual competitions, and more.<br/>Such infrastructure also provides an important access point for<br/>users, who can find all the solvers at one site, or even run solvers<br/>on the infrastructure cluster to test their relative capabilities.<br/>The goal of this research is to build a single piece of shared<br/>computing infrastructure called StarExec, which will be used by many<br/>different logic solving communities. StarExec will provide improved<br/>services for established logic-solving communities, and lower the<br/>entry barrier for new and emerging communities.<br/><br/>The StarExec infrastructure will consist of a custom web service<br/>interfacing to a medium-sized compute cluster. This open-source<br/>service will allow multiple logic-solving communities to host<br/>benchmark libraries, run jobs comparing different solvers, and host<br/>competitions. StarExec will leverage economies of scale to provide<br/>more sophisticated services than is feasible for most individual<br/>logic-solving communities. A very important goal of StarExec is not<br/>just to collocate different logic-solving communities, but to unite<br/>them. To this end, the StarExec team will develop formal<br/>specifications of both the syntax and proof-theoretic semantics of<br/>different communities' logical languages. This will be done using a<br/>meta-language called LFSC (""Logical Framework with Side Conditions""),<br/>developed in previous NSF-funded research. Translation of formulas<br/>between compatible fragments of different logics will be implemented,<br/>which will will enable a greater degree of integration between solver<br/>communities than was previously possible. For example, it will be<br/>possible for solvers in one community to be run on benchmarks from<br/>another. This integration will also aid users of logic solvers, who<br/>will have a greater variety of options, all in a common framework, for<br/>solving their problems. The broader impact of the StarExec project<br/>will be to accelerate the development, adoption, and convergence of<br/>different logic-solving technologies. This will enable faster<br/>progress in nationally important application areas such as artificial<br/>intelligence, verification, security, and cyber-physical systems,<br/>which increasingly depend on high-performance logic solvers."
9733018,CAREER:  RUI: Temporal/Multi-dimensional Reasoning with     Imprecision and Uncertainty,IIS,ARTIFICIAL INTELL & COGNIT SCI,12/15/1998,10/18/2000,Debasis Mitra,"Mitra, D","Mitra, D",MS,Jackson State University,Continuing grant,Michael E. Lesk,11/30/2001,"$150,068.00 ",,dmitra@cs.fit.edu,1400 J R LYNCH ST.,Jackson,MS,392170002,6019792008,CSE,6856,"9216, 9229, HPCC",$0.00 ,normalFunding,"  The goal of this project is to develop algorithms for the purpose of reasoning with time and other higher   dimensional space.  Reasoning with time and three-dimensional space is ubiquitous in our daily life as   well as in computer systems.  For example, a detective would often check the temporal consistency of an   alibi of some suspects. A system for packing boxes in a container would reason with space. For about the   last  two decades some researchers within the artificial intelligence community have been engaged in   studying this area. The PI has been involved in critically analyzing some of the existing algorithms and   developing new efficient algorithms for temporal reasoning.  A particular area of interest in this  project is on studying temporal reasoning under uncertainty. If the input information is not completely   known and is ringed with uncertainty, then how does it affect the reasoning process? How is it possible to   determine possible causes for events from the available temporal information?  These are the types of   questions, which are being investigated in this work. Viewing temporal (or higher dimensional)   information as constraints, an algorithmic approach for constraint propagation is being employed in the  research. A deeper understanding of dimension related reasoning and more efficient mechanisms for   doing it computationally will emerge from this project.    http://stallion.jsums.edu/~dmitra/str.html"
637714,SBIR Phase I: Artificial Intelligence Tutoring and Assessment for Teacher Development,IIP,SMALL BUSINESS PHASE I,1/1/2007,6/8/2007,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Ian M. Bennett,12/31/2007,"$150,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,5371,"1658, 9218, HPCC",$0.00 ,normalFunding,"This Small Business Technology Transfer Phase I research project focuses on bringing the power and benefits of cutting-edge artificial intelligence tutoring technology to the arena of teacher professional development. The need for effective, high-quality professional development in science is particularly serious for teachers who are new and/or teaching outside their field of expertise. Conventional models of professional development (e.g. attending workshops and seminars) have little impact for a truly struggling teacher. Web-based materials, though available on demand, currently lack the depth and sophistication needed to effectively meet the needs of the new teacher for pedagogy and content in complex scientific subjects. The proposed innovation is the creation of professional development resources that use advanced AI technology to model and teach proven effective content and pedagogical strategies of an outstanding teacher, and provide the teacher with a sophisticated means of self-monitoring and assessment. This will have an especially meaningful impact for new teachers and teachers struggling out-of-field.<br/><br/>The results of this research will be an artificial intelligence-based professional development system delivered in a just-in-time fashion over the Internet. The ability to leverage proven effective artificial intelligence educational technology for professional development represents a new design paradigm, which will have broad implications for developing new models of sophisticated, AI-based professional development in many subjects beyond chemistry. Though the impact will be most immediate for new teachers and teachers struggling out of field, the technology and approach hold potential to benefit teachers at all levels of experience. The prospective applications of the approach will address the goals of the American Competitiveness Initiative (ACI) and Highly Qualified Teachers in No Child Left Behind."
1046036,SBIR Phase I: Artificial Intelligence Software to Tutor Literary Braille to the Blind and Visually Impaired,IIP,"SMALL BUSINESS PHASE I, REAL",1/1/2011,12/15/2010,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Glenn H. Larsen,6/30/2011,"$150,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,"5371, 7625","5371, 6856, 9177, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project aims to focuses on developing the first artificial intelligence software to tutor literary Braille to blind/visually impaired students. Braille is the primary medium for written communication for the blind and there has been a dramatic decline in Braille literacy, negatively impacting academic performance, ability to navigate the everyday world and employment opportunities. The ability to bring proven effective AI technology to the table, will make a meaningful difference in providing equitable education opportunities to all students, as this project speaks directly to issues of basic literacy. Initially targeted for K-12 students, the majority of which are mainstreamed students served by the itinerant teacher of the visually impaired (TVI), the tutor will be web-based, enabling anyone to receive expert support on demand during study at school and home. Importantly, the tutor will operate using standard accessibility technology already in use. Because the tutor is supplemental to existing curricula and integrates directly with existing lessons, it will not require teachers/TVIs to change lessons, teaching materials, or schedules. In addition to improving learning outcomes for students, this project will also include support for teachers/TVIs responsible for instruction.<br/><br/>The broader/commercial impact of this project will be the potential for Braille education software based on artificial intelligence, delivered just-in-time through the Internet. The anticipated impact is that students achieve literacy and are able to perform at a higher level (e.g. academics, daily living, employment) resulting in improved quality of life and increased societal contributions. To have an impact, the product must be affordable, effective for a heterogeneous population in diverse learning environments, easy to use and easily accessed at convenient times and locations in informal and formal educational settings. In SBIR research supported by NIH, Quantum has successfully created AI-based educational software that is accessible to the blind (in chemistry). Furthermore, Quantum has successfully patented and commercialized unique AI technologies in chemistry and accounting using a business-to-business licensing model that provides educational companies with first-to-market and strong sustainable advantages. This model engages the entire spectrum of educational vendors, offering breakthrough technology that permits increased market share for customers and rapid dissemination to end users. For this project, Quantum will partner with organizations with established channels, who distribute the software as an online service, such as the American Printing House for the Blind, a partner on this project."
1550705,EAGER: A Theory of Local Learning,IIS,ROBUST INTELLIGENCE,9/1/2015,7/23/2015,Pierre Baldi,"Baldi, P","Baldi, P",CA,University of California-Irvine,Standard Grant,Weng-keen Wong,2/28/2017,"$150,000.00 ",,pfbaldi@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,"7495, 7916",$0.00 ,normalFunding,"Artificial intelligence draws its inspiration from biological intelligence, and both rely on learning to achieve intelligent behavior. Thus, within AI, the field of machine learning plays a central role having indeed achieved impressive successes in dealing with many complex tasks, ranging from computer vision to language understanding, and thereby benefiting billions of humans. Machine learning uses large networks of artificial neurons, which are simplified versions of biological neurons, where learning is implemented by progressively adjusting the weights of the connections between these neurons. The deep learning problem faced by both biological and artificial neural networks is precisely the problem of how deep neurons, located far away from the network inputs or outputs, can adjust their connection weights to ensure that the networks behave intelligently. This fundamental problem and the space of its possible solutions are not well understood. Because deep learning has wide range of applications in technology and science, from computer vision to protein structure prediction, progress in our fundamental understanding of deep learning is likely to have a broad impact across multiple areas.  Furthermore, the theory of local learning is inspired by biological considerations and it has the potential for strengthening the bridge between AI/machine learning and neuroscience. The resulting theory, algorithms, data, software, and results will be broadly disseminated through multiple channels and integrated into educational and outreach efforts.  The project PI will continue his broad activities bringing research into undergraduate and graduate courses, outreach to local high school students through hosting at a summer program and lectures to high school students.<br/><br/>To try to address the deep learning problem, over half a century ago D. Hebb proposed a vague strategy often summarized by the expression ""neurons that fire together, wire together"". The essence of this effort is to improve our fundamental understanding of deep learning by bringing clarity to Hebb's proposal and providing a novel rigorous framework for studying learning rules. The framework requires first introducing the notion of local learning: in a physical neural system, learning rules for adjusting connection weights must be local, i.e. functions of only variables that are available locally. Thus one must separate the definition of local variables from the functional form that ties them together into a learning rule. This separation enables the creation of a systematic program for studying local learning rules, by first stratifying learning rules according to their functional complexity, and then studying their behaviors in networks of increasing complexity, from shallow and linear to deep and non-linear. The proposed program of study is likely to lead to the discovery of new learning rules and a better understanding of the capacity and limitations of local learning, ultimately advancing our theoretical and practical understanding of the deep learning problems and its solutions."
1138325,CRPA: Communicating Avatars: Artificial Intelligence + Computer Graphics = Innovative Science,DRL,AISL,10/1/2011,9/25/2011,Avelino Gonzalez,"Gonzalez, A","Gonzalez, A|DeMara, R",FL,University of Central Florida,Standard Grant,Paul W. Jennings,9/30/2014,"$150,000.00 ",Ronald DeMara,gonzalez@ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,EHR,7259,"9177, SMET",$0.00 ,normalFunding,"This CRPA project will produce a human-like avatar exhibit for the Orlando Science Center that will verbally communicate with middle and high school grade visitors, engaging them in the subjects of computer science, artificial intelligence, and engineering. Human-like characteristics include features to match the demographics of the Center's clientele and verbal communication in the English language. In addition to discussing how avatars are developed and how artificial intelligence works, the avatar image will answer questions from the visitors on selected topics, including subjects from the media models of Avatar and IBM's Watson event on Jeopardy. <br/><br/>Considerable planning and research has gone into this project to make sure that the avatar is life-like and can engage in realistic dialog. The avatar images will resemble real individuals who have diverse demographic characteristics in order to enhance the human-computer interface. The system is designed to deal with background noise and antagonistic visitors. Evaluation at all levels (front-end, formative, and summative) will make the exhibit most effective and facilitate the goals of the project which are to inform the target audience on STEM subjects.<br/><br/>The desire to have electronic analogs of humans has been a goal for half of a century. This project builds on prior research in this area and is one of the most sophisticated contemporary models in the field. It is anticipated that this work may contribute to future applications in education and assistance for individuals with disabilities. Moreover, engagement with the avatar may ignite curiosity among young visitors and stimulate interest in science careers."
1047441,SBIR Phase I:  Commercial Scale-Up Of An Intelligent Modular Robot Platform iMobot for Research and Education,IIP,SMALL BUSINESS PHASE I,1/1/2011,12/9/2010,Graham Ryland,"Ryland, G","Ryland, G",CA,"Barobo, Inc.",Standard Grant,Glenn H. Larsen,6/30/2011,"$150,000.00 ",,gryland@barobo.com,"813 Harbor Blvd, Suite 335",West Sacramento,CA,956912201,9167158840,ENG,5371,"1658, 5371, 9216, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project will study the feasibility for commercialization of an intelligent reconfigurable modular robot system called iMobot, which was originally developed at the University of California, Davis. Nowadays, robotics has grown beyond automation to encompass intelligent systems that are self-reliant, reconfigurable, mobile, intelligent, and aware of their environment. iMobot has four degrees of freedom capable of full mobility and assembly into clusters. Because of its flexibility, modularity, and reconfigurability, iMobot will be an ideal platform for many research and teaching programs in colleges and universities. For example, it allows researchers to study artificial intelligence, swarm technology, robot collaboration, mobile networking, and programming for reconfigurability. iMobot is designed with open architecture. Each module has a processor capable of supporting sensor fusion, gait simulation, and runs an open source embedded Linux operating system. Users can customize software and accessories for their specific needs. Proposed product feasibility research includes adaptable connectivity between modules, intelligent plug-and-play sensors, a robust and lightweight chassis, and re-configurability. In this proposed project, a professional design team will re-design and build a commercial quality prototype of iMobot for manufacturing in a large quantity. <br/><br/>The broader impact/commercial potential of this project is that the proposed project will be one of the first attempts to scale up an intelligent reconfigurable modular robot for commercial deployment. The iMobot could be used for university research and teaching, K-12 STEM education, and life-saving rescue and search operations in the first responder system. With a standardized hardware base using an open architecture, users will be able to more widely share their work with each other, and to create a valuable open educational resource. Robotics is an interdisciplinary field. The unique full mobility and reconfigurability of iMobot are very appealing to college and K-12 students. The robot can be used alone or in collaboration with others, making it a flexible and scalable educational tool. By introducing students to interesting robotic projects with affordable hardware platforms, which involve a variety of math, physics, information technology, and engineering principles, we can excite their imagination and give them confidence to pursue STEM careers, especially for underrepresented and economically disadvantaged groups."
520333, Collaborative Research:   NeTS-NBD:   Intelligent and Adaptive Networking for the Next Generation Internet,CNS,Networking Technology and Syst,8/15/2005,8/16/2007,S.J.Ben Yoo,"Yoo, S","Yoo, S|Levitt, K|Wu, S|Olshausen, B|Chuah, CN|Rowe, J",CA,University of California-Davis,Standard Grant,Darleen L. Fisher,7/31/2008,"$150,000.00 ","Karl Levitt, Shyhtsun Wu, Bruno Olshausen, Chen-Nee Chuah, Jeffrey Rowe",yoo@ece.ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,CSE,7363,"7388, 9218, HPCC",$0.00 ,normalFunding,"This project investigates the Next Generation Network Technology and Systems capable of understanding and learning the high-level perspective of the network.  The proposed approach pursues a new cognitive intelligent networking paradigm that maintains the success of today's Internet but which also incorporates cognitive intelligence in the network--a new networking technique that provides the ability for the network to know what it is being asked to do, so that it can step-by-step take care of itself as it learns more. In particular, we explore new networking architecture and network elements that will lead to a future network with (a) improved robustness and adaptability, (b) improved usability and comprehensibility, (c) improved security and stability, and (d) reduced human intervention for operation and configuration.  This project pursues a set of comprehensive studies that seek innovations through the design and modeling of a new brain-reflex cognitive intelligence architecture, an intelligent programmable network elements architecture, and an intelligent network control and management design.  <br/><br/>Broader Impact:  The team approach covering neuroscience, datamining, computer science, systems engineering, artificial intelligence, and networking will provide rich opportunities for students to learn beyond their primary fields of study.  New courses developed by the faculty members will disseminate the new material covering neuroscience and information technology.<br/><br/>"
1345495,SBIR Phase I: Beating back bullying: A virtual role-playing simulation that teaches perspective taking using artificially intelligent characters and crowdsourcing,IIP,SMALL BUSINESS PHASE I,1/1/2014,12/31/2013,Geoff Marietta,"Marietta, G","Marietta, G",MA,Marietta Geoff E,Standard Grant,Glenn H. Larsen,6/30/2014,"$150,000.00 ",,gem160@mail.harvard.edu,1 Oxford St.,Cambridge,MA,21382901,6177773364,ENG,5371,"110E, 5371, 8031, 8032, 8042",$0.00 ,normalFunding,"This SBIR Phase I project proposes to create a pro-social simulation to reduce aggressive behaviors in children, using a novel platform for simulated role-playing from crowdsourced data. Through a browser or mobile app, participants enter a 3D virtual school environment where they play the roles of a bullying victim and bystander, and interact with characters controlled by artificial intelligence (AI). By walking in another's shoes, users take the perspective of others and empathize with them -- capacities proven to foster improved relationships. The effectiveness of the simulation lies in allowing users to interact in the virtual world as they would in their real-world school. Virtual characters respond authentically by drawing from a massive database of recorded human dialogue, providing individualized responses tailored to unique user input. The project makes three important intellectual merit contributions. In furthering computer science, it integrates advanced computing techniques -- AI, natural language processing, and crowdsourcing -- in a novel way. Second, it makes theoretical contributions to social science by enhancing understanding of how social psychology principles function in the virtual world. Third, in the field of analytics, software tools will mine patterns of communication strategies, generating knowledge about the impact of specific phrases on relationships. <br/><br/>The broader/commercial impact of reducing bullying and improving relationships between children through unscripted, psychologically vivid, safely-controlled interactions in virtual environments is enormous. An extensive and deep body of research shows that bullying is pervasive in schools and has significant acute and chronic effects on learning and health outcomes. Despite the tremendous societal cost of bullying -- estimated around $25 billion -- and legal mandates to address the problem, a majority of schools do not have anti-bullying interventions in place. Existing interventions are expensive, difficult to implement, and focus on building awareness, rather than changing behaviors. This project will create a cost-effective and rapidly-scalable technology that mimics the complexities of human interaction to increase social perspective taking and empathy in children and adolescents. Dozens of middle and high schools have already agreed to implement the technology once developed. Improvement in student relationships and learning in these schools will be immediate. The technology developed has tremendous commercial potential for any training that relies on social and communication skills, such as corporate management, doctor-patient communication, autism therapy, and English language learning. Applications in these and other areas will generate dozens of new jobs for educators, engineers, developers, and data analysts."
1214817,SBIR Phase I: A Novel Human Robot Interaction System Using Affective Theory-of-Mind Computing to Improve User-Responses and Efficacy of Automated Tutoring,IIP,SMALL BUSINESS PHASE I,7/1/2012,10/23/2012,Kino Coursey,"Coursey, K","Coursey, K",TX,Hanson Robokind And Intelligent Bots LLC,Standard Grant,Muralidharan S. Nair,6/30/2013,"$150,000.00 ",,kino.coursey@gmail.com,10515 Lennox Lane,Dallas,TX,752295415,2148084591,ENG,5371,"5371, 6840, 8034, 9139, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project advances artificial intelligence (AI) and robotics by developing the foundation for emotionally responsive systems. Building on Theory of Mind research in psychology and robotics, this project focuses on enhancing a robot's capacity to integrate two pieces of information in order to determine a third piece. These inferences can be concrete or as abstract as conjectures about another agent's - including a human user's -beliefs, desires, and intentions. The project creates a framework for the robot's AI system to maintain several competing models of the world (particles) and select and modify those models that have a higher likelihood of matching the real world (filtering). This method of ""Particle Filtering"" is an effective strategy or navigating complex environments. The core research focuses on adapting and assessing particle filtering methods within abstract contexts including knowledge, emotional, and goal states. If successful, as the robot gains additional information through sensors and language processing, it will adapt its models of the users' emotional state and adjust its interactions accordingly. Essentially, this integrative framework will enable robots to understand human desires and frustrations to find creative solutions in response to those needs. <br/><br/>The broader impact/commercial potential of this project is the evolution of an Artificial Intelligence interface that emulates an empathic human-to-human experience. Because the system will represent and track multiple dimensions about a human user, the robot can recognize when a user is confused or frustrated and respond accordingly. This intuitive, naturalistic AI platform has substantial research, education, and therapeutic applications and commercialization channels. With its open source software infrastructure and the relative low-cost of the platform, the initial commercial targets are as a platform for robust Science, Technology, Engineering, and Mathematics (STEM) education and as therapeutic technology for children and adults on the autism spectrum."
1546829,EAGER: Automated Content-Based Detection of Public Online Harrassment,CNS,Secure &Trustworthy Cyberspace,7/1/2015,7/9/2015,Jennifer Golbeck,"Golbeck, J","Golbeck, J",MD,University of Maryland College Park,Standard Grant,Ralph Wachter,12/31/2016,"$150,000.00 ",,jgolbeck@umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,8060,"7434, 7916, 9102",$0.00 ,normalFunding,"Public, online harassment takes many forms, but at its core are posts that are  offensive, threatening, and intimidating.  It is not an isolated problem. The Pew Research Center found 73% of people had witnessed harassment online, and a full 40% of people had experienced harassment directly. This research develops a method for analyzing the things people post online, and automatically detecting which posts fall into the category of severe public online harassment -- messages posted simply to disrupt, offend, or threaten others. This helps websites better limit what messages are posted and reduce the amount of harassment people experience online.<br/><br/>The researchers develop a corpus of online comments from a number of media outlets and social media platforms where each post is labeled as harassing or non-harassing. Then, they apply a set of computational linguistic techniques that describe features of the message, including types of words and language structure, which is passed to rule-based and machine learning artificial intelligence systems for classification. The goal is to develop models that can automatically detect the public online harassment messages with high accuracy."
1247360,SBIR Phase I: Data-Driven Guiding Technology: Transforming Training and Therapy,IIP,SMALL BUSINESS PHASE I,1/1/2013,11/8/2012,John Nosek,"Nosek, J","Nosek, J",PA,SenseMaking Technologies Corporation,Standard Grant,Glenn H. Larsen,6/30/2013,"$150,000.00 ",,johnnosek@verizon.net,721 Dresher Road Suite 2400,Horsham,PA,190442218,6096059273,ENG,5371,"5371, 8031, 8032",$0.00 ,normalFunding,"The innovation is an agent-based, data-driven guiding technology that will augment the human facility to evaluate task performance by overcoming human limitations to recall complex processes that require high expertise. The cloud-based, mobile technology will assist teams of varying expertise and capabilities to more effectively instruct, coordinate, and assess learning progress of students, especially those with developmental delays. The technology will provide natural, hands-free support for the instructor who guides the student in each attempt within a complex program of study. The technology will 1) select the task, 2) provide pre-evaluation guidance on setup, prompts, target response and instructions, 3) using speech recognition, record task performance evaluations, 4) provide post-evaluation guidance on what reinforcement to provide, if any, and 5) select the next task. The enabling of automatic capture of rich, high quality data for each task attempt will facilitate the use of advanced artificial intelligence techniques, such as associative data mining, to provide more customized programs of instruction. This project will overcome instructor expertise and process complexity barriers and eliminate data collection burdens while increasing data and program fidelity that will result in better, faster learning. <br/><br/>The broader/commercial impact of this innovation will occur in both Applied Behavior Analysis (ABA) and non-ABA areas. Initially it will help tackle the crisis in providing cost effective, quality therapy to individuals with autism. Autism affects more than 1% of the world?s population. ABA is the gold standard in treating autism. Up to fifty percent of children with autism who undergo early treatment improve their IQs and developmentally progress so they can mainstream into standard classrooms with no educational assistants. Without early intervention, there is almost no chance. ABA is most effective when the team of certified ABA analysts, non-certified ABA therapists, educational assistants and family members coordinate instruction. However, expertise and process complexity barriers experienced by instructors, coupled with the burdens of data collection, limit its effectiveness, while the shortfall of trained therapists and its high costs (60K/child/year) limit its availability. The technology will increase available ABA therapy by 1) accelerating training, 2) enabling team members to instruct more easily and effectively with greater data and program fidelity and 3) lowering costs. This innovation will accelerate the availability of transformational, affordable technology that will improve the lives of many and ameliorate a major world health problem."
623166,HSD:  Research Community Development: Distributed Learning and Collaboration (DLAC) for Next Generation Educational Settings,BCS,HSD - AGENTS OF CHANGE,10/1/2006,3/7/2007,Eric Hamilton,"Hamilton, E","Hamilton, E|Hesse, F|Shen, R|Carmona, G",CO,United States Air Force Academy,Interagency Agreement,Thomas J. Baerwald,9/30/2008,"$150,000.00 ","Friedrich Hesse, Ruimin Shen, Guadalupe Carmona",eric.hamilton@pepperdine.edu,2354 Fairchild Dr Ste 2h29,USAF Academy,CO,808406208,7193334195,SBE,7318,"0000, 7318, OTHR",$0.00 ,normalFunding,"This project seeks to carry out research community development in the area of distributed learning and collaboration for next-generation educational settings.  The project is a follow-up to the international  Distributed Learning and Collaboration Symposium (DLAC, reported at http://dlac-research.net) lead-funded by the National Science Foundation (NSF) and hosted by Shanghai Jiao Tong University (SJTU) in June 2006.  This new project cuts across domains like artificial intelligence, cognitive neuroscience, net-based communication systems, online learning, pedagogical agent systems, science, mathematics and engineering education reform, and international education development. <br/><br/>The investigators contend that high-performance learning environments of the future will require profound steps of integration if those learning environments are to immersively and fully engage learners in the challenging and changing forms of science, mathematics, or engineering, to enable new forms of meaningful collaboration become part of the rhythm of daily experience, and to enable teachers to undertake new and more meaningful tasks.<br/><br/>Some of the most important advances in fields critical to these new learning environments have come as a result of strategic investments by NSF and others in the U.S.A., but many of the most important or successful pacesetters are researchers in other nations.  They possess experimental approaches, data, discoveries and ways of analyzing and resolving problems that are crucial to the work of U.S. investigators.  This project's goal is to build an integrative and productive international research community whose participants are at home with the language, traditions, approaches, and frontiers of each other.<br/>  <br/>The project will be carried out through multiple mechanisms.  A formal research symposium, ""DLAC-II"" will take place at the Knowledge Media Research Centre (KMRC) in Tuebingen, Germany.   KMRC will co-fund this symposium.  A series of web-based research seminars with participants internationally will take place before and after the DLAC-II.  The project will also provide seed support for a series of international collaborations among early career investigators. <br/>"
1147641,EAGER: IIS: RI: Learning in Continuous and High Dimensional Action Spaces,IIS,ROBUST INTELLIGENCE,9/1/2011,8/5/2011,Ronald Parr,"Parr, R","Parr, R",NC,Duke University,Standard Grant,todd leen,8/31/2013,"$149,996.00 ",,parr@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7495,7916,$0.00 ,normalFunding,"The proposed research is in the general area of ""planning under uncertainty.""  This topic addresses the problem of choosing good actions in situations where actions do not have deterministic outcomes.  Applications for this general framework include but are not limited to robotic control, medical decision making, and business optimization.  The overarching mathematical framework for this problem is that of decision theory or Markov decision processes, topics that are studied in a wide range of fields, including engineering, economics, operations research and, more recently, artificial intelligence.  <br/><br/>Recent technical efforts in this area have sought to address large problems by combining successful statistical and machine learning techniques with decision-theoretic reasoning.  The underlying insight behind these efforts is that machine learning can generalize across similar states of the world, thereby allowing algorithms to propose good actions for new states of the world without explicitly considering every possible state or outcome, as was required by classical approaches.<br/><br/>The combination of classical decision theoretic methods and machine learning has shown great promise for large state spaces, but one aspect that has been under-explored is large action spaces.  Large action spaces arise naturally from a fine discretization of a continuous action space or from a large set of discrete choices, such as assignments of firefighters to regions on a map.  One way to address the general challenge would be to group actions into sets and use machine learning methods to predict which set is preferred.  By doing this multiple times over carefully arranged partitions of the action space, it should possible to achieve an exponential reduction in the effort required to select the best action.<br/><br/>Potential applications of this research include robotic control, power grid management, and forest/fire management strategies."
937629,QIC: Query in Context for Educational Collections,DUE,NATIONAL SMETE DIGITAL LIBRARY,10/1/2009,8/20/2009,Min Song,"Song, M","Song, M",NJ,New Jersey Institute of Technology,Standard Grant,Herbert H. Richtol,9/30/2012,"$149,985.00 ",,min.song@njit.edu,University Heights,Newark,NJ,71021982,9735965275,EHR,7444,"9178, SMET",$0.00 ,normalFunding,"With its accessibility and explosive growth of content, the NSDL repositories are in a prime position to provide quality material teachers and other knowledge seekers need. Still, studies show teachers' dissatisfaction with online resources. They are frustrated with the time-consuming manual effort to retrieve and review each link when searching for appropriate material. This often leads to settling for good enough content. To sustain and increase the utilization of NSDL's quality resources, it is important a more sophisticated methodology for query and retrieval be developed.<br/>Query in Context for Educational Collections (QIC) is a research project utilizing context sensitive retrieval, semantic query analysis, and concept extraction techniques to create QIC's portable unified knowledge discovery system. QIC minimizes human intervention in the extraction process and reduces the number of contextually inaccurate results displayed. It revolutionizes individual search by shifting the burden of information overload from the user to the computer. QIC's functionality extends NSDL's NCore search services without significant changes to the format and organization of digital collections or extensive additional user provided data. <br/>With QIC, teachers find relevant information in the initially retrieved entries, thereby increasing satisfaction through reduced time and effort. This effectiveness improves digital library utilization, encourages knowledge seeking, and idea exploration. This contributes to the sustainability of NSDL and partner collections. QIC's long-term goal is to provide personalized information retrieval by discovering information in multiple formats and incorporating Web2.0 tools to improve the display and relevance of results."
631602,Inducing Features from Visual Noise using Statistical Machine Learning Techniques,SES,MATHEMATICAL SOC & BEHAV SCI,11/15/2006,11/2/2006,Andrew Cohen,"Cohen, A","Cohen, A",MA,University of Massachusetts Amherst,Standard Grant,Cheryl L. Eavey,1/31/2010,"$149,980.00 ",,acohen@psych.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,SBE,7397,"0000, 7303, OTHR",$0.00 ,normalFunding,"Understanding how humans differentiate between visual objects is a central problem for psychologists who want to understand the visual system and for computer scientists who want to emulate its abilities. <br/>Previous work has developed techniques for determining the image locations and spatial frequencies most responsible for human performance in classification and identification tasks. These techniques, however, cannot tell us if the important image features are detected in a single step, for example, by matching the visual object to a single internal representation such as a template, or by combining the result of multiple detectors. With support from the National Science Foundation, Dr. Andrew Cohen from the University of Massachusetts, Amherst, will develop a new model, the Multiple Independent Template Induction Model (MITIM), designed to answer such questions.<br/><br/>Human behavioral experiments on tasks such as word recognition in noisy images have suggested that people do not always recognize objects holistically. Rather, they appear detect pieces independently and then combine those results. If this is true in domains such as face or object classification and recognition, understanding these abilities requires knowledge of the independently detected parts and their relative importance. The proposed MITIM algorithm will use statistical techniques from artificial intelligence research to process human image classification data and discover the independent templates used in object recognition. The insights gained will help illuminate human visual performance and help scientists and engineers better understand how to build computer systems that can replicate that performance, functionality that is increasingly important in web search, robotic, and security applications.<br/><br/>This award was supported as part of the fiscal year 2006 Mathematical Sciences priority area special competition on Mathematical Social and Behavioral Sciences (MSBS)."
1345724,"SBIR Phase I: Trains of Thought, a novel game-based learning curriculum module to teach STEM and entrepreneurship skills",IIP,SMALL BUSINESS PHASE I,1/1/2014,11/6/2013,James Niehaus,"Niehaus, J","Niehaus, J",MA,Charles River Analytics Inc,Standard Grant,Glenn H. Larsen,6/30/2014,"$149,966.00 ",,jniehaus@cra.com,625 Mount Auburn Street,Cambridge,MA,21384545,6174913474,ENG,5371,"5371, 8031, 8032, 8043, 9117",$0.00 ,normalFunding,"This SBIR Phase I project proposes to design and demonstrate the feasibility of Trains of Thought, a novel game-based learning curriculum module to teach STEM (science, technology, engineering, and mathematics) and entrepreneurship skills to high school students. This project has significant intellectual merit. US kindergarten through twelfth grade (K-12) STEM education is falling behind global standards (National Science Board, 2007; US Department of Labor, 2007), and current educational practice is not doing enough to prepare our students to compete in the global economy. Trains of Thought explores new applications of game-based learning to this problem. The approach combines (1) proven educational research in preparation for future learning (Schwartz & Martin, 2004) and guided experiential learning with scaffolding (Hmelo-Silver, Duncan, & Chinn, 2007); (2) an existing, popular, open source business simulation video game; and (3) artificial intelligence experience management (Weyhrauch, 1996), (Roberts, 2011), (Mott & Lester, 2006) to balance educational objectives with engaging gameplay, maintaining a sense of flow. The project builds upon emerging educational research results to develop a fundamentally new methodology for game-based learning. If successful, this effort should set new standards for the use of games for teaching STEM and entrepreneurship in K-12 classrooms.<br/><br/>The broader/commercial impact of the proposed research, curriculum module, and accompanying game software can help to reverse the trend of declining US STEM and entrepreneurship education. This effect directly supports our future business leaders in driving American innovation and our nation's long-term economic prosperity. The transformative concept of effective game-based learning has the potential to reach out to under-represented demographics in STEM-based entrepreneurial businesses - including women, African-American, Hispanic, and Latino populations - by providing students new ways to engage, interact, and learn from core educational content. The knowledge gained from the proposed effort also has significant implications to the scientific and educational communities for the design and application of game-based learning. Our principles, methods of development, and evaluation outcomes may form a model for developing additional curriculum modules on a variety of subjects, therefore increasing effectiveness of US STEM and entrepreneurship education in a wider context. These results may also spur new research efforts to refine and extend our findings in game-based learning, creating more effective STEM and entrepreneurship education in future efforts."
9628685,RIMI: Intelligent Fault Diagnostic Tools for Advanced Predictive and Preventive Maintenance of Manufacturing Systems,HRD,RES IMPROVE IN MINORITY INSTIT,9/1/1996,10/14/1997,Amir Shirkhodaie,"Shirkhodaie, A","Shirkhodaie, A|Bodruzzaman, M",TN,Tennessee State University,Standard Grant,William A. Sibley,8/31/1998,"$149,958.00 ",Mohammad Bodruzzaman,ashirkhodaie@tnstate.edu,3500 John A. Merritt Blvd.,nashville,TN,372091561,6159637631,EHR,9130,"9161, AMPP",$0.00 ,normalFunding,"HRD - 9628685 Shirkhodaie Tennessee State University The College of Engineering and Technology at Tennessee State University proposes an instructional research activity to develop intelligent fault diagnostic tools for advanced predictive and preventative maintenance of manufacturing systems. The significant impact of this dual purpose project is four fold. First, it will support the college's effort to implement a maintenance engineering program at the graduate level. Secondly, it will strengthen the College's research capability to undertake maintenance projects of mutual interest to industry, Federal Government and funding research organizations. Finally, it will expand the College's research capabilities in one of its major core competencies, that of intelligent health monitoring of structures, and mechanical/thermal fluid systems. For this purpose, a 30-month, four phase project is proposed to develop and test intelligent fault diagnostic tools for advanced predictive and preventative maintenance of manufacturing systems. The research goal of the proposed project is to develop advanced predictive maintenance tools which can detect a potential maintenance problem (i.e., dry bearing) 25 to 50 percent sooner than traditional diagnostic techniques. In addition to detecting a potential problem, the proposed tools will identify the source of the potential problem and propose a corrective measure(s). Phase 1 research will focus on development of neural network based fault detection tools for pump-motor sets found in manufacturing systems. Phase 2 research objective is to add intelligent diagnostic capabilities to the neural network based fault detection tools. Artificial intelligence and fuzzy logic will be incorporated to make the tool intelligent with the capability to identify the source of a potential problem and recommend a corrective action(s). Phase 3 research will focus on testing the developed tools in a simulated, real world, manufacturing en vironment. This proof-of-concept testing will compare fault detection and identification rates using conventional techniques to that of intelligent fault diagnostic tools. Phase 4 involves the concurrent modernization of the College's Vibration Laboratory. It is in this laboratory that the advanced predictive tools will be tested. The proposed four phase research project will be completed over a 30-month period at a cost $150,000.00. At the completion of the proposed instructional research project the College of Engineering and Technology will have in place a maintenance engineering program at the graduate level, with predictive and preventative maintenance as a core instructional focus, in addition to proven analytical techniques for developing intelligent diagnostic tools with a Vibration Laboratory for testing the developed tools."
1549078,SBIR Phase I:  Big Data Analytics for Facility Operations and Management,IIP,SMALL BUSINESS PHASE I,1/1/2016,9/6/2016,Burcu Akinci,"Akinci, B","Akinci, B",PA,"LeanFM Technologies, Inc.",Standard Grant,Peter Atherton,10/31/2016,"$149,850.00 ",,bakincileanfm@gmail.com,100 S Commons,Pittsburgh,PA,152120000,4129532517,ENG,5371,"5371, 8032",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to help owners and operators of commercial and institutional buildings to improve resource allocation by analyzing data from built infrastructure to enable smarter decision-making supported by detailed, measureable, real-time knowledge. By automatically integrating building information that is stored using various software applications and formats, this innovation enables owners and facilities managers to efficiently search for information and respond to emergency and failures, and proactively plan for operation and maintenance tasks. This innovation also applies artificial intelligence to automatically conduct big data analysis and identify opportunities to improve energy efficiency and operating performance of assets and indoor environment. Organizations can not only save operating budget by reducing equipment failures and energy waste, but also improve the quality of life and productivity for occupants. <br/><br/>This Small Business Innovation Research (SBIR) Phase I project is aimed at developing middleware technology to automatically integrate and analyze both structured and unstructured data from facilities design and operations. Facilities maintenance and operating is the longest phase in the life-cycle of buildings, accounting for more than 60% of the total cost of ownership. Owners and facilities managers are faced with the challenges of efficiently managing aging and crowded building infrastructure to extend the life of assets and control costs. However, fragmented and under-analyzed building information results in most maintenance work being conducted reactively to address problems that have already caused significant loss or waste. The vision of this innovation is to develop a fully commercialized software package to enable facilities managers to be more proactive in improving building occupant comfort, aligning limited resources where they have the most significant impact, and reducing wasted energy through optimized mechanical controls. This project aims to demonstrate the conceptual feasibility of using big data analytics and machine learning to revolutionize facilities operating and maintenance decisions. The results from this applied research will include algorithms and methods to combine structured data with field collected unstructured data into qualitative and quantitative output appropriate for improved decision making."
930785,IRES:  U.S.-Czech Network Centric Intelligent System:  Drexel and Czech Technical University,OISE,IRES Track I: IRES Sites (IS),9/1/2009,8/17/2009,William Regli,"Regli, W","Regli, W|Greenstadt, R",PA,Drexel University,Standard Grant,Bonnie Thompson,8/31/2012,"$149,814.00 ",Rachel Greenstadt,regli@umd.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,O/D,7727,"0000, 5930, 5979, 6890, OTHR","$149,814.00 ",normalFunding,"OISE 0930785<br/>Regli<br/><br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>This U.S.-Czech program for International Research Experiences for Students (IRES) links partners from Drexel University in Philadelphia with counterparts from Czech Technical University (CTU) in Prague. The U.S. team, led by William Regli and Rachel Greenstadt, brings expertise in artificial intelligence, wireless networks, privacy and security to a three-year collaborative program with Czechs partners who have complementing strengths in multi-agent systems and meta-reasoning.  In Prague, the IRES program will be headed by Michael Pechoucek, in the CTU Department of Cybernetics. These U.S. and Czech mentors share the goal of contributing to the field of agent communications while providing the graduate and undergraduate students they mentor with early career research experience in design of systems that are tolerant of severe disruptions and interference. <br/><br/>During the course of the collaborative IRES, the US-Czech team will integrate three areas of their current research in emerging communication and collaborative intelligent systems to provide broad and promising new topics for student projects. The focus areas include: 1) agent communication in constrained environments, 2) metrics on multi-agent systems, and 3) design patterns for multi-agent systems. Overall, the combined efforts of researchers and students are expected to contribute to improvements in network centric intelligent systems.  <br/><br/>This interdisciplinary IRES in engineering and computer science fulfills the program objective of advancing scientific knowledge and engaging students by enabling experts in the United States and Europe to combine complementary talents and share research resources in areas of strong mutual interest and competence.  Broader impacts include early career introduction of U.S. junior researchers, including women and minority students, to experts in the international research community who are involved in the design of agent based systems as well as innovative modeling.  The results of this well balanced U.S.-Czech IRES program are expected to enhance performance in mobile agent-based computing."
130768,CISE Research Resources: A Compute-Intensive Sensor-Based Environment for Research in Computer Vision and Artificial Intelligence,CNS,"CISE RESEARCH INFRASTRUCTURE, CISE RESEARCH RESOURCES",9/15/2001,3/18/2002,Sudeep Sarkar,"Sarkar, S","Sarkar, S|Hall, L|Goldgof, D|Fink, E",FL,University of South Florida,Standard Grant,Rita V. Rodriguez,8/31/2003,"$149,713.00 ","Lawrence Hall, Dmitry Goldgof, Eugene Fink",sarkar@cse.usf.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,CSE,"2885, 2890","2885, 9218, 9251, HPCC",$0.00 ,normalFunding,"EIA-0130768   <br/>Sudeep Sarkar<br/>University of South Florida<br/><br/>CISE Research Resources:  A Compute-Intensive Sensor-Based Environment for Research in Computer Vision and Artificial Intelligence<br/><br/>Automated learning of grouping parameters for perceptual organization of complex images, modeling and reconstruction of elastic objects from image sequences, real-time matching of buyers and sellers for E-commerce, and learning models from extremely large databases, all require large data storage and a computing environment that supports exploring extremely large parameter spaces along with the ability to process huge quantities of data. A multiprocessor computing environment with substantial memory and disk storage is requested for high-performance computing associated with these four research projects in the general areas of computer vision and artificial intelligence. The compute server will increase the present capabilities by an order of magnitude.<br/><br/>In addition, image acquisition devices, including high-resolution color cameras, digital video cameras, stereo cameras, and laser range scanners are requested for gathering color, motion, and range data.  The ability to acquire fast range images and motion sequences will enable the consideration of the problem of integrating motion and range into the perceptual organization process. Also, the ability to acquire fast and high-resolution range, with registered color, will facilitate development of physics-based non-rigid algorithms and models that incorporate true material properties, which have, heretofore, not been possible.<br/><br/>"
742440,"SGER Proposal: A ""Transderivational"" Search Engine for Creative Analogy Generation in Mixed-Media Design",IIS,ITR-CreativeIT,9/15/2007,10/6/2009,Huong Dinh,"Dinh, H","Dinh, H|Fisher, E",NJ,Stevens Institute of Technology,Standard Grant,Pamela L. Jennings,2/28/2010,"$149,664.00 ",Ebon Fisher,quynh@cs.stevens-tech.edu,CASTLE POINT ON HUDSON,HOBOKEN,NJ,70305991,2012168762,CSE,7655,"0000, 7655, 9237, OTHR, 9102",$0.00 ,normalFunding,"This project will develop a transderivational search engine based on the neurological condition known as synaesthesia in which two or more senses are crossed (e.g., when seeing a color causes one to hear a sound) to help people to discover connections between text, 1D audio, 2D image, 3D geometry and 4D motion data. The project is inspired by the ability of artists and designers to find analogies between diverse artifacts and bring them together to compose a coherent and novel narrative.<br/><br/>The intellectual merit of this research is the development of matching algorithms that suggest analogies across different media forms by looking at structural similarity within media content. The result will be a transformative technology at the intersection of art, computer graphics, machine learning, cognitive psychology, and human-computer interaction (HCI). Transderivational search will enhance the synaesthetic effect in analogy generation and will naturally lend itself to a wide range of brainstorming pursuits. Finding analogies between media of different forms (e.g., audio and 3D shapes) has not been explored, nor has there been much focus on non-literal search engines. Literal searches rely only on explicit meaning (e.g., the word ?three? and an image of the number 3) and categorization to determine similarity. Instead, this project will compare media samples by looking for structural similarity using analytical approaches such as statistical shape distributions, frequency analysis, and machine learning techniques to discover relationships between mixed- (multi-dimensional) media samples.<br/><br/>The broader impacts of this research are in advancing artificial intelligence through transderivational search (essential to language and cognitive processing) and in opening up new research questions on search technology. The educational impacts are in drawing more women and minorities into CS and improving retention in CS programs by showing the relevance of search technology to creative design and to multimedia management. The transderivational search tools will be used by students in introductory level CS courses to build basic media management software. Transderivational search can also serve as a testbed for exploring algorithms in high level CS courses on machine learning, computer vision and graphics."
1046589,SBIR Phase I: Serious Gaming Platform for Mastering the Physician-Patient Diagnostic Interview,IIP,SMALL BUSINESS PHASE I,1/1/2011,12/15/2010,David Baker,"Baker, D","Baker, D",WV,IntelligentSimulations LLC,Standard Grant,Glenn H. Larsen,6/30/2011,"$149,335.00 ",,vicbaker01@gmail.com,1022 Laurelwood Drive,Morgantown,WV,265088900,3042918977,ENG,5371,"1658, 5371, 9216, HPCC, 9150",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project aims to implement a new strategy for teaching medical students to interact with and relate to patients. Present teaching methods are labor intensive for instructors and students and limited to fixed settings. The project team will develop a serious gaming software platform that captures the human element by simulating patient responses (level of trust, topic comfort, and sense of urgency) through the use of ?intelligent, emoting avatars? (virtual patients) represented through artificial intelligence (AI) and dynamic video. The software platform replaces the passive experience of dialog tree based character interaction with the active experience of dynamic conversation. The training platform will have elements of virtual reality (interactive, immersive, and experiential) and be capable of supporting libraries of virtual patients. The innovation will enable applications to provide a new level of emotional experience for the users by achieving an emotional attachment and sense of bonding with intelligent virtual characters, capable of dynamic conversation and emotional responses based on concepts involving level of trust, topic comfort, and sense of urgency. The product will enable the student to practice and learn at their own computer on their own schedule within a ?learning environment? that is extraordinarily rich and realistic.<br/><br/>The broader impact/commercial potential of this project will change the way medical students learn in the medical school environment. Medical school teaching methods are costly, labor intensive for instructors and students and limited to fixed settings. The project team will develop a serious gaming software platform that relies on artificial intelligence and makes use of the interactive, immersive, and experiential elements of virtual reality that have made video games so successful. They will adapt these elements to serious gaming to create an instructional technology to teach medical students to interact with and relate to patients. The student will interact with a virtual patient by entering keyboard based dialog or by using speech recognition technology. The product will enable the student to practice and learn at their own computer on their own schedule. The essentially passive experience of dialog tree based character interaction is replaced with the active experience of dynamic conversation. This technology is intended to address the problems posed by present expensive medical school teaching methods which are labor intensive for instructors and students. The technology will offer advances over traditional on-line and class-room instruction materials such as video presentations, PowerPoint and flat written formats. Over the long term, this entirely scalable technology has the potential to fundamentally enrich the educational environment for medical school teaching with a correspondingly enormous commercial profitability and societal impact."
1745410,EAGER: Deep Learning-Based Self-Organizing Network for B5G Communications with Massive IoT Devices,ECCS,"COMMS, CIRCUITS & SENS SYS",9/1/2017,7/20/2017,Meryem Simsek,"Simsek, M","Simsek, M",CA,International Computer Science Institute,Standard Grant,Akbar Sayeed,8/31/2019,"$149,217.00 ",,simsek@ICSI.Berkeley.EDU,1947 CENTER ST STE 600,Berkeley,CA,947044115,5106662900,ENG,7564,"153E, 7916",$0.00 ,normalFunding,"Future wireless networks are expected to provide a platform for highly reliable and ultra-low latency information exchange that will revolutionize the way machines communicate and how people interact. A vast number of devices, particularly sensors and actors, is anticipated to be able to connect to a single wireless access point, empowering the deployment of massive Internet of Things devices that generate an enormous amount of information, namely Big Data. The management of both, the wireless connections of the devices and the Big Data they generate, requires substantial changes to legacy wireless networks. The goal of this project is to conduct exploratory research on such changes, which, if successful, will deliver a key corner stone to the future deployment of massive Internet of Things. This deployment will constitute an essential component in various aspects of life, such as improvements in consumer products, e.g. home automation and better consumer oriented entertainment; in health, through smart body sensors and remote, low-cost diagnosis; in more cost-efficient manufacturing; in environmental monitoring, e. g., for enhancing environmental conditions like reduced air pollution; or in the realization of smart cities.<br/><br/>Following the recent great success of artificial intelligence, machine learning, and specifically deep learning in many different applications, the goal of this project is to explore and to perform research on novel deep-learning-assisted autonomous decision-making approaches for the self-management of future wireless communications networks. The problem to be solved is to establish an efficient and effective wireless network self-management architecture that is flexible enough to facilitate the deployment and operation of diverse massive Internet of Things devices. This architecture is expected to be able to exploit hidden information in Big Data generated by the Internet of Things devices through deep learning techniques. The research into this architecture comprises the exploration of novel machine learning algorithms for the intelligent, predictive, and autonomous allocation of radio and network resources at different layers of the wireless network. Ultimately, a novel multi-layer self-organizing network architecture will be introduced that fully exploits the flexibility and capability of future wireless networks for servicing massive Internet of Things. The developed approaches will lay the foundations of substantially enhancing legacy self-organizing wireless networks and will impact the design of future wireless networks, its efficiency, and the realization of various emerging use cases generating Big Data likewise. The results will also provide novel insights into the role of Big Data for the communications industry, potentially fostering the development of new business models and strengthening the industry's national and international competitiveness."
9906128,Choosing Among Approaches to Probability,SES,Hist & Philosophy of SET,9/1/1999,6/20/2000,Henry Kyburg,"Kyburg, H","Kyburg, H",NY,University of Rochester,Continuing grant,Bruce E. Seely,8/31/2001,"$148,715.00 ",,kyburg@redsuspenders.com,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,SBE,1353,"0000, 9179, OTHR",$0.00 ,normalFunding,"There is an ever-increasing variety of procedures for managing uncertainty available. These methods are discussed in the literature of artificial intelligence, as well as in the literature of philosophy of science. Heretofore these methods have been evaluated by intuition, discussion, the general philosophical method of argument and counterexample. The present project consists of the analytical development of a test according to which these methods can be compared to each other.<br/><br/>One difficulty with developing such tests is that almost any method of uncertainty management will have the property that in the long run it will deliver numbers approaching the frequency of the kinds of events at issue. Thus unbiased estimates in classical statistics approach the corresponding long run frequencies and the degrees of belief of subjective Bayesians approach the same number. To find a measure that will provide a meaningful evaluation of these treatments of uncertainty, we must look, not at the long run, but at the short or intermediate run.<br/><br/>Our project attempts to develop such a measure in terms of short or intermediate length performance. We represent the effects of practical choices by the outcomes of bets offered to agents characterized by various uncertainty management approaches.<br/><br/>We focus on only two treatments of uncertainty, the subjective Bayesian treatment, and the frequency-based treatment developed by the author elsewhere. A number of parameters are identified that affect the results of this test, and their importance and effect will be examined. It is hoped that the general approach will prove applicable to the test of other approaches than these two."
9502260,Scaling Up Planning Systems Using Parallel Hardware and     Machine Learning,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/1/1995,5/15/1997,Diane Cook,"Cook, D","Cook, D",TX,University of Texas at Arlington,Continuing grant,Ephraim P. Glinert,2/29/2000,"$147,375.00 ",,cook@eecs.wsu.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,CSE,6856,"1045, 9139, 9251, HPCC",$0.00 ,normalFunding,"The objective of this project is to scale up the applicability of  planning   algorithms  developed  in  the  field  of   Artificial  Intelligence. The basic research component of the project  is  to  first   investigate  techniques  for  improving  scalability   of  planning  using  parallel  techniques, then  to  explore  machine  learning  techniques  for reusing and refining  generated  plans.  Industrial  applications  of  AI planning  algorithms  have  been  limited  largely by the computational complexity of the  planning  task. The significant speedup that can be obtained using parallel  hardware  and  machine learning techniques  can  bridge  the  gap  between  research and a wide variety of industrial  applications.  To  demonstrate the power of the techniques developed here,  they  will  not only be formally verified but will be applied  to  such  applications  as automated assembly and cooperative  planning  of  unmanned  ground  vehicles. The CAREER project will  also  impact  graduate and undergraduate education. Existing seminar courses in  Parallel  AI  and in Planning and Robotics will be  refined.   An  industrial  team will be formed to suggest topics and to  oversee  class  projects. All course materials developed for these classes  will be packaged and available for general dissemination over the  Internet."
1319974,HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative,IIS,Cyber-Human Systems (CHS),8/1/2013,6/27/2014,Joseph Magliano,"Magliano, J","Magliano, J",IL,Northern Illinois University,Continuing grant,William Bainbridge,7/31/2017,"$146,950.00 ",,jmagliano@niu.edu,301 Lowden Hall,De Kalb,IL,601152828,8157531581,CSE,7367,"7367, 7923",$0.00 ,normalFunding,"The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments.  Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure.  The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves.  Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br/><br/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br/><br/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines.  Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process."
957820,Automata in Science,SES,"SCIENCE, TECH & SOCIETY",7/1/2010,5/17/2010,Elly Truitt,"Truitt, E","Truitt, E",PA,Bryn Mawr College,Standard Grant,Linda Layne,6/30/2012,"$146,158.00 ",,etruitt@brynmawr.edu,101 N. Merion Avenue,Bryn Mawr,PA,190102899,6105265298,SBE,7603,"0000, 1353, OTHR",$0.00 ,normalFunding,"Automata-artificial objects that are, or appear to be, self-moving-were culturally significant in medieval Europe. They appear as diplomatic gifts from distant rulers to European courts; in stories and legends and chronicles of distant lands and times; as manifestations of esoteric and sometimes forbidden knowledge; in courtly settings of great luxury; attached to monumental clockworks; as examples of technological innovation, and in the service of the Church. This research project examines the presence of automata in visual, textual, and material form in medieval Europe and, in the course of this examination, traces the interpenetration of scientific ideas, technological developments, philosophical theories, and cultural history. By examining different types of primary sources, including philosophical treatises, historical chronicles, scientific texts, archival documents, visual representations of automata, technical drawings, and literary sources, and using close analysis of textual, visual, and material sources, this study examines the developments in how automata were created from the twelfth to the fifteenth centuries, and how these shifts relate to developments in medieval natural philosophy and technology. Additionally, a particular theme of this project is how automata, and the knowledge needed to create them, were initially believed to be from the Arabic-speaking world, and were thus viewed with mistrust, suspicion, and fear, as well as desire and wonder. Over time, however, automata were decoupled from these origins, and took on new significance.  <br/> <br/>This research will make significant intellectual contributions to several different fields. By revealing that automata were central to western medieval society, it will contribute to histories of science and technology as well as establish the importance of science and technology in medieval history. The project will also have a broader impact on scholars and scientists who work on robots, artificial life, and artificial intelligence. This project will place these scholars' interests and research on contemporary science into historical context, showing that current ideas about artificial, self-moving objects and the categories used to organize them have an intellectual, cultural, and scientific history that has been largely invisible. Lastly, this research will compellingly demonstrate that ideas often assumed to be novel developments of early modern natural philosophy are in fact rooted in medieval philosophy, scientific culture, and technological developments."
9414948,Replacement and Renovation of Computer Science Research and Research Training Laboratories,OIA,ACADEMIC RESEARCH INFRASTRUCTU,7/1/1995,10/15/1999,Albert Hoffman,"Hoffman, A","Hoffman, A|Stollenwerk, D|Dickinson, A|Ross, P|Hutchens, D|Webster, R",PA,Millersville University,Standard Grant,Sherrie B. Green,1/31/2001,"$145,204.00 ","Donald Stollenwerk, Arthur Dickinson, Paul Ross, David Hutchens, Roger Webster",ahoffman@maurauder.millersv.edu,PO Box 1002,Millersville,PA,175510302,7178723820,O/D,9155,"0000, 9155, OTHR",$0.00 ,normalFunding,"  Millersville University, located in Lancaster County, Pennsylvania, is one of the 14 state owned institutions of higher education that comprise the Pennsylvania State System of Higher Education.  The mission of the institution, inclusive of the sciences, is to provide excellent programs conforming to the higher standards of a traditional liberal arts education.  To emphasize its commitment to science, the University and the Commonwealth of Pennsylvania are providing the resources required to construct a new science building, the centerpiece of a science complex that includes the existing science facility, Roddy Hall.  Obsolete space vacated by the Chemistry Department in Roddy will be available for the Computer Science Department, currently residing in Wickersham Hall.  Relocating Computer Science to the 30 year old building, will allow all the science departments to be in close proximity physically, as well as establishing collaborative efforts between scientific disciplines.  It is for this purpose, that funds from the Academic Research Infrastructure Program have been awarded to Millersville University.  A former chemistry laboratory and support space will be renovated and remodeled to accommodate the needs of the research and research training program of the Computer Science Department . Space will be reconfigured by the removal of existing walls and equipment such as workbenches and fume hoods. The improved space will provide modern research facilities for faculty engaged in Robotics, Computer Vision, Artificial Intelligence, Software Engineering, Scientific Visualization, and Real-Time Systems Engineering.  Scientific Visualization research will focus on high-performance 3D computer graphics for scientific modeling, vitural world modeling, and virtual reality simulations for research training and experimentation in the natural and physical sciences.  All science students will benefit from this project, giving them opportunities to engage in research and learn high performance computer visualization techniques at the undergraduate level.  With the improved facility there will be increased student involvement in collaborative, scientific investigations with faculty, generating quality senior research projects that may facilitate student interest in pursuing additional scholarly activities, as well as attracting prospective students and new research faculty."
1415757,SBIR Phase I:  Translational Information Management for Industry,IIP,SMALL BUSINESS PHASE I,7/1/2014,5/20/2014,Bruce Buchanan,"Buchanan, B","Buchanan, B",TX,i2k Connect LLC,Standard Grant,Peter Atherton,12/31/2014,"$143,800.00 ",,buchanan@cs.pitt.edu,10419 Ten Point Lane,Missouri City,TX,774592996,7134137880,ENG,5371,"5371, 8032",$0.00 ,normalFunding,"The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be improved effectiveness of document management systems in U.S. Businesses.  The project integrates novel approaches to unsupervised machine learning, concept identification, and ontology construction to create a sustainable content management system that will allow companies to find and associate information more accurately and efficiently. Corporations run on information, and routine operations depend on finding information efficiently. For example, corporate acquisitions require filing information quickly in the acquiring company's systems; employee turnover necessitates intelligent analysis to enable continuing operations; and regulatory compliance and legal retention requirements demand consistent categorization and correct retention of records. While creating electronic documents is easy, finding and analyzing them remain difficult tasks. The proposed project is intended to provide effective assistance to companies, within everyday business practices, without requiring major investments in change. Distribution of information between corporate data centers and the cloud further necessitates tools to help with classification consistency and searchability. If successful, this project will provide an encompassing framework within which company workflows are integrated and corporate workers can more easily and efficiently extract usable information from corporate IT systems. <br/><br/>This Small Business Innovation Research (SBIR) Phase I project provides new software tools for knowledge workers. Industrial information technology requires the integration of proven methods in a robust, sustainable framework. The investigators' prior work in artificial intelligence demonstrated that a well-designed framework, with open source packages and interstitial software, can provide an effective knowledge management system. In this project the company intends to mine and extend research ideas from knowledge management, artificial intelligence, natural language processing, machine learning, information retrieval and human-computer interfaces. Work in artificial intelligence has shown that domain knowledge is necessary for high performance problem solving. The company intends to leverage corporate knowledge to augment keyword search with semantics of the domain.  Concept identification methods developed for natural language processing will be used to augment the powerful statistical tools provided by unsupervised machine learning and information retrieval technology."
9502548,"CAREER:  Planning, Execution, and Learning in Autonomous    Agents",IIS,"ROBOTICS, ARTIFICIAL INTELL & COGNIT SCI",6/15/1995,1/20/1999,Manuela Veloso,"Veloso, M","Veloso, M",PA,Carnegie-Mellon University,Continuing grant,Ephraim P. Glinert,5/31/1999,"$143,250.00 ",,veloso@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"6840, 6856","1045, 9146, 9216, HPCC, MANU",$0.00 ,normalFunding,"  IRI-9502548  Veloso, Manuela  Carnegie-Mellon University  $45,000 - 12mos    CAREER: Planning, Execution, and Learning in Autonomous Robotic  Agents    Autonomous robotic agents need the ability to plan for and  achieve high-level tasks. Current agents can achieve low-level  execution goals such as object avoidance, but lack the ability to  reason about and to carry out multiple interacting tasks.  Integrating planning and execution by a robot is a complex task,  requiring learning from prior experience to improve significantly  the overall capabilities of the intelligent agent. We will  explore the integration of planning, execution, and learning,  where the robot's successes and failures are incorporated into a  knowledge base to improve future goal-achievement performance.  This project entails the investigation of a variety of system and  knowledge engineering issues, including: communication between  the planner and the executor; interaction between the robotic  agent, the planning system, and the human user who may, at any  time, request that certain tasks be performed; and gathering and  interpretation of information to learn from experience.  The  scientific goal underlying this research is to understand the use  of past experience to solve problems in complex situations  affected by multiple factors with different degrees of  controllability and interdependency.  Even partial achievement of  this goal could be of great significance to both the robotics and  cognitive science or artificial intelligence research  communities, bridging the representation and reasoning gap  between high level planner-learner and autonomous agent executing  tasks in the real world"
1315129,EAGER:  Self-Assembly of Complex Systems,CCF,BIO COMPUTING,8/10/2012,12/18/2012,Russell Deaton,"Deaton, R","Deaton, R",TN,University of Memphis,Standard Grant,Mitra Basu,7/31/2014,"$142,989.00 ",,rjdeaton@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,7946,7916,$0.00 ,normalFunding,"Abstract for EAGER: Self-Assembly of Complex Systems <br/>Intellectual Merit:  <br/>Self-assembly is a model for how individual components arrange themselves through local interactions to form organized structures. It originated as a model for construction of nanotechnology. The theory of complex systems describes many phenomena in nature, from human intelligence and evolving communities of organisms to human social networks, economies, and cultures. In these systems, complexity emerges in ways that is not immediately obvious from an understanding of the component parts and the relationships between them. In this project, self-assembly will be investigated as a mechanism for creation of complex systems. Self-assembly can be shown to be equivalent to other models of complex systems. In addition, it can be programmed like a computer. A goal of this project is to develop efficient ways to program self-assembly to produce interesting complex systems, which have practical applications. As a beginning to this, we have developed a mapping of self-assembly onto graphs that enables us to use an efficient algorithm to determine the system that is constructed. Thus, self-assembly should be able to generate complex systems and to provide efficient and realistic simulation of those types of systems. In the project, the self-assembly algorithms will be applied to automatic content generation for games, in which the self-assembly automatically creates situations and non-player characters with which players of the game interact. The conjecture is that this will provide more dynamic and realistic game environments, and moreover, will be an interesting test-bed for investigation of the relationship between self-assembly and complex systems.<br/>Broader Impacts:  <br/>This research integrates ideas from chemistry, physics, biology, and computer science to relate self-assembly to complex systems, and to produce potentially transformative tools that will not only improve understanding of complex systems, but also form the basis for innovative complex systems in a variety of application domains. These include nanotechnology, artificial intelligence, art, literature, and computer games. There are many natural phenomena (i.e. human intelligence, living systems) for which traditional symbolic models of computation are only able to capture a part of their essential capabilities and characteristics.  Human language is an example. This research conceivably could result in software that is able to produce target systems that capture some of the capability, adaptability, and complexity that is observed in nature.  If successful, the project could result in a new paradigm for realistic and complex behavior through computer programs, and would potentially impact not only nanotechnology, but also applications that require automatic generation of realistic content. Moreover, our models of self-assembly can generate this content in tractable ways. In addition, under the direction of the investigator, graduate and undergraduate students will work together in a team on this project, and will be educated in the unique multidisciplinary approach that has been proposed."
1216253,HCC: EAGER:  Authoring Game AIs by Demonstration for Real-Time Strategy Games,IIS,Cyber-Human Systems (CHS),9/1/2011,1/31/2012,Ashwin Ram,"Ram, A","Ram, A",CA,Palo Alto Research Center Incorporated,Standard Grant,William Bainbridge,12/31/2012,"$142,921.00 ",,ashwin.ram@parc.com,3333 Coyote Hill Road,Palo Alto,CA,943041314,6508124055,CSE,7367,"7367, 7916, 9251",$0.00 ,normalFunding,"This research will explore novel ""authoring by demonstration"" techniques for real-time strategy (RTS) games. Creating rich artificial intelligence (AI) behavior sets for complex computer games requires significant engineering effort. Developers need to anticipate all imaginable circumstances that the AI may encounter within the game world. The resulting AI is often static and results in predictable behaviors, detracting from the player experience. In addition, it is difficult for average players to create AI behaviors, without significant expertise in both AI and scripting. Modeling human-like goals and behaviors required for multiplayer games with semi-autonomous avatars adds additional complexity. This potentially transformative project will develop novel learning techniques that allow users to create intelligent behaviors simply by demonstrating them. The research will be done within the domain of RTS games, as these domains pose significant challenges that must be tackled in order to scale up the learning techniques to real-world tasks.<br/><br/>Case-based planners, hierarchical task network planners, or industry-standard behavior-tree execution engines require a library of base behaviors or methods in order to generate complete plans, which traditionally are coded by hand. The project will investigate ways to automate the process of generating such behavior libraries based on novel methods for learning strategic plans from user demonstrations. The techniques will be evaluated in the context of a case-based planning system for RTS games. RTS games are complex and involve strategic decision-making, multi-agent coordination, real-time interaction, and partially-observable environments. These properties pose significant challenges to existing AI methods for planning and learning. This research will make fundamental scientific contributions to learning, case-based reasoning, and AI for real-time strategic domains, addressing key problems in goal recognition, plan learning, and authoring support. <br/><br/>This research will enable game designers and other non-programmers to create the behavior sets for RTS games without requiring programming knowledge. This capability has two main consequences: first, it allows game developers to create games with less effort, and second it will enable a new genre of games where players would be able to create their own AIs as part of the game play. Additionally, as RTS games are essentially domain-specific simulations, the research will support authoring of behavior sets for domains such as simulation environments for training, real-time robotic control, organizational modeling for business decision-making, or sophisticated market simulations for economics strategy or public policy. The educational impact of the project is twofold. First, the project will constitute an important advance towards easy authoring of training simulators for educational applications that require environment with complex AI behaviors. This will enable development of new educational technologies with simulators or virtual worlds. Second, the project will involve undergraduate and graduate students in all phases of the work."
9803649,New Monte Carlo Methods for Scientific and Statistical Computing,DMS,STATISTICS,9/1/1998,12/14/1999,Jun Liu,"Liu, J","Liu, J",CA,Stanford University,Continuing grant,William B. Smith,5/31/2001,"$142,255.00 ",,jliu@stat.harvard.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,MPS,1269,"0000, OTHR",$0.00 ,normalFunding,----------------------------------------------------------------------- Proposal Number: DMS 9803649 PI: Jun S Liu Institution: Stanford University Project: New Monte Carlo Methods for Scientific and Statistical Computing Abstract: Monte Carlo methods hav
9317256,Models for Classification and Memory,BCS,HUMAN COGNITION & PERCEPTION,6/1/1994,5/31/1996,William Estes,"Estes, W","Estes, W",MA,Harvard University,Continuing grant,Jasmine V. Young,5/31/1998,"$141,136.00 ",,wkestes@indiana.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,SBE,1180,"0000, OTHR",$0.00 ,normalFunding,"9317256  ESTES    This project will be devoted to the continuing development of  mathematical and computer models for human memory and  classification performance.  The objectives are twofold.  One  function of the models, analogous to that of the gene model in  genetics, is to help us understand what goes on in the memory  system when it is impaired by aging or brain damage or when it  gives rise to super-normal or ""expert"" performance, and to  provide an essential framework for relating experimental results  on cognitive functioning to mechanisms revealed by research in  neural science.  The second role of the models is that of   ""learning machines"" that can serve as components of intelligent  systems for accomplishing complex tasks like speech recognition,  language comprehension, medical diagnosis, and coping with the  vast quantities of data returned from spacecraft.    Estes has developed two types of models under his long-term NSF  support, one based on symbol processing, as in traditional  artificial intelligence, and one based on structures and  processes suggested by work on neural networks.  In this  research, Estes will test and refine both models further in  relation to several major outstanding problems:  How is it  possible to gain rapid access to the large amount of information  stored in human long-term memory?  How can people learn many  difficult categorizations simultaneously with little  interference, e. g., learning several languages or several  computer operating systems?  How do people make decisions among  alternatives that differ in their constellations of associated  values and uncertainties of outcomes?  How do the hypothesized  short- and long-term memory systems of the computational models  relate to the neural systems of the hippocampus and frontal  cortex that are currently being studied.    ***"
1306133,Collaborative Research:Transfer Learning for Chemical Analyses from Laser-Induced Breakdown Spectroscopy,CHE,Chemical Measurement & Imaging,9/15/2013,9/8/2013,Melinda Dyar,"Dyar, M","Dyar, M",MA,Mount Holyoke College,Standard Grant,Kelsey D. Cook,8/31/2016,"$141,129.00 ",,mdyar@mtholyoke.edu,50 College Street,South Hadley,MA,10756456,4135382000,MPS,6880,"7433, 8084",$0.00 ,normalFunding,"With support from the Chemical Measurements and Imaging program, Professors Melinda Dyar of Mt. Holyoke College and Sridhar Mahadevan of University of Massachusetts at Amherst and their students will use laser-induced breakdown spectroscopy (LIBS) measurements, including laboratory investigations of standard materials at varying experimental conditions, to develop numerical methods that will address limitations to the broad application of LIBS imposed by matrix effects and plasma variability. State-of-the-art dimensionality reduction and transfer learning methods from machine learning and statistics will be used to build innovative LIBS-based predictive models. These investigations will extend classical methods in statistics for dealing with multiple paired data sets, such as canonical correlational analysis, to deal with unlabeled data, and extract nonlinear low-dimensional regularities in the data. The project includes the design of a suite of model-building tools that can deal with a range of problems and optimization objectives, including different types of correspondence information available across datasets, diversity of global objectives ranging from preserving local to global geometry, and producing linear or nonlinear mappings to lower-dimensional factors. <br/><br/>Laser-induced breakdown spectroscopy (LIBS) is a chemical analysis tool that uses the light emitted by a sample when a focused laser pulse generates a plasma at the sample surface. LIBS has a number of features that make it particularly useful for field use, including rapid analysis, minimal sample preparation and suitability for stand-off, that is remote, detection. Moreover, LIBS can detect and quantify light elements that are not always measured using other methods. Consequently, LIBS is well-suited to many applications including, defense interests (e.g., military explosive detection, illegal drug detection, airport security), in-situ analysis of archeological sites, field work at hazardous waste sites, and geological resource exploration. However, utilization of LIBS measurements is limited by signal variability with measurement and sample conditions. This project launches an integrated research program to couple state of the art LIBS instrumentation at Mount Holyoke College to equally state of the art numerical methodology in artificial intelligence and machine learning at the nearby University of Massachusetts to increase the utility of LIBS measurements. This project will provide an interdisciplinary training environment that includes undergraduate, graduate and post-doctoral researchers."
1751765,AF: EAGER: Homomorphism Problems in Digraphs (Dichotomies),CCF,ALGORITHMIC FOUNDATIONS,9/15/2017,9/5/2017,Arash Rafiey,"Rafiey, A","Rafiey, A|Exoo, G|Kinne, J|Egri, L",IN,Indiana State University,Standard Grant,Tracy J. Kimbrel,8/31/2019,"$141,056.00 ","Geoffrey Exoo, Jeffrey Kinne, Laszlo Egri",Arash.Rafiey@indstate.edu,200 N 7TH STREET,TERRE HAUTE,IN,478091902,8122373088,CSE,7796,"7916, 7926, 7927",$0.00 ,normalFunding,"Graph coloring is one of the most important problems in theoretical computer science.  Many combinatorial optimization problems can be viewed as graph coloring problems.  For a given graph G and integer k, the question is whether there exists a coloring of its vertices with k colors such that any two adjacent vertices receive different colors.  The Graph (or Directed Graph) Homomorphism Problem is a generalization of graph coloring.  In the Graph Homomorphism Problem, the goal is to find a mapping from an input graph (or digraph) to a fixed target graph (or digraph) H that preserves adjacency.<br/><br/>Homomorphism problems, and the equivalent formulation as so-called constraint satisfaction problems (CSPs), enjoy a wide variety of applications as optimization problems that must be solved in practice.  Such applications can be seen in scheduling, planning, databases, artificial intelligence, and many other areas.<br/><br/>The Digraph Homomorphism Problem and CSPs have been two very active research areas in Theoretical Computer Science over the last two decades.  Several  tools (mostly algebraic) have been developed for solving CSPs, and very recently a number of proposed solutions (including our solution) to the main conjecture in the area (known as the CSP Conjecture) have arisen.  The present project aims to verify in detail each approach to distill the most elegant proof and most efficient algorithms.  The approach is purely combinatorial, using techniques from graph theory.<br/><br/>The project will also tackle problems closely related to the newly proposed solutions to the CSP Conjecture.  For example, the PIs seek forbidden obstruction characterizations for the types of digraphs H that make homomorphism problems feasible. This would help to improve the running time of the current algorithm.<br/><br/>The project aims also to have a high educational impact, through training graduate students in theoretical computer science, producing <br/>freely available and high quality lecture notes and survey material on the field, seeking connections between the research and other important areas of research across computing, and utilizing novel teaching and dissemination methods."
1545599,EAGER: Mobile Solutions for Multifold Increase of Survival Rates Through High Quality Chest Compressions,IIS,Smart and Connected Health,8/1/2015,7/23/2015,Ram Dantu,"Dantu, R","Dantu, R",TX,University of North Texas,Standard Grant,Wendy Nilsen,7/31/2018,"$140,845.00 ",,rdantu@unt.edu,1155 Union Circle #305250,DENTON,TX,762035017,9405653940,CSE,8018,"7916, 8018",$0.00 ,normalFunding,"It is estimated that approximately 600,000 people each year in the United States experience a cardiac arrest, and survival rates for arrests that occur in community settings are less than 6%. On June 30, 2015, the Institute of Medicine released a report on strategies for increasing survival rates after cardiac arrest.  The report calls for effective treatment, demanding an immediate response from bystanders to recognize cardiac arrest, call 911, and initiate cardiopulmonary resuscitation (CPR). Given that the time interval for Emergency Medical Service (EMS) arrival is often 7 to 8 minutes or longer, based on American Heart Association (AHA) research, survival falls 7% to 10% for each minute without CPR.  Chest compressions during CPR can generate a small but critical amount of blood flow to vital organs such as the brain and heart until circulation is restored by EMS personnel. While defining high-quality CPR, the AHA puts priority on specific characteristics including the rate of compressions, depth, and full release after each compression (recoil).  To follow AHA's guidelines and improve CPR technique, researchers at the University of North Texas propose an effective smartphone application that can be used to provide real-time evaluation and feedback during CPR. The developed science and technology from this EAGER project can be used to evaluate and certify community workers, provide resuscitation quality improvement (RQI), and offer assistance to bystanders during a cardiac arrest. <br/><br/>Typical CPR training for health care workers entails watching videos and listening to lectures in a classroom setting every two years. Looking to the future, the EAGER campaign has the potential to transform the way CPR training and administration is handled. Based on the data yielded from the EAGER proposal, healthcare workers would only need to spend 5-10 minutes each month to effectively improve CPR administration and substantially increase the survival rate of patients. In order to accomplish this, we propose to: i) change the CPR training period to 5-10 minutes each month instead of one day every two years, ii) effectively assist bystanders who have no prior training in CPR administration, and iii) create a special glove that will house the mobile phone, start the CPR application automatically, and communicate with 9-1-1 operators and physicians.  Hence, the success of EAGER can transform the way we administer and offer CPR training. With favorable outcomes of the proposed research, variability of effective-CPR would dramatically be reduced, leading to higher survival rates. This EAGER project advances interdisciplinary knowledge (mechanics, fluid control, signal processing, and artificial intelligence) in the hopes that cardiac arrest survival no longer depends on environmental factors (e.g., inside or outside of hospital)."
1247834,"Collaborative Research: Design, Analysis and Implementation of Social Interactions in Cognitive Radio Networks",CNS,SPECIAL PROJECTS - CISE,10/1/2012,9/12/2012,Husheng Li,"Li, H","Li, H|Chen, Cf",TN,University of Tennessee Knoxville,Standard Grant,Wenjing Lou,9/30/2015,"$140,000.00 ",Chien-fei Chen,husheng@eecs.utk.edu,1 CIRCLE PARK,KNOXVILLE,TN,379960003,8659743466,CSE,1714,"7976, 9150",$0.00 ,normalFunding,"Cognitive radio is an efficient approach to access frequency spectrum. The performance of cognitive radio networks is substantially determined by the information on spectrum occupancies. Experiments have demonstrated the temporal and spatial correlations of spectrum availability, which is of key importance in the design and analysis of cognitive radio networks. Motivated by the observation, this research studies the social interaction mechanism for secondary users to fully exploit the correlations. A recommendation mechanism is useful for secondary users to share correlated information about the spectrum. Collaborative filtering can enhance the capability of better learning the spectrum situations. For better understand and assist the design, analysis is conducted for the social interaction mechanism, based on powerful tools in social networks, such as master equation, mean filed dynamics and epidemic propagation. Continuum model, such as partial differential equations for diffusions, is also employed as the limit case of discrete cognitive radio networks. Beacon based and packet based mechanisms are used for the recommendation protocols. A 100-node hardware cognitive radio network testbed is built to demonstrate the proposed mechanisms, algorithms and protocols. The research involves aspects of wireless communications, networking, artificial intelligence and physics; thus the inter-disciplinary essence of the research also lends itself to cross-disciplinary education. New courses are devised, which involve the topics of cognitive radio networks, machine learning and image processing. This project also attracts traditionally underrepresented groups, as well as outreach high school students."
1551338,EAGER: Similarity Measures Based on Refinement Operators and Metric Embedding Applied to the Analysis of Immune Repertoires,IIS,ROBUST INTELLIGENCE,9/1/2015,8/19/2015,Santiago Ontanon,"Ontanon, S","Ontanon, S|Shokoufandeh, A|Hershberg, U",PA,Drexel University,Standard Grant,Jie Yang,8/31/2017,"$139,849.00 ","Ali Shokoufandeh, Uri Hershberg",santi@cs.drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,7495,"7495, 7916",$0.00 ,normalFunding,"The notion of similarity plays a key role in modern machine learning and artificial intelligence (AI) in general, since it serves as an organizing principle by which algorithms classify objects, form concepts, and make generalizations. While similarity assessment has been widely studied, the important special case of assessing similarity in domains where the data of interest is structured has not received sufficient attention. These structured representations, however, play a key role in many domains, such as biomedicine, where data of interest naturally lends itself to structured representations. The research performed in this project aims at filling the gap in structural similarity knowledge by creating a novel generalized framework for similarity assessment. To achieve the creation of this framework the PIs will focus on the specific biomedical application of immune cell populations and their dynamics during development and in response to disease. By focusing on this specific domain, the performed research will evaluate the new approach in a real-world setting, while leading to significant contributions to the understanding of immune dynamics.<br/><br/>The key concepts that will be developed in this research project are refinement operators and metric embedding. The key insight of the proposed work is that refinement operators can be used to define similarity measures, and to abstract away from the underlying representation formalism. This will lead to a new framework for similarity assessment that is applicable to a broad range of representation formalisms. Moreover, we propose to use metric embedding techniques to provide computationally efficient numerical approximations to the resulting similarity measures. The definition of general and tractable similarity measures, applicable to a range of structured representations, will be a significant contribution to structured machine learning and AI. The research team will use data collected from high throughput sequencing experiments, and evaluate the generality and performance of the proposed similarity measures by using them to analyze how repertoires of immune cell populations can be described and compared by their clonotypes (sets of cells with the same progenitor cell). The results from applying similarity measures to this problem will help us start to construct a comprehensive view of the impact of clonotype and whole repertoire information on our understanding of the dynamics of immune responses in general."
9634823,Importance Sampling and the Impact of the Protection        System on Power System Reliability,ECCS,"CONTROL, NETWORKS, & COMP INTE",9/15/1996,5/1/1998,James Thorp,"Thorp, J","Thorp, J",NY,Cornell University,Continuing grant,Marija Ilic,8/31/2000,"$139,679.00 ",,jsthorp@vt.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,ENG,1518,"0000, OTHR",$0.00 ,normalFunding,"9634823  Thorp    The study of North American Reliability Council reports over a  five year period indicates that protection systems frequently  play a role in the sequence of events that lead to power system  disturbances.  It is likely that reliability will be treated as a  commodity in the deregulated systems of the future.  For example  the failure of the Independent Systems Operator (ISO) to  facilitate a negotiated sale of power between a producer and a  load because of a false trip of a key transmission line could  result in the payment of a penalty or otherwise effect the price  of transmission services.  In spite of its importance, the impact  of protection system malfunctions on overall system reliability  has not been well studied.  The existing protection system with  its multiple zones of protection and redundant systems is biased  toward dependability, that is a fault is always cleared by some  relay.  Present day relaying systems are designed to be  dependable at the cost of security. While it is generally  believed that the self-monitoring and self-checking feature of  digital relays will reduce the probability of undetected or  ""hidden failures"" in relays, the number of installed  microprocessor relays is still small.  Further, there has been no  qualitative evaluation of the effect on system reliability of the  installation of large number of digital relays.         The proposed research is to develop techniques to evaluate   the impact on system reliability of the protection system and to  appraise the value of the installation of new digital relays with  built in self-monitoring and self-checking or other modifications  of the protection system.  It seems possible that the new  paradigm for power system operation will provide the impetus for  a more modern protection system. That is, the economics of  transmission system reliability will require that the relaying  system be modernized.  The two key elements of the proposed  approach are the use of ""importance sampling"" and th e generation  of large data bases of power system operating conditions such as  those used for training of various artificial schemes and  evaluation of the performance of new control schemes.  The  ""importance sampling"" technique is a simulation technique to  study ""rare"" events such as major power system disturbances. The  generation of data bases of power system operating conditions for  training of various artificial intelligence schemes has become a  subject of recent study.  They have been used for preventive  control for transient stability, for prediction of instability  from real-time phasor measurements, or the control of DC lines  using real-time phasor measurements.  The essence of the proposed  research is to combine the two techniques i.e., to create a  database biased toward the unlikely events as the probabilities  are based in importance sampling.  Data base generation has been  recognized as a statistical approach where the data base could be  generated by randomly sampling the parameters that describe  system operation.  The work proposed here would use the data base  as a surrogate for the underlying probability space.  The data base  would be biased toward the unlikely events just as the  probabilities are altered in importance sampling so that the impact  of reducing ""hidden failures"" can be studied through simulation.    The specific tasks involved in the proposed research are:       *    Investigation of probability models for the dependence            of hidden failures on system conditions..       *    Modifications of importance sampling to make it more            appropriate for power system applications       *    Examination of performance indices appropriate to the            importance sampling approach       *    Generation of data bases using the Cornell Production            Super Computer  ***"
551849,"Scholar's Award - The Matter of Calculation: Early Modern Calculating Machines, Statecraft and Thinking about Thinking",SES,Hist & Philosophy of SET,6/1/2006,12/20/2006,Matthew Jones,"Jones, M","Jones, M",NY,Columbia University,Continuing grant,Frederick M Kronz,2/29/2008,"$139,539.00 ",,mj340@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,SBE,1353,"0000, OTHR",$0.00 ,normalFunding,"The Matter of Calculation:<br/>Early Modern Calculating Machines, Statecraft and Thinking about Thinking<br/>Matthew L. Jones Columbia University<br/><br/>In the seventeenth century mathematicians devised calculating machines capable of<br/>performing arithmetical operations long considered the exclusive province of rational beings. The new machines invented by Blaise Pascal and Gottfried Wilhelm Leibniz challenged the boundary between the merely animal and rational capacities of human beings. Existing histories of early modern calculating machines largely chart their technological development with little attention to philosophical and political context or uses. Pascal and Leibniz initially conceived and produced their machines as practical tools of calculation for governance and scientific work. This project will first describe the local bureaucratic, political, and technical contexts, largely in France and Germany, in which Pascal and Leibniz developed their machines; and then will explore the philosophical, technological, and political implications they and others found in their machines into the eighteenth century. The project will also examine the work of Samuel Morland, an English artisan who developed his own calculating machine in the eighteenth century. The project will rely heavily on analysis of archival sources in Germany, England and France. Intellectual merit: This project will go beyond existing technical histories of the calculating machines by providing an informed study of the political and bureaucratic contexts of their creation, their intended uses, and their philosophical and scientific implications. The project will make a significant contribution to the history of modern calculation, to the role of calculation in statecraft, and to a history of philosophy that pays close attention to the concrete, technical work done by philosophers. Broader impact: The project aims to produce a text for an audience of general well educated readers that (1) explores early modern concerns about the boundary between machine and human intelligence, (2) compares them with contemporary questions about artificial intelligence, and (3) underscores the interplay of intellectual innovation and artisanal skill in technological change."
647120,REU Sites: Collaborative Research: Advances of Machine Learning in Theory & Applications (AMALTHEA),IIS,RSCH EXPER FOR UNDERGRAD SITES,3/1/2007,3/1/2007,Michael Georgiopoulos,"Georgiopoulos, M","Georgiopoulos, M|Morrison-Shetlar, A",FL,University of Central Florida,Standard Grant,todd leen,2/29/2012,"$138,750.00 ",Alison Morrison-Shetlar,michaelg@ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,CSE,1139,"9218, 9250, HPCC",$0.00 ,normalFunding,"<br/><br/>Title: REU Site: Collaborative Research: Advances of Machine Learning in Theory and Applications (AMALTHEA)<br/><br/>PI:  Georgios C Anagnostopoulos    <br/>Institution: Florida Institute of Technology<br/><br/>PI: Michael Georgiopoulos<br/>Institution: University of Central Florida<br/><br/>AMALTHEA is a collaborative effort between two closely-located universities, Florida Institute of Technology in Melbourne and University of Central Florida in Orlando, Florida. The project seeks to provide top quality educational experiences to a diverse community of learners through research participation in the area of Machine Learning (ML). Machine Learning is nowadays a high-importance, ever- expanding discipline that draws concepts from a variety of fields, including artificial intelligence, cognitive sciences, information theory, statistics, mathematics, physics, philosophy and biology among others. On the other hand, automatic target recognition, earthquake prediction, gene expression discovery, intelligent credit fraud protection and affectionate computing, to mention just a few, are examples of cutting-edge applications of ML in various technological and scientific domains. The project's thrust area is the theory of ML and how it can be integrated and applied to important real-life problems, thus exposing participants to both theory and applications.<br/><br/>AMALTHEA involves ten undergraduate students annually in ML research over ten weeks in the summer. Overall, the project will impact a diverse group of 30 students, as well as 12 graduate students, which will participate in undergraduate teaching and mentoring activities.  <br/>The undergraduate students perform supervised research on ML topics that have the potential to impact the field of ML itself, as well as how ML is applied to other scientific disciplines. REU research results are expected to be published in interdisciplinary conferences, and, potentially, technical journals. Additionally, these REU research advances are fed back and integrated into the teaching of ML-related courses at the partnering institutions.<br/><br/>The project involves four faculty who have significant overall experience in ML research and education; they have mentored over 50 undergraduates in research and co-authored over 20 conference and journal papers with them. The project is also supported in its endeavors by an actively participating Advisory Board consisting of industry and government professionals with interest and expertise in ML.<br/><br/>URL: http://my.fit.edu/amalthea<br/>"
1523788,NSF Postdoctoral Fellowship in Biology FY 2015,DBI,Broadening Participation of Gr,9/1/2015,7/29/2015,Phillip Barden,"Barden, P","Barden, P",NY,Barden                  Phillip        M,Fellowship,Daniel Marenda,8/31/2017,"$138,000.00 ",,,,New York,NY,100245192,,BIO,1157,7137,$0.00 ,normalFunding,"This action funds an NSF Postdoctoral Research Fellowship in Biology for FY 2015, Broadening Participation. The fellowship supports a research and training plan in a host laboratory for the Fellow and a plan to broaden participation of groups under-represented in science.  The title of the research plan for this fellowship to Phillip Barden is ""Utilizing fossils in the age of genomes: a case study of ants and amber."" The host institution for this fellowship is Rutgers University-Newark, and the sponsoring scientist is Dr. Jessica Ware. <br/><br/>As the cost and difficulty of generating molecular (DNA) data decreases, new questions are emerging regarding the role of paleontological information in the ""age of genomes."" While massive DNA-based datasets offer unprecedented insight into the history of life on Earth, fossils can provide otherwise unknowable details related to evolutionary timing, ancient morphology, and biogeography. The fellowship research seeks to evaluate the utility of fossils in large-scale molecular datasets through the lens of one of nature's greatest success stories. Today, ants comprise over 13,000 highly social, diverse, and ecologically impactful species found across terrestrial vegetated landscapes worldwide - but this was not always the case. The fossil record suggests that ants were a relatively minor component of arthropod fauna until approximately 50 million years ago. In addition, paleontological evidence, particularly amber fossil deposits, suggests that many of the earliest ants were distinct from their modern relatives and ultimately doomed to extinction. What drove some lineages to extinction while others led to modern levels of diversity and prevalence? Why did prevalence remain low for so long? Paleontological data are being derived from newly discovered fossils from approximately 100 to 50 million years ago, as well as numerous species known from other key moments in ant diversification and extinction. High throughput DNA sequencing is being utilized as a cost-effective method for obtaining large amounts of molecular data for living species. Combined analyses of molecular and morphological data provide a foundation for testing hypotheses relating to the history of ants, as well as a case study for incorporating fossil and large-scale molecular datasets. Ants are an emerging model system for research ranging from artificial intelligence to the study of aging and gene networks, and genome-scale molecular datasets are generated for numerous other organismal groups with rich fossil histories.<br/> <br/>Training goals include gaining expertise in molecular sequencing and bioinformatics to compliment previous training in paleontology and systematics.  Educational outreach at Rutgers University-Newark, recognized as one of the most diverse national universities in the United States, includes serving as a role model and mentoring high school and undergraduate students in fossil description, molecular sequencing, and analysis to generate excitement and encouragement for scientific research among underrepresented groups."
647811,Games with Unawareness - Theory and Applications,SES,"ECONOMICS, COLLABORATIVE RESEARCH",3/1/2007,8/7/2007,Burkhard Schipper,"Schipper, B","Schipper, B",CA,University of California-Davis,Standard Grant,Nancy A. Lutz,10/31/2010,"$137,775.00 ",,bcschipper@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,SBE,"1320, 7298","0000, 1320, 5952, 5979, 5980, OTHR",$0.00 ,normalFunding,"Decision makers in complex situations such as in business, politics or sciences are not aware of all relevant facts when making decisions. They face not just uncertainty about which facts obtain but may be also unable to conceive of all relevant facts. Consequently, large resources are devoted to explore unmapped terrain, figure out opportunities, conceive of novelties, and to provide for unanticipated events. Yet, in economics, decision theory and game theory, it is assumed that decision makers can conceive of all relevant facts. Indeed, Modica and Rustichini (1994) and Dekel, Lipman and Rustichini (1998) showed that it is impossible to model unawareness with standard state-space models that are widely used to analyze incomplete information. This limits substantially the application of economic theory, decision theory and game theory. <br/><br/>The project is aimed to overcome the unrealistic assumption of full awareness, to provide a foundation for game theory with unawareness, and to explore the implications of asymmetric unawareness in economics. Based on prior work by Heifetz, Meier and Schipper (2006), an unawareness belief structure is developed, which has standard properties of probabilistic beliefs but nevertheless allows for unawareness. Using unawareness belief structures, Bayesian games with unawareness are introduced, equilibrium is defined, and the existence and structure of equilibria is analyzed. Such games are not necessarily ""common knowledge"" since players may have asymmetric awareness of payoff-relevant events, actions or opponents. The project would prove a ""No-Agreement-to-Disagree"" Theorem. As an application to markets, it is shown that speculative trade is possible under unawareness. Yet, a ""No-Trade"" Theorem is proved according to which arbitrary small transaction costs rule out speculation under unawareness. The project also develops dynamic games with unawareness including learning of new concepts and making others strategically aware of issues during the play. Games with unawareness are applied to incomplete contracts, the design of institutions, multi-issue bargaining and strategic framing. <br/><br/>The broader impact of this project is to provide tractable tools to the social scientist for analyzing situations with unanticipated events. These tools should be applicable to more complex situations ranging from business and finance over politics up to explorative sciences. The project is a contribution to formal logic, computer science and artificial intelligence since it provides a multi-person semantic structure for reasoning about unawareness and beliefs. Moreover, the project yields also a clear categorization of knowledge, belief and awareness, which is relevant to cognitive sciences. Altogether the research is expected to provide a better understanding of decision making with unanticipated events.<br/>"
1156847,REU Site: The Rice University Summer Institute of Statistics (RUSIS),DMS,WORKFORCE IN THE MATHEMAT SCI,4/15/2012,5/1/2013,Javier Rojo,"Rojo, J","Rojo, J",TX,William Marsh Rice University,Continuing grant,Jennifer Slimowitz Pearl,4/30/2014,"$137,686.00 ",,javier.rojo@oregonstate.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,MPS,7335,9250,$0.00 ,normalFunding,"This award provides continued support for a successful 10-week summer REU site within the Statistics Department at Rice University for the study of Statistics and its applications. As the number of domestic graduate students in the Mathematical Sciences continues to decline, there is a critical need to develop human resources to continue supporting the United States' advantage in the world of science and technology. The Rice University Summer Institute of Statistics (RUSIS), now in its 10th year and fourth funding cycle, has been successful in encouraging students to pursue graduate degrees in Mathematics and Statistics. Roughly 85% of the students who have attended RUSIS and have graduated, are now doctoral students in Ph.D. programs around the country, and roughly 61% of them are members of underrepresented populations in Mathematics. RUSIS has accomplished this through intensive courses, close supervision of research projects, and visits to various research institutes and agencies in Houston. <br/><br/><br/>The program will train and mentor 12 (7 NSF- and 5 NSA-supported) selected underrepresented minority students and students with no easy access to a research experience at their institution, including community college students, through intensive core courses in probability, stochastic processes, and statistical inference, with special emphasis on areas of current interest; e.g. multiple comparisons, extreme value theory, multivariate survival analysis, risk-reliability-sustainability of complex infrastructure systems, artificial intelligence, statistical learning, statistical genetics, and general biostatistics. The RUSIS engages the students in research projects under close collaboration with faculty mentors, and with the objective of producing joint publications, when the summer work merits it. Students present their results at national meetings and they are mentored in the preparation and presentation of their talks. In addition, students meet with an advisory committee composed of top scientists and present their work to them. The RUSIS also teaches short courses on the use of Unix platforms, LaTeX, and software to be utilized for research purposes such as Mathematica, Splus and/or R, and Matlab. In addition, the program organizes student and faculty visits to scientific facilities (e.g., Biomathematics and Biostatistics at MD Anderson Cancer Center, NASA). Through informal meetings, the program discusses a variety of topics ranging from applying to Graduate School to career experiences by outstanding scientists, and discussion of cutting-edge topics in Statistics. The program evaluates and monitors the progress of students for seven years (expected time for them to finish graduate school) after their participation, and an annual evaluation of the program by the participating students and an external advisory committee is an integral and valuable part of the program. The investment is starting to produce concrete results. The first RUSIS alumnus received his Ph.D. during the summer of 2011 and is now an assistant professor of statistical sciences in a Ph.D. program. Several more are due to obtain their PhDs in the next few years."
1725659,Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students,DUE,IUSE,9/1/2017,7/21/2017,Benjamin Caldwell,"Caldwell, B","Caldwell, B",TX,LeTourneau University,Standard Grant,Heather Watson,8/31/2022,"$137,420.00 ",,BenjaminCaldwell@letu.edu,P O BOX 7001,Longview,TX,756077001,9032333100,EHR,1998,"8209, 8244, 9178",$0.00 ,normalFunding,"Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
98114,Collaborative Research on Semantic Unification and its Applications,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT",8/15/2001,8/31/2001,Deepak Kapur,"Kapur, D","Kapur, D",NM,University of New Mexico,Standard Grant,Robert B Grafton,7/31/2005,"$137,082.00 ",,kapur@cs.unm.edu,"1700 Lomas Blvd. NE, Suite 2200",Albuquerque,NM,871310001,5052774186,CSE,2865,"9216, HPCC",$0.00 ,normalFunding,"Proposal #0098114<br/>Kupar, Deepak<br/>University of Mexico<br/><br/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br/><br/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br/><br/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br/><br/>This award is one of three in a collaborative research team.   The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany).<br/>"
79770,MRI:  Web Host Access Tools,CNS,"MAJOR RESEARCH INSTRUMENTATION, CISE RESEARCH RESOURCES",9/1/2000,10/17/2001,Lillian Cassel,"Cassel, L","Cassel, L|Soong, N|Wolz, U|Hardt, D|Klassner, F",PA,Villanova University,Standard Grant,Rita V. Rodriguez,8/31/2004,"$136,551.00 ","Norman Soong, Ursula Wolz, Daniel Hardt, Frank Klassner",cassel@acm.org,800 Lancaster Avenue,Villanova,PA,190851676,6105196000,CSE,"1189, 2890","1189, 9152, 9218, 9251, HPCC, SMET",$0.00 ,normalFunding,"EIA-0079770<br/>Cassel, Lillian N.<br/>Villanova University<br/><br/>MRI:  Web Host Access Tools<br/><br/>This is a cooperative effort among computing faculty at Villanova University and the College of New Jersey and the objective is the acquisition of web host access tools.  The combined research activities address important questions in artificial intelligence, information gathering, human-computer interface and networking all in the context of a common problem. The problem that joins these topics is assisting a user retrieving and using information obtained from the World Wide Web. The actives involve an integration of research and education with an explicit goal to introduce students to a significant research project while advancing the state of the art in enhanced web resource access.  <br/>"
512050,Diffusion Multiscale Analysis,DMS,COMPUTATIONAL MATHEMATICS,7/1/2005,6/29/2005,Mauro Maggioni,"Maggioni, M","Maggioni, M",CT,Yale University,Standard Grant,Leland M. Jameson,10/31/2006,"$136,505.00 ",,mauro.maggioni@jhu.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,MPS,1271,"0000, 9263, OTHR",$0.00 ,normalFunding,"In this proposal, the investigator and his collaborators address <br/>several questions arising from the mathematical analysis of multiscale <br/>geometries of sets, and multiscale decomposition of function spaces, <br/>that arise from the action of a diffusion semigroup on a manifold, a <br/>graph and other rather general metric spaces. While these multiscale <br/>geometries are partly implicit (and classical) in differential geometry, <br/>in partial differential equations, as well as in many branches in graph <br/>theory (with applications to problems in computer science), only <br/>recently a very general, yet efficient, coherent and unifying <br/>construction has been introduced by the investigator and his <br/>collaborators. Multiscale function space decompositions that mirror <br/>these multiscale diffusion geometries are also constructed, through the <br/>introduction of special wavelet functions. This is a far-reaching, and <br/>long sought, generalization of wavelet analysis, both mathematically and <br/>computationally. The investigator and his collaborators have shown that <br/>algorithms for efficiently computing these multiscale decompositions <br/>exist, which generalize the fast wavelet transform and Fast Multipole <br/>Methods, yielding fast multiscale algorithms guaranteeing <br/>high-precision. The investigator will study the construction of <br/>biorthogonal diffusion multiscale decompositions, multiscale function <br/>approximation on rough sets, multiscale diffusion analysis of data sets <br/>and its relationships with geometric measure theory, multiscale Markov <br/>chains, numerical analysis of PDEs, learning theory, hyperspectral <br/>imaging and document corpora analysis.<br/>The investigator expects this novel multiscale construction to have <br/>impact in all these disciplines, in a way similar to the impact wavelet <br/>analysis had on low-dimensional signal processing and numerical analysis.<br/><br/>The present proposal stresses the inter-disciplinary nature of several <br/>aspects of multiscale analysis, and the vast applicability of the ideas, <br/>tools, constructions, to pure and applied mathematics, and to other <br/>disciplines such as computer science, physics, engineering, astronomy <br/>and statistics, among others. The introduction of these novel multiscale <br/>techniques reveals new and interesting multiscale geometric structures <br/>of graphs and sets, together with effective computational tools to <br/>discover them. The range of applications is very wide, and includes the <br/>analysis and organization of large and complex networks (e.g. computer <br/>networks, biological regulatory networks etc...), document corpora for <br/>information extraction, hyperspectral imagery (for applications to <br/>medicine, target recognition etc...), and large datasets in general. It <br/>has also applications to the development of new algorithms for learning <br/>and artificial intelligence, for the automation of complex tasks. The <br/>investigator aims at strenghtening his existing collaborations, and <br/>establishing new ones, with other institutions, both in the United <br/>States and abroad, across several disciplines, in particular computer <br/>science, astronomy, biology, and medicine. He will continue his existing <br/>collaborations with companies developing next-generation <br/>instrumentation, for applications to hyperspectral imaging. He will <br/>continue to actively participate in multi- and inter-disciplinary <br/>conferences, workshops and research activities, and effectively <br/>communicating and disseminating ideas and techniques to <br/>multi-disciplinary audiences, making his work, including papers and <br/>computer code for the corresponding algorithms, easily accessible <br/>electronically."
1620070,Collaborative Research:  Algorithms for Large-scale Stochastic and Nonlinear Optimization,DMS,COMPUTATIONAL MATHEMATICS,8/1/2016,6/17/2016,Richard Byrd,"Byrd, R","Byrd, R",CO,University of Colorado at Boulder,Standard Grant,Leland M. Jameson,7/31/2019,"$136,371.00 ",,richard@cs.colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,MPS,1271,9263,$0.00 ,normalFunding,"The promise of artificial intelligence has been a topic of both public and private interest for decades. Starting in the 1990s the field has been benefited from the rapidly evolving and expanding field of machine learning. The intelligent systems that have been borne out of machine learning, such as search engines, recommendation platforms, and speech and image recognition software, have become an indispensable part of modern society.  Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on increasingly powerful computing platforms and the availability of very large datasets.  One of the pillars of machine learning is mathematical optimization, which, in this context, involves the computation of parameters for a system designed to make decisions based on yet unseen data. The goal of this project is to develop new optimization algorithms that will enable the continuing rise of the field of machine learning.<br/>  <br/>The research consists of two projects, which are thematically related and address the solution of optimization problems that are nonlinear, high dimensional, stochastic, involve very large data sets and in some cases are non-convex. Two families of algorithms will be developed to garner the benefits of both stochastic gradient methods and batch methods, while avoiding their shortcomings. One of these algorithms uses a gradient aggregation approach that re-uses gradient values computed at previous iterations. The challenge is to design an algorithm that is efficient in minimizing testing error, not just training error. The second approach employs adaptive sampling techniques to reduce the noise in stochastic gradient approximations as the optimization progresses. An important aspect of this research is the design of an efficient strategy for incorporating second-order information that captures curvature of the optimized loss function, even in the case when Hessian estimates are based on inaccurate gradients. In all cases, the goal is research is to design and implement algorithms in software, and test them on realistic machine learning applications."
9619680,REU: The University of Alabama Undergraduate Computer       Science Research Program: Research Experiences for          Undergraduates,CNS,CISE RESEARCH INFRASTRUCTURE,2/15/1997,11/5/1998,David Cordes,"Cordes, D","Cordes, D|Parrish, A",AL,University of Alabama Tuscaloosa,Continuing grant,Lawrence Burton,1/31/2000,"$135,600.00 ",Allen Parrish,David.Cordes@ua.edu,801 University Blvd.,Tuscaloosa,AL,354870005,2053485152,CSE,2885,"9178, 9250, SMET",$0.00 ,normalFunding,"9619680  Cordes, David  University of Alabama    REU: The University of Alabama Undergraduate Computer Science Research Program : Research Experiences for Undergraduates    This Research Experiences for Undergraduates (REU) Site project supports 9 students per year in programs carried out during the summers, for three years.  Students are recruited from smaller, primarily undergraduate schools throughout the South with emphasis on recruitment of women and minority students.  Research projects within the department from which the students have an opportunity to select include software testing, database systems, parallel algorithms, human-computer interfaces, distributed systems, artificial intelligence, programming languages, and performance analysis.  Students are required to create a formal, written report documenting their summer activities and, at the completion of the program, to present a short talk to the students and faculty of their home institution."
840936,SGER: Semi-Formal Design Validation with Swarm Intelligence,CCF,"DES AUTO FOR MICRO & NANO SYS, DES AUTO FOR MICRO & NANO SYST",8/1/2008,6/19/2009,Michael Hsiao,"Hsiao, M","Hsiao, M",VA,Virginia Polytechnic Institute and State University,Standard Grant,Sankar Basu,7/31/2010,"$135,000.00 ",,hsiao@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,CSE,"4710, 7945","9218, 9237, 9251, HPCC",$0.00 ,normalFunding,"Proposal ID: 0840936 <br/>PI Name: Michael S. Hsiao<br/>Title: Semi-Formal Design Validation with Swarm Intelligence<br/>Inst: Virginia Tech Blacksburg, VA <br/><br/>ABSTRACT<br/>The objective of this research is to elicit the swarming power to solve the very difficult problem of design validation.  This is a high-risk, high pay-off investigation on an approach that has not been done in the past.  Individual knowledge acquired during the search is extracted to benefit collective effort.  This is enabled via cultivation of knowledge exchange, accumulation, and utilization.  The intelligent partitioning and grouping of the state variables allows for the construction of many effective abstract navigation tracks in large designs.  This is a key breakthrough as the mined tracks naturally provide multiple valuable abstractions of the design upon which collective and diverse effort can be conducted.  The development of new theories and algorithms will be an original contribution that will allow for transformative understanding of semi-formal verification and state space exploration, all in a rigorous framework.<br/><br/>The theories and practice that will result from this work will not only enable us for a deeper understanding of collective effort, it will shed light on other intractable problems as well, from closely related research areas such as manufacturing test to artificial intelligence.<br/><br/>This project will directly promote the education of the involved students.  In regard to outreach to under-represented students, the PI currently advises multiple women Ph.D. students (under-represented in engineering), and this project will continue to encourage aspiring female students to participate in the research endeavor.  In addition, the PI will actively recruit summer minority interns from programs within Virginia Tech to take part in this project.<br/><br/>"
1433021,REU Site: The Rice University Summer Institute of Statistics (RUSIS),DMS,WORKFORCE IN THE MATHEMAT SCI,3/1/2014,4/21/2014,Javier Rojo,"Rojo, J","Rojo, J",NV,"Board of Regents, NSHE, obo University of Nevada, Reno",Continuing grant,Jennifer Slimowitz Pearl,12/31/2015,"$134,611.00 ",,javier.rojo@oregonstate.edu,1664 North Virginia Street,Reno,NV,895570001,7757844040,MPS,7335,"9150, 9250",$0.00 ,normalFunding,"This award provides continued support for a successful 10-week summer REU site within the Statistics Department at Rice University for the study of Statistics and its applications. As the number of domestic graduate students in the Mathematical Sciences continues to decline, there is a critical need to develop human resources to continue supporting the United States' advantage in the world of science and technology. The Rice University Summer Institute of Statistics (RUSIS), now in its 10th year and fourth funding cycle, has been successful in encouraging students to pursue graduate degrees in Mathematics and Statistics. Roughly 85% of the students who have attended RUSIS and have graduated, are now doctoral students in Ph.D. programs around the country, and roughly 61% of them are members of underrepresented populations in Mathematics. RUSIS has accomplished this through intensive courses, close supervision of research projects, and visits to various research institutes and agencies in Houston. <br/><br/><br/>The program will train and mentor 12 (7 NSF- and 5 NSA-supported) selected underrepresented minority students and students with no easy access to a research experience at their institution, including community college students, through intensive core courses in probability, stochastic processes, and statistical inference, with special emphasis on areas of current interest; e.g. multiple comparisons, extreme value theory, multivariate survival analysis, risk-reliability-sustainability of complex infrastructure systems, artificial intelligence, statistical learning, statistical genetics, and general biostatistics. The RUSIS engages the students in research projects under close collaboration with faculty mentors, and with the objective of producing joint publications, when the summer work merits it. Students present their results at national meetings and they are mentored in the preparation and presentation of their talks. In addition, students meet with an advisory committee composed of top scientists and present their work to them. The RUSIS also teaches short courses on the use of Unix platforms, LaTeX, and software to be utilized for research purposes such as Mathematica, Splus and/or R, and Matlab. In addition, the program organizes student and faculty visits to scientific facilities (e.g., Biomathematics and Biostatistics at MD Anderson Cancer Center, NASA). Through informal meetings, the program discusses a variety of topics ranging from applying to Graduate School to career experiences by outstanding scientists, and discussion of cutting-edge topics in Statistics. The program evaluates and monitors the progress of students for seven years (expected time for them to finish graduate school) after their participation, and an annual evaluation of the program by the participating students and an external advisory committee is an integral and valuable part of the program. The investment is starting to produce concrete results. The first RUSIS alumnus received his Ph.D. during the summer of 2011 and is now an assistant professor of statistical sciences in a Ph.D. program. Several more are due to obtain their PhDs in the next few years."
9818489,"A Gigabits/s, VIA-Enabled Cluster Arch. for Res. in High Performance Systems Software, Scalable Knowledge Discovery, Visualization, and Parallel Planning under Uncertainty",EIA,CISE RESEARCH RESOURCES,1/15/1999,1/11/1999,Anthony Skjellum,"Skjellum, A","Skjellum, A|Reese, D|Hodges, J|Hansen, E|Boggess, L|Bridges, S|Machiraju, R",MS,Mississippi State University,Standard Grant,Frederica Darema,12/31/2001,"$133,293.00 ","Donna Reese, Julia Hodges, Eric Hansen, Lois Boggess, Susan Bridges, Raghu Machiraju",tony-skjellum@utc.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,CSE,2890,"9216, HPCC",$0.00 ,normalFunding,"9818489<br/>Skjellum, Anthony<br/>Hodges, Julia<br/>Mississippi State University<br/><br/>A Gigabit/s, VIA-Enabled Cluster Architecture for Research in High<br/>Performance Systems Software, Scalable Knowledge Discovery, Visualization,<br/>and Parallel Planning under Uncertainty<br/><br/>This research instrumentation enables research projects in:<br/><br/>- Multi-Grain Parallel Processing,<br/>- Scalable Knowledge Discovery,<br/>- Parallel Volume Visualization for Computational Field Simulation, and<br/>- Parallel Processing for Markov Model Planning.<br/><br/>Concurrency is an important enabling technology for several areas of computational science, unlocking the potential for new science.  This research instrumentation proposal brings together three innovative<br/>computational activities together with a fourth research activity that enhances the capability and understanding of parallel processing environments, notations, and services.  Six investigators at Mississippi<br/>State University, Department of Computer Science, undertake the following projects: enhanced infrastructure for multi-grain parallel processing (including extensions to MPI, MPI-2, and MPI/RT), scalable knowledge<br/>discovery (artificial intelligence plus high performance computing to achieve automatic document classification and unsupervised learning algorithms), parallel volume visualization for computational field<br/>simulation, and parallel processing for Markov Model Planning (study of fast algorithms for exact solutions to planning under uncertainty).  To achieve this new science, a parallel processing cluster, consisting of thirty, two-way SMP Pentium II systems is to be assembled, together with multiple high speed networks, one of which supports the Virtual Interface Architecture for low processor overhead and high bandwidth.  Commercial-grade message passing software (MPI) and scheduling software are used to provide a production environment under Windows NT immediately, in complement to the research experiments involving parallel processing that further enable the environment over time, including part-time Linux-based operation.<br/><br/><br/><br/><br/>"
1217073,RUI: Uncertainty reduction through better nonlinear particle filters,DMS,COMPUTATIONAL MATHEMATICS,8/15/2012,7/1/2014,Haiyan Cheng,"Cheng, H","Cheng, H",OR,Willamette University,Continuing grant,rosemary renaut,7/31/2016,"$132,169.00 ",,hcheng@willamette.edu,900 State Street,Salem,OR,973013930,5033706617,MPS,1271,"9178, 9229, 9251, 9263",$0.00 ,normalFunding,"The objective of this project is to create and implement new methods for improving the performance of filtering, or data assimilation techniques, applied to non-linear, non-Gaussian systems. Many problems in computational statistics, artificial intelligence, and geophysics involve such systems, and utilize specialized Monte Carlo sampling methods, called particle filters, for data analysis and forecasting, and for better understanding of the underlying phenomena. The principal investigator studies variational data assimilation methods to demonstrate that targeted ensemble generation using those methods delivers more effective filter performance, and that dynamic adaptation of the size of the particle ensemble improves the computational efficiency of the filter.<br/><br/>Statistical computations are an essential tool for the solution of problems in such diverse areas as artificial intelligence, industrial and consumer electronics, robotics, weather systems, climate change, ocean ecosystems, and land surface processes.  The proposed research improves statistical computations required for the analysis, estimation, and forecasting of information that arrives over time, and contributes to a better combination of theoretical models with observational data.  In addition, the project involves the training of undergraduate students in applied scientific research.   <br/>"
619340,"MRI: Acquisition of a Virtual Reality Testbed  for Research and Teaching in Visualization, Simulation, and Edutainment",CNS,Unallocated Program Costs,8/15/2006,8/16/2006,Jim Chen,"Chen, J","Chen, J|Carr, D|Pullen, JM|Tecuci, G|Wegman, E",VA,George Mason University,Standard Grant,Rita V. Rodriguez,7/31/2008,"$131,616.00 ","Daniel Carr, J  Mark Pullen, Gheorghe Tecuci, Edward Wegman",jchen@cs.gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,9199,"1189, 9218, HPCC",$0.00 ,normalFunding,"Project Proposed:<br/><br/>This project, acquiring virtual reality infrastructure, aims at supporting research in computer graphics, visualization, and virtual reality. Spanning the areas of artificial intelligence, computer game development for computer science education, anatomy visualization, surgical simulation, and statistical data visualization, the infrastructure would service Computer Games for Learning (Edutainment), Virtual Surgery Simulation, and Scientific Data Visualization. The facility might enable experiments in the use of immersive networked virtual environments for distance education. On surgery simulation the current projects expand into an immersive environment with direct user manipulation of virtual objects through haptic devices, supplying a better sense of reality for both patients and surgeons. Providing a different perspective of data visualization, manipulation, and mining, the infrastructure would contribute to a new initiative on virtual environment construction through video images.<br/><br/>"
646677,Scholar's Award: Asymmetry and Intervention: The Role of Causation in Fundamental Science,SES,Hist & Philosophy of SET,9/1/2007,3/26/2007,Mathias Frisch,"Frisch, M","Frisch, M",MD,University of Maryland College Park,Standard Grant,Frederick M Kronz,8/31/2008,"$131,541.00 ",,mfrisch@umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,SBE,1353,"0000, OTHR",$0.00 ,normalFunding,"Introduction<br/>The PI proposes to examine the role of causal notions in fundamental science, focusing in particular on the relation between causation and intervention and on the causal asymmetry and its relation to other physical and cognitive temporal asymmetries. Causal notions have come to play an increasingly important role in the tool kit of contemporary philosophy and are invoked in the foundations of prominent approaches to a wide range of philosophical topics (such as arguments for the identity of mind and brain; discussions of free will; and theories of reference, perception, and memory). Moreover, recent research in a variety of different disciplines, such as cognitive psychology and artificial intelligence, points to the usefulness and central importance of a rich concept of cause in our cognitive architecture. Yet much of the work on causation in the foundations of physics is deeply skeptical of causal notions and the issue as to how the concept of cause can be grounded in what is arguably our most fundamental conception of the world -- that of fundamental science -- remains unresolved. The asymmetry of causation, in particular, is at the root of much that is obscure about the role of causation in our conception of the world. An asymmetric distinction between cause and effect appears to be essential to many of the uses to which causal notions are put. Yet the relation of the causal asymmetry to other physical temporal asymmetries (such as that of thermodynamics) remains poorly understood, and it has seemed to many that there is no place for such an asymmetric notion in a fundamental scientific conception of the world. There are frequent appeals to causal constraints in the physics literature, both as expressing time-asymmetric constraints and as expressing prohibitions against action-at-a-distance. But how such appeals are ultimately to be interpreted and whether the notions of cause at issue can be reduced to non-causal notions remain open questions. The PI aims to make progress towards answering these questions. The project (1) presents a range of novel criticisms of 'anti-causal' arguments; (2) develops and defends an account of the role of causal notions in fundamental science that appeals to conceptual connections between the notions of intervention and causation; (3) applies this account to an investigation of the relation between the causal asymmetry, the thermodynamic asymmetry, and time-asymmetric epistemic constraints on deliberating agents. The PI also plans to develop further an account of scientific theorizing defended in his recent book, arguing that the proper place for causal assumptions is not, as many would argue, in a theory's mathematical formalism but in an interpretive framework of (generally non-formalized) background assumptions.<br/><br/>Academic Merit<br/>The project will advance significantly our understanding of the foundational status of one of the central notions in science -- the concept of cause. It offers the first in-depth criticism of recent reductive accounts of causation and proposes a novel defense of the importance of causal notions even to fundamental science, drawing on recent interventionist theories of causation. The project will be of interest to anyone working on causation across a number of disciplines and will be useful to physicists who wish to understand the role of putatively causal constraints in physics and their justification. The project also will contribute to our understanding of the nature of scientific theorizing and scientific modeling and of the independent role of experiments in the production of scientific knowledge.<br/><br/>Broader Impact<br/>The PI is a member of an interdisciplinary and international working group on the origins and role of causal thinking and his project will contribute to the group's goal -- to advance our understanding of the role of causation in science through an interdisciplinary dialogue. As part of the project the PI is developing an interdisciplinary undergraduate course on causation that is aimed at attracting students from a broad range of backgrounds. The aim of the course is to promote scientific literacy and critical interdisciplinary discourse. A graduate student research assistant will be actively involved in the development of the course and, by participating in the project, will have the opportunity to do advanced research in a core area of philosophy of science. In the case of equal qualification, the research position will be awarded to a member of a minority underrepresented in philosophy."
527315,Collaborative Research - Traffic Congestion: Actions and Reactions,BCS,HSD - DYNAMICS OF HUMAN BEHAVI,9/1/2005,9/14/2005,Sudipta Sarangi,"Sarangi, S","Sarangi, S",LA,Louisiana State University & Agricultural and Mechanical College,Standard Grant,Amber L. Story,8/31/2009,"$130,435.00 ",,sarangi@lsu.edu,202 Himes Hall,Baton Rouge,LA,708032701,2255782760,SBE,7319,"0000, 7319, 9150, OTHR",$0.00 ,normalFunding,"This interdisciplinary research focuses on the effects of traffic congestion, and on evaluating alternative investments to manage the demand for transport services, as well as the social and behavioral impact of these investments. Today traffic flows continue to rapidly outpace resources available to society for improving the transportation infrastructure, and better management of existing facilities would be a cost effective way for resolving the problem. Since congestion depends on the policies chosen by the traffic authorities, and on the social interaction of individuals as drivers and passengers, analyzing congestion requires an integrated approach that allows for different viewpoints: the transportation agencies', the consumers', as well as the perspective of society as a whole. The primary objective of this research is to find an optimal mix of strategies that will spread traffic congestion over geographical space and time by better utilization of current resources, thereby reducing its costs. These strategies, such as dynamic pricing or highway reservation methods, have either been implemented in few selected areas in the United States, or have been discussed conceptually; however, their effects on travel and the urban infrastructure are not well understood. We propose to bring together tools from economics, systems engineering, and transportation engineering for a comprehensive analysis of the congestion problem. A number of concurrent objectives will be pursued in this research, which involves artificial intelligence models of users' transportation services, a set of economic experiments to evaluate different transportation policies, a model of the interaction of social networks and transportation choices, and a system dynamics analysis of transportation and social networks and their dynamic evolution. The successful completion of this research will have the potential to lead to new paradigms of traffic analysis and to a new understanding of the linkages between transportation, the urban infrastructure and ultimately the regional economy."
856311,Collaborative Research:   I/UCRC:    Safety Security Rescue Research Center (SSR-RC),IIP,"CISE RESEARCH RESOURCES, INDUSTRY/UNIV COOP RES CENTERS, ",9/1/2008,11/6/2008,Kimon Valavanis,"Valavanis, K","Valavanis, K",CO,University of Denver,Continuing grant,Rathindra DasGupta,7/31/2010,"$129,365.00 ",,kvalavan@du.edu,2199 S. University Blvd.,Denver,CO,802104711,3038712000,ENG,"2890, 5761, T672","0000, 1049, OTHR",$0.00 ,normalFunding,"This multi-university Industry/University Cooperative Research Center for Safety, Security and Rescue Research located at the University of South Florida and the University of Minnesota will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions in robotics for activities conducted by the police, FBI, FEMA, firefighting, transportation safety, and emergency response to mass casuality-related activities.  The need for safety, security, and rescue technologies has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics in February 2003.  <br/><br/>The Center will be built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at the University of South Florida (the lead institution) and the University of Minnesota.<br/>"
2620,COLLABORATIVE RESEARCH:  RUI:  Perceptual Grouping Effects on Perceived Lightness,BCS,HUMAN COGNITION & PERCEPTION,9/1/2000,6/6/2002,Frederick Bonato,"Bonato, F","Bonato, F",NJ,St Peter's University,Continuing grant,Christopher T. Kello,8/31/2005,"$128,580.00 ",,Fbonato@saintpeters.edu,2641 Kennedy Boulevard,Jersey City,NJ,73065943,2017616303,SBE,1180,"0000, 9229, OTHR",$0.00 ,normalFunding," The human visual system perceives shades of gray with remarkable accuracy despite large changes in the intensity of the illumination and the brightness of surrounding surfaces. For example, a middle gray piece of paper will generally appear middle gray regardless if it illuminated by a bright light or a dim light. The change in illumination results in retinal images that are also very different, yet in most cases the paper is perceived as middle gray. Lightness contrast and other errors have been studied in an attempt to understand more fully the visual system's design and logic in determining shades of gray. Simultaneous lightness contrast (SLC) has been one of the most widely studied of these errors. SLC is illustrated by placing a gray target on a white background and a physically identical gray target on a black background. The target on the white will appear darker than the target on black. Models attempting to explain SLC can be grouped into two main categories: 1) models that treat SLC as a residual byproduct of low-level retinal processes, namely, lateral inhibition, and 2) models based on perceptual grouping processes that must take place above the retinal level in the visual pathway. Perceptual grouping models are not well defined in terms of physiological structuresand functions. The main goal of the proposed project is to more fully explore the roles perceptual grouping processes play in determining perceived surface color. The research will focus on three novel paradigms recently discovered in the PIs' lab. One set of experiments will involve a variation of SLC in which two gray targets appear to move across their respective backgrounds. Another set of experiments will require the observer to fuse gray targets presented to one eye with backgrounds presented to the other eye. In a third set, the observer will judge the lightness of sequentially presented targets in an effort to understand the effect of the perceived gray shade of one surface on the perceived gray of a subsequently viewed surface. Experiments will test whether these recently discovered phenomena are primarily the results of retinal processes or perceptual processes that occur at a higher level in the visual system. <br/><br/> The results of these experiments will contribute to a better understanding of the mechanisms underlying these effects, their location, and the interaction between subsystems involved in determining perceived surface color. In short, the search field for neurological mechanisms important for perceived surface color will be narrowed. Models based on perceptual grouping may be better operationally defined in terms of neurobiology. This research will contribute to the fields of perceptual psychology, neuropsychology and artificial intelligence.<br/>"
1806332,SCH: EXP: Intelligent Clinical Decision Support with Probabilistic and Temporal EHR Modeling,IIS,Smart and Connected Health,8/15/2017,11/17/2017,Sriraam Natarajan,"Natarajan, S","Natarajan, S",TX,University of Texas at Dallas,Standard Grant,Sylvia J. Spengler,12/31/2018,"$127,346.00 ",,sriraam.natarajan@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,8018,"8018, 8061",$0.00 ,normalFunding,"Clinical decision support has the potential to reduce healthcare costs and improve patient outcomes, while shedding light into policy questions surrounding healthcare costs and practices in the US.  This project aims to develop intelligent clinical decision support techniques for recommending optimal action plans - including both diagnostic tests and medical interventions - for treating chronic disease, performing multi-step and adaptive treatments, and modifying long-term health habits. In an effort to integrate evidence-driven decision-making with established clinical practices, the research will develop disease-agnostic artificial intelligence techniques that combine data from large electronic health records (EHRs) with recommendations from human experts. A prototype decision support system will be tested on three clinical settings - cardiology, clinical depression, and emergency room readmission - using existing EHR datasets and consultation with domain experts from clinical partners. Outcomes-driven and cost-driven optimized decisions will be compared to current clinical practice. This exploratory research will provide the groundwork for follow-up projects in decision support information presentation, integration with clinical workflow and IT systems, and making the transition from retrospective studies to clinical trials.  Other broader impacts include workshops for healthcare applications of AI, and women and minority students will be recruited and mentored in graduate and undergraduate computer science research.<br/><br/>The technical approach of this research builds on state-of-the-art machine learning and artificial intelligence methods to automatically learn, simulate, and reason about patient-specific treatment plans.  Such methods must be simultaneously probabilistic and temporal.  Probabilistic techniques are needed to handle significant uncertainties in clinical diagnoses and outcomes, much like a human clinician would.  Temporal techniques are needed to consider sequences of future decisions over the course of treatment, rather than decisions at single time points.  More specifically, this project will consider the use of statistical relational learning (SRL) techniques to mine for probabilistic, temporal patterns in large electronic health records, and these patterns will be used in partially-observable Markov decision processes (POMDPs) that exhaustively search for optimal treatment sequences. Recent results indicate that SRL achieves superior performance to other machine learning methods in predicting cardiac arrest from demographic and lifestyle observations, and POMDP treatment plans outperform existing fee-for-service practices by reducing costs by 50% and improving outcomes by 40% on a clinical depression dataset.  By combining SRL and POMDPs, specifically, using SRL to learn a disease progression model used by the POMDP, this project aims to achieve further improvements in recommendation quality and computational scalability for complex treatments.  Furthermore, because EHRs may suffer from limited or missing data, clinical decision support tools should follow established practices and expert knowledge when necessary.  To do so, new workflows for integrating expert knowledge into SRL and POMDPs will be explored.  Evaluation will be performed on a variety of disease scenarios in conjunction with clinical partners at Marshfield Clinic, Centerstone, Wake Forest School of Medicine, and South Bend Memorial Hospital."
9610082,REU: Micro-Robot Soccer Playing - A R&D Project for         Undergraduate Students,CNS,CISE RESEARCH INFRASTRUCTURE,3/15/1997,3/14/2001,Bir Bhanu,"Bhanu, B","Bhanu, B",CA,University of California-Riverside,Continuing grant,Lawrence Burton,9/30/2001,"$126,580.00 ",,bhanu@cris.ucr.edu,Research & Economic Development,RIVERSIDE,CA,925210217,9518275535,CSE,2885,"9178, 9250, SMET",$0.00 ,normalFunding,"9610082  Wang, Jing  University of California,  Riverside    REU:  Micro-Robot Soccer Playing - A R&D Project for Undergraduate Students    This Research Experiences for Undergraduates (REU) Site project supports 8 students per year in programs carried out during the summers, for three years.  The projects involve research and development aspects of micro-mobile robots, robots that can cooperate to ""play"" soccer against another robot team--an innovative research project promoted internationally by the IEEE Robotics and Automation Society.  A robot soccer game is played on a court of 140 cm X 90 cm by two teams of autonomous mobile robots, each of which must fit in a 7.5 cm cube.  A team consists of 3 to 5 robots.  Participants will work on micro-robot structures, computer vision systems, onboard-robot processing units and peripherals, local motion and sensing, inter-robot communication, computer simulation, and game strategies.  The program is designed to train students to become research-minded and to think independently while gaining technical and ethical experiences.  Students will be exposed to cutting edge research in various technical areas including robotics, artificial intelligence, distributed computing, real-time systems, and computer organization."
84796,Minimization of Health Risks Due to Metalworking Fluid Microbes and Biocides:  An Optimal Control System using Microfiltration and Flow Cytometry,CMMI,"Manufacturing Machines & Equip, GRANT OPP FOR ACAD LIA W/INDUS",9/15/2000,12/14/2000,Steven Skerlos,"Skerlos, S","Skerlos, S",MI,University of Michigan Ann Arbor,Standard Grant,george hazelrigg,8/31/2003,"$125,000.00 ",,skerlos@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,ENG,"1468, 1504","1049, 1504, 1669, 9146, MANU",$0.00 ,normalFunding,"This grant provides funding for the development of an automated and cost-effective control system to minimize occupational health and safety risks posed by microorganisms and excessive reliance on biocides in metalworking fluid (MWF) systems.  First, the research aims to understand the mechanisms that permit membrane-based microfiltration technology to remove microorganisms and associated endotoxin from biocide-free MWFs without disrupting chemical integrity.  The research will examine the interactions between MWF chemistry, membrane transport, and ingredient retention.  Second, the research will examine a novel application of flow cytometry technology for real-time microbial detection in MWFs.  The research will evaluate the physicochemical conditions that maximize flow cytometry performance in MWF applications.  Third, an optimal control system will be developed based on flow cytometry and microfiltration.  The control system will utilize artificial intelligence methodologies on-line to dynamically predict the required microbial removal rate and optimal microfiltration operating parameters.<br/><br/>The control system aims to eliminate microbial-based health risks to approximately 1.2 million workers in the United States.  The system would also significantly improve the competitive position of the United  States machine tool industry by reducing environmental impact, lowering total machining costs, and minimizing MWF performance variability by enabling contaminant removal and recycling.  These considerations are of increasing importance since legislative pressure is mounting at the national level to compel the industry to address the environmental and health risks associated with MWF applications (e.g., EPA Metal Products and Machinery Rule and NIOSH Recommended MWF Exposure Criteria).  Recent studies have also demonstrated that total MWF system costs, including acquisition, disposal, and maintenance, are significant in machining, in many cases far-outweighing the cost of tooling.  Owing to the technical difficulty removing MWF from manufacturing processes, these drivers will continue to push industry demand for biocide-free microbial control systems and recycling of MWFs to reduce health risks, cost, environmental impact, and performance variability."
1652052,CAREER: Active and Action-Centric Visual Understanding,IIS,ROBUST INTELLIGENCE,7/1/2017,8/22/2018,Ali Farhadi,"Farhadi, A","Farhadi, A",WA,University of Washington,Continuing grant,Jie Yang,6/30/2023,"$124,002.00 ",,afarhad2@gmail.com,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7495,"1045, 7495",$0.00 ,normalFunding,"This project develops technologies for visual semantic planning; the problem of producing ordered sequences of actions that change the current world state from what is depicted in a given image or video to the state defined by a query task. The project bridges the gap between current levels of image understanding and what is needed to actively understand the visual world to the extent that an agent can plan and perform tasks. The project develops the technology for a crucial next step in recognition: active and action-centric image understanding by semantic understanding of actions, their preconditions and effects, and visual planning.  Doing so empowers several applications in healthcare, prospective memory failure care, visually impaired care, elderly care, robotics, entertainment, and education.<br/><br/>This research addresses the visual planning problem that entails knowing what actions are, how they change the world state, and which sequences of actions change the current state to a desired one. Successful active understanding of images requires addressing several fundamental and challenging problems at the intersection of computer vision and artificial intelligence. The research is focused on the development of a framework for active visual understanding, new scalable algorithms for joint detection of actions and their arguments, new datasets and representations for actions' preconditions and effects, new algorithms for predicting the consequences of actions with intuitive laws of physics, and visual semantic planning. The developed framework is designed for active and action-centric image understanding by large-scale, semantic action recognition, modeling actions' preconditions and effects, predicting consequences of actions, and visual planning. These resources not only enable new research directions in computer vision, robotics, and AI, but also bring together some of the independent efforts across these disciplines."
9530637,Mathematical Sciences: Dynamics and Kinetics of Spatially Extended Systems,DMS,ANALYSIS PROGRAM,6/15/1996,2/19/1998,Leonid Bunimovich,"Bunimovich, L","Bunimovich, L",GA,Georgia Tech Research Corporation,Continuing grant,Joe W. Jenkins,5/31/2000,"$123,000.00 ",,bunimovh@math.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,MPS,1281,"OTHR, 0000",$0.00 ,normalFunding,"Abstract Bunimovich The proposed research deals with the dynamics of spatially extended systems. The systems under study include nonlinear hyperbolic partial differential equations, lattice dynamical systems (in particular, coupled map lattices), lattice gas cellular automata and the systems of interacting particles. The pattern formation problem will be studied as well as order-chaos transitions. Most of the questions that will be addressed have their origin in physics and hydrodynamics, and were transformed into the mathematical form by the principal investigator with collaborators during the last fifteen years. A broad approach will be used that combines methods of the ergodic theory, the theory of nonuniformly hyperbolic dynamical systems, stability theory of infinite dimensional dynamical systemq and the theory of bifurcations. The recent breakthrough in the understanding of a complex (chaotic) dynamics of systems evolving in time (dynamical systems) was connected with the studies of nonextended (point) dynamical systems whose dynamics can be completely described by measurements performed at a single point of a real (physical) space. Evolution of extended systems such as the flow of fluids and gases, large systems of interacting elements in electronics (e.g. Josephson junctions) needs to be studied in space and time simultaneously. The purpose of this research is to pursue the adequate approaches to study such space-time evolution and to develop algorithms to evaluate quantities that characterize space-time dynamics. The other novelty is the study of systems with dynamics which have both random and deterministic components (but not small, random perturbations of deterministic systems or vise versa). Most of systems in applications are of this type, e.g. in chemistry, artificial intelligence, in the management of warehouses etc."
202565,"Variational and PDE Models, and their Computation for Image Inpainting",DMS,APPLIED MATHEMATICS,7/1/2002,4/5/2004,Jianhong Shen,"Shen, J","Shen, J",MN,University of Minnesota-Twin Cities,Continuing grant,Henry A. Warchall,6/30/2006,"$121,322.00 ",,jhshen@math.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,MPS,1266,"0000, OTHR",$0.00 ,normalFunding,"DMS Award Abstract<br/>Award #: 0202565<br/>PI: Shen, Jianhong<br/>Institution: University of Minnesota, Twin Cities<br/>Program: Applied Mathematics<br/>Program Manager: Catherine Mavriplis<br/><br/>Title: Variational and Partial Differential Equation Models, and their Computation for Image Inpainting<br/><br/>This project is intended to discover and develop the most fundamental and crucial mathematical principles and frameworks for highly diversified applications of digital inpainting. These frameworks will allow us to further construct many universally applicable inpainting models, and design their efficient and robust computational algorithms. Our proposed approach is to employ several high level mathematical tools for the modeling and computation of inpainting, which include the Bayesian decision theory, nonlinear partial differential equations (e.g. mean curvature motions, nonlinear transport and diffusion), variational methods in the space of Bounded Variations and for free boundary problems, a variety of state-of-the-art tools from harmonics analysis such as wavelets and multiresolution analysis, and many efficient schemes in numerical analysis and computational partial differential equations. The project is also highlighted by the fact that we are proposing for the first time to integrate visually important curve, surface, and image geometry into the traditionally statistical models and dynamic processes. <br/><br/>Digital inpainting is to develop an automatic process to intelligently recover and complete the missing, unavailable, or purposely disguised image information. Such loss of information occurs ubiquitously in a variety of important fields including computer vision, network (especially wireless) communication, robust image coding and transmission (from the Hubble Space Telescope for example), three-dimensional volumetric organ reconstruction from two-dimensional medical images, disguise of enemy weapons and personnel in the battlefields, and the digital restoration of cracked ancient paintings in digitized fine art museums. This project will develop a mathematical framework for image inpainting. Besides the broad impact on the numerous important fields mentioned above, the project will also strengthen the integration of high level pure mathematics into the contemporary digital, computer, and artificial intelligence technology, and in return, create numerous opportunities for mathematical modeling, analysis, and computation. It will also help the principal investigator develop new curricula and train new graduate students in this booming fresh field of applied mathematics.<br/><br/>Date: May 22, 2002"
9410180,RIA:  Designing and Implementing a Distributed Meeting      Scheduler,IIS,"CISE RESEARCH RESOURCES, DIGITAL SOCIETY&TECHNOLOGIES",8/1/1994,8/14/1996,Sandip Sen,"Sen, S","Sen, S",OK,University of Tulsa,Continuing grant,C. Suzanne Iacono,7/31/1998,"$120,000.00 ",,sandip@utulsa.edu,800 S. Tucker Drive,Tulsa,OK,741049700,9186312192,CSE,"2890, 6850","9216, 9251, 9264, HPCC",$0.00 ,normalFunding,"     Routine, time-consuming, and repetitive information processing  tasks performed by employees in organizations can be potentially  automated.  Possible benefits from automation include relieving  employees to concentrate on relatively fruitful and productive  jobs, and in improving the quality of work by eliminating human  errors that are inadvertently introduced due to the tedious nature  of work.         A candidate task for automation is that of scheduling meetings  between individuals.  Though past efforts have produced necessary  techniques for building distributed agents that can schedule  meetings on behalf of associated users, much work remains to be  done in encoding user goals and constraints before a useful system  can be implemented.  The proposed research will produce an  efficient implemented system that effectively schedules meetings  without compromising user preferences and constraints.  This will  fill a void in the currently available calendar management  software.         This research will involve developing a language and inference  procedure to specify and reason about user preferences, building  models of agents from limited information, and developing  negotiation mechanisms to coordinate partially cooperative agents.   A unique contribution of this research lies in developing  intelligent agents that are adaptive to the environmental demands  and the needs of associated users at the same time.  These  techniques will be a significant contribution to the evolving field  of Distributed Artificial Intelligence, and can be gainfully  applied in fields like Cooperative Information Systems and Computer  Supported Cooperative Work."
505865,Collaborative Research: Graphical and Algebraic Models for Multivariate Categorical Data,DMS,STATISTICS,7/1/2005,4/28/2005,Thomas Richardson,"Richardson, T","Richardson, T",WA,University of Washington,Standard Grant,Gabor J. Szekely,6/30/2009,"$120,000.00 ",,tsr@stat.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,MPS,1269,"0000, OTHR",$0.00 ,normalFunding,"The proposed research project develops models for multivariate categorical<br/>data by mimicking Gaussian models with a desired model structure that can<br/>be captured in terms of the non-parametric concept of conditional<br/>independence.  This method has a long history: graphical log-linear models<br/>can be induced in this way by Gaussian models defined by zero constraints<br/>on the inverse covariance matrix. The project seeks to greatly extend the<br/>scope of the approach.  It is proposed to define and study marginal<br/>independence models for contingency tables, discrete-valued time series<br/>with moving average-like dependence structure, seemingly unrelated<br/>regressions with discrete response variables, and discrete graphical<br/>models based on the recently introduced AMP chain graphs and ancestral<br/>graphs.  The main objectives of the study are development of<br/>parameterizations, construction and implementation of efficient algorithms<br/>for maximum likelihood estimation, and investigation of procedures for<br/>model selection. A particular focus of the project will be on employing<br/>modern tools from computational algebra in the analysis of the structure of<br/>parameter spaces and properties of likelihood functions.<br/><br/>Multivariate statistical models seek to describe the complex relationships<br/>between a large set of variables. A particular class of such models,<br/>called graphical models, has found wide-spread application in fields like<br/>artificial intelligence, bio-informatics, biology, epidemiology, and<br/>speech recognition.  The models proposed in the project extend the realm<br/>of graphical models and it is anticipated that they will be applied in<br/>many of these fields.  Moreover, the proposed methodology will provide new<br/>tools for the analysis of data of public interest such as census data.<br/>The researchers also plan to make software tools freely available as part<br/>of a larger open source statistical software package called R.<br/>"
98095,Collaborative Research on Semantic Unification and its Applications,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT",8/15/2001,8/31/2001,Paliath Narendran,"Narendran, P","Narendran, P",NY,SUNY at Albany,Standard Grant,Sankar Basu,7/31/2005,"$119,588.00 ",,pnarendran@albany.edu,1400 WASHINGTON AVE,Albany,NY,122220100,5184374550,CSE,2865,"9216, HPCC",$0.00 ,normalFunding,"Proposal #0098095<br/>Narendran, Paliath<br/>SUNY Albany<br/><br/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br/><br/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br/><br/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br/><br/>This award is one of three in a collaborative research team. The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany)."
1050168,GV: EAGER: Innovative Analysis and Visualization Approaches for Understanding Model Uncertainty,IIS,GRAPHICS & VISUALIZATION,9/1/2010,12/2/2013,Marie desJardins,"desJardins, M","desJardins, M|Rheingans, P",MD,University of Maryland Baltimore County,Standard Grant,Maria Zemankova,8/31/2014,"$119,299.00 ",Penny Rheingans,mariedj@cs.umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,CSE,7453,"7453, 7916, 9251",$0.00 ,normalFunding,"This exploratory project strives to develop a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex models.Specifically, the focus in the project is on understanding several types of uncertainty that are associated with model predictions.<br/>Sample uncertainty occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. Model instability occurs when model predictions vary, depending on the training data that was used to construct the model. Prediction variability occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. Novel analytical techniques are developed to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, novel visualization methods represent these meta-models in a display space. Finally, a novel evaluation methodology is used to measure whether, and in what ways, important characteristics of the meta-models are captured in the visualization display space.<br/><br/>This work develops novel techniques in the fields of machine learning and data visualization. Contributions in machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Data visualization research focuses on new approaches for representing multi-valued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty. An interdisciplinary contribution is the development of a novel methodology for evaluating the quality of model visualizations with respect to the preservation of important model and meta-model characteristics.<br/><br/>The broader impacts of this project may be grouped into three major clusters: a new model building paradigm; fostering scientific collaboration; and integrating research and education. The results are expected to provide foundations for further research is management of uncertainty in deriving models representing a wide range of phenomena. This project lays a technical groundwork that can contribute to new collaborations between the PIs and application domain experts, facilitating broad interdisciplinary collaborations. Project results will be widely disseminated via the project web site (http://maple.cs.umbc.edu/complexmodels/). Finally, through teaching and training activities, this research project is also well suited to include the introduction of undergraduates to the possibilities of research and the incorporation of project topics into the PIs' courses on visualization and artificial intelligence."
537285,SGER:   Rescuing the MIT Film History of AI,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2005,6/2/2006,Rodney Brooks,"Brooks, R","Brooks, R|Levenson, T|Greene, T",MA,Massachusetts Institute of Technology,Standard Grant,Douglas H. Fisher,12/31/2006,"$118,524.00 ","Thomas Levenson, Thomas Greene",brooks@ai.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,6856,"6856, 7484, 9216, 9218, 9237, HPCC",$0.00 ,normalFunding,"This project will collect, organize and preserve historic materials, particularly film, that are part of the historical record of the field of Artificial Intelligence (AI). It will create an organized digital archive and use highlights selected from the archive to illustrate the intellectual history of AI in a coherent narrative. It is intended that these materials will be made publicly available, for instance through a web site or DVD. Sources for this project included notes, memos and technical reports from MIT and elsewhere, and in particular, a uncatalogued, unconserved and uncurated collection of films that recently came to light at MIT. <br/><br/>The project will proceed in two phases. In Phase 1, the project will gather films, inventory their condition and content, organize them into a historic time line, convert the collection into digital format, and create an on-line archive of the collection. In Phase 2, the project will create a connecting narrative at the level appropriate to a broad popular audience (e.g., at the level of viewership of PBS's NOVA series). This phase will also select a collection of anecdotal film clips from the larger collection to highlight some of the major moments in the history of AI. Lastly, the project will create a web site or DVD to showcase the selected clips, the connecting narrative, and other more technical materials.<br/>"
409497,Machine Learning Laboratory Experiences for Introducing Undergraduates to Artificial Intelligence,DUE,"CCLI-ADAPTATION AND IMPLEMENTA, CCLI-Type 1 (Exploratory)",7/15/2004,5/25/2006,Ingrid Russell,"Russell, I","Russell, I|Markov, Z|Neller, T",CT,University of Hartford,Standard Grant,Stephen C. Cooper,6/30/2007,"$116,469.00 ","Zdravko Markov, Todd Neller",irussell@hartford.edu,200 Bloomfield Avenue,West Hartford,CT,61171545,8607685938,EHR,"7428, 7494","9178, SMET, 7428, 1032",$0.00 ,normalFunding,"Computer Science (31)<br/><br/>This project unifies the artificial intelligence (AI) course around the theme of machine learning and creates a framework for core AI concepts around that theme. This is adapted from NSF-funded work at the University of Central Florida. The project develops and tests an adaptable framework to present core AI topics that emphasizes the relationship between AI and computer science in general. It is producing a laboratory manual that presents a suite of projects that can be closely integrated into a one-term AI course. The project involves faculty from three schools, and an additional 21 institutions have committed to using the results of this project when it is complete."
1654651,HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative,IIS,Cyber-Human Systems (CHS),5/16/2016,9/9/2016,Robert Young,"Young, R","Young, R",UT,University of Utah,Continuing grant,William Bainbridge,7/31/2017,"$115,313.00 ",,young@cs.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,CSE,7367,"7367, 7923",$0.00 ,normalFunding,"The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments.  Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure.  The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves.  Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br/><br/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br/><br/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines.  Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process."
1657600,CRII: RI: Reasoning Geometric Commonsense for 3D Image/Video Parsing,IIS,CRII CISE Research Initiation,5/1/2017,5/3/2017,Xiaobai Liu,"Liu, X","Liu, X",CA,San Diego State University Foundation,Standard Grant,Jie Yang,4/30/2019,"$115,062.00 ",,xiaobai.liu@mail.sdsu.edu,5250 Campanile Drive,San Diego,CA,921822190,6195945731,CSE,026Y,"7495, 8228",$0.00 ,normalFunding,"Commonsense reasoning studies the consensus reality, knowledge, causality, and rationales available to the overwhelming majority of people, and can be used to enhance all aspects of Artificial Intelligence (AI). This project develops representations of geometric commonsense as well as computing principles of commonsense reasoning for computer vision applications. The project systemically studies commonsense knowledge over geometric dimensions of scene entities, e.g., the length of a sedan is shorter than that of a bus; or that window edges on the same fa???ade are parallel to each other and are orthogonal to the edges on the ground. These first-order and second-order knowledges, once extracted, are fairly stable across different types of scenes, and are informative enough for enhancing the understanding of images or videos in both 2D and 3D. The project integrates research with education by supporting graduate students, and outreaches to computer vision and AI research communities by organizing workshops in the relevant conferences.<br/><br/>This research studies geometric commonsense reasoning for 3D scene parsing in images or videos, and contributes a unified probabilistic approach that is capable of reconstructing a wide variety of scene categories (e.g., suburb, urban, campus) from a single input image or a monocular video sequence.  The project approaches the problem from two aspects. First, a new attributed grammar model is developed to represent both images and the associated geometric commonsense knowledge using a hierarchical graphical structure. With this grammar model, the segmentation of semantic regions, the reconstruction of scene entities, and the reasoning of geometric commonsense can be all solved through creating a valid parse graph from images or videos. Second, a new computing framework is introduced so that the inference of image parsing can be conducted in the joint space of discrete semantic labels and continuous geometric labels, and the learning of grammar models can be conducted over training images with weak supervision. The developed techniques enable a state-of-the-art computer vision system that can robustly estimate semantic and geometric scene structures from images or videos."
1247414,EAGER: Toward Scalable Life-long Representation Learning,IIS,ROBUST INTELLIGENCE,8/1/2012,7/19/2012,Honglak Lee,"Lee, H","Lee, H",MI,University of Michigan Ann Arbor,Standard Grant,todd leen,7/31/2014,"$115,000.00 ",,honglak@eecs.umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,7495,7916,$0.00 ,normalFunding,"Machine learning is a powerful tool for artificial intelligence and data mining problems. However, its success critically relies on a good feature representation of the data; therefore, the problem of feature construction poses a fundamental challenge. In recent years, representation learning has emerged as a promising method for learning useful feature representations from data. However, the current state-of-the-art methods are still limited in building intelligent agents that can learn and interact with complex environments and large amounts of sensory input. Specifically, the majority of the existing methods cannot scale well to large-scale data.<br/><br/>The goal of this project is to fill this gap by formulating a new framework that can effectively learn representations from complex environments and scale to large data. Specifically, we propose novel approaches for learning robust representations from large-scale data by (1) controlling the complexity of the feature representations and (2) adaptively modeling relevant patterns in the presence of significant amounts of irrelevant patterns or noise.<br/><br/>Key intellectual contributions of this project will be (1) a novel framework of representation learning that provides robust representations from large amounts of unlabeled data and relatively small amounts of labeled data, and (2) theoretical and algorithmic advances for inference, learning, and related optimization problems in representation learning for large-scale, complex sensory information processing.<br/><br/>This work will serve as a catalyst leading to applications, such as multimedia processing and search, medical image processing, speech recognition, and autonomous navigation. The results will be disseminated through publications and free software."
1540996,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,ICER,EarthCube,9/1/2015,7/28/2015,Nicholas McKay,"McKay, N","McKay, N",AZ,Northern Arizona University,Standard Grant,Eva E. Zanzerkia,8/31/2018,"$113,015.00 ",,Nicholas.McKay@nau.edu,"ARD Building #56, Suite 240",Flagstaff,AZ,860110001,9285230886,GEO,8074,7433,$0.00 ,normalFunding,"Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.<br/><br/>Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines."
92618,The Impact of Information Technology on the Taxonomic Organization of Knowledge,BCS,"CULTURAL ANTHROPOLOGY, EPSCoR Co-Funding",5/15/2001,5/14/2001,F. Allan Hanson,"Hanson, FA","Hanson, FA",KS,University of Kansas Center for Research Inc,Standard Grant,Deborah Winslow,4/30/2005,"$113,000.00 ",,hanson@ku.edu,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,SBE,"1390, 9150","0000, 9150, OTHR",$0.00 ,normalFunding,"0092618<br/>Hanson<br/> This research investigates how computer automation is contributing to changes in the status, conceptualization and use of knowledge in American society by means of a case study of legal information. The researcher, a cultural anthropologist from the University of Kansas, will investigate the impact of artificial intelligence in the form of expert systems for automated processing of legal procedures and computer assisted legal research.  The difference between the traditional conceptualization of the law as a hierarchical, taxonomic form of knowledge and the more contemporary computer-influenced conceptualization of computerized keyword searching, which implies a more horizontal, loosely structured network will be studied for its impact on the practice of law.  Methods include a literature search and inventory of legal expert systems, open ended interviews with legal theorists and practitioners in law firms and courts, and comparative research in Europe and Australia where the use of legal expert systems is more advanced than in the USA.  The research will plot the number of citations to non-legal sources in opinions issued by selected state Supreme Courts and Federal District Courts over the past forty years, as well as perform other quantitative analyses to assess the permeability of the boundary between the law and other disciplines.  This research should advance our understanding of the impact of computerized information technologies on legal institutions.  The new knowledge to be created will be valuable to theorists as well as practitioners of the law. <br/>"
1736065,EXP: Collaborative Research: Empowering Learners to Conduct Experiments,IIS,IUSE,9/1/2017,8/23/2017,Camillia Matuk,"Matuk, C","Matuk, C",NY,New York University,Standard Grant,William Bainbridge,8/31/2019,"$112,000.00 ",,cmatuk@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,CSE,1998,"8045, 8209, 8841, 9178",$0.00 ,normalFunding,"This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
421347,Collaborative Research: Interactive Level-Set Modeling for Visualization of Biological Volume Datasets,CCF,ADVANCED COMP RESEARCH PROGRAM,10/1/2003,2/23/2004,David Breen,"Breen, D","Breen, D",PA,Drexel University,Continuing grant,Almadena Y. Chtchelkanova,9/30/2005,"$111,602.00 ",,david@cs.drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,4080,"9216, HPCC",$0.00 ,normalFunding,"As scientific data becomes larger and more complex, the problem of presenting data effectively is joined by another, potentially more difficult one - how to extract presentable data from the flood of raw information. This problem is equally difficult for results from large simulations and data from high-resolution instruments. Thus, the field of scientific visualization becomes intimately tied to more traditional studies of data analysis, including image processing, pattern recognition, artificial intelligence, and computer vision. However, in contrast to those fields, visualization explicitly includes the user in the process of filtering, extracting, and rendering meaningful data. The goal of this project is to make level-set modeling - a useful but computationally expensive visualization technique - interactive for use in 3-D visualization of biological data sets.<br/><br/>Technically, the project has three components. The first is the design and implementation of a hardware and software system for interactive level-set surface model computation and display. This system will use off-the-shelf PC hardware and graphics boards and new algorithms and software to reach its interactivity goals. The second component will create the human-computer interface that allows users to interact with the level-set models. This will require mapping user input onto the mathematical descriptions controlling surface motion and deformation in the models. Finally, the third component will be the application of the techniques to visualize large biological data sets by researchers in this project.<br/><br/>This is a collaborative project between California Institute of Technology and the University of Utah.<br/>"
1143734,EAGER:  Decision Support System for Reasoning with Preferences,CCF,SOFTWARE & HARDWARE FOUNDATION,8/1/2011,7/14/2011,Samik Basu,"Basu, S","Basu, S|Lutz, R",IA,Iowa State University,Standard Grant,Nina Amla,7/31/2013,"$111,393.00 ",Robyn Lutz,sbasu@cs.iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,CSE,7798,"7916, 7944, 9150",$0.00 ,normalFunding,"Automated decision support systems help users make informed and intelligent choices over a set of alternatives, taking into account user preferences and trade-offs among multiple system attributes. In the software engineering domain decision support systems are used to help in evaluating alternative design, technical and managerial choices in terms of quantitative preferences and trade-offs. Preferences over alternatives are evaluated either by directly soliciting from the stakeholders a measure of the perceived utility/value of each attribute, or by quantifying such utility/value based on past experience and expertise. In most practical settings, however, preferences over attributes cannot all be quantified. On the other hand, considering preferences only qualitatively (specifying them as simple relative orderings between alternatives) is also not practical. To overcome these limitations, the proposed research focuses on developing a new paradigm for decision support systems, where preferences are specified both in qualitative and quantitative terms.<br/><br/>The main thrust of this work will be to: (a) develop robust formalisms for representing and reasoning with quantitative and qualitative preferences in an unified fashion, (b) investigate application-domain specific extensions to the formalisms, and (c) identify implementation strategies for practical application of the decision support system as a preference analyzer. The anticipated results will help realize application-specific robust decision support systems in multiple domains, including product-line engineering, safety-critical system development, and goal-oriented requirements engineering, by enabling improved automated reasoning about preferences.  This work will contribute to research-based training of a postdoctoral scholar and a graduate student in techniques that cut across software engineering, formal methods and artificial intelligence. Research results will be disseminated through publications in journals and conferences."
604065,"Structure and algorithms, between logic and algebra",DMS,"ALGEBRA,NUMBER THEORY,AND COM",6/15/2006,4/17/2009,Ralph McKenzie,"McKenzie, R","McKenzie, R",TN,Vanderbilt University,Standard Grant,Tomek Bartoszynski,1/31/2010,"$110,973.00 ",,rn.mckenzie@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,MPS,1264,"0000, 9150, OTHR",$0.00 ,normalFunding,"McKenzie will investigate algorithmic<br/>questions which involve properties of finite algebras determined by the<br/>varieties and quasi-varieties they generate, and<br/>structural questions which involve the necessary algebraic properties<br/>that must be true throughout a locally finite variety or quasi-variety <br/>as a consequence of that class possessing some natural property defined <br/>through logical or set-theoretic means.  <br/>The outstanding algorithmic questions:  Is there an algorithm to<br/>determine if the quasi-equations valid in a finite algebra  F  <br/>are finitely based?  Is there an algorithm to determine if the <br/>quasi-variety generated by  F  possesses a natural duality?  <br/>Is the class of finite algebras possessing a finite equational basis <br/>recursively enumerable?  Is the class of finite algebras generating <br/>a residually large variety recursively enumerable?  <br/>Among the important structural questions:  What collection of algebraic<br/>properties is necessary and sufficient for a finitely generated variety to<br/>be finitely decidable, or to have few models?  <br/>He will work on an algebraic conjecture that, if proved, would establish an<br/>important case of the<br/>dichotomy conjecture for the constraint satisfaction problem of<br/>theoretical computer science:  every finite algebra  F  in a meet semi-distributive<br/>variety has finite relational width.<br/><br/><br/>The principal investigator believes that research<br/>into the interplay between, on the one hand, the existence or nonexistence<br/>of algorithms to recognize fundamental properties of finite algebras, <br/>and on the other hand, the levels of structural complexity manifested <br/>in the algebras---what this project is all about---has the potential <br/>not only to expand our understanding of the structural possibilities in <br/>finite algebraic systems (which it has already done), but to produce<br/>fundamental breakthroughs in theoretical computer science.<br/>The most likely place for this to occur soon is in the algebraic approach<br/>to the constraint satisfaction problem (CSP).<br/>Specific instances of the constraint satisfaction problem, <br/>including graph homomorphism problems,<br/>are ubiquitous in many areas of artificial intelligence, computer<br/>science, database theory, scheduling, networking, hardware verification, etc. <br/>The algebraic approach puts some of the most developed areas of<br/>universal algebra, especially the machinery of tame congruence theory<br/>developed by the principal investigator, to work in the study of combinatorial problems <br/>related to the CSP;<br/>and it may have potential applications<br/>in the study of other computational paradigms, such as approximation <br/>and randomized algorithms, and quantum computation."
9411157,Dynamics of Task-oriented Communication: Tests of Computer  Models of Affect Control Theory,SES,SOCIOLOGY,8/15/1994,2/24/1998,Lynn Smith-Lovin,"Smith-Lovin, L","Smith-Lovin, L",AZ,University of Arizona,Standard Grant,,8/31/1998,"$110,796.00 ",,smithlov@soc.duke.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,SBE,1331,"0000, 9139, 9251, HPCC, OTHR",$0.00 ,normalFunding,"     This is a study of dynamics of identity maintenance in conversational interaction, focusing on turn-taking and interruption in conversation, based on a new theoretical approach that combines the three dimensions of status (deference), power (dominance), and expressivity.  Two studies will test this new model.  Study 1 uses data from 53 mock juries.  Identity measurements are taken from group participants before the discussions began.  Event history analysis will model the risk of ending a turn with either a normal transition or an interruption.  Identity information from both the current speaker and the next speaker will be used to predict turn length and type of transition.  Study 2 will use an experimental design to manipulate the identities that people bring to conversations.  By assigning people to roles with varying evaluative and potency connotations, then having them engage in activities to instantiate those roles, the experiment will randomly assign the identities expected to be maintained in conversational interaction.  Event history analyses parallel to Study 1 will be used to test the theoretical predictions.  %%%   This project is a step toward important new developments in advanced computing.  It employs affect control theory, a formal, mathematical model of the interrelationship of identity, behavior, emotion and attribution.  The theory is embodied in a computer simulation called INTERACT that predicts the emotional and evaluative responses of human beings confronted with various complex situations.  This research will test the computer simulation's predictions, and if the hypotheses are supported will enable the elaboration of INTERACT to allow prediction of small group behavior.  Most importantly, INTERACT software can then be expanded to include a much larger set of linguistic terms, running on faster and larger machines, that would permit computers to simulate emotional behavior and to respond more appropriately to the emotional behavior of human beings.    %%%   Affect c ontrol theory is a major intellectual force in contemporary social psychology, and the sociology of emotions is among the most active new subdisciplines, so this research will be of wide interest to social and behavioral scientists.  The improvement of simulation models of emotion in social interaction will have significant implications for artificial intelligence and for human-computer communication."
1205195,CI-ADDO-EN: Collaborative Research: 3D Dynamic Multimodal Spontaneous Emotion Corpus for Automated Facial Behavior and Emotion Analysis,CNS,COMPUTING RES INFRASTRUCTURE,9/1/2012,6/28/2012,Jeffrey Cohn,"Cohn, J","Cohn, J",PA,University of Pittsburgh,Standard Grant,Ephraim P. Glinert,8/31/2016,"$110,001.00 ",,jeffcohn@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,7359,7359,$0.00 ,normalFunding,"Emotion is the complex psycho-physiological experience of an individual's state of mind.  It affects every aspect of rational thinking, learning, decision making, and psychomotor ability.  Emotion modeling and recognition is playing an increasingly important role in many research areas, including human computer interaction, robotics, artificial intelligence, and advanced technologies for education and learning.  Current emotion-related research, however, is impeded by a lack of a large spontaneous emotion data corpus.  With few exceptions, emotion databases are limited in terms of size, sensor modalities, labeling, and elicitation methods.  Most rely on posed emotions, which may bear little resemblance to what occurs in the contexts wherein the emotions are really triggered.  In this project the PIs will address these limitations by developing a multimodal and multidimensional corpus of dynamic spontaneous emotion and facial expression data, with labels and feature derivatives, from approximately 200 subjects of different ethnicities and ages, using sensors of different modalities.  To these ends, they will acquire a 6-camera wide-range 3D dynamic imaging system to capture ultra high-resolution facial geometric data and video texture data, which will allow them to examine the fine structure change as well as the precise time course for spontaneous expressions.  Video data will be accompanied by other sensor modalities, including thermal, audio and physiological sensors.  An IR thermal camera will allow real time recording of facial temperature, while an audio sensor will record the voices of both subject and experimenter. The physiological sensor will measure skin conductivity and related physiological signals.  Tools and methods to facilitate and simplify use of the dataset will be provided.  The entire dataset, including metadata and associated software, will be stored in a public depository and made available for research in computer vision, affective computing, human computer interaction, and related fields.<br/><br/>Intellectual Merit <br/>This research will involve construction of a corpus of spontaneous multi-dimensional and multimodal emotion and facial expression data, which is significantly larger than any that currently exist.  To elicit natural and spontaneous emotions from subjects, the PIs will employ five approaches using physical experience, film clips, cold pressor, relived memories tasks, and interview formats.  The database will employ sensors of different modalities including high resolution 2D/3D video cameras, infrared thermal cameras, audio sensors, and physiological sensors.  The video data will be labeled according to a number of categories, including AU labeling and emotion labeling from self-report and perceptual judgments of na???ve observers.  Comprehensive emotion labeling will include dimensional approaches (e.g., valence, arousal), discrete emotions (e.g., joy, anger, smile controls), anatomic methods (e.g., FACS), and paralinguistic signaling (e.g., back-channeling).  Additional features will be derived from the raw data, including 2D/3D facial feature points, head pose, and audio parameters.<br/><br/>Broader Impact <br/>Project outcomes will immediately benefit researchers in computer vision and emotion modeling and recognition, because the database will allow them to train and validate their facial expression and emotion recognition algorithms.  The new corpus will facilitate the study of multimodal fusion from audio, video, geometric, thermal, and physical responses.  It will contribute to the development of a comprehensive understanding of mechanisms involving human behavior, and will allow enhancements to human computer interaction (e.g., through emotion-sensitive and socially intelligent interfaces), robotics, artificial intelligence, and cognitive science.  The work will likely also significantly impact research in diverse other fields such as psychology, biometrics, medicine/life science, law-enforcement, education, entrainment, and social science."
1247778,"Collaborative Research: Design, Analysis and Implementation of Social Interactions in Cognitive Radio Networks",CNS,SPECIAL PROJECTS - CISE,10/1/2012,9/12/2012,Robert Qiu,"Qiu, R","Qiu, R",TN,Tennessee Technological University,Standard Grant,Monisha Ghosh,9/30/2017,"$110,000.00 ",,rqiu@tntech.edu,Dixie Avenue,Cookeville,TN,385050001,9313723374,CSE,1714,"7976, 9150",$0.00 ,normalFunding,"Cognitive radio is an efficient approach to access frequency spectrum. The performance of cognitive radio networks is substantially determined by the information on spectrum occupancies. Experiments have demonstrated the temporal and spatial correlations of spectrum availability, which is of key importance in the design and analysis of cognitive radio networks. Motivated by the observation, this research studies the social interaction mechanism for secondary users to fully exploit the correlations. A recommendation mechanism is useful for secondary users to share correlated information about the spectrum. Collaborative filtering can enhance the capability of better learning the spectrum situations. For better understand and assist the design, analysis is conducted for the social interaction mechanism, based on powerful tools in social networks, such as master equation, mean filed dynamics and epidemic propagation. Continuum model, such as partial differential equations for diffusions, is also employed as the limit case of discrete cognitive radio networks. Beacon based and packet based mechanisms are used for the recommendation protocols. A 100-node hardware cognitive radio network testbed is built to demonstrate the proposed mechanisms, algorithms and protocols. The research involves aspects of wireless communications, networking, artificial intelligence and physics; thus the inter-disciplinary essence of the research also lends itself to cross-disciplinary education. New courses are devised, which involve the topics of cognitive radio networks, machine learning and image processing. This project also attracts traditionally underrepresented groups, as well as outreach high school students."
738341,"""Exploring the Feasibility of a Virtual Video Archive""",IIS,ROBUST INTELLIGENCE,9/15/2007,8/21/2008,Bruce Buchanan,"Buchanan, B","Buchanan, B",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,2/28/2009,"$108,840.00 ",,buchanan@cs.pitt.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9218, 9237, HPCC",$0.00 ,normalFunding,"Proposal 0738341<br/>""Exploring the Feasibility of a Virtual Video Archive""<br/>PI: Bruce G. Buchanan<br/>AAAI<br/><br/><br/>ABSTRACT<br/><br/>Many early demonstrations of Artificial Intelligence (AI) programs and many lectures of the field's pioneers explaining basic AI topics have been captured on videotape and film, but few of these have been preserved in archival form or have been accessible from a common web portal. This historical record is threatened and vulnerable to loss as time passes because of format incompatibility and deterioration of original materials. For videos that have already been digitized, much work is needed to index and edit materials, so that they are useful to students, teachers, and the public at large, and that the relevant materials can be accessed with much more ease than is the case today, where materials, even if available on the web, are not catalogued or organized in a coherent manner. <br/><br/>This project will explore the feasibility of a low-cost plan to collect and preserve the video record of significant scientific events in the history of AI. Information will be collected in a ""virtual archive"" that will contain original tapes and movies critical to the intellectual history of the field. It will be integrated with the current AAAI AITopics portal, which at present contains information on central AI topics (e.g., machine learning, knowledge representation, speech, robotics). AITopics will be re-designed so that both the new video pages and the existing document pages have the same look-and-feel. The project will exploit the 'wiki' model of knowledge sharing to collect information about AI-related videos and to move original videotapes and movies from the hands of individuals into long-term archival storage. In doing so, the project will develop a set of procedures for preservation, and for the growth and use of the website by the community of AI scientists and students.<br/><br/>"
311549,Using Robots to Enhance An Undergraduate Liberal Arts Computer Science Curriculum with Open-Lab Projects,DUE,"CCLI-ADAPTATION AND IMPLEMENTA, CCLI-Type 1 (Exploratory)",6/1/2003,5/25/2006,Amruth Kumar,"Kumar, A","Kumar, A",NJ,Ramapo College of New Jersey,Standard Grant,Mark James Burge,12/31/2006,"$107,223.00 ",,amruth@ramapo.edu,505 Ramapo Valley Road,Mahwah,NJ,74301623,2016847500,EHR,"7428, 7494","7428, 9178, SMET",$0.00 ,normalFunding,"Computer Science (31) This project uses robots in an undergraduate liberal arts computer science curriculum to enhance two courses: Artificial Intelligence (AI) and Advanced Topics. Work done by other educators on using robots in the Artificial Intelligence course are adapted and extended in two ways: 1) learning objective for the use of robots is based on high-level knowledge-based AI algorithms rather than low-level reactive algorithms, and the impact of robot construction on liberal arts students is minimized; and 2) robots are incorporated into the existing AI course rather than by creating a separate course on robotics. This minimizes the impact of using robots on faculty resources at smaller liberal arts Computer Science departments. Finally, robots are used for open-lab projects thereby minimizing the impact of using robots on the credit requirements for the major, while at the same time, providing students with a greater opportunity to be creative in their solutions. This project adapts the work done earlier in incorporating robots into the AI curriculum at St. Bonaventure University, Bryn Mawr College, and Swarthmore College."
9525127,Intelligent Decision Making and System Development for Comprehensive Waste Minimization in the Electroplating Industry,CBET,"Proc Sys, Reac Eng & Mol Therm",9/15/1995,9/12/1995,Yinlun Huang,"Huang, Y","Huang, Y",MI,Wayne State University,Standard Grant,Geoffrey Prentice,8/31/1998,"$105,668.00 ",,yhuang@wayne.edu,5057 Woodward,Detroit,MI,482023622,3135772424,ENG,1403,"1099, 1403, 9197, EGCH",$0.00 ,normalFunding,"Abstract - Huang - 9525127 The manufacturing of precious metal products usually involves electroplating. There are over 3,000 electroplating plants in the U.S. which utilize more than 100 chemicals to electroplate parts with any one or a combination of over 100 different metal coatings. This has given rise to the generation of large volumes of waste streams. Techniques for waste minimization (WM) have been developed, but they have not permeated the plants, partly because they have not been well classified and compared in terms of cost and efficiency. Also, implementation of these methodologies and techniques requires various kinds of experience in order to achieve not only WM efficiency, but also the lowest cost and the highest productivity. The PIs plan to use artificial intelligence techniques to realize comprehensive WM. A knowledge base for source reduction, in-process recycling, and source waste (pre)treatment will be developed. Two decision making algorithms are planned for optimizing the use of both first-principles and heuristic knowledge residing in the knowledge base. The ultimate goal of this project is to develop an intelligent decision support system for WM in the plating plants of any size. The system will perform at an expert level and will be a tool with which the plating industry can improve WM practice with the lowest possible cost. It is expected that the source reduction part of the system will help electroplaters evaluate current WM levels and identify new opportunities for further waste reduction in various types of plating processes. The source wastewater treatment (with in-process recycling) part of the system will provide decisions on selecting the most efficient and cost-effective (pre) treatment processes. Reductions of about 10 percent of wastewater and sludges will be targeted. This system is expected to be initially tested by 50 selected plants over the project period, and eventually to be introduced into the plating industry, with arrangements by the AESF Society and technical help from Hughes Research Laboratories."
9952819,"Solving the Distance Learning Problem Through ""Super-Teaching""",DUE,CCLI-EDUCATIONAL MATERIALS DEV,5/15/2000,5/10/2000,Selmer Bringsjord,"Bringsjord, S","Bringsjord, S|Noel, R",NY,Rensselaer Polytechnic Institute,Standard Grant,Myles G. Boylan,6/30/2002,"$105,619.00 ",Ronald Noel,selmer@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,EHR,7427,"7427, SMET, 9178",$0.00 ,normalFunding,"Interdisciplinary (99) Distance learning is exploding in popularity. But is such learning ""as good as"" traditional learning? How, exactly, is it different than traditional learning? And is it possible that intensely interactive courses (via, e.g., such pedagogical techniques as the Socratic method and hands-on robotics) can be successfully rendered in the distance mode? There are still no answers to this important question. One reason is that much research on this subject has been flawed in certain specific ways -- ways recently summarized in ""What's the Difference? A Review of Contemporary Research on the Effectiveness of Distance Learning in Higher Education (Institute for Higher Education Policy for the American Federation of Teachers and the National Education Association, 1999). This project is testing the feasibility of a solution that comes in (at least) two parts: (1) The first part is to harness a quartet of advanced information technologies -- ""2D"" virtual reality, avatars, artificial agents, and high-bandwidth networks -- to turn the tables on the problem by enabling what we call ""super-teaching,"" which allows distance education to have the tried-and-true distinguishing features of quality classroom education. The ""human factor"" is absent in today's distance education (or at least severely minimized). Super-teaching is devoted to giving distance learning the same intimate feel as traditional face-to-face instruction. (2) Carry out three experiments, one for each of three courses (1. Introduction to Logic; 2 Philosophy of Artificial Intelligence; 3 Introduction to Cognitive Robotics). Each experiment is a controlled one covering a substantial part of each course. (Subjects are being assigned on the basis of aptitude and skill in the relevant domains, and the PIs are examining both performance on post-tests and satisfaction (as expressed in surveys).) While these three courses share an intellectual foundation (logic and computation), they are nonetheless fundamentally different in promising ways. The first course is a large-enrollment course that does not put a premium on face-to-face interaction between student and instructor; and the course seeks to cultivate a very specific skill: proof construction. The second course, Philosophy of AI, is a traditional philosophy course centered around the Socratic method; this course is perhaps as interactive as a course can get. The emphasis in this course is on cogent argumentation in clear English. The third course is also interactive, but in a different way: students and instructor work together around physical objects (sensors, effectors, logic controllers, etc.). The objective is to determine whether or not first-rate distance learning can take place for courses as intensely interactive as the second and third. We hypothesize that our results will show super-teaching to be nearly as effective as intensely interactive face-to-face instruction on our campus. The final part of the solution would involve generalizing and sharing super-teaching with others in the United States, but a plan for doing so would be part of a full scale development effort that lies in the future."
98270,Collaborative Research on Semantic Unification and its Applications,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT",8/15/2001,9/8/2004,Christopher Lynch,"Lynch, C","Lynch, C",NY,Clarkson University,Standard Grant,Robert B Grafton,7/31/2005,"$103,147.00 ",,clynch@clarkson.edu,8 Clarkson Avenue,Potsdam,NY,136761401,3152686475,CSE,2865,"9216, HPCC",$0.00 ,normalFunding,"Propoal #0098270<br/>Clarkson University<br/>Lynch, Christopher<br/><br/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br/><br/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br/><br/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br/><br/>This award is one of three in a collaborative research team. The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany)."
845230,CAREER:  Telling the Story of a Visual World: Event Classification and Integrated Image Understanding,IIS,ROBUST INTELLIGENCE,7/15/2009,7/2/2009,Fei-Fei Li,"Li, FF","Li, FF",NJ,Princeton University,Continuing grant,Jie Yang,2/28/2010,"$102,338.00 ",,feifeili@cs.stanford.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,7495,"1045, 1187, 9102, 9215, HPCC",$0.00 ,normalFunding,"The ability to make meaning out of a visual world, such as recognizing objects, scenes and semantically meaningful activities and events, is a cornerstone of artificial intelligence. In computer vision, very important progress has been made recently in object and scene level recognition. But such tasks are often performed without an integrated and coherent description of the scene. Moreover, very few current algorithms are capable of further interpreting higher level semantic meanings of an image such as an event or activity. The goal of this project is to achieve event classification via an integrated image understanding given a single unknown image.<br/>This project aims to push the frontier of integrated and descriptive understanding of images through the development of sophisticated learning frameworks suitable for training algorithms by using a large amount of real-world data such as the ones from the Internet. High accuracy performance, minimal human supervision, flexibility and scalable learning will be the focus of this endeavor.  This project?s theoretical framework ties together several areas of computer vision, offers interesting model representations for the machine learning field, and connects more semantically driven visual recognition problem with the natural language processing field. <br/>The results are vital for image understanding technology for the visually- impaired; automatic annotation of images for large digital library as well as the next generation of image retrieval engines; and translation, education and rehabilitation technology for language students and medical patients (such as aphasia, stroke, etc.). <br/>The project?s long-term educational plan focuses on bringing the latest visual computation and cognition research directly into the classroom and the community at large, with an emphasis on reaching the underrepresented groups of students. <br/>"
232223,SBIR Phase I: Artificial Intelligence Software for Student Assessment in Chemistry Education,IIP,RESEARCH ON LEARNING & EDUCATI,1/1/2003,11/22/2002,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Sara B. Nerlove,6/30/2003,"$100,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,1666,"9177, 9178, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research Phase I project focuses on the development of meaningful interactive tutoring and assessment capabilities for chemistry tutorial software. Although there has been a clearly articulated user demand for advancement in this area, it has been repeatedly identified as one for which existing offerings are weak. Quantum Simulations a new and different approach, adapting and incorporating new concepts from artificial intelligence (AI). More than just assigning a grade, meaningful opportunities will be created for students to learn directly from the assessment itself. The proposed technology will benefit all students. The technology, however, is specifically targeted to help those who have the greatest need--such as students of average or marginal performance and students from historically underrepresented groups--by lowering barriers to accessing high-quality science instructional software. The firm has established a partnership with an NSF-funded systemic reform initiative to further these goals.<br/> The customers for the proffered technology include textbook publishers, software providers, hardware vendors and distance learning companies. Quantum has entered into a long-term contract with a prominent textbook publishe, Holt, Rinehart and Winston, to commercialize this technology. This arrangement will result in rapid dissemination to an established end user base."
9726836,SGER:  Toward a Better Understanding of Engineering Design  Models,CMMI,ENGINEERING DESIGN AND INNOVAT,9/1/1997,8/15/1997,Yan Jin,"Jin, Y","Jin, Y|Wang, C|Lu, SCY",CA,University of Southern California,Standard Grant,george hazelrigg,8/31/1999,"$100,000.00 ","Chunming Wang, Stephen C-Y. Lu",yjin@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,ENG,1464,"9148, 9237, MANU",$0.00 ,normalFunding,"    This research project seeks to contribute to the scientific foundation of engineering design by developing a conceptual framework that can be used to study, correlate and compare existing engineering design models, which may obtain from widely different perspectives.  The resulting framework will consist of a design concept interchange language with rigorous mathematical evaluations.  This interchange language will be used to explain the rationales and correlate the concepts used in different models.  The mathematical evaluations will be used to explicate underlying assumptions of various design models and to evaluate their validity and limitations.  Six to ten engineering design models will be selected from engineering, decision theory, and artificial intelligence fields for this research.  The framework will be developed based on the critical review of these selected design models.  An interdisciplinary research team, including engineers, mathematicians, and decision theorists, is assembled to develop this framework for engineering design models.       Design is the essence of engineering profession; and engineering design has been a topic for researchers from different disciplines.  Some of them are from various engineering disciplines, others from decision theory or artificial intelligence fields.  Although a number of engineering design models have been proposed to date, little cross reference exists in these models and communication among the researcher has been difficult.  It is commonly recognized that the lack of communication among researchers has become a major obstacle for the progress of engineering design research.  If successful, the results of this research project will provide a common language and framework for engineering design researchers to share their insights and results in order to identify gaps between the models and directions for the future research."
637069,SGER:  Concepts in Context: Representations for Recognition,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/15/2006,7/11/2006,Manuela Veloso,"Veloso, M","Veloso, M",PA,Carnegie-Mellon University,Standard Grant,Douglas H. Fisher,6/30/2007,"$100,000.00 ",,veloso@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,6856,"7632, 9216, 9237, HPCC",$0.00 ,normalFunding,"ABSTRACT<br/><br/>This project seeks to investigate fundamental questions about how to define and represent concepts, particularly in contexts where robots need to identify and use objects. This project focuses on representations that result from observations about object usage. The underlying assumption is that usage reveals fundamental information about the nature of objects. The fundamental question to be addressed in this project is: How can concepts be defined in terms of multiple representations for the purpose of effective recognition? This project will investigate how context and usage can allow recognition that might not be possible when an object is observed in isolation, and how the enormous variation in the visual appearance of objects can be accounted for through combination of functional definitions and simple visual descriptions. The project is organized around three tasks: (1) investigation of multi-faceted knowledge representation techniques that include exemplar-based and usage-based representations, and the use of weighted (probabilistic) representations; (2) multi-representation recognition algorithms that allow for probabilistic balancing of evidence and weighted representations and the combining of exemplar-based and non-exemplar-based representations; and (3) parameter and structure learning that allows adaptation of weights used in concept representations and definitions. The project will use mobile robots equipped with various sensors as a test bed. In addition to its own sensory input, the robot will use observations of humans interacting with objects in its environment. The project will build on the PIs ongoing work on object definition and recognition techniques that use visual features and functional representations. This project has potential Broader Impact not only on robotics and artificial intelligence but also on cognitive science and psychology in general.<br/>"
9860581,SBIR Phase I: Automated Performance Assessment Tools,IIP,INSTRUCTIONAL MATERIALS DEVELP,1/1/1999,12/2/1998,John Leddo,"Leddo, J","Leddo, J",VA,Research Development Corporation,Standard Grant,Sara B. Nerlove,6/30/1999,"$100,000.00 ",,jleddo@rdc.dgsys.com,2875 Towerview Road Suite A4,Herndon,VA,220713205,7039041808,ENG,7355,"9177, SMET, 9145, 5371",$0.00 ,normalFunding,"9860581<br/> New educational reforms calling for challenging standards that emphasize real world problem solving skills have caused a paradigm shift in assessment to more authentic forms that support measurement of these skills. Within the authentic assessment movement, an important thrust is performance assessment; namely assessment based on students performing realistic tasks. This Small Business Innovation Research Phase I project from Research Development Corporation seeks to develop an automated system for presenting and scoring performance tasks. The system will use artificial intelligence as a means to make scoring more timely, cost effective, and reliable. Research Development Corporation proposes that the problems of labor intensiveness, costs, and inconsistencies across an inherently subjective rating process in scoring large scale assessments can be addressed by creating performance tasks within a simulated problem environment and using intelligent tutoring system and assessment technologies to automatically assess the students. Specifically, the project will generate an automated performance assessment system for high school science using simulated science experiments as performance tasks, and it will evaluate the reliability of the technology by comparing ratings made by the technology to ratings made by trained teachers using the same scoring rubrics.<br/> Research Development Corporation proposes an innovative automated tool for the rapid assessment of students that has potential for a significant impact on student assessment, the learning process, and on the way science is taught. Being able to easily measure gains in the applications and synthesis of knowledge is crucial to promoting the value of higher level thinking and application of content in our Nation's schools."
757490,Collaborative Research:   Pilot Research on Language-Based Strategies for Creative Problem Solving,IIS,CreativeIT,7/1/2008,6/25/2008,Michael Littman,"Littman, M","Littman, M",NJ,Rutgers University New Brunswick,Standard Grant,Pamela L. Jennings,6/30/2010,"$100,000.00 ",,mlittman@cs.brown.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7788,"9215, HPCC",$0.00 ,normalFunding,"When people reformulate a problem space, previously unseen structure emerges. This process can be decomposed into two steps: People must first recognize and then exploit novel structure. We suggest that both of these steps can be improved by experienced application of creative nominalization. Here, nominalization refers to the process of recognizing a novel concept and naming it appropriately. This project demonstrates that experience in nominalization can improve problem solving and that successful training and experience on nominalization has the potential to enhance people?s intrinsic motivation, and thereby effectiveness, with respect to creative aspects of problem solving. In parallel, the project explores the potential for nominalization as a strategy to enhance machine-learning agents in reinforcement learning environments. Inspired by research on animal learning, reinforcement learning is a branch of artificial intelligence research concerned with creating motivated, learning agents. In the reinforcement-learning setting, nominalization has the potential to create a first-class object, something that can be directly manipulated, recorded, analyzed, and composed with other objects to form higher-order structures. In addition, reinforcement-learning researchers have recently begun to consider how learning might be enhanced with intrinsic motivation to explore problem spaces. Thus nominalization can function in reinforcement-learning settings both as a direct strategy and indirectly via intrinsic motivation. The most significant broader impact of this project will be to provide a new intervention that will enhance the creativity and efficacy of problem solvers working alone or in collaborative groups. If successful, the relative simplicity of the intervention and its general applicability would make it a prime candidate for wide dispersal to people in disparate walks of like."
549663,SGER:  Mapping Nanotechnology Development Based on the ISI Literature-Citation Database,CMMI,SPECIAL STUDIES AND ANALYSES,9/15/2005,9/9/2005,Hsinchun Chen,"Chen, H","Chen, H",AZ,University of Arizona,Standard Grant,Charalabos C. Doumanidis,8/31/2006,"$100,000.00 ",,hchen@eller.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,ENG,1385,"9146, 9237, MANU",$0.00 ,normalFunding,"The proposed research plans to assess and map the development of NSE through the analysis of published papers indexed in the Thompson ISI literature-citation database. The effort will plan to conduct bibliographic analysis on NSE-related papers and citations. In addition the effort plans to analyze the impact of NSF funding on NSE research from the perspective of paper publication. Finally the effort plans to identify and visualize the themes covered by the NSE literature. <br/>Intellectual merit:  The U.S. government has an explicit interest in monitoring global development of NSE both to ensure that adequate funding is being provided by sponsors to ensure U.S. preeminence in this field, and that industry investment is also kept competitive Monitoring global development means understanding the impact of the funding in the field, and examining as well the research and development status in  industry and academic institutions. NSE patents and literatures are informative in representing NSE development. The University of Arizona Artificial Intelligence Lab has already achieved a successful research record in conducting analyses of NSE developments, developed several tools suitable for the proposed project, accumulated extensive implementation experience, and attained fruitful results in using citation analysis and other techniques to address the problem of understanding NSE development.<br/>Broader impact:  Research results will be reported to the National Science Foundation for use in making decisions about future NSF programs and funding.  Results will also be published in diverse media (e.g., journal papers, conference proceedings, and websites) to reach as broad an audience as possible in industry and academia. Finally, this project will provide numerous opportunities for training Ph.D. and Master's students in the areas of citation analysis, text mining, visualization, and statistical hypothesis testing. <br/>"
60379,SBIR Phase I: Advanced Software for Interactive Chemistry Tutoring,IIP,RESEARCH ON LEARNING & EDUCATI,1/1/2001,12/1/2000,Benny Johnson,"Johnson, B","Johnson, B",PA,Quantum Simulations Incorporated,Standard Grant,Sara B. Nerlove,6/30/2001,"$100,000.00 ",,johnson@quantumsimulations.com,5275 SARDIS RD,MURRYSVILLE,PA,156689536,7247338603,ENG,1666,"9177, 9178, SMET",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project is aimed at advancing the state-of-the-art in chemistry education software in a critically important respect demanded by students and teachers. The primary research objective is the development of meaningful interactive tutoring capabilities for problem solving. This area has been repeatedly identified as that where existing offerings are weakest. This project offers a new and different approach, adapting and incorporating certain concepts from artificial intelligence that have not previously been applied in chemistry education. A program will be constructed that not only solves problems, but also can explain its work to the student coherently and respond to various questions. The program will dynamically create detailed explanations of worked-out solutions for problems entered by the student or teacher, and provide the connections to the underlying fundamental chemical concepts. This technology will be implemented as a sophisticated tutoring ""engine"" that can be easily interfaced to add interactive tutoring capabilities to any existing educational program or curriculum, such as those dealing with practical real-world applications of chemistry.<br/><br/>The chemistry education software has broad commercial implications, creating opportunities for tremendous synergy in use with other packages and curricula. In addition, the improvement to be developed is of a fundamental nature, is portable and scalable, and can be deployed equally well on CD-ROM, on the desktop, or on the Internet."
9552411,"An Interactive, Animation-Based Laboratory for Computer Science",DUE,UNDERGRAD INSTRM & LAB IMPROVE,6/1/1995,4/18/1995,Gary Harkin,"Harkin, G","Harkin, G|Ross, R|Starkey, D",MT,Montana State University,Standard Grant,Theodore J. Sjoerdsma,5/31/1998,"$100,000.00 ","Rockford Ross, Denbigh Starkey",harkin@cs.montana.edu,309 MONTANA HALL,BOZEMAN,MT,597172470,4069942381,EHR,7400,"9178, 9267, SMET",$0.00 ,normalFunding,"This project provides the Computer Science Department with the funds to equip laboratory rooms with modern computing equipment essential for carrying out experiments and exercises in computer science. The Department has implemented an innovative set of laboratory courses that span the undergraduate curriculum. The cornerstone of this set of laboratory courses is a unique, breadth-first sequence of four courses required of all majors, minors, and preservice teachers of computer science, entitled CS I-IV. This sequence incorporateq all of the traditional lower- division topics in advanced programming, data structures, algorithms, and discrete math--along with a strong ethics component and introductions to the major subject areas of computer science (artificial intelligence, compilers, networks, operating systems, and so forth)--into a seamless presentation. The laboratory sections accompanying CS I-IV allow students to explore and experiment with these topics in weekly 2-hour meetings. An innovative program animation system (DYNALAB) has been developed locally with NSF funds in support of these labs; algorithm and concept animators from other sources are also being incorporated. Students in upper-division undergraduate laboratory courses use professional software and hardware tools for their experiments."
60306,STTR Phase I: IntelliStitch AI: Intelligent Computerized Embroidery Design Automation for the Textile Industry,IIP,STTR PHASE I,1/1/2001,5/8/2002,David Goldman,"Goldman, D","Goldman, D",NY,"Soft Sight, Inc.",Standard Grant,Rathindra DasGupta,5/31/2002,"$99,999.00 ",,dgoldman@softsightinc.com,3105 KNAPP RD,VESTAL,NY,138503038,6077974073,ENG,1505,"5514, 9147, MANU",$0.00 ,normalFunding,"This Small Business Technology Transfer Research (STTR) Phase I project builds upon the technology and success of the company's software product, one of the industry's first embroidery design automation systems. It provides the textile industry with simplified mechanisms for converting scanned artwork into high quality embroidery design data. This data is then utilized by commercial sewing equipment to produce the embroidered artwork that has become quite common on all types of garments and woven goods. Unfortunately, embroidered artwork is often quite expensive to produce. In many cases, it may substantially exceed the costs of the actual garments being imprinted. These costs arise from a variety of factors including an embroidered design's size, layout, and complexity. Well-designed embroidered artwork permits efficient production with high yields (i.e. causing very few defective items to be produced). Automating this design creation process provides additional benefits by eliminating the time consuming manual process that must otherwise be undertaken by a human expert. With these factors as the primary motivation, this research will investigate advanced artificial intelligence and machine vision mechanisms, such as neural nets and structural indexes, to substantially improve capabilities and performance. <br/><br/>The advantages of a robust automation system to the textile industry are quite substantial. Creating sophisticated embroidery designs is a tedious, time-consuming activity requiring the skills of a human expert (called a digitizer). Even after this process has been completed, any miscalculations by the digitizer could substantially impede production on machinery. A well-designed expert system could inevitably eliminate these costs and perhaps even provide a level of quality that is not achievable by its human counterparts. Additionally, this research may also have broad application within other fields such as document processing or other areas where image understanding and interpretation is important."
9861247,SBIR Phase I: A New Approach to Solving the Shortest Path Problem,IIP,SMALL BUSINESS PHASE I,1/1/1999,11/16/1998,Chujen Lin,"Lin, C","Lin, C",MD,"Intelligent Automation, Inc",Standard Grant,Michael F. Crowley,6/30/1999,"$99,998.00 ",,chujen@i-a-i.com,15400 CALHOUN DR 190,ROCKVILLE,MD,208552737,3012945221,ENG,5371,"9139, HPCC",$0.00 ,normalFunding,"9861247<br/> This Small Business Innovation Research Phase I project details an analog parallel distributed (APD) solution to the shortest path-problem, the time complexity of which depends on the required accuracy of the solution. The algorithm is based on Bellman's formulation of the SPP. Rather than implementing a classic gradient descent in our system as is typical, a new energy minimization technique was developed. The resulting modified gradient descent has the important benefit of not stabilizing at local minima. It also permits a straightforward distributed VLSI implementation which with the currently available technology is expected to have a peak accuracy within 0.5% and time constant of a fraction of a microsecond. A powerful decomposition technique has already been devised and used to characterize the dynamic behavior of the system.<br/> Applications of the algorithm involve analog routing assessment or routing control and search problems in chip-level artificial intelligence. The decomposition method may be useful in analyzing the APD paradigm for other combinatorial problems on graphs."
829959,Approximating Network Design Problems on Directed and Undirected Graphs,CCF,THEORY OF COMPUTING,2/1/2009,7/21/2008,Guy Kortsarz,"Kortsarz, G","Kortsarz, G",NJ,Rutgers University Camden,Standard Grant,Balasubramanian Kalyanasundaram,1/31/2012,"$99,997.00 ",,guyk@crab.rutgers.edu,311 N. 5th Street,Camden,NJ,81021400,8562252949,CSE,2860,"9218, HPCC",$0.00 ,normalFunding,"Problems that require communication between among users abound in modern life. Such problems present a collection of users and all possible links among all pairs of users, each link carrying a cost. The links can be directed or undirected (in the undirected case both parties can exchange information along the link). The goal is to select a minimum cost collection of links under some communication constraints.  The simplest example of such problem is that every user will be able to send a message to every other user perhaps via a series of links.  One of the main goals of this proposal is to understand some of the most fundamental network design problems on directed networks whose exact approximability status remains unclear for a very long time.  Directed networks appear frequently when modeling the problem by an undirected network is not enough. Applications for which the networks arising are naturally directed include web related problems, problems in social networks, problems on dynamic (namely changing) links in artificial intelligence and more. A crucial example is the directed Steiner problem that is to connect a set of given terminals (stations, users) to a given root (central command) by directed links at low cost. The intellectual merit of the proposal includes expanding our understanding of the power of approximation algorithms and their limitations. In a more broader context, the project will include the creation of a new graduate course on approximation algorithms in the Computer Science department at Rutgers University, Camden. Students taking the course will be encouraged to undertake research work in this subject, or alternatively, work on a large practical project that will compare the theoretical performance guarantees of approximation algorithms versus their performance in practice."
60377,SBIR Phase I: An Intelligent Qualitative Coding Program,IIP,SMALL BUSINESS PHASE I,1/1/2001,6/5/2001,Brent Myer,"Myer, B","Myer, B",MO,Idea Works Inc,Standard Grant,Sara B. Nerlove,6/30/2001,"$99,992.00 ",,bmyer@ideaworks.com,100 West Briarwood,Columbia,MO,652031678,5734454554,ENG,5371,"9215, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project from Idea Works, Inc. tests the feasibility of using intelligent programming strategies to improve the quality, timeliness, and cost effectiveness of qualitative research. A prototype computer program for qualitative data analysis, currently in initial stages of development, will be further developed and assessed. This program uses artificial intelligence strategies of natural language understanding, machine learning, rule-based expert systems, semantic networks, and case-based reasoning to actively assist researchers in coding data. Two related experiments will compare experienced and inexperienced coders performing with and performing without the aid of the program in order to assess the program's ability to help in coding, to enhance reliability and validity, and to increase the speed of coding. Ease of use and user acceptance of the program will also be examined. The program is expected to improve the quality of research while dramatically reducing cost, time, and training requirements. This will make it feasible to apply rigorous qualitative research techniques to a vast range of problems, from coding transcripts or field notes, to examining the content of Internet sites, to conducting literature reviews.<br/><br/>The program proffered by Idea Works, which marks a significant improvement over existing qualitative analysis programs by offering suggestions for code assignments to the users, has commercial potential in both research and business applications. Not only can the computer program be used to assist trained social scientists in coding a wide range of data from field notes to interviews to documents, but, because the program is not limited to any specific coding scheme, it can also be applied in areas as divergent as doctor-patient interaction, studies of man/machine interfaces, content analysis of Internet documents, and literature reviews. The project has the potential to dramatically improve the quality and cost-effectiveness of qualitative coding of a broad range of data. It has the potential for achieving cost effectiveness; not only by reducing the time required to code, but also by making it possible for less experienced coders to code with higher levels of reliability and validity."
519421,SGER: Requirements Assessment for a Multiple Robot-Multiple Human Interface,IIS,HUMAN COMPUTER INTER PROGRAM,3/15/2005,2/13/2006,Julie Adams,"Adams, J","Adams, J",TN,Vanderbilt University,Standard Grant,Ephraim P. Glinert,2/28/2007,"$99,990.00 ",,julie.a.adams@oregonstate.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,6845,"9150, 9215, HPCC, 9237",$0.00 ,normalFunding,"There exist many examples of Human-Robotic Interaction (HRI) for a single robot or a small number of robots (2-4). But HRI development for large robot teams requires novel techniques for presenting large amounts of data so as to support a human's ability to maintain situation awareness while not overloading his/her cognitive capabilities. In this project the PI will assess needs and requirements, and develop preliminary interface designs, for tools that will permit a small number of humans to supervise large robotic teams, a capability not available with current HRI methodologies. To this end, the PI will build on prior work in HCI, CSCW, and complex human-machine systems. She will interact continuously with and solicit feedback from the Metro Nashville Police Chemical, Biological, Radiological, Nuclear, and Explosive (CBRNE) search and rescue team, because a basic premise of the work is that in order to develop useful interfaces one must first understand how organizations will actually use large teams of robots, which in turn requires an understanding of how the human team currently completes their tasks (without robots), their expectations of a robotic team, and requirements for robotic team capabilities.<br/><br/>Broader Impacts: This work will advance the fields of robotics, artificial intelligence, and human factors. Specifically, it will advance the community's understanding of how large numbers of robots can be effectively supervised, managed, and guided by a small number of human operators, thus affording more usable systems while reducing the associated manpower and exposure to potentially dangerous contaminants. Due to the project's focus on deploying robots for CBRNE attacks, the results will have broad affects on developing deployable robotic systems based upon user feedback to meet ever-increasing Homeland Security needs."
1744356,Workshop: Understanding Emerging Technologies and the Future of Work,BCS,"SOCIAL PSYCHOLOGY, IUSE, SCIENCE, TECH & SOCIETY",9/1/2017,8/31/2017,Laurel Smith-Doerr,"Smith-Doerr, L","Smith-Doerr, L|Branch, E|Zilberstein, S|Roberts, S|Renski, H",MA,University of Massachusetts Amherst,Standard Grant,Steven Breckler,8/31/2019,"$99,970.00 ","Enobong Branch, Shlomo Zilberstein, Shannon Roberts, Henry Renski",lsmithdoerr@soc.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,SBE,"1332, 1998, 7603",063Z,$0.00 ,normalFunding,"Intelligent, interactive, and highly networked machines are a growing part of work and the workplace.  Automation is moving from the factory floor to knowledge and service occupations.  The potential benefits of technology include increased productivity and more job opportunities.  But technology connected to work can also carry substantial social costs.  The workshop supported by this award will promote the convergence of education, social and behavioral sciences, computational sciences, and engineering with stakeholders. This diverse group will define key research challenges that focus on the intersection of humans, technology, and work.  Convergence is the deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. Two workshops will address the future of work at the human-technology frontier. The workshops will focus on the challenges of shaping emergent technologies that are equitable. They will also consider how the technologies will engage a wider range of people in the workforce of the future.  The results of the workshops will include reports, communication materials, and the organization of interdisciplinary panels at professional scientific meetings.<br/><br/>The specific focus of this workshop effort is on understanding the social and technical dimensions of new technologies. The goal is to develop a research agenda that will help us understand the challenges of shaping emergent technologies in ways that result in good jobs for a wide range of U.S. workers. This includes a workshop that will bring together expert scientists to consider (1) how the changing organization of work and technology affects income inequality; (2) how decisions are made in developing artificial intelligence and processes for human-technology partnerships; (3) how to develop methods for assessing emerging technologies in terms of likely work satisfaction and inequality in employment outcomes; and (4) how workforce development and economic systems can help make high-paying stable jobs widely available. The second workshop will include stakeholders and will focus on how to use these ideas at the local level."
9761057,SBIR Phase I: Adaptive Control of Chemical Processes Based on Fourier Transform Infrared (FT-IR) Spectroscopy and Artificial Neural Networks,IIP,SMALL BUSINESS PHASE I,1/1/1998,11/18/1997,Michael Serio,"Serio, M","Serio, M",CT,"Advanced Fuel Research, Inc.",Standard Grant,Joseph E. Hennessey,6/30/1998,"$99,806.00 ",,mserio@AFRInc.com,87 Church Street,East Hartford,CT,61083720,8605289806,ENG,5371,"9153, MANU",$0.00 ,normalFunding,"*** 9761057 Serio This Small Business Innovation Research Phase I project will demonstrate the feasibility of using Fourier Transform Infrared (FT-IR) spectroscopy measurements and artificial neural networks (ANNS) for adaptive control of chemical processes. Three recent events together provide an opportunity to develop a new generation of process monitoring and control systems: 1) the availability of low cost, high speed computation with personal computers; 2) the availability of user friendly software involving artificial intelligence techniques such as neural networks; 3) the availability of rugged, compact FT-IR spectrometers. The capabilities of FT-IR spectrometers to monitor multiple components of a gas phase process stream have been demonstrated by Advanced Fuel Research, .Inc. (AFR) and other researchers in numerous field demonstrations. However, the marriage of this technology with adaptive process control software such as ANNs to produce a superior process control algorithm remains to be proven. The objective of the Phase I program is to demonstrate the proof-of-concept of this approach for a model chemical process.. The Phase II program will concentrate on refinement and generalization of the methodology so that it will work in a full-scale plant as part of a distributed control system. The successful completion of this program would result in process control methodology for maximizing conversion, selectivity and/or environmental acceptability of many common chemical processes which involve gas phase intermediates and products. This technology would provide both economic and environmental benefits to the nation, and potential installations exist at thousands of sites in the U.S. and abroad. ***"
441467,SBIR Phase I: Artificial Intelligence and Character Animation,IIP,SMALL BUSINESS PHASE I,1/1/2005,5/20/2005,Michal Hlavac,"Hlavac, M","Hlavac, M",MA,"Ingeeni Studios, Inc.",Standard Grant,Errol Arkilic,6/30/2005,"$99,750.00 ",,michal@ingeeni.com,271 Windsor Street,Cambridge,MA,21390000,6178187547,ENG,5371,"1087, 9102, 9139, 9216, HPCC",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project seeks to create a tool, a program that would allow a user to create interactive, animated character with movements and a personality. This is Artificial Intelligence for Character Animation. Until recently, artificial intelligence has resided only in laboratories, research institutions and professional game development studios. The main innovations will be in taking a system that has resided in academia, and putting that power of creating characters into the hands of every professional software developer and artist. To develop the proposed tool research must be undertaken in the following areas: Brain Architecture - networks and nodes that determine the character's brain, Brain Functionality - relationships among networks in the character's brain, and Real-Time Authoring - interactively specifying a character's personality. The tool envisions a graphical editing environment that reads in data, allows the user to modify it, and writes it out again. It reads in the "".ing"" file together with industry-standard file formats for specifying 3D models, animations, textures, sounds, etc. It allows the user to compose characters and to author their behavioral specifications through a set of Graphical User Interface (GUI) Editors. <br/><br/>The proposed tool will allow everyone from large companies to individual people to create an interactive AI-based communication means to sell products or services. The latest trend is to not sell a product, but to sell a brand, to make the consumer create an affinity with a brand and its brand icon: e.g., the Planters' Peanut, the M&Ms, the Michelin Man. Characters connect with consumers on a visceral, emotional level. This tool will allow a professional developer or artist to create a character that represents the artist and the company associated with the artist to put that character on the Internet. As Internet users clamor for increasingly compelling content, millions of jobs have been created. This innovation creates developer jobs and allows both large companies and individuals to offer their products and services in a mass communication forum."
1730146,CompCog:  Collaborative Research:  Learning Visuospatial Reasoning Skills from Experiences,BCS,Science of Learning,8/15/2017,8/16/2017,Linda Smith,"Smith, L","Smith, L",IN,Indiana University,Standard Grant,Soo-Siang Lim,7/31/2019,"$99,691.00 ",,smith4@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,SBE,004Y,059Z,$0.00 ,normalFunding,"This project uses methods from artificial intelligence (AI) to better understand how people learn visuospatial reasoning skills like mental rotation, which are a critical ingredient in the development of strong math and science abilities.  In particular, this project proposes a new approach to quantify the learning value contained in different visual experiences, using wearable cameras combined with a new AI system that learns visuospatial reasoning skills from video examples.  Results from this project will not only advance the state of the art in AI but also will enable researchers to measure how valuable different real-world visual experiences are in helping people to learn visuospatial reasoning skills.  For example, certain types of object play activities might be particularly valuable for helping a child to learn certain visuospatial reasoning skills.  Ultimately, this new measurement approach could be used to identify early signs of visuospatial reasoning difficulties in children and could also help in the design of new visuospatial training interventions to boost children?s early math and science development.<br/><br/>The core scientific question that this project aims to answer is: How are visuospatial reasoning skills learned from first-person visual experiences?  This question will be answered through computational experiments with a new AI system---the Mental Imagery Engine (MIME)---that learns visuospatial reasoning skills, like mental rotation, from video examples.  Training data will include first-person, wearable-camera videos from two different settings that are both important for human learning:  unstructured object manipulation by infants and visuospatial training interventions designed for children.  Results from experiments with the MIME AI system will advance the state of the art in both AI and the science of human learning by helping to explain how visuospatial reasoning skills can be learned from visual experiences, and, in particular, how having different kinds of visual experiences can affect the quality of a person?s learning outcomes in different ways."
757193,Collaborative Research:   Pilot Research on Language-Based Strategies for Creative Problem Solving,IIS,CreativeIT,7/1/2008,6/25/2008,Richard Gerrig,"Gerrig, R","Gerrig, R",NY,SUNY at Stony Brook,Standard Grant,Pamela L. Jennings,6/30/2010,"$99,683.00 ",,rgerrig@notes.cc.sunysb.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,CSE,7788,"7655, 9215, HPCC",$0.00 ,normalFunding,"<br/>When people reformulate a problem space, previously unseen structure emerges.  This process can be decomposed into two steps: People must first recognize and then exploit novel structure. We suggest that both of these steps can be improved by experienced application of creative nominalization.  Here, nominalization refers to the process of recognizing a novel concept and naming it appropriately.  This project demonstrates that experience in nominalization can improve problem solving and that successful training and experience on nominalization has the potential to enhance people?s intrinsic motivation, and thereby effectiveness, with respect to creative aspects of problem solving.  In parallel, the project explores the potential for nominalization as a strategy to enhance machine-learning agents in reinforcement learning environments.  Inspired by research on animal learning, reinforcement learning is a branch of artificial intelligence research concerned with creating motivated, learning agents.  In the reinforcement-learning setting, nominalization has the potential to create a first-class object, something that can be directly manipulated, recorded, analyzed, and composed with other objects to form higher-order structures.  In addition, reinforcement-learning researchers have recently begun to consider how learning might be enhanced with intrinsic motivation to explore problem spaces.  Thus nominalization can function in reinforcement-learning settings both as a direct strategy and indirectly via intrinsic motivation.   The most significant broader impact of this project will be to provide a new intervention that will enhance the creativity and efficacy of problem solvers working alone or in collaborative groups.  If successful, the relative simplicity of the intervention and its general applicability would make it a prime candidate for wide dispersal to people in disparate walks of like.  <br/><br/>"
441679,SBIR Phase I: Developing a Cost-Effective Method for Creating Cognitive Models for Cognitive Tutors,IIP,RESEARCH ON LEARNING & EDUCATI,1/1/2005,11/8/2004,Stephen Gilbert,"Gilbert, S","Gilbert, S",IA,Clearsighted,Standard Grant,Ian M. Bennett,6/30/2005,"$99,638.00 ",,stephen@clearsighted.net,Suilte 4210,Ames,IA,500104514,5152335137,ENG,1666,"9177, 9178, SMET, 1666",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project addresses the difficulties of authoring intelligent tutoring systems. Intelligent Tutoring Systems have proven to be highly effective in delivering computer-based instruction, but have historically been expensive and difficult to build, requiring specialized skill in Artificial Intelligence and production systems programming. This proposal describes a Software Development Kit (SDK) composed of four components: Cognitive Model Authoring, Problem Authoring, Tool Authoring, and Curriculum Authoring. The proposed research activity centers on the first of these components: Cognitive Model Authoring. Cognitive Model Authoring is comprised of three separate steps: defining an object hierarchy, defining the goal structure of the problem task, and representing the behavior of the instructional system. The proposal is to define an object-oriented visualization of these steps, so that non-cognitive scientists can create cognitive tutors. This tool will decrease the amount of time it takes to author the cognitive model portion of a tutor for an experienced cognitive modeler, and it also will decrease the amount of time it takes for a new person with no cognitive modeling experience to come up to speed with creating cognitive models<br/><br/>The Cognitive Tutor SDK will have two impacts: 1) easier production of new Cognitive Tutors, and hence the ability to bring them to market more quickly and 2) development of a Software Development Kit that could be independently marketed, enabling other companies to produce intelligent tutors in other domains, languages, countries and markets. There are four markets for the Cognitive Tutor SDK: internal developers, external users interested in adapting existing tutor materials for related markets (prisons, welfare-to-work programs), internal and external developers of tutors in related mathematical disciplines, and external developers of tutors in other domains. The emphasis on accountability in education provides a strong market need for effective instruction, which should help drive the desire for proven technology like Intelligent Tutoring Systems."
225774,SGER: Assisted Cognition: First Steps Towards Computer Aids for People with Alzheimer's Disease,IIS,HUMAN COMPUTER INTER PROGRAM,9/1/2002,8/26/2002,Oren Etzioni,"Etzioni, O","Etzioni, O|Kautz, H|Fox, D",WA,University of Washington,Standard Grant,Mary P. Harper,8/31/2003,"$99,513.00 ","Henry Kautz, Dieter Fox",etzioni@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,6845,"9218, 9237, HPCC",$0.00 ,normalFunding,"This small grant for exploratory research will support development of novel computer systems that will enhance the quality of life of people suffering from Alzheimer's Disease and similar cognitive disorders. Assisted Cognition systems use ubiquitous computing and artificial intelligence technology to replace some of the memory and problem-solving abilities that have been lost by an Alzheimer's patient. Assisted Cognition systems: sense aspects of an individual's location and environment, both outdoors and at home, relying on a wide range of sensors such as Global Positioning Systems (GPS), active badges, motion detectors, and other ubiquitous computing infrastructure; learn to interpret patterns of everyday behavior, and recognize signs of distress, disorientation, or confusion, using techniques from state estimation, plan recognition, and machine learning; offer help to patients through various kinds of interventions including speech and natural language processing; and alert human care-givers in case of danger.<br/><br/>Two concrete examples of the Assisted Cognition systems that will be developed are an activity compass that helps reduce spatial disorientation both inside and outside the home, and an adaptive prompter that helps patients carry out multi-step everyday tasks. This project will explore an emerging area that could be of great humanitarian, commercial, social, and scientific importance in the coming decades.<br/>"
1738065,EAGER: SC2: Intelligent spectrum collaboration via a dynamically reconfigurable radio architecture,CNS,Networking Technology and Syst,4/1/2017,3/24/2017,Tan Wong,"Wong, T","Wong, T|Shea, J",FL,University of Florida,Standard Grant,Monisha Ghosh,3/31/2019,"$99,363.00 ",John Shea,twong@ece.ufl.edu,1 UNIVERSITY OF FLORIDA,GAINESVILLE,FL,326112002,3523923516,CSE,7363,7916,$0.00 ,normalFunding,"Current engineering practices and regulatory approaches on the use of the radio frequency (RF) spectrum are too antiquated to meet the ever<br/>surging demand on the RF spectrum. A promising new solution to tackle this spectrum scarcity problem is to equip radio networks with artificial intelligence so that they can learn and predict the RF environment, as well as be social by interacting with other radio networks, leading to more collaborative use of the RF spectrum. This project will develop a software-defined radio system that can intelligently sense and adapt to others' use of the radio spectrum and collaborate with other radio networks in sharing the common RF spectrum. The developed system will be characterized by its flexibility to quickly and agile adaptability to changes in how others are using the RF spectrum. It will be also be characterized by how it uses machine-learning techniques to both extract the most relevant information about how the RF spectrum is being used and to adapt the communication strategies based on this information.<br/><br/>A dynamically reconfigurable system architecture will be developed in this project to make most efficient use of all the available computational resources in order to support all radio and ML functionalities. This highly flexible software-defined structure takes advantage of the learned knowledge about the RF environment by adapting the physical and medium access control layers use of spectrum and coordinating this utilization through carefully designed network protocols. A machine learning system is developed to identify the key information about the evolution of the communication scenario, and autonomously learn the state of the model.  Reinforcement learning will be used to generate appropriate adaptive communication strategies based on the system state."
335353,SGER:  New Research Directions in Integrated Cognitive Architectures,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/1/2003,8/2/2004,Pat Langley,"Langley, P","Langley, P",CA,Institute for the Study of Learning and Expertise,Standard Grant,Kenneth C. Whang,7/31/2005,"$99,271.00 ",,pat.langley@sv.cmu.edu,2164 Staunton Court,Palo Alto,CA,943061438,6504943884,CSE,6856,"9218, 9237, HPCC",$0.00 ,normalFunding,"This small grant for exploratory research aims to develop an integrated architecture for intelligent behavior. Most work in this area has focused on a particular class of architectures - production systems. This work proposes a new novel cognitive architecture, Icarus, that embodies quite different principles.  The research will make basic advances in representation, utilization, and acquisition of knowledge in intelligent physical agents.  Moreover, it relies centrally on the integration of these capabilities into a unified cognitive architecture that must be general enough to operate in many domains. Such a unified framework for intelligent behavior could have a major impact on both artificial intelligence and cognitive science.<br/>"
1744386,Convergence HTF: A Workshop Shaping Research on Human-Technology Partnerships to Enhance STEM Workforce Engagement,BCS,"SOCIAL PSYCHOLOGY, INSPIRE",9/1/2017,8/23/2017,Keivan Stassun,"Stassun, K","Stassun, K|Kunda, M|Warren, Z|Tong, F|Sarkar, N",TN,Vanderbilt University,Standard Grant,Steven Breckler,8/31/2019,"$98,346.00 ","Maithilee Kunda, Zachary Warren, Frank Tong, Nilanjan Sarkar",keivan.stassun@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,SBE,"1332, 8078","060Z, 063Z, 7556",$0.00 ,normalFunding,"The landscape of jobs and work is changing rapidly, driven by the development of new technologies. Intelligent, automated machines and services are a growing part of jobs and the workplace. New technologies are enabling new forms of learning, skills assessments, and job training. The potential benefits of these technologies include increased productivity and satisfaction, and more job opportunities. The workshop supported by this award aims to harness these innovations to enhance the science, technology, engineering, and mathematics (STEM) job opportunities and workforce engagement of individuals with autism spectrum disorder (ASD), and related developmental disabilities. The workshop will promote the convergence of psychology, data science, computer science, engineering, learning science, special education, organizational behavior, and business to define key challenges and research imperatives at the nexus of humans, technology, and work. This convergence workshop will employ deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. The results of the workshop will include the identification and sharing of new research directions and tools to enhance STEM workforce engagement of individuals with ASD and related developmental disabilities. This convergence workshop addresses the future of work at the human-technology frontier.<br/><br/>The workshop will explore tools and approaches to enhance retention, engagement, and productivity in STEM jobs, and specifically to harness unique capabilities and accommodate for individual needs of individuals with ASD. The workshop will develop a convergence research agenda around four topics, including 1) human-technology partnerships to support success in K-12 STEM education, 2) tools for characterizing individual capabilities and affinities and mapping these to STEM workforce needs, 3) artificial-intelligence and visual-cognition tools for human interaction with data, and 4) technologies to accommodate for unique needs and capabilites in the workplace. These topics will integrate previously disparate disciplines and research approaches, with speakers encompassing a wide range of subject matter expertise; from engineers and technologists who are developing human-technology interfaces and devices, to psychologists who are harnessing human-technology partnerships to better understand unique human capabilities for STEM, to computer scientists who are studying and developing novel data-visualization approaches patterned on autistic visual thinking, to organizational scientists developing innovative employment models for the creation of STEM sector employment spaces and technologies that leverage and support autistic individuals in the workforce. The conclusions and recommendations from the workshop will be disseminated via a white paper, and will be used to design a research agenda to help leverage human-technology advances to maximize workforce opportunities and productivity."
1159236,IRFP: Metalanguage Identification for Interactive Language Technologies,OISE,IRFP,7/1/2013,7/25/2012,Shomir Wilson,"Wilson, S","Wilson, S",MD,Wilson                  Shomir,Fellowship,Cassandra M. Dudka,2/28/2015,"$98,100.00 ",,,,College Park,MD,207403155,,O/D,5956,"5946, 5956",$0.00 ,normalFunding,"The International Research Fellowship Program enables U.S. scientists and engineers to conduct nine to twenty-four months of research abroad. The program's awards provide opportunities for joint research, and the use of unique or complementary facilities, expertise, and experimental conditions abroad.  <br/><br/>This award will support a twenty-month research fellowship by Dr. Shomir Wilson to work with Prof. Jon Oberlander at the University of Edinburgh in Scotland and Prof. Alan Black at Carnegie Mellon University in Pittsburgh, Pennsylvania.  <br/><br/>Metalanguage is a crucial linguistic mechanism which allows us to communicate information about language itself. It is essential for many language activities, including attributing statements, explaining meaning, assigning names, clarifying assumptions, and correcting misunderstandings. The ability to understand metalanguage is a skill that humans employ frequently in conversation and assume in fellow interlocutors, regardless of context or topic. However, in spite of its centrality to linguistic communication, metalanguage has received little attention in the development of interactive language technologies, leaving such technologies unable to cope with or exploit occurrences of the phenomenon in human-computer dialog.  <br/><br/>This research is the first effort to study the use of computational methods to identify occurrences of metalanguage in informal English contexts. This project consists of three stages. The first is the creation of corpora of instances of metalanguage in informal contexts, particularly from spoken conversations and informal blog texts. The second is the detection and delineation of the phenomenon, using features of metalanguage that are peculiar to the phenomenon. Finally, the third stage is the practical evaluation of metalanguage detection and processing within the context of a spoken dialog system deployed for use by the general public.  <br/><br/>The project will fill a long-standing and consequential research gap in artificial intelligence and computational linguistics. The practical applications of spoken dialog systems - such as voice menus, car GPS voice interfaces, and accessibility software for the blind - are expanding rapidly, as improvements are made to speech recognition, natural language processing, and other technologies that support conversational interaction with computers. Studying metalanguage will remedy a missing element in the design these of dialog systems, bringing them further in-line with users' expectations and thus making them more natural to use. Moreover, this research will lead to new international collaborations between the principal investigator and the two hosts' research groups, the Institute for Language, Cognition, and Computation (ILCC) at the University of Edinburgh and the Language Technologies Institute (LTI) at Carnegie Mellon University."
427597,"Sensors: Intelligent Multi-Sensor Modeling, Identification, and Data Fusion for Automated Manufacturing",CMMI,SENSORS AND SENSING SYSTEMS,10/1/2004,11/15/2006,Devendra Garg,"Garg, D","Garg, D",NC,Duke University,Standard Grant,Shih-Chi Liu,9/30/2007,"$98,000.00 ",,dpgarg@duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,ENG,1639,"032E, 1057, 1059, 7224, 9231, 9251, CVIS, 116E, 7233",$0.00 ,normalFunding,"Intelligent Multi-Sensor Modeling, Identification, and Data Fusion for Automated Manufacturing<br/>(NSF Proposal No. 0427597)<br/>Abstract<br/><br/>The primary goal of this research effort is to develop innovative methodologies for modeling, identifying and fusing data from multiple heterogeneous information sources/sensors in a flexible manufacturing workcell environment. Major contributions resulting from this research would consist of integrating artificial intelligence techniques, such as Genetic-Neuro-Fuzzy method and Bayesian estimation, with elements of signal processing and statistical techniques such as Extended Kalman filtering, and parametric estimation methods such as Maximum Likelihood, and Expectation Maximization. This research project would focus on the following three major components: 1) precise sensor modeling which would include obtaining analytical and probabilistic models of sensors and associated noises, understanding their capabilities and limitations, 2) extracting real-time data from multiple sensors and interpreting the data on a common processing platform, and 3) developing strategies to combine the noise-free data from these sensors to remove uncertainty and to obtain accurate model of the environment the manufacturing system operates in. The innovative theories developed would be tested and validated via experiments conducted at Duke University's flexible manufacturing workcell. Since the research would emphasize the use of a variety of sensors in manufacturing processes, the manufacturing industry would be a major beneficiary."
319860,SBIR Phase I: Robotic Scrub Technician,IIP,SMALL BUSINESS PHASE I,7/1/2003,6/3/2003,Michael Treat,"Treat, M","Treat, M",NY,"ROBOTIC SURGICAL TECH, INC.",Standard Grant,Om P. Sahai,12/31/2003,"$94,875.00 ",,mt23@columbia.edu,79 Alexander Ave Suite 35-A,Bronx,NY,104544433,7184017500,ENG,5371,"9181, BIOT",$0.00 ,normalFunding,"This Small Business Innovation Research (SBIR) Phase I project proposes to develop the initial component of a cognitive structure for a robotic scrub technician in the operating room. The scrub technician will maintain a tray of instruments, handing an instrument to the surgeon when requested and retrieving the instrument when the surgeon is finished with it. The opportunity is to reduce hospital personnel costs and alleviate a critical nursing shortage problem. The problem is to provide the robot with situational awareness comparable to an experienced human scrub technician, particularly in the ability to anticipate the surgeon's next request. The objective of the project is to determine the feasibility of using artificial intelligence and statistical techniques to provide this ability. The research method will compare selected techniques for time series prediction and classification, using data sets from actual surgeries. The candidate techniques will include first to third order Markov methods, N-sequence matching, neural networks and fuzzy set based inference. The end product is expected to be a prediction engine that will enable the clinical version of the robot to perform as well or better than an experienced human scrub technician. <br/><br/>The commercial application of this project is in the area of biomedical devices and instrumentation."
549548,CAREER: Reducing Drought Hazards by Improving Drought Plans,CMMI,Geotechnical Engineering and M,6/22/2005,10/11/2005,Anne Steinemann,"Steinemann, A","Steinemann, A",WA,University of Washington,Continuing grant,Richard J. Fragaszy,9/30/2006,"$94,433.00 ",,acstein@u.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,ENG,1636,"1039, 1045, 1057, 1576, CVIS",$0.00 ,normalFunding,"This career project deals with drought, one of the most complex and costly of all natural disasters.  However, recent research found that drought plans often suffer from deficiencies that limit their value in actual droughts.  Drought plans may fail to incorporate valuable expertise and experience from previous droughts.  In addition, agencies lack readily accessible methods to test and improve their plans.  Because agencies' plans may be inadequate, metropolitan regions may unwittingly be susceptible to disasters.<br/><br/>This research project addresses two key needs for development of drought plans:  to improve drought plans before a drought occurs, and to tap existing expertise on drought water management.  The research will generate new knowledge and methods for the development and evaluation of drought plans, using a knowledge-based engineering approach.  This approach applies artificial intelligence techniques to acquire, formalize, and disseminate expert heuristics within an integrated decision-support system.<br/><br/>The research objectives are to: (1) investigate the factors that reduce drought hazards; (2) design a framework for developing and evaluating drought contingency plans, using knowledge-based engineering methods; (3) test drought plans, using expert heuristics and drought scenarios; and (4) develop an integrated knowledge-based system to help agencies prepare and improve their drought plans.  <br/><br/>This integrated CAREER plan will also address deficiencies in water resources education.<br/><br/>The educational objectives are to: (1) provide students experience with real-world water resources problems in which they work directly with agencies and stakeholders; (2) develop and implement problem-based learning exercises that enable students to develop reasoning skills for active, lifelong learning; (3) use information technologies, including knowledge-based systems, in educational and professional settings; and (4) provide students opportunities to contribute both to the advancement of research and to the solution of problems in their community.  An interdisciplinary degree program will be developed to establish internships with industries and agencies, and engage students in research and K-12 outreach programs that link scientists and educators from over 5,000 schools in 65 countries.  This educational plan will help to meet the growing need for engineers and water resources professionals who can work and communicate effectively when faced with complex, multidisciplinary problems that affect both the public and private sectors.<br/>"
527534,Collaborative Research: Traffic Congestion: Actions and Reactions,BCS,HSD - DYNAMICS OF HUMAN BEHAVI,9/1/2005,9/14/2005,Laura Razzolini,"Razzolini, L","Razzolini, L",VA,Virginia Commonwealth University,Standard Grant,Amber L. Story,8/31/2010,"$91,992.00 ",,lrazzolini@cba.ua.edu,P.O. Box 980568,RICHMOND,VA,232980568,8048286772,SBE,7319,"0000, 7319, OTHR",$0.00 ,normalFunding,"This interdisciplinary research focuses on the effects of traffic congestion, and on evaluating alternative investments to manage the demand for transport services, as well as the social and behavioral impact of these investments. Today traffic flows continue to rapidly outpace resources available to society for improving the transportation infrastructure, and better management of existing facilities would be a cost effective way for resolving the problem.  Since congestion depends on the policies chosen by the traffic authorities, and on the social interaction of individuals as drivers and passengers, analyzing congestion requires an integrated approach that allows for different viewpoints: the transportation agencies', the consumers', as well as the perspective of society as a whole.  The primary objective of this research is to find an optimal mix of strategies that will spread traffic congestion over geographical space and time by better utilization of current resources, thereby reducing its costs. These strategies, such as dynamic pricing or highway reservation methods, have either been implemented in few selected areas in the United States, or have been discussed conceptually; however, their effects on travel and the urban infrastructure are not well understood. We propose to bring together tools from economics, systems engineering, and transportation engineering for a comprehensive analysis of the congestion problem. A number of concurrent objectives will be pursued in this research, which involves artificial intelligence models of users' transportation services, a set of economic experiments to evaluate different transportation policies, a model of the interaction of social networks and transportation choices, and a system dynamics analysis of transportation and social networks and their dynamic evolution. The successful completion of this research will have the potential to lead to new paradigms of traffic analysis and to a new understanding of the linkages between transportation, the urban infrastructure and ultimately the regional economy."
1107011,IJCAI 2011 Doctoral Consortium and International Experience,IIS,"COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE",2/1/2011,1/20/2011,Judith Goldsmith,"Goldsmith, J","Goldsmith, J",KY,University of Kentucky Research Foundation,Standard Grant,Jie Yang,1/31/2012,"$90,000.00 ",,goldsmit@cs.uky.edu,109 Kinkead Hall,Lexington,KY,405260001,8592579420,CSE,"7298, 7495","5914, 5979, 7484, 9150",$0.00 ,normalFunding,"The project funds two related activities for US-based graduate students: (1) attendance at the doctoral consortium at the International Joint Conference on Artificial Intelligence (IJCAI), where students discuss their research with senior members of the community, network with students from around the world, and discuss issues related to ethics in computing research; (2) extended research visits to European research groups, where students are exposed to new research paradigms and approaches within artificial intelligence and robotics, and build bridges between the European host and their own research group for long term cooperation. <br/> <br/>The goals of the project are to give students a clearer idea of what ethical dilemmas they may encounter as computer scientists; meet other students and professionals; have the opportunity to present their work to others in related research subfields; receive feedback from a senior member of their research community.   Students who participate in the extended visits also do research with a new research group and/or begin a new research project; work with European colleagues; live, albeit briefly, in a foreign country; report their work at the doctoral consortium. <br/><br/>The outcomes of the project are assessed with pre- and post-surveys administered to the students and the European hosts. Participation in the project is expected to help graduate students become members of the international community of scholars,  and develop into the global scientists that are needed for the future. These cooperations will advance science and industry in all countries."
1151951,IIS: III: Workshop on Discovery Informatics,IIS,INFO INTEGRATION & INFORMATICS,9/1/2011,8/29/2011,Yolanda Gil,"Gil, Y","Gil, Y",CA,University of Southern California,Standard Grant,Sylvia J. Spengler,8/31/2012,"$90,000.00 ",,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7364,"7364, 7556",$0.00 ,normalFunding,"The workshop aims to identify the research challenges and opportunities for transforming the scientific discovery process through advances in computing and information sciences in general, and intelligent systems in particular. It seeks to define a research agenda in Discovery Informatics. The workshop is organized around three themes: (1) efficient experimentation and discovery processes, (2) practical issues in building and refining predictive models from scientific data, and (3) social computing for science.<br/><br/>The participants include experts and visionaries in the areas of knowledge representation and inference, machine learning and data mining, experiment design and planning, information integration, computational models of discovery, collaborative technologies, robotics, social networks, visualization, and representative application (science) domains. <br/><br/>Research in Discovery Informatics is expected to integrate advances in multiple subdisciplines of artificial intelligence and cognitive science to develop the next generation informatics driven exploratory apparatus for scientific discovery. The resulting formal frameworks and computational tools have the potential to not only accelerate discovery but enable new modes of discovery by providing the tools that empower scientists to reach across disciplinary boundaries. Such tools can also contribute to enhanced modes of teaching and learning in science, technology, engineering, and mathematics (STEM) disciplines.<br/><br/>The results of the workshop (including the workshop report) will be freely disseminated to the larger scientific research and educational community."
742946,SGER:  Creativity and Computer Programming: A New Research Program,IIS,ITR-CreativeIT,9/15/2007,9/19/2007,Selmer Bringsjord,"Bringsjord, S","Bringsjord, S|Arkoudas, K",NY,Rensselaer Polytechnic Institute,Standard Grant,Pamela L. Jennings,8/31/2008,"$90,000.00 ",Konstantine Arkoudas,selmer@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,7655,"0000, 7655, 9237, OTHR",$0.00 ,normalFunding,"This project investigates human creativity as a basis for: creating computational models of such creativity; advancing the area at the intersection of artificial intelligence and software engineering known as automatic programming; and developing educational technology to better teach computer programming. The project advances computational creativity with a new theoretical model of creativity in computer programming, steps toward a significant contribution to automatic programming, and insights into better education in computer programming. The project will devise a formal theory of computer programming as a creative process. This formal theory would place clear constraints on an overarching computational theory of domain-independent human creativity. Some initial implementations and corresponding demonstrations of the formal theory will be engineered. As a precursor to the formal theory, a general architecture of programming creativity will be developed. The project will develop algorithm-sketches showing how the creativity of human programmers can by exploited to develop a new approach to automatic programming. <br/><br/>The formal models of computational creativity and automatic programming will provide guidance as to how to better train computer programmers. Students will be exposed to computational models of programming creativity that integrate deductive, inductive, and abductive reasoning. Students will also be introduced to the role of diagrammatic thinking and reasoning in visualizing data structures and transformations on such data structures during the creative/exploratory part of programming. An emphasis on creativity in the teaching of programming will entice a greater number of students to pursue computer science. <br/>"
1818643,XPS: FULL: Collaborative Research: Parallel and Distributed Circuit Programming for Structured Prediction,CCF,Exploiting Parallel&Scalabilty,10/1/2017,6/18/2018,Vivek Sarkar,"Sarkar, V","Sarkar, V",GA,Georgia Tech Research Corporation,Standard Grant,Anindya Banerjee,7/31/2019,"$88,265.00 ",,vsarkar@rice.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,8283,,$0.00 ,normalFunding,"This project develops a system for ""circuit programming,"" which allows a programmer to focus on the high-level solution to a problem rather than on the details of how the computation is organized. Circuit programming consists of writing rules that describe how data items depend on one another. The intellectual merits lie in the design of a new programming language for specifying these rules, along with the algorithms whereby the computer automatically finds efficient strategies for managing the necessary computations on available parallel hardware.  The project's broader significance and importance lie in its potential to streamline work in areas such as artificial intelligence and machine learning.  With the growing complexity of systems in these areas and their need to process big data in depth, research and teaching typically get bogged down in programming details, especially for parallel platforms; this project aims to delegate those details to automatic methods.<br/><br/>The research develops a programming system for Dyna, a circuit programming language that enables concise specification of large function graphs that may be cyclic and/or infinite. Dyna employs (1) a pattern-matching notation that augments pure Prolog with evaluation and aggregation and (2) an object-like mechanism for dynamically defining new sub-circuits as modifications of old ones.  This project is building an adaptive system that can mix forward and backward chaining to seek a fixpoint of the circuit and to update this fixpoint as the inputs change.  The system will perform compile-time and runtime analysis of the Dyna program and will map it to Habanero, a system for scheduling parallel computations on multicore processors, with extensions for task priorities, task cancellation, GPU execution, and distributed execution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
505612,Collaborative Research: Graphical and Algebraic Models for Multivariate Categorical Data,DMS,STATISTICS,7/1/2005,4/28/2005,Mathias Drton,"Drton, M","Drton, M|Richardson, T",IL,University of Chicago,Standard Grant,Gabor J. Szekely,6/30/2008,"$88,001.00 ",Thomas Richardson,md5@uw.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,MPS,1269,"0000, OTHR",$0.00 ,normalFunding,"The proposed research project develops models for multivariate categorical<br/>data by mimicking Gaussian models with a desired model structure that can<br/>be captured in terms of the non-parametric concept of conditional<br/>independence.  This method has a long history: graphical log-linear models<br/>can be induced in this way by Gaussian models defined by zero constraints<br/>on the inverse covariance matrix. The project seeks to greatly extend the<br/>scope of the approach.  It is proposed to define and study marginal<br/>independence models for contingency tables, discrete-valued time series<br/>with moving average-like dependence structure, seemingly unrelated<br/>regressions with discrete response variables, and discrete graphical<br/>models based on the recently introduced AMP chain graphs and ancestral<br/>graphs.  The main objectives of the study are development of<br/>parameterizations, construction and implementation of efficient algorithms<br/>for maximum likelihood estimation, and investigation of procedures for<br/>model selection. A particular focus of the project will be on employing<br/>modern tools from computational algebra in the analysis of the structure of<br/>parameter spaces and properties of likelihood functions.<br/><br/>Multivariate statistical models seek to describe the complex relationships<br/>between a large set of variables. A particular class of such models,<br/>called graphical models, has found wide-spread application in fields like<br/>artificial intelligence, bio-informatics, biology, epidemiology, and<br/>speech recognition.  The models proposed in the project extend the realm<br/>of graphical models and it is anticipated that they will be applied in<br/>many of these fields.  Moreover, the proposed methodology will provide new<br/>tools for the analysis of data of public interest such as census data.<br/>The researchers also plan to make software tools freely available as part<br/>of a larger open source statistical software package called R.<br/>"
1054419,CAREER: Computationally Generated Biomarkers,IIS,INFO INTEGRATION & INFORMATICS,2/1/2011,5/17/2013,Zeeshan Syed,"Syed, Z","Syed, Z",MI,University of Michigan Ann Arbor,Continuing grant,Sylvia J. Spengler,5/31/2013,"$87,538.00 ",,zhs@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,7364,"1045, 7364",$0.00 ,normalFunding,"The focus of the proposed research is to develop a computational framework that allows for the systematic exploration of the growing human ""physiome"" for clues to predict and prevent major diseases. This research is motivated by the observation that despite recent progress in medicine, the disease burden of many important clinical conditions remains unacceptably high because of a failure to promptly match patients to treatments that are appropriate to their current condition or their individual risk. This situation is true of many different areas of medicine: in cardiology, over 300,000 deaths take place each year due to fatal arrhythmias; in psychiatry, 34% of patients with bipolar disorder have an interval longer than 10 years before they first receive a diagnosis; in the setting of intensive care, there are over 650,00 cases of unanticipated sepsis each year. These are only some examples, where the therapies to significantly improve patient outcomes and reduce healthcare costs exist, but are often not applied in a timely fashion due to the absence of adequate information-based tools to guide their use.<br/><br/>There is a critical need in this setting for novel biomarkers to guide decision-making. Particularly striking is the lack of good biomarkers that exploit recent advances in acquiring large physiological datasets continuously from patients over long periods. The existing practice of discovering disease markers in such data is highly dependent on human input and subjective abilities; inappropriate for large datasets and subtle markers; and unable to generalize for different systems and diseases. The goal of this research is to bridge this gap, through computational methods for the structured discovery of novel, highly-discriminative risk markers from terabytes and even potentially petabytes of physiological data.<br/><br/>Inspired by the translational impact of computational biology in extracting valuable insights from large volumes of genomic and proteomic data, this research endeavors to lay the foundations of a complementary body of research focused around a vision of ""computational physiomics"". The PI proposes a computational framework where large volumes of waveform data are first abstracted into a uniform string representation, and the resulting physiological text is then studied for characteristics associated with risk. The abstraction of physiological signals into text creates the opportunity to study these signals in a fundamentally different manner from earlier efforts (and to thereby discover new insights). As part of this work, the PI will address the challenges associated with transforming the many different kinds of physiological time-series signals (e.g., quasi-periodic, aperiodic, non-uniformly sampled, multi-channel) into symbolic sequences, registering these symbols across patients, formulating problems relating to risk stratification in the context of textual data, and developing algorithms to efficiently and accurately solve these problem statements. In addition, through extensive collaborations with clinical colleagues, he will rigorously evaluate the clinical utility of the research on real-world datasets drawn from different high-impact clinical applications.<br/><br/>Early investigation of the ideas that form the basis of the proposed work have shown great promise for cardiovascular applications. Clinical studies in two separate cohorts with nearly 6,000 patients show that the computational framework enables the discovery of risk markers from ECG signals that identify patients at an 8-9 fold increased risk of death within three months of a heart attack, and moreover, that this information is independent of other generally accepted risk variables (e.g., demographics, comorbidities, imaging results, biomarkers, other ECG variables etc.). The research should enable continued progress in the case of cardiovascular disease, as well as similar progress for other focus applications (e.g., psychiatry, critical care, neurology, and obstetrics) through clinical collaborations. In addition to impact in these specific cases, the research also lays the foundation of a broader body of research (i.e., the vision of ""computational physiomics"") that can transform medical data analysis by including large volumes of continuous physiological signals in a rubric that today can only handle discrete data. This research represents a central piece in this context that connects advances in continuous patient monitoring to advances in classification methods. While the research is motivated by clinical applications, the computational questions addressed by the work and the techniques will also advance existing work on time-series prediction and on sequential data mining and machine learning more generally. The challenge of extracting insights from large volumes of time-series data is increasingly important across many different disciplines. The research promises to significantly advance both the broad goal of time-series analysis, as well as individual sub-problems in the areas of motif discovery, long-term signal comparison, anomaly detection, characterizing complexity, and identifying structure in apparently noisy signals.<br/><br/>This research will help to establish a strong inter-disciplinary program in computer science and medicine at the University of Michigan. This program will be inherently translational, and have a significant education component that provides graduate and undergraduate students with coursework and research opportunities exposing them to real-world medical problems, complex and large clinical datasets, computational methods, and the design of experiments. The PI will use the methods and materials related to this proposal both in the development of new courses (such as the biomedical machine learning course that the PI has introduced at Michigan), and to enrich existing courses in algorithms and data structures (which the PI teaches) and artificial intelligence and machine learning (which are taught by other faculty in the CSE department). Replacing some of the traditional applications covered in these courses by applications of clear importance to human health should engender a sense of excitement among students as they understand first-hand the role computation can have in improving the human condition. Developing, implementing, and evaluating our computational framework will also generate several undergraduate research positions that will allow students to experience and learn about multi-disciplinary research.  The PI is also committed to making the datasets that form the basis of the proposed research available to the broader research and educational communities for use in a de-identified manner. This will enable researchers who do not have established clinical partners to enter the research area and educators to construct laboratory activities, and facilitate the uniform assessment of risk stratification algorithms on a common set of signals."
9412764,Automated Classification and Analysis of Power System       Disturbance Waveforms Using a Neural Network Approach,ECCS,"CONTROL, NETWORKS, & COMP INTE",9/15/1994,10/18/1996,David Lubkeman,"Lubkeman, D","Lubkeman, D",SC,Clemson University,Standard Grant,Vijay Vittal,5/31/1998,"$87,378.00 ",,david.lubkeman@eng.clemson.edu,230 Kappa Street,CLEMSON,SC,296345701,8646562424,ENG,1518,"1038, CVIS",$0.00 ,normalFunding,"9412764  Lubkeman  The objective of this proposed project is to investigate and  develop a scheme to further automate the monitoring, recording,  and diagnosis of power disturbances for power quality studies,  using a combination of artificial neural network (ANN) and case-  based reasoning (CBR) approaches.    The proposed research is (a) to develop a scheme to automate the  data collection process of recorders--this involves an ANN  methodology for the classification of waveforms that are captured  and a rule-based relational database design for the effective  archival of data, and (b) to investigate the applicability of a  case-base reasoning approach towards aiding the diagnosis of  disturbances.  This research represents a step in the direction  of intelligent diagnostic and measurement tools using state-of-  the-art artificial intelligence technologies which are just  emerging.  It would be a significant improvement over present-day  recorders, providing for further automation of the measurement  and diagnosis of disturbances.  ***"
94504,"The History of Cybernetics: Ashby, Beer and Pask",SES,Hist & Philosophy of SET,11/1/2001,11/9/2001,Andrew Pickering,"Pickering, A","Pickering, A",IL,University of Illinois at Urbana-Champaign,Standard Grant,Keith R. Benson,11/30/2003,"$85,452.00 ",,pickerin@uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,SBE,1353,"0000, OTHR",$0.00 ,normalFunding,"ABSTRACT:  SES 00-94504<br/>Andrew Pickering<br/>The History Of Cybernetics: Ashby, Beer And Pask<br/><br/>Cybernetics increasingly commands serious interest amongst historians of science, in part,<br/>no doubt, because of a sense that it has sought to grasp the world in an interestingly different way from the more familiar natural and social sciences-holistically rather than<br/>reductively, to put it crudely. Most historical interest has focussed on the World<br/>War II founders of cybernetics-Norbert Wiener, John von Neumann, Warren<br/>McCulloch, Claude Shannon-and the series of Macy conferences (1946-53) in which<br/>their views were propagated. And most attention has been paid to the conceptual<br/>singularity of cybernetics-cybernetics as a theory of negative feedback and control, or as<br/>a world-view or ideology.<br/><br/>This project extends our understanding of the substance and history of cybernetics along<br/>several axes. First, it examines new characters and a later period. Based on research over the past couple of years, the PI believes that some of the most fascinating and original work in cybernetics was done from the early 1950s onwards by a group of British scientists-foremost amongst them W. Ross Ashby, Stafford Beer and Gordon Pask. Second, while I am, of course, interested in the ideas of these men, I am also interested in what they did-the practice of cybernetics, a largely unexplored topic. This leads, third, into the material stratum of cybernetics. Like Wiener's before them, the cybernetics of the English group referred directly to a constellation of fascinating material systems and artefacts. The singularity of cybernetics, the PI argues, resides at least as much at this level as it does at the level of ideas. The interest in practice also leads, fourth, into the social structure of cybernetics. We are familiar with the usual academic/disciplinary centering of the traditional sciences, but cybernetics was not like that. The cyberneticians have typically been wanderers or vagrants, moving readily between institutional bases that we generally think of as distinct, including the university, but also the arts, business, industry and the military. This social level constitutes another, hitherto not well recognised, aspect of the singularity of cybernetics. <br/><br/>This proposal for a sabbatical year supports preparation of a book on the British<br/>cyberneticians, especially the research on Beer and Pask.  (The PI's a graduate student is already working intensively on Ashby). Key informants have agreed to be interviewed and furnish documents in their possession.   The book seeks to emphasise that, in its specific entanglements of the material, social and conceptual, cybernetics was a different kind of historical formation from the reductive sciences-a new and fascinating kind of object for study by the STS community that may increasingly command much wider scholarly and popular interest.  Certain theoretical concerns of the PI go along with his interest in cybernetics, which he intends to open up in the last chapter of the book by locating cybernetics within a larger body of cognate work, including current work on 'complexity' and his own work on the 'mangle of practice.'  The project contributes significantly to theoretical discussions within and beyond science and technology studies.  The PI also explores the relevance of such discussions for contemporary work in artificial intelligence, information technology and cognitive science.<br/><br/>"
958160,Collaborative  Research: CI-ADDO-NEW: *-EXEC: A Cross-Community Solver Execution Service,CNS,COMPUTING RES INFRASTRUCTURE,5/1/2010,5/5/2010,Aaron Stump,"Stump, A","Stump, A|Tinelli, C",IA,University of Iowa,Standard Grant,todd leen,4/30/2012,"$84,197.00 ",Cesare Tinelli,aaron-stump@uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,7359,"9218, HPCC",$0.00 ,normalFunding,"Ongoing breakthroughs in nationally important research areas like Verification and Artificial Intelligence depend on continuing advances in high-performance automated theorem proving tools. The typical use of these tools is as backends: application problems are translated by an application tool into (typically very large and complex) logic formulas, which are then handed off to a logic solver. Different tradeoffs between linguistic expressiveness and the difficulty of solving the resulting problems give rise to different logics. Solver communities, formed around these different logics, have developed their own community research infrastructures to encourage innovation and ease adoption of their solver technology. Such infrastructure includes standard formats for logic formulas, libraries of benchmark formulas, and regular solver competitions to spur solver advances.<br/><br/>Currently, these different infrastructures are all developed separately, at significant cost in equipment and support. These costs are paid again and again for the different services, since there is currently no global piece of computing infrastructure suitable for the logic solving domain, which all these communities can use. This project is building a simplified proof-of-concept of a single piece of shared computing infrastructure, which could eventually be used by many different logic solver communities. The award also provides other support for soliciting research community feedback on the prototype and the design of a comprehensive infrastructure."
9750648,An Undergraduate Parallel/Distributed Computing Laboratory,DUE,UNDERGRAD INSTRM & LAB IMPROVE,7/1/1997,5/28/1997,Stephen Ben-Avi,"Ben-Avi, S","Ben-Avi, S",NY,Cooper Union,Standard Grant,Ernest L. McDuffie,6/30/1999,"$82,421.00 ",,benavi@cooper.edu,"30 Cooper Square, 8th Floor",New York,NY,100030000,2123534138,EHR,7400,"9178, 9267, SMET",$0.00 ,normalFunding,"Through this project, the Department of Electrical Engineering (EE) continues to update and expand its Undergraduate Parallel/Distributed Computing Laboratory.  The project supports existing curriculum offerings and widens the use of the technology by using it as a base in other, non-parallel-focused courses, such as Databases, and Artificial Intelligence.    Modern computers connected by a LAN can provide a parallel virtual machine with sufficient reliability that the parallel/distributed techniques can become an ordinary, everyday tool rather than just the focus of special interest courses.  Old transputer boards have become obsolete and almost impossible to use after 6 years of heavy utilization, and this project is designed to retain the parallel/message-passing paradigm in the EE's curriculum.    Many algorithms have portions that could be executed at the same time if facilities to do this exist.   Except for expensive special purpose machines, computers have traditionally been SISD (Single Instruction Single Data) processors, executing instructions without the possibility of simultaneous execution.  On a parallel machine or facility, such as this new heterogeneous PVM (Parallel Virtual Machine), students are able to execute parallel simultaneous instructions over separate vectors or partitions of data.  A modern EE curriculum should include the application of parallel/distributed techniques to problems at the frontiers of computing speed such as image or speech analysis, neural nets, modeling, and graphics.    The machines must also be the object of study and be available for student experimentation.  A reconfigurable heterogeneous PVM lends maximum flexibility to the laboratory, at modest cost, and uses existing facilities.  The refurbished laboratory is immediately available owing to prior expertise in this area, the readiness of space, current computers, and extant LAN facilities.  *"
9986151,The International Conferences on Cognitive and Neural Systems at Boston University,DRL,KDI-COMPETITION,10/1/1999,9/17/1999,Stephen Grossberg,"Grossberg, S","Grossberg, S",MA,Trustees of Boston University,Standard Grant,Kenneth C. Whang,9/30/2001,"$82,000.00 ",,steve@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,EHR,"7256, 8877","9177, SMET",$0.00 ,normalFunding,"This grant would enable the annual International Conference on Cognitive and Neural Systems to continue on May 24-27, 2000 and in May, 2001. The conference focuses on the two general themes: How Does the Brain Control Behavior? and How Can Technology Enable Biological Intelligence? The conference would also emphasize Learning and Intelligent Systems. Many conferences are covering cognitive or neurobiological data. A few conferences are covering cognitive or neurological models, but not both. Yet other conferences are covering artificial neural networks and other neuromorphic applications . The Cognitive and Neural Systems conference is unique in covering both cognitive and neural experiments and models, as well as a range of intelligent applications, and doing so within a conference program with a single program track. The meeting was prepared to do this because this is precisely what the CNS graduate program at Boston Universitiy was created to do. The conference will include invited tutorials and lectures, and contributed lectures and posters by experts on the biology and technology of how the brain and other intelligent systems adapt to a changing world. The conference is aimed at researchers and students of computational neuroscience, connectionists cognitive science, artificial neural networks, neuromorphic engineering, and artificial intelligence."
650413,Diffusion Multiscale Analysis,DMS,COMPUTATIONAL MATHEMATICS,8/1/2006,9/22/2006,Mauro Maggioni,"Maggioni, M","Maggioni, M",NC,Duke University,Standard Grant,Leland M. Jameson,6/30/2009,"$81,368.00 ",,mauro.maggioni@jhu.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,MPS,1271,"0000, 9263, OTHR",$0.00 ,normalFunding,"In this proposal, the investigator and his collaborators address <br/>several questions arising from the mathematical analysis of multiscale <br/>geometries of sets, and multiscale decomposition of function spaces, <br/>that arise from the action of a diffusion semigroup on a manifold, a <br/>graph and other rather general metric spaces. While these multiscale <br/>geometries are partly implicit (and classical) in differential geometry, <br/>in partial differential equations, as well as in many branches in graph <br/>theory (with applications to problems in computer science), only <br/>recently a very general, yet efficient, coherent and unifying <br/>construction has been introduced by the investigator and his <br/>collaborators. Multiscale function space decompositions that mirror <br/>these multiscale diffusion geometries are also constructed, through the <br/>introduction of special wavelet functions. This is a far-reaching, and <br/>long sought, generalization of wavelet analysis, both mathematically and <br/>computationally. The investigator and his collaborators have shown that <br/>algorithms for efficiently computing these multiscale decompositions <br/>exist, which generalize the fast wavelet transform and Fast Multipole <br/>Methods, yielding fast multiscale algorithms guaranteeing <br/>high-precision. The investigator will study the construction of <br/>biorthogonal diffusion multiscale decompositions, multiscale function <br/>approximation on rough sets, multiscale diffusion analysis of data sets <br/>and its relationships with geometric measure theory, multiscale Markov <br/>chains, numerical analysis of PDEs, learning theory, hyperspectral <br/>imaging and document corpora analysis.<br/>The investigator expects this novel multiscale construction to have <br/>impact in all these disciplines, in a way similar to the impact wavelet <br/>analysis had on low-dimensional signal processing and numerical analysis.<br/><br/>The present proposal stresses the inter-disciplinary nature of several <br/>aspects of multiscale analysis, and the vast applicability of the ideas, <br/>tools, constructions, to pure and applied mathematics, and to other <br/>disciplines such as computer science, physics, engineering, astronomy <br/>and statistics, among others. The introduction of these novel multiscale <br/>techniques reveals new and interesting multiscale geometric structures <br/>of graphs and sets, together with effective computational tools to <br/>discover them. The range of applications is very wide, and includes the <br/>analysis and organization of large and complex networks (e.g. computer <br/>networks, biological regulatory networks etc...), document corpora for <br/>information extraction, hyperspectral imagery (for applications to <br/>medicine, target recognition etc...), and large datasets in general. It <br/>has also applications to the development of new algorithms for learning <br/>and artificial intelligence, for the automation of complex tasks. The <br/>investigator aims at strenghtening his existing collaborations, and <br/>establishing new ones, with other institutions, both in the United <br/>States and abroad, across several disciplines, in particular computer <br/>science, astronomy, biology, and medicine. He will continue his existing <br/>collaborations with companies developing next-generation <br/>instrumentation, for applications to hyperspectral imaging. He will <br/>continue to actively participate in multi- and inter-disciplinary <br/>conferences, workshops and research activities, and effectively <br/>communicating and disseminating ideas and techniques to <br/>multi-disciplinary audiences, making his work, including papers and <br/>computer code for the corresponding algorithms, easily accessible <br/>electronically."
646933,Understanding Concepts: An Essential Aspect of Robust Intelligence,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/15/2006,9/18/2007,Patrick Winston,"Winston, P","Winston, P",MA,Massachusetts Institute of Technology,Standard Grant,Douglas H. Fisher,2/29/2008,"$80,000.00 ",,phw@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,6856,"7495, 9218, 9237, HPCC",$0.00 ,normalFunding,"Proposal 0646933<br/>""Understanding Concepts: An Essential Aspect of Robust Intelligence""<br/>PI: Patrick H. Winston<br/>MIT<br/><br/>                                                          ABSTRACT<br/><br/>This project will investigate foundational issues about the nature and representation of concepts, a critical prerequisite for building robust intelligence systems. In this project, which will be carried out in the Genesis Group of the MIT CSAIL laboratory, a concept is a complex, cross-modal model that crystallizes out of experience. As a step toward learning how to use experience, real and surrogate, to build such models, this project will collect and devise a rich collection of cross-linked, understanding-oriented experts, each specialized to a particular representation of the world, all backed by both individual associative memories and by associative memories that span multiple representations. The memories will be populated from a stream of sentences and phrases, thereby accumulating a humanlike capacity to associate states and actions that appear in one modality with those that appear in other modalities. This project will distill and test important aspects of concept representation by building a system called the Gauntlet System in which sentences and phrases stream past a line of representation-centered experts, each of which can either interpret an element of the data in its own terms or ignore it and pass it along to other downstream experts for their consideration. The project plans to build an on-line library of representation summaries for use by other researchers interested in concept formation, robust systems and Artificial Intelligence.<br/><br/><br/>"
342849,"Workshop:   Restructured Power System Reliability and Security:    Building a Mathematical Paradigm With New Analytical & Computational Tools;  Sept. 24-26, 2003; Washington, D",ECCS,"CONTROL, NETWORKS, & COMP INTE",8/15/2003,8/4/2003,Joe Chow,"Chow, J","Chow, J",NY,Rensselaer Polytechnic Institute,Standard Grant,Kevin Tomsovic,9/30/2005,"$80,000.00 ",,chowj@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,ENG,1518,"0000, 1238, OTHR",$0.00 ,normalFunding,"This proposal requests funding to run a workshop on applied mathematical aspects of power systems under restructuring, focusing on reliability and security. The workshop has several objectives:<br/><br/>1. It will provide a forum for the interchange of ideas between power system researchers and applied mathematicians.<br/><br/>2. The workshop focus is of prime importance, namely, the reliability and security in a restructured power system. Three main themes have been identified: (a) optimization of restructured power system operation, (b) system stability and dynamic performance, and (c) computational intelligence methods.  Experts in optimization methods, control theory, and artificial intelligence will be invited to give presentations on the new advances that have high potential of fruitful power system application.<br/><br/>3. To motivate the workshop, an article on open problems of reliability and security in restructured power systems will be written jointly by the organizers (JHC and FFW) and the NSF program director, and be distributed to the workshop participants to help them prepare their presentations. In addition, each presenter will be asked to prepare an article before the workshop, such that the conference activities can be recorded in a monograph.<br/><br/>As a continuation of Reliability and Security Workshop, a Strategic US-Africa Research-Education Planning Workshop is proposed to bring together about 15 researchers from US and a comparable number of African researchers to discuss research and training ideas and then to prioritize the activities, to jump start the US-Africa Research-Education Exchange Initiative program.<br/><br/>Intellectual Merits: The Security and Reliability Workshop will cultivate the exchange of ideas between researchers in several distinct communities: the power system researchers who are more problem-driven and practical, versus the applied mathematicians who have stronger theoretical and computational bases.  We anticipate the cross fertilization of new ideas will establish a mathematical paradigm in power system research in which new analytical and computational tools will play a dominant role in improving the reliable and secure operation of a deregulated electric power market. The Strategic US-Africa Research-Education Planning Workshop will lay out a roadmap of network research and training, setting priorities on a large number of research, training, and development activities.<br/><br/>Broader Impacts: We encourage a diversity of participants at the Security and Reliability Workshop. We will invite women faculty and faculty from underrepresented groups to participate. Young faculty members are of particular interest because the workshop may help to shape their research and careers. Although the number of participants of the workshop may be limited, the workshop monograph and web site will help to extend the benefits to the power system and applied mathematics community at large. An undergraduate student, preferably a minority, will be supported to develop and maintain the workshop web site and to help coordinate the compilation of the articles for the monograph. The Strategic US-Africa Research-Education Planning Workshop will potentially propel the research activities of universities in several African countries to a much higher level, which will have a spillover effect to other universities and to other African countries.  The social and economic benefits of this Workshop can be substantial.<br/>"
9711753,Exploiting Structure in Reinforcement Learning Problems,IIS,ARTIFICIAL INTELL & COGNIT SCI,12/1/1997,12/15/1997,Satinder Baveja,"Baveja, S","Baveja, S",CO,University of Colorado at Boulder,Continuing grant,Ephraim P. Glinert,11/30/1998,"$80,000.00 ",,baveja@umich.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,6856,"9216, HPCC",$0.00 ,normalFunding,"Algorithms for learning by interaction, or reinforcement learning, typically ignore all structure in the   environment and consequently tend to scale poorly. The goal of this research is to develop novel, efficient,   and theoretically well-founded algorithms and architectures for learning by interaction in structured   environments. Three kinds of environmental structure are considered: factorial structure in states and   actions, additive structure in payoff functions, and hierarchical structure in states and actions. Such   structure is common because many environments are composed from multiple, weakly interacting,   components that are often organized hierarchically. The approach consists of exploiting this structure by   learning separately for the different components and then compensating in a structure dependent manner   for the approximation so introduced. The results of this research will elucidate many different interesting   and useful structures common in learning by interaction problems and provide new reinforcement   learning algorithms that make it possible to solve significantly larger structured problems than possible   with the traditional approach. Possible applications include large-scale, dynamic, resource allocation   problems intelecommunications, networking, and scheduling, as well as multi-agent problems from   distributed control and artificial intelligence."
1721445,Collaborative Research: Automatic Video Interpretation and Description,DMS,"OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS",9/1/2017,8/20/2017,Yunzhang Zhu,"Zhu, Y","Zhu, Y",OH,Ohio State University,Standard Grant,Christopher W. Stark,8/31/2020,"$79,999.00 ",,Zhu.219@osu.edu,Office of Sponsored Programs,Columbus,OH,432101016,6146888735,MPS,"1253, 6892, 8069","1253, 7433, 8004, 8083, 9263",$0.00 ,normalFunding,"Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
520798,SGER:  Generating Animations of American Sign Language Classifier Predicates,IIS,UNIVERSAL ACCESS,6/1/2005,5/12/2006,Mitchell Marcus,"Marcus, M","Marcus, M|Badler, N",PA,University of Pennsylvania,Standard Grant,Ephraim P. Glinert,11/30/2006,"$77,830.00 ",Norman Badler,mitch@central.cis.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,6846,"9218, 9237, HPCC",$0.00 ,normalFunding,"American Sign Language (ASL) is a full natural language, with a linguistic structure distinct from English, used as the primary means of communication for approximately one half million deaf people in the United States.  Furthermore, because they are unable to hear spoken English during the critical language acquisition years of childhood, the majority of deaf high school graduates in the U.S. have only a fourth grade English reading level.  Because of this low English literacy rate and because English and ASL have such different linguistic structure, many deaf people in the United States could benefit from technology that translates English text into animations of ASL performed by a virtual human character on a computer screen.  But previous English-to-ASL machine translation projects have made only limited progress.  Instead of producing actual ASL animations, these projects have produced restricted subsets of the language, thus allowing them to side-step many important linguistic and animation issues, including in particular the ubiquitous ASL linguistic constructions called ""classifier predicates"" that are required in order to translate many English input sentences.  Classifier predicates are an ASL phenomenon, in which the signer uses the space around his or her body to position invisible objects representing entities or concepts under discussion; the signer's hands show the movement and location of these objects in space.  Classifier predicates are the ASL phenomenon that is most unlike elements of spoken or written languages, and they are therefore difficult to translate by machine translation software.  In this research the PIs and their graduate students will build on prior research in ASL linguistics, machine translation and artificial intelligence, 3D graphics simulation and human animation, to design and implement a prototype software system capable of producing animations of classifier predicates from English text.  In doing so, they will address some of the most challenging issues in English-to-ASL translation, with the goal of producing a software design that can serve as a robust framework for future implementation of a complete English-to-ASL machine translation system.  The prototype implementation will have sufficient visual quality and linguistic breadth to enable a pilot evaluation of the design and the quality of the output animations by deaf native ASL signers.<br/><br/>Broader Impacts:  This research will lead to significant advances in the state of the art relating to English-to-ASL machine translation software, which will eventually allow development of new applications to provide improved access to information, media and services for the hundreds of thousands of deaf Americans who have low English literacy.  Instead of displaying English text, devices like computers, closed-captioned televisions, or wireless pagers could show deaf users an animation of a virtual human character performing ASL.  Novel educational reading applications software for deaf children to promote English literacy skills could also be developed.  The project will also expose the graduate students involved to research issues relating to ASL and animation, and will support a summer ASL language training program at Gallaudet University for these students."
9818322,CISE Research Instrumentation: A Laboratory for Interactive Applications for Computational Vision and Language,EIA,CISE RESEARCH RESOURCES,12/15/1998,11/16/2001,Sven Dickinson,"Dickinson, S","Dickinson, S|Stone, M|Stevenson, S",NJ,Rutgers University New Brunswick,Standard Grant,Frederica Darema,11/30/2002,"$76,928.00 ","Matthew Stone, Suzanne Stevenson",sven@cs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,2890,"9216, HPCC",$0.00 ,normalFunding,"9818322<br/>Dickinson, Sven<br/>Stevenson, Suzanne<br/>New Brunswick, NJ 08854-8010<br/><br/>A Laboratory for Interactive Applications of Computational Vision and Language<br/><br/>This research instrumentation enables research projects in:<br/>- Visual Object Recognition and its Applications to Robotic Aids for the Disabled,<br/>- Model-Based Estimation, Tracking, and Recognition for Observing Human Activities,<br/>- Evaluating Interactive Systems Based on Natural Language Generation, and<br/>- Resolving Ambiguities in Interactive Instructions.<br/><br/>This award supports established, on-going research in computer science and engineering at Rutgers University and contributes to the purchase of a Minolta 3-D laser scanner/object modeler, a Nomadics Technologies XR4000 Robotic Arm and Stereo Vision Upgrade, a Vision One Video Tracking Platform, four STW Linux-based PC's, and a membership in the Linguistic Data Consortium (a source of text corpora). The equipment forms the basis for a new Laboratory for Interactive Applications of Computational Vision and Language, directed by the four PIs, and will be shared among four collaborative research projects spanning the areas of computer vision and natural language processing: (1) the integration of object recognition and language understanding in a robotic system for the disabled; (2) the development of integrated vision systems that combine estimation, tracking, and recognition of both objects and events in a model-based framework; (3) the design of a video analysis system for evaluating automatically generated instructions; and (4) the development of automatic ambiguity resolution procedures for natural language instructions. In each case, the resulting technologies are embedded within human-computer interfaces, thereby taking a step toward achieving the goal of more natural interactive systems."
9455606,Mathematical Interactive Network Design (MIND): A Computer Lab for Developmental Mathematics,DUE,DUE COURSE & CURRICULUM PROG,2/1/1995,11/4/1997,Kathryn Wetzel,"Wetzel, K","Wetzel, K|Pool, J",TX,Amarillo College,Standard Grant,Elizabeth Teles,12/31/1998,"$75,394.00 ",John Pool,kwetzel@dcccd.edu,P O BOX 447,Amarillo,TX,791780001,8063455548,EHR,7410,"7419, 9178, SMET",$0.00 ,normalFunding,"9455606 Wetzel The Mathematical Interactive Network Design (MIND) project is a computer laboratory designed for interactive multi-media instruction in developmental mathematics. Using Visual Basic, multi-media software and object oriented programs are being developed by supervising instructors. Students are utilizing a graphical user interface and icon driven software to access and control various instructional media. The goal is to immerse the student in an intensely interactive, but easily constructed, simulated learning environment. This radically new system is meeting each student's unique and specific needs and providing an individualized tutorial session with appropriate, constructive, instructive, and timely feedback. Artificial intelligence techniques are being applied to implement the concept of guides whose behavior and even personality is being made to depend upon the attributes of the learner. The guide presents a combination of interactive digitized video and audio integrated with graphics and text to provide the students with choices of lecture, drill, problem solving, review and testing as deemed beneficial or necessary through monitoring of the student's progress and relative success. The software is being used to supplement and enhance, not replace, coursework."
1725785,Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students,DUE,IUSE,9/1/2017,7/21/2017,Vimal Viswanathan,"Viswanathan, V","Viswanathan, V",CA,San Jose State University Foundation,Standard Grant,Heather Watson,8/31/2022,"$75,155.00 ",,vimal.viswanathan@sjsu.edu,210 North Fourth Street,San Jose,CA,951125569,4089241400,EHR,1998,"8209, 8238, 8244, 9178",$0.00 ,normalFunding,"Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
341311,Application of Artificial Intelligence To Enhance Student Learning of Metallography,DUE,"CCLI-EDUCATIONAL MATERIALS DEV, EPSCoR Co-Funding",4/1/2004,4/2/2004,Alan Anderson,"Anderson, A","Anderson, A|Weiss, J",SD,South Dakota School of Mines and Technology,Standard Grant,Don L. Millard,3/31/2007,"$75,000.00 ",John Weiss,alan.anderson@sdsmt.edu,501 East Saint Joseph Street,Rapid City,SD,577013995,6053941218,EHR,"7427, 9150","9150, 9178, SMET",$0.00 ,normalFunding,"This project is creating a learning environment for teaching metallography and is developing techniques for automated microstructure recognition. In the first phase of this project, it is developing a database of micrographs. This database provides a gallery of micrographs and all of the required information to produce the micrograph. In addition, it provides a description of the microstructure and instructions for identifying the significant features and is being used as a learning tool for students and scientists.<br/><br/>The second phase of this project is leveraging the information collected from the<br/>micrograph database to develop methods for automatic characterization of micrographs through the use of image analysis and processing, texture analysis, neural networks, and artificial intelligence algorithms.<br/><br/>This project is also leading to improved pedagogical activities for teaching faculty in both Materials Science and Computer Science. The work is fostering interdisciplinary cooperation and providing student mentoring to both graduate and undergraduate students. The modules developed are being disseminated to similar institutions to help foster learning of metallography skills that are required in industry.<br/><br/>"
352703,SGER:    Development of Linux Attack Scenarios in Support of Intrusion Detection in High Performance Clusters,CNS,"CYBER TRUST, ITR-CYBERTRUST",10/1/2004,4/29/2005,Rayford Vaughn,"Vaughn, R","Vaughn, R|Bridges, S",MS,Mississippi State University,Standard Grant,Karl Levitt,9/30/2006,"$75,000.00 ",Susan Bridges,ray.vaughn@uah.edu,PO Box 6156,MISSISSIPPI STATE,MS,397629662,6623257404,CSE,"7371, 7456","7254, 9218, 9237, HPCC",$0.00 ,normalFunding,"NSF-0352703<br/><br/>Title: SGER:  Development of Linux Attack Scenarios in Support of Intrusion Detection in High Performance Clusters<br/><br/>PI: Rayford B. Vaughn<br/><br/>Cluster and grid clusters based on the Linux operating system have become widely used computational resources in environments where large amounts of data have privacy, defense, reliability, or other security concerns.  Cluster nodes exchange information through both TCP/IP and high-speed network fabrics that often bypass operating system controls.  As clusters become ubiquitous with Internet connection commonplace, the services they deliver will likely place them at a greater risk for attacks or intentional misuse by insiders.  Mississippi State University has been pursuing research in anomaly detection within High Performance Computing (HPC) networks since 2000.  This work is currently sponsored by the National Science Foundation and the Department of Defense.  One of the major challenges for research in anomaly detection within high performance networks is the dearth of data sets for evaluating performance. Such data sets are necessary to validate the efficacy of artificial intelligence techniques that are under development for the detection of anomalies resulting from misbehavior of users or programs or from faults, and for performance monitoring.  Three different classes of attacks against clusters have been designed and simulated at MSU.  This research will refine these attacks and introduce additional classes of attacks in HPC clusters and will archive data sets for general use by the research community looking at anomaly detection in HPC environments.  <br/>"
341521,Reading the Forest Floor:  Online Case-Based Inquiry Learning in Forestry,DUE,CCLI-EDUCATIONAL MATERIALS DEV,5/1/2004,5/4/2004,Beverly Woolf,"Woolf, B","Woolf, B|Winship, L",MA,University of Massachusetts Amherst,Standard Grant,Jeanne Small,10/31/2005,"$74,984.00 ",Lawrence Winship,bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,EHR,7427,"9178, SMET",$0.00 ,normalFunding,"Biological Science (61). This CCLI Educational Materials Development proof-of-concept project addresses the need to engage forest ecology students, including non-majors and future teachers, in activities that require critical thinking and scientific reasoning.  It does this by building inquiry-oriented materials that approach forestry as an environmental mystery, asking students ""Why are there no middle sized trees in this well developed forest?"" ""How often and which species of trees were logged?"" and  ""How long ago was this beaver pond abandoned?"" The software automatically records and analyzes students' observations, data and hypotheses and helps students draw inferences and revise hypotheses. The software works on a desktop computer and on a Personal Digital Assistant so students can record data and perform data analysis during field trips. The three forestry cases developed are tested for their effectiveness in a variety of post-secondary institutions and secondary schools, examining how and if inquiry learning is supported by the materials. Evaluation includes assessment of the software's usability and the consequent changes in student attitudes towards scientific reasoning. This work incorporates artificial intelligence, interactive multimedia and web-based technology in a rich, reliable and authoritative collection of teaching materials, thereby addressing the need for instruction appropriate to students of different learning styles and genders.<br/>"
231325,Development of a Pedagogical Computer Game Engine Library in Support of Computer Science Education,DUE,CCLI-EDUCATIONAL MATERIALS DEV,1/15/2003,1/8/2003,John Laird,"Laird, J","Laird, J|Jamin, S",MI,University of Michigan Ann Arbor,Standard Grant,Stephen R. Cunningham,12/31/2004,"$74,913.00 ",Sugih Jamin,laird@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,EHR,7427,"7427, 9178, SMET",$0.00 ,normalFunding,"This is a proof of concept project in which software modules that support the development of a variety of computer game genres are developed. These software modules can be used to teach undergraduates computer game design and development. The software can also be used as a shell for explorations of many computer science disciplines for undergraduates where students can replace one of the modules with their own, thereby allowing them to concentrate on specific CS disciplines ranging from basic data structures and algorithms, to database management, issues in concurrent programming, design of network protocols, distributed systems and security, graphics programming, user interface design, and design of artificial intelligence algorithms; but still having the ability to create a computer game. The computer gaming context provides a very strong motivational construct to which most computer science students have a natural affinity. Placing these disciplines within the construct of a computer game helps students concretize and apply the concepts studied. The software is developed by University of Michigan undergraduate and graduate students. The results and software of this project are disseminated to the broader computer games and computer science community via appropriate conferences and the Internet. At the University of Michigan, the PI has been offering a Computer Games course since 1997 and the coPI has been teaching a Computer Networks course. Both PIs have developed pedagogical software packages in their respective fields that have been used by faculties in other universities nationwide."
9980375,Incorporating Agent-Based Computing into Computer Science and Engineering Curriculum,DUE,CCLI-EDUCATIONAL MATERIALS DEV,1/1/2000,12/2/1999,Yi Shang,"Shang, Y","Shang, Y|Shi, H",MO,University of Missouri-Columbia,Standard Grant,Andrew P. Bernat,12/31/2001,"$74,327.00 ",Hongchi Shi,shangy@missouri.edu,115 Business Loop 70 W,COLUMBIA,MO,652110001,5738827560,EHR,7427,"7427, 9178, SMET",$0.00 ,normalFunding,"Computer Science (31)<br/><br/>In recent years, agent-based computing is increasingly being used in information management and distributed computing.  In undergraduate computer science education the technical aspects of agent-based computing are closely related to other areas of the discipline.  This proof-of-concept project incorporates agent-based computing across the computer science and engineering curriculum.  The objectives of the project are to design and develop course materials, including examples and exercises for an introductory course, Foundations of Agent-Based Computing, and a series of in-depth course modules, including teaching materials and agent software, that can be integrated into other computer science courses such as artificial intelligence, distributed computing, networking and distributed computing.    <br/><br/>The project is being evaluated internally with help from the College of Education and externally in collaboration with five other sites.  The evaluation is based upon the feedback from the collaborating sites regarding the effectiveness of the agent-based teaching materials for the introductory course as well as the modules for other courses.  Results are being disseminated through a website, professional conference presentations and journal articles. <br/><br/>If the evaluation of the prototype produces positive results, future plans include full development of the agent-based concepts in collaboration with professors from the external sites, extending the course materials to Spanish-speaking audiences, and the publication of a textbook on agent-based computing.<br/>"
88884,Robotics as a Unifying Theme for Computing Curriculum 2001,DUE,CCLI-EDUCATIONAL MATERIALS DEV,1/1/2001,12/6/2000,Frank Klassner,"Klassner, F","Klassner, F|Anderson, S",PA,Villanova University,Standard Grant,Stephen R. Cunningham,6/30/2004,"$73,401.00 ",Scott Anderson,frank.klassner@villanova.edu,800 Lancaster Avenue,Villanova,PA,190851676,6105196000,EHR,7427,"7427, 9178, SMET",$0.00 ,normalFunding,"Computer Science (31) <br/>This project demonstrates that robotics (in particular, the LEGO<br/>Mindstorms platform) can be a cost-effective and widely-applicable tool for teaching a significant proportion of the ACM/IEEE Computing Curriculum 2001 (CC2001) Body of Knowledge. We are developing an extensible set of 30-40 assignments and laboratory exercises that use LEGO Mindstorms robot kits to motivate and support active student learning across applicable knowledge areas of the CC2001. Examples of such knowledge areas include concurrency in Operating Systems, distributed systems in Networking, and agent design in Artificial Intelligence. Secondly we create new software tools and adapt existing freeware packages available in the Mindstorms user community for our more advanced purposes."
320867,MRI:     Acquisition of dSPACE Real-Time Development System and Electromechanical Apparatuses for Research in Smart Control Systems,ECCS,MAJOR RESEARCH INSTRUMENTATION,8/1/2003,8/4/2003,Marc Karam,"Karam, M","Karam, M",AL,Tuskegee University,Standard Grant,Radhakisan S. Baheti,7/31/2005,"$72,349.00 ",,karam@tusk.edu,1200 W Montgomery Road,Tuskegee Institute,AL,360881923,3347278233,ENG,1189,"0000, 1189, 9150, OTHR",$0.00 ,normalFunding,"In the department of Electrical Engineering at Tuskegee University, the PI and three students<br/>(two graduates and one undergraduate) are conducting research in the area of Smart Control<br/>Systems. The following two projects are underway: robust optimal control using a recurrent<br/>dynamic neural network, and compensation of global feedback linearization control of nonlinear<br/>systems using neural networks. However, these research activities are confined to theoretical<br/>investigations and applications to computer simulated system models using Matlab/Simulink<br/>software from the MathWorks Inc. No physical plants and corresponding real-time<br/>implementation software are currently available to test the smart control algorithms and refine<br/>them.<br/>The requested instrumentation to be acquired includes the ACE1103PX4CLP prototyping<br/>system from dSPACE Inc., which contains powerful hardware and comprehensive software tools<br/>for development of real-time control systems. In order to apply the dSPACE products to actual<br/>plants, we are in addition requesting the acquisition of the following electromechanical<br/>apparatuses from ECP, a leading manufacturer of mechanisms for research in control: the<br/>Rectilinear Mass/Spring/Damper (ECP Model 210), the Industrial Plant Emulator (ECP Model<br/>220), the Inverted Pendulum (ECP Model 505), the Magnetic Levitator (ECP Model 730), and<br/>the Control Moment Gyroscope (ECP Model 750).<br/>The acquired instrumentation will contribute to greatly advancing the above-listed research<br/>projects by providing the possibility of implementing the current Matlab/Simulink codes and<br/>models of the neural controllers on dSPACE hardware, and testing them in real-time as applied<br/>to actual electromechanical apparatuses, as well as checking the robustness of the neural<br/>controllers in the presence of noise and disturbances. The feedback obtained from the actual<br/>implementation of the various neural algorithms will contribute to significantly evaluating,<br/>refining, and improving the smart controllers design.<br/>The intellectual merit of this proposal resides in the fact that, if funded, the smart control<br/>research at Tuskegee University would be greatly enhanced, which in turn would affect the<br/>global research community in the area of artificial intelligence and control, since several journal<br/>and conference publications have resulted thus far from this research, and more would result<br/>with higher quality if the instrumentation is acquired.<br/>Broader impacts of the requested instrumentation include introduction of a new graduate<br/>course in Advanced Control Design at Tuskegee University, which is an HBCU committed to the<br/>high quality education of African-American students. Moreover, the acquired equipment will<br/>boost the research level and researchers motivation and learning experience and contribute to<br/>attracting new graduate students to Tuskegee University that are interested in the area of smart<br/>control systems. The development of this area that is expected to occur due to the requested<br/>instrumentation will have the additional impact of attracting research funding from industry and<br/>government agencies. Furthermore, the experience that students will have with dSPACE<br/>products will be very beneficial for their future career, since these products are used in major<br/>industries worldwide. Finally the acquired equipment will encourage the multidisciplinary trend<br/>in the College of Architecture, Engineering, and Physical Sciences at Tuskegee University by<br/>being made equally available to the faculty and students of the Aerospace, Chemical, Electrical,<br/>and Mechanical Engineering departments, which all offer courses in control systems."
852139,Collab. Proposal: Partial and Point Identification of Causal Net and Mechanism Effects Under Different Treatment Assignments with Heterogeneous Effects: Theory and Applications,SES,ECONOMICS,2/15/2009,2/13/2009,Alfonso Flores-Lagunes,"Flores-Lagunes, A","Flores-Lagunes, A",FL,University of Florida,Standard Grant,Nancy A. Lutz,1/31/2010,"$72,195.00 ",,alfonsofl@ufl.edu,1 UNIVERSITY OF FLORIDA,GAINESVILLE,FL,326112002,3523923516,SBE,1320,"0000, OTHR",$0.00 ,normalFunding,"Within the literature on causal statistical inference, an important goal is to examine the causal mechanisms or channels through which the treatment or intervention affects the outcome of interest. Net (or direct) causal effects measure the effect of the treatment on the outcome while blocking the effect of the treatment on the variable that represents the mechanism. Hence, net effects are useful in learning about the ways in which the treatment causally affects the outcome and, as a result, can be used for policy purposes in the design, development, and evaluation of interventions. Despite their evident importance, the latest theoretical developments on the definition, identification, and estimation of this type of effects have taken place in fields outside economics. The research objectives of this proposal are to: (i) introduce developments on net and mechanism effects in other fields to economics, employing familiar econometric language; (ii) contribute to the literature on these causal effects by providing new conditions for their partial and point identification (nonparametric as well as parametric) under different treatment assignments, allowing for heterogeneous effects; and, (iii) provide relevant applications and simulations of the methods that can guide future applied research.<br/><br/>More specifically, this project first employs the potential outcomes framework (Neyman, 1923; Rubin, 1974) and related concept of principal stratification (Frangakis and Rubin, 2002) to introduce into economics the concepts of net average treatment effect (NATE) and mechanism average treatment effect (MATE). These two effects decompose the total average treatment effect (ATE). Related concepts have been previously introduced in other fields by Robins and Greenland (1992) and Pearl (2001). Second, this project provides new results for the nonparametric partial identification of net treatment effects under minimal assumptions. Subsequently, the project presents different sets of assumptions that allow parametric as well as nonparametric point identification of NATE. The nonparametric results follow from an application of the insights in the seminal work of Imbens and Angrist (1994) and Angrist, Imbens and Rubin (1996) on local average treatment effects. The analysis is done for the cases in which the treatment is randomly assigned, when selection is based on observables, and when selection is based on unobservables. This last case has not been considered in the recent literature on net effects in other fields, and it is important in economics. Finally, applications of the methodologies are provided based on substantive and well known empirical problems employing data sets available to the investigators. They will be complemented by Monte Carlo simulations. These simulations offer further insights on the application of the methods and the robustness of alternative identification assumptions.<br/><br/>This project makes a clear and significant contribution to the econometrics literature on causal inference. It also provides linkages among econometrics, statistics, epidemiology, artificial intelligence, and other areas that emphasize estimation of causal effects. The proposed research is also likely to impact many areas of economics and other sciences by adding new tools to the kit of applied researchers. This is particularly the case in those fields in which the estimation of treatment effects is important for analysis and policymaking, such as labor, public, agricultural and health economics, among others. To this effect, the project stresses the inclusion of empirical applications and simulations that will provide guidance for applied researchers as they implement the methods introduced in this proposal.<br/><br/>Broader Impacts: The results and methods developed in this project will be used as a teaching tool in graduate courses in economics and agricultural economics at the University of Florida and the University of Miami. The research assistants selected for the project ???who will help with coding the statistical programs for the empirical applications and simulations???will be well-trained in this regard, and every effort will be made to ensure that they come from underrepresented groups (which is anticipated to be no problem given the existing diversity at the principal investigators? institutions). The project also broadens the participation of underrepresented groups because both PIs, in addition to being junior faculty, are members of such a group. Finally, the project will promote synergies between the University of Miami and the University of Florida, and particularly between economics and agricultural economics, as the PIs are members of each department."
1319941,EAGER: Aggregating Online Information in Science,IIS,ROBUST INTELLIGENCE,9/15/2013,9/10/2013,Bruce Buchanan,"Buchanan, B","Buchanan, B",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Hector Munoz-Avila,8/31/2015,"$71,832.00 ",,buchanan@cs.pitt.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7916",$0.00 ,normalFunding,"This project continues the development of the AITopics information portal, a service to the Artificial Intelligence research community and an educational resource for the general public.  The portal can be found at www.aitopics.org. This site was originally conceived as a compendium of introductory and historical articles about artificial intelligence for use by the AI community as well as the general public. The initial prototype was a manual effort conducted by volunteers at the Association for the Advancement of Artificial Intelligence (AAAI). Following this, an NSF-funded effort was undertaken in 2012 to reduce the time required of volunteers without reducing the quality of information provided. This project advances the sophistication of the portal by  automating the time-consuming process of selecting content from the literature to post on the website, and by enhancing a deployed AI news finder program employed to feed the site with fresh content. The ultimate goal of this work is to build a generally useful content management framework that would be applicable to such outreach effort across all sciences. <br/><br/>The project activities include A) development of the NewsFinder program to browse online AI journals as well as current periodicals to find interesting overview articles; B) creation of additional content management technology including tools for user interaction and feedback; creation of meta-data for search engines, creation of summary descriptions; automatically learning criteria for interesting items; and creation of tools to identify new topics as the field changes; C) continued curating of online versions of classic books and papers, including scanning material only available in hard copy; D) extension of NewsFinder to find articles describing new applications in each Applications area; E) as well as to provide useful information to practitioners in a new area of technology, including classification of IAAI papers by industry and type of problem; and F) expansion of the use of social media and mobile devices to refine and deliver information."
1343,Power Engineering Load / Component Modeling Using Advanced Concepts Of Dynamic Systems and Data Mining for Risk Management,ECCS,"GRANT OPP FOR ACAD LIA W/INDUS, CONTROL, NETWORKS, & COMP INTE, AMERICAS PROGRAM",7/15/2001,5/16/2002,Gerald Heydt,"Heydt, G","Heydt, G",AZ,Arizona State University,Continuing grant,James Momoh,6/30/2003,"$70,998.00 ",,heydt@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,ENG,"1504, 1518, 5977","0000, 1504, 5922, OTHR",$0.00 ,normalFunding,"0001343<br/>Heydt<br/><br/>This is a proposed project in electric power engineering. The main thrust is the application of advanced mathematical tools in the area of power system component and load modeling. The project spans five researchers at three universities; two universities are in Mexico and one in the United States. The emphasis is on the condensation and processing of time series recorded electrical system measurements for power system load and component models. A goal of the work is the enhancement of model accuracy. The use of these models in a deregulated environment is proposed to manage power system operating risk while maximizing operating revenues. Of course, accurate models are also needed in the mainstream operation of power systems, regulated or deregulated, for such tasks as stability studies, reliability analysis, system loading, and control of power flow. The main methods to be studied are: symbolic analysis, blended models, data mining, and risk management. Because the level of mathematical models is complex, part of the project is to prepare these methods in a form suitable for visualization by power system operators.<br/><br/>The project contains an educational component which includes a research experience for undergraduates, development of a web site on electrical load and component modeling, and a workshop/meeting for researchers and students from both Mexico and the USA. The intent of the website is to acquaint students and practicing engineers alike on the capabilities of advanced modeling techniques. In the case of power engineering students, the goal is to attract highly qualified persons to the field. In the case of practicing engineers, the PI would like to provide to them tools so that they can utilize the data at their disposal."
9704436,A New Class of Model Selection Criteria Based on Kullback's Symmetric Divergence,DMS,STATISTICS,7/1/1997,5/14/1997,Joseph Cavanaugh,"Cavanaugh, J","Cavanaugh, J",MO,University of Missouri-Columbia,Standard Grant,Gabor J. Szekely,12/31/2000,"$70,120.00 ",,cavanaugh@stat.missouri.edu,115 Business Loop 70 W,COLUMBIA,MO,652110001,5738827560,MPS,1269,"0000, OTHR",$0.00 ,normalFunding,"                  A New Class of Model Selection Criteria                   Based on Kullback's Symmetric Divergence                              Joseph E. Cavanaugh                     University of Missouri - Columbia    The selection of a statistical model from a collection of candidates can   often be facilitated by the use of a model selection criterion, which   evaluates a fitted model by assessing whether it offers an optimal balance   between ""goodness of fit"" and parsimony.  This research considers the   development of model selection criteria based on Kullback's symmetric   divergence measure.  The symmetric divergence is related to Kullback's   directed divergence, better known as the Kullback-Leibler information,   which serves as the basis for the well-known Akaike information criterion   and its subsequent variants.  In the context of model selection, the   symmetric and directed divergence can both be utilized to measure the   discrepancy between the model which presumably generated the data and a   fitted approximating model.  It can be argued, however, that the symmetric   divergence is more sensitive to deviations between these two models and   therefore functions as a better discriminant.  Consequently, an estimator   of the symmetric divergence may serve as a more effective model selection   criterion than an estimator of the directed divergence, provided that   the former estimator is accurate enough to sufficiently reflect the   sensitivity of the targeted measure.  The preceding notion serves as the   impetus for this research, which involves the development and investigation   of a new class of model selection criteria based on estimation of the   symmetric divergence.    Scientists who model phenomena are often faced with the dilemma of how to   choose an appropriate model to characterize an underlying set of data.    A model selection criterion is a measure which assigns a ""score"" to each   model in a candidate collection, an index which reflects how well the   associat ed model satisfies a certain optimality principle.  These scores   allow an analyst to simply and objectively choose a final model based on   an evaluation of a potentially expansive class of candidates.  Thus, model   selection criteria provide an ideal means for the computer to occupy a   central role as a decision maker in statistical investigations.    The importance of this notion is discussed by Cheeseman and Olford   (""Selecting Models from Data: Artificial Intelligence and Statistics IV,""   Springer-Verlag Lecture Notes in Statistics, 89, page v):     ""...Computers will increasingly be required to draw robust      inferences from data, sometimes very large quantities of data...      And, because the scale of the problems arising from large computer      databases quickly overwhelms the human analyst, it is desirable to      have a computer assume as much of the role of analyst as possible.""  In the future evolution of statistical methodologies and practices, model   selection criteria will play an increasingly vital function.  Thus, it is   essential that continuing work is conducted in this area, pertaining not   only to the evaluation and improvement of existing criteria, but also to   the introduction and investigation of new criteria based on appealing   statistical principles.  This research focuses on the latter.  The results   of this investigation will have potential impact on many scientific areas,   including engineering (e.g., image and signal processing), economics (e.g.,   econometric modeling), and computer science (e.g., artificial   intelligence).     ------------------------------------------------------------------------------"
1736056,EXP: Collaborative Research: Empowering Learners to Conduct Experiments,IIS,IUSE,9/1/2017,8/23/2017,Steven Sutherland,"Sutherland, S","Sutherland, S",TX,University of Houston - Clear Lake,Standard Grant,William Bainbridge,8/31/2019,"$70,000.00 ",,Sutherland@UHCL.edu,2700 Bay Area Boulevard,Houston,TX,770581002,2812833016,CSE,1998,"8045, 8209, 8841, 9178",$0.00 ,normalFunding,"This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
9711202,The Epistemology of Non-Symbolic Cognition,SES,Hist & Philosophy of SET,10/1/1997,9/19/1997,Robert Cummins,"Cummins, R","Cummins, R",AZ,University of Arizona,Continuing grant,Edward J. Hackett,9/30/1998,"$70,000.00 ",,rcummins@ucdavis.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,SBE,1353,"0000, OTHR",$0.00 ,normalFunding,"A central problem in understanding the brain concerns how knowledge is stored in synaptic connections among neurons.  In artificial neural networks this phenomenon is modeled by connection weights, which determine how much of the activation of one neuron is passed to another neuron.  The goal of this project is to understand how knowledge is stored in a set of connection weights, and to use this understanding as the foundation for an epistemology that is directly grounded in what we know of the brain.  Our understanding of the brain and of the neural networks that model it, including those used for artificial intelligence purposes, will be limited until we understand how to correlate specific changes in connection weights with specific changes in stored knowledge.  For similar reasons, psychological explanations of cognitive processes and the philosophic theories of epistemology that build on them both rely fundamentally on understanding what knowledge is stored, and under what conditions, within a neural network."
742109,The Role of Sensorimotor and Perceptual Features in Perceiving and Enacting Actions,IIS,Cyber-Human Systems (CHS),9/1/2007,8/21/2007,Shulan Lu,"Lu, S","Lu, S|Henley, T|Harter, D",TX,Texas A&M University-Commerce,Standard Grant,Ephraim P. Glinert,8/31/2008,"$70,000.00 ","Tracy Henley, Derek Harter",lu.shulan@gmail.com,Office of Sponsored Programs,Commerce,TX,754293011,9038865964,CSE,7367,"7367, 9102, 9215, 9237, HPCC",$0.00 ,normalFunding,"Providing virtual training has become an increasingly important method for training skills that are risky, expensive, or otherwise infeasible to carry out in the real world (e.g., military operations). One long standing question has been how well skills learned in a simulated training environment can be transferred to real world practice. The simulated world differs from the real world in a number of aspects. In particular, there are significant differences in sensory, motor, and perceptual features.  Advances in embodied cognitive science have consistently demonstrated how the human body, and the environment which the body inhabits, together form a complex system in producing mental activities. However, most studies that have been reported thus far only examined small incremental differences in cognitive processes as predicted by the embodied versus classic cognitive science. There are few studies that have investigated whether the incremental differences will translate into tangible consequences in learning new skills. The central hypothesis being investigated in this research project is whether there are differences in how people perceive and enact risky versus non-risky actions in the simulated versus the real world. One of the major difficulties in such studies is to create simple parallel task environments that are amenable to controlled experimentation but can be scaled up for real world applications. This research project accomplishes this by selecting everyday actions that can be inherently risky and uses methods that examine the time course in which event perception unfolds. For perceiving actions, participants will perform perceptual segmentation tasks, have their eye movements recorded, and answer questions regarding the memory of actions. For enacting actions, participants will indicate how they would complete the actions. <br/><br/>The long-term practical objective of this research is to provide an empirical basis for developers of simulated training environments in the following three areas: 1) determining the appropriate level of specifications for perceptual and sensory information; 2) determining the appropriate level of instructions to either highlight or compensate some of the significant differences that result from enacting actions in the simulated world; and, 3) determining what actions can be learned via simulations versus what actions ought to be learned via real world practices. This research project brings together an interdisciplinary integration of theory and empirical research from the fields of embodied cognitive science, artificial intelligence, human-computer interaction, and robotics.  Cognitive psychology has not begun, until recently, to understand how humans spontaneously segment the constant flux of multimodal information into discrete events and exert cognitive control over the ongoing world. This research project goes a step forward towards conceptualizing human and complex machine behaviors in terms of the multimodal segmentations of the incoming world. The better design of simulated environments will result from this understanding and will benefit all of society, in which we are increasingly interacting with technology and being trained in technology driven learning environments."
1650204,EAGER: Lexicalized Reasoning,IIS,ROBUST INTELLIGENCE,9/1/2016,8/30/2016,Christopher Geib,"Geib, C","Geib, C",PA,Drexel University,Standard Grant,James Donlon,8/31/2017,"$69,474.00 ",,cwg33@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,7495,"7495, 7916",$0.00 ,normalFunding,"Many problems in artificial intelligence form natural pairs of a recognition and generation problem.  For example, parsing natural language sentences, and generating new natural language sentence are natural inverses.  Similarly, recognizing the plans being executed by others and building our own plans seem intimately intertwined. Unfortunately research on methods to solve these problems has often required specialized representations and algorithms.  As a result, unified models of intelligence remain elusive and the results from one problem area do not translate to another.  This project is part of a research program based on the idea that unified models of intelligence require unifying representations and algorithms across research problems.  In particular, in the last ten years, Steedman's Combinatory Categorial Grammars (CCGs), which had already been shown to be successful in both natural language parsing and generation, have been shown to be effective for both directing probabilistic plan recognition and planning.  This gives us good evidence for seeing CCGs as a unifying representation.  However, this success immediately raises the question where do such grammars come from, and can they be learned?  The main goal of this project is to begin to answer this question.<br/><br/>Natural language researchers have proposed a number of methods for learning CCGs for natural languages. However, none of these methods have been applied to the learning of grammars for plans.  Therefore, this project is the first exploration of these algorithms for learning grammars to direct plan recognition and planning.  Specifically, the focus of this work will be to modify a recently published algorithm for learning natural language CCGs to learn plan grammars.  We will use input datasets generated from the publicly available International Planning Competition domains and attempt to learn grammars to both recognize future instance of plans and to direct the construction of future plan instances.  We will evaluate the effectiveness of the learned plan CCGs using traditional metrics from language grammar learning.  In addition, since these CCGs are intended specifically to direct planning and plan recognition, we will measure the effectiveness of the resulting CCG at these problems using the traditional metrics from these research areas.  For planning this includes runtime and length of plan, and for plan recognition accuracy, runtime, and mean time to recognition."
737207,Workshop on Contemporary Approaches to Human-Level Artificial Intelligence,IIS,ROBUST INTELLIGENCE,6/15/2007,8/15/2008,Leslie Kaelbling,"Kaelbling, L","Kaelbling, L",MA,Massachusetts Institute of Technology,Standard Grant,Douglas H. Fisher,5/31/2009,"$68,374.00 ",,lpk@csail.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,"7495, 9218, HPCC",$0.00 ,normalFunding,"Proposal 0737207<br/>""Workshop on Contemporary Approaches to Human-Level Artificial Intelligence""<br/>PI: Leslie P. Kaelbling<br/>MIT<br/><br/><br/>ABSTRACT<br/><br/>This award supports the organization and the participation of approximately 35 experts in a two-day workshop to be held July 12-13, 2007 at MIT Endicott House in Dedham, Massachusetts. The purpose of this workshop is to bring together leading researchers in Artificial Intelligence to assemble a research agenda for developing AI systems capable of human level performance (Human Level AI or HLAI). HLAI includes the following constellation of capabilities exhibited by human beings: (1) The ability to adapt and survive for an extended period of time in a rich, complex physical and social environment; (2) The ability to learn throughout this extended period of existence and, in particular, to improve performance on a fixed set of tasks, learn to perform new tasks, transfer knowledge and skill from one task to another, the ability to execute a new task after being told (or shown) how to do it; (3) The ability to reason about their own capabilities and limitations, to formulate new tasks, and to gather information needed for learning how to perform those tasks; (4) The ability to communicate and interact (e.g., cooperate) with other agents, to form teams, to recognize the goals, beliefs, and intentions of other agents, to persuade and negotiate with other agents; and (5) The ability to design and execute changes in the environment (physical and social) to improve their ability to survive and achieve their goals. In other words, an HLAI system is characterized by the potential to perform a great breadth of tasks--including those not pre-envisioned by the system designer--and by the ability to reflect on and improve all of its own capabilities, and to do so in a robust, flexible manner. This workshop will review the current state of the art, propose new integrated architectures for robust integrated intelligent systems, and suggest ways for researchers to leverage results across the many subspecialties in AI."
725478,Natural and Artificial Intelligence - An International Workshop at Oxford University (Oxford),IIS,ROBUST INTELLIGENCE,4/15/2007,4/12/2007,Paul Cohen,"Cohen, P","Cohen, P",CA,University of Southern California,Standard Grant,Sylvia J. Spengler,3/31/2008,"$67,978.00 ",,cohen@sista.arizona.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,"1707, 9218, HPCC",$0.00 ,normalFunding,"Proposal 0725478<br/>""Natural and Artificial Intelligence An International Workshop at Oxford University (Oxford)""<br/>PI: Paul R. Cohen<br/>University of Southern California<br/><br/><br/><br/><br/>ABSTRACT<br/><br/>This proposal will subsidize in part the participation of experts from the U.S. in a three-day workshop to be held June 24-27, 2007 at Oxford University in Oxford, England. The primary objective of the workshop is to bring together two remote scientific communities in artificial intelligence/cognitive science and behavioral ecology to discuss various aspects of cognition in humans, other animals, and artificially intelligent systems. The goal is to elucidate general cognitive principles what the workshop organizers term universal models of cognition that apply in humans, animals and AI systems. A secondary goal of the meeting is to help establish collaborative research relationships among scientists in the contributing fields and among researchers from the US, Europe, and other countries. The workshop will involve approximately 30 experts from AI, cognitive science, behavioral ecology, and psychology. Approximately half will be from the U.S. This award will be used to help defray the costs (airfare, hotels, meals, etc.) for the U.S. attendees."
536375,CAREER:  Artificial Intelligence Planning with Realistic Preference Models,IIS,ARTIFICIAL INTELL & COGNIT SCI,2/15/2005,9/19/2005,Sven Koenig,"Koenig, S","Koenig, S",CA,University of Southern California,Continuing grant,Douglas H. Fisher,1/31/2007,"$67,147.00 ",,skoenig@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,6856,"1045, 9216, 9218, HPCC",$0.00 ,normalFunding,"This is the first year of funding of a 4-year continuing award. Preference models determine which one of several plans to prefer. It is important that planners use the same preference models as human decision makers because planners should make the same decisions as their human users, otherwise the planners are not of much use. The PI will investigate how to build planners that fit the preference models of human decision makers better than current planners, by combining constructive methods from artificial intelligence with more descriptive methods from utility theory in order to take advantage of the strengths of the two decision-making disciplines and to extend the applicability of Al planners. The PI will study optimal vs. good or near-optimal (""satisficing"") planning with a variety of preference models. He win explore how to exploit the structure of complex sequential planning tasks to solve them efficiently for realistic preference models suggested by utility theory, with an emphasis on preference models in high-stakes decision situations. To this end, he will focus on representation changes that make use of existing planners from AI by transforming planning tasks with nonlinear utility functions into others that these planning methods can solve, and will study the errors that result for the original planning task when satisficing planning methods are used instead. The research will be performed in the context of managing environmental crisis situations, such as cleaning-up marine oil-spills."
9706159,U.S.-Brazil Workshop on Intelligent Robotic Agents,IIS,"CISE RESEARCH INFRASTRUCTURE, AMERICAS PROGRAM, ROBOTICS, DIGITAL SOCIETY&TECHNOLOGIES, ARTIFICIAL INTELL & COGNIT SCI",2/15/1997,2/14/1997,Manuela Veloso,"Veloso, M","Veloso, M",PA,Carnegie-Mellon University,Standard Grant,Larry H. Reeker,1/31/1998,"$65,000.00 ",,veloso@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"2885, 5977, 6840, 6850, 6856","9216, HPCC",$0.00 ,normalFunding,"     It has been a long-standing goal of both the Artificial  Intelligence and the Robotics communities to develop  physical artifacts that can act intelligently .  From the  Robotics side, the priority has been on the development of  mechanical agents that would exhibit navigation,  manipulation, perception, and action skills, along with the  ability to work cooperatively.  The results on low-level  control, including sensor uncertainty, limited reasoning  about geometric and physical properties, and skills like  object avoidance have proved interesting and useful, but  most autonomous robotic agents still lack the ability to  perform higher level intelligent operations either alone or  in concert.  This is partly because of their need to proceed  with reasonable expedience, while the known methods are  demonstrably very complex, and therefore slow.  It is hoped  that recent results in AI planning, learning, reasoning, and  cooperation among agents will help in bridging the gap  between high-level reasoning and low-level physical  execution.  The purpose of this workshop is to examine the  available results and research agenda in this `bridging`  area, while also establishing international links between  American and Brazilian researchers working in the same areas  and between NSF and its Brazilian counterpart organization  CNPq, which will provide support for the Brazilian  participants."
834032,Recursion: Structural Complexity in Language and Cognition,SBE,Science of Learning Activities,10/1/2008,9/29/2008,Margaret Speas,"Speas, M","Speas, M|Roeper, T",MA,University of Massachusetts Amherst,Standard Grant,Joan Straumanis,1/31/2010,"$64,737.00 ",Thomas Roeper,pspeas@linguist.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,SBE,7704,"0000, OTHR",$0.00 ,normalFunding,"Workshop on Recursion<br/><br/>It is well-known that language is an window into the human mind, not<br/>just because our words reveal our thoughts, but because the way we put<br/>words together reflects principles of organization that allow<br/>creativity to flourish. Recent mathematically based research in<br/>linguistic theory has identified computational principles that promise<br/>to provide the software behind our neurological hardware. This<br/>workshop will bring together linguists, biologists, psychologists,<br/>philosophers and computer scientists who are discovering how these<br/>linguistic principles provide the abstract basis for language learning<br/>and learning in general. Central to this enterprise is a simple<br/>concept, recursion, the idea of building complex structures through<br/>repeated application of simple rules, which may provide a metaphor for<br/>the organization of all human action.<br/><br/>This workshop is timely because research on complex structures in<br/>language and cognition is now reaching a point where the various types<br/>of complexity can begin to be defined with sufficient precision to<br/>consolidate results and discover the sources and limits of complex<br/>human cognition. By identifying the ways in with complex structures<br/>and complex can arise from the application of simple rules, this<br/>research lays the foundation for new ways of designing curriculum for<br/>optimal learning, new perspectives on artificial intelligence and new<br/>insight into the evolutionary changes that distinguish animal<br/>cognition from human cognitive abilities."
9803782,Using Knowledge Discovery in Database & Data Mining to Develop Techniques in Medical Informatics Applied to Surgical Databases,DMS,"INFRASTRUCTURE PROGRAM, OFFICE OF MULTIDISCIPLINARY AC",6/1/1998,4/24/1998,Patricia Cerrito,"Cerrito, P","Cerrito, P",KY,University of Louisville Research Foundation Inc,Standard Grant,Lloyd E. Douglas,5/31/2000,"$64,676.00 ",,pcerrito@louisville.edu,The Nucleus,Louisville,KY,402021959,5028523788,MPS,"1260, 1253","0000, 1504, OTHR",$0.00 ,normalFunding,"The tools used in the field of medical informatics are those of knowledge discovery in databases (KDD) or alternatively, data mining. KDD spans a variety of fields: statistics, pattern recognition, artificial intelligence, and data warehousing. However, it has become a distinct discipline with its own objectives. The purpose of data mining is to extract previously unknown and potentially useful information. KDD differs from the more traditional statistical tools by focusing on model identification while minimizing misclassification. Statistical methods tend to focus on estimation and model identification. The hypotheses generated by the KDD process must then be validated by standard statistical techniques. It has become increasingly clear that more traditional techniques are not adequate because of the size and complexity of the databases. One 450-bed hospital maintained a database with six months of laboratory tests and medications as well as summaries of patient followup for 15 months. The storage capacity of the computer had to be increased by 12 gigabytes. The dependence upon an investigator examining relationships in the data must yield to an automated process. KDD can generate interesting and unexpected hypotheses which can be examined by statistical methods. The automatic hypothesis formation and testing cycle can continue until important patterns emerge. This project involves the study and development of data mining techniques applied to several databases primarily stored in the Alliant Health System. This includes a database containing a 25-year followup on a cohort of 10,000 women in Kentucky to examine patterns of health and lifestyle. In addition, the techniques will be applied to a database of student information to examine relationships between student habits, student success, and student learning. Using the developed materials and databases, a course will be taught to students in the Department of Mathematics on applications of data mining. This GOALI project is jointly supported by the MPS Office of Multidisciplinary Activities (OMA) and the Division of Mathematical Sciences (DMS)."
9729875,CISE Instrumentation: Applying Software Engineering         Methodologies to Robotics Tasks: A Cross Disciplinary       Approach,EIA,CISE RESEARCH RESOURCES,12/1/1997,12/15/1997,Mats Per Erik Heimdahl,"Heimdahl, MPE","Heimdahl, MPE|Boley, D|Gini, M|Papanikolopoulos, N",MN,University of Minnesota-Twin Cities,Standard Grant,Frederica Darema,11/30/1999,"$64,011.00 ","Daniel Boley, Maria Gini, Nikolaos Papanikolopoulos",heimdahl@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,2890,"9218, HPCC",$0.00 ,normalFunding,"9729875  Heimdahl, Mats, P.E.  University of Minnesota, Twin Cities     CISE Research Instrumentation: Applying Software Engineering Methodologies to Robotics Tasks: A Cross Disciplinary Approach    This research instrumentation enables research projects in:- Rapid Prototyping and Synthesis of Software for Embedded Systems, - Studies of Different Issues in Vision-Based Robotic Grasping,- Sensor Fusion in Vehicle Applications, and  - Behaviors of Multiple Self-Interested Robots.    To support the aforementioned projects, the Department of Computer Science at the University of Minnesota will purchase a VXI-bus embedded real-time software development environment, several mobile platforms, and robot simulation software which will be dedicated to research in software engineering, robotics, and artificial intelligence. The equipment will be used for several research projects, including in particular: requirements-based prototyping and synthesis of control software for embedded systems, closed-loop vision-based robotic grasping, sensor fusion for vehicle applications, and behaviors of multiple self-interested robots.      In addition to the contributions of the individual projects, the collaboration between the PIs will help evaluate cutting edge software engineering techniques on realistic projects (for example, evaluation of scalability, evaluation of ease of use, and applicability to the domain) as well as evaluate the use of  rigorous software engineering techniques in robotics and AI applications (for example, the effect on reuse of control algorithms, and the effect on system performance, robustness, and safety).    The equipment purchase includes (1) a complete VXI-bus embedded software development environment, (2) one VXI-bus embedded computer with interfaces for sensing and control applications, (3) low-cost mobile platforms serving as testbeds for the proposed projects, and (4) robotics simulations software to be used in task planning and software prototyping."
1450502,A Workshop on Extensible Distributed Systems,CNS,Computer Systems Research (CSR,9/1/2014,8/25/2014,Robbert VanRenesse,"VanRenesse, R","VanRenesse, R|Alvisi, L",NY,Cornell University,Standard Grant,M. Mimi McClure,8/31/2015,"$60,772.00 ",Lorenzo Alvisi,rvr@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7354,7556,$0.00 ,normalFunding,"A Distributed System is a system consisting of multiple computers communicating through message passing.  In the past 50 years, distributed systems have evolved from being a novelty to a fact of life---a very large fraction of computers today are part of a distributed system.  With computers, sensors, and actuators becoming embedded in virtually every device, users are themselves becoming, as it were, embedded in a ubiquitous computing fabric.  An Extensible Distributed System is a distributed system that is pervasively integrated into people's environments.  The distributed systems research community has developed models and techniques that have supported this remarkable success story and enabled technologies, such as cloud computing, that have the potential to fundamentally change the way in which individuals, businesses, and government access computing resources.  The pervasive or ubiquitous systems community in the meantime has leveraged distributed systems and networking technology, as well as artificial intelligence, to integrate devices even closer into our experience.  And in the post Dennard-Scaling era, computer architecture is undergoing a profound transformation, and, in an effort to address the conflicting goals of delivering performance and saving energy, it is exploring designs that are exporting weaker abstractions to software developers.<br/><br/>There are, however, gaps between the foundations built by the various research communities and the opportunities offered by today's and tomorrow's applications and infrastructure.  To respond to these challenges, the field not only needs to profoundly retool today's techniques and abstractions, but also to develop a new vision, designed to address the opportunities offered by new hardware, new networking, and new applications. This project supports a workshop that will serve as a catalyst for triggering the process of reflection and innovation necessary to develop this new vision and the research agenda that will bring it about.<br/><br/>Extensible Distributed Systems are the cornerstone of, to name a few, cloud computing, sensor/actuator networks, and industrial control systems, and their impact and ubiquity is likely to only increase in the next decade. The in-depth discussions about the state of field and research agenda that this workshop aims to develop are thus likely to have tremendous impact on society. In addition to helping define a research agenda for the extensible distributed systems community, this workshop will help crystallize the shape of future graduate and undergraduate education in distributed computing.  The workshop will balance academic and industrial participation, will engage leaders in the field, and will actively seek participation from underrepresented groups."
2050,COLLABORATIVE RESEARCH: RUI: Perceptual Grouping Effects on Perceived Lightness,BCS,HUMAN COGNITION & PERCEPTION,9/1/2000,7/27/2000,Joseph Cataliotti,"Cataliotti, J","Cataliotti, J",NJ,Ramapo College of New Jersey,Continuing grant,Rodney R. Cocking,11/30/2000,"$59,786.00 ",,jcatalio@ramapo.edu,505 Ramapo Valley Road,Mahwah,NJ,74301623,2016847500,SBE,1180,"0000, 9229, OTHR",$0.00 ,normalFunding,"BCS-0002050<br/>PI: Cataliotti<br/><br/> The human visual system perceives shades of gray with remarkable accuracy despite large changes in the intensity of the illumination and the brightness of surrounding surfaces. For example, a middle gray piece of paper will generally appear middle gray regardless if it illuminated by a bright light or a dim light. The change in illumination results in retinal images that are also very different, yet in most cases the paper is perceived as middle gray. Lightness contrast and other errors have been studied in an attempt to understand more fully the visual system's design and logic in determining shades of gray. Simultaneous lightness contrast (SLC) has been one of the most widely studied of these errors. SLC is illustrated by placing a gray target on a white background and a physically identical gray target on a black background. The target on the white will appear darker than the target on black. Models attempting to explain SLC can be grouped into two main categories: 1) models that treat SLC as a residual byproduct of low-level retinal processes, namely, lateral inhibition, and 2) models based on perceptual grouping processes that must take place above the retinal level in the visual pathway. Perceptual grouping models are not well defined in terms of physiological structuresand functions. The main goal of the proposed project is to more fully explore the roles perceptual grouping processes play in determining perceived surface color. The research will focus on three novel paradigms recently discovered in the PIs' lab. One set of experiments will involve a variation of SLC in which two gray targets appear to move across their respective backgrounds. Another set of experiments will require the observer to fuse gray targets presented to one eye with backgrounds presented to the other eye. In a third set, the observer will judge the lightness of sequentially presented targets in an effort to understand the effect of the perceived gray shade of one surface on the perceived gray of a subsequently viewed surface. Experiments will test whether these recently discovered phenomena are primarily the results of retinal processes or perceptual processes that occur at a higher level in the visual system. <br/><br/> The results of these experiments will contribute to a better understanding of the mechanisms underlying these effects, their location, and the interaction between subsystems involved in determining perceived surface color. In short, the search field for neurological mechanisms important for perceived surface color will be narrowed. Models based on perceptual grouping may be better operationally defined in terms of neurobiology. This research will contribute to the fields of perceptual psychology, neuropsychology and artificial intelligence."
630206,CAREER: Knowledge Discovery in Databases and Data Mining as New Tools to Support Research and Educational Advances in Modern Construction Management,CMMI,CIVIL INFRASTRUCTURE SYSTEMS,6/1/2005,7/13/2006,Lucio Soibelman,"Soibelman, L","Soibelman, L",PA,Carnegie-Mellon University,Standard Grant,Edward John Jaselskis,8/31/2006,"$59,692.00 ",,lucio@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,ENG,1631,"1039, 1045, 1057, 9102, 9251, CVIS, 029E",$0.00 ,normalFunding,"ABSTRACT CMS0094022 ""Knowledge Discovery in Databases and Data Mining as New tools to Support Research and Educational Advances in Modern Construction Management "" PI: Lucio Soibelman, University of Illinois at Urbana-Champaign<br/><br/>The construction industry is seeing an explosive growth in its capabilities to both generate and collect data. Advances in scientific data collection, the introduction of bar codes for almost all-commercial products, new sensor technologies, wireless computing, and new laser scanning technologies, have generated a flood of data. These advances coupled with advances in data storage technology, such as faster, higher capacity, and cheaper storage devices, better database management systems, and data warehousing technology, have increased the availability of computerized construction data. However, in most cases, these data are used only for communication purposes and stored in a file or a database without being analyzed. This project intends to study this increasing amount of available data by applying data mining and knowledge discovery in databases. Knowledge discovery in databases and data mining are technologies that combine techniques from machine learning, artificial intelligence, pattern recognition, statistics, databases and visualization to automatically extract concepts, concepts interrelationships, and patterns of interest from large databases. <br/>The objectives of this CAREER program are to: 1) Generate improved methods to obtain novel knowledge from large construction databases developing model-building templates and wizards to guide novice construction knowledge model builders through the process of creating models based on their own data; 2) Improve access to past construction management experience and knowledge by practitioners and students; 3) Use active learning techniques to improve education of students at all levels by developing an educational simulation game with the knowledge generated during this research; and 4) Teach civil and environmental engineering graduate students the process of knowledge generation through the application and development of data mining, machine learning and artificial intelligence tools.<br/>Given the importance of the construction industry in the U.S economy and the large amount of money wasted in litigation due to project delays, impractical budgets, and projects that neither satisfy quality requirements nor meet performance expectations, improved management tools are critically needed. This research promises to result in valuable management tools for improving project planning and control, which, if applied to large-scale infrastructure projects, may result in substantial cost savings nationwide. These research benefits can be extended to all sub-fields of construction management"
9860759,SBIR Phase I: Aeroshaping Optimization Using Computational Fluid Dynamics,IIP,SMALL BUSINESS PHASE I,1/1/1999,12/8/1998,James Gallo,"Gallo, J","Gallo, J",NY,QuEST LLC,Standard Grant,G. Patrick Johnson,6/30/1999,"$58,500.00 ",,galloj@quest-llc.com,155 Erie Boulevard,Schenectady,NY,123052235,3132743888,ENG,5371,"1057, 1441, CVIS",$0.00 ,normalFunding,"9860759<br/> This Small Business Innovation Research Phase I project aims at developing a shape design optimization tool by integrating a state-of-the-art computational fluid dynamics (CFD) technique within an efficient multi-disciplinary design optimization (MDO) strategy. The ability to adaptively optimize aerodynamic shape of hypersonic flight vehicles is an issue of prime interest to aircraft and spacecraft designers. The physics of flow and the spectrum of aerodynamic features involved in this flight regime are quite involved and include expansions, shocks, separation, recirculations, and reattachments. The computational simulation of such complex flow fields requires an efficient, robust, and extremely accurate numerical solution technique that is stable for a wide range in Reynolds number and Mach number flows. At the same time, nonlinear optimization of aerodynamic shape requires a sequence of these problems to be solved successively to arrive at an optimum design. The optimization techniques that can reduce the number of redundant design options can result in considerable savings in time. Employing an Artificial Intelligence (AI) network around this highly accurate shape design synthesis capability, the resulting tool shows a drastic reduction in the number of cycles required to reach an optimum aerodynamic shape, thus economizing the design cycle and reducing the cost and time.<br/> If successful, the project will lead to an inexpensive and fast tool for aerodynamic shape optimization of hypersonic and transonic flight vehicles. The two products from this work; (a) the optimization tool, and (b) the flow solver, will be marketed as stand-alone capabilities as well as an integrated design-optimization software. In addition to the aeronautical industry, this software will be of tremendous interest to the automotive industry for aerodynamic shape optimization of the new generation cars, trucks and bullet trains."
1736899,Cambridge to Cambridge Competition Support,DGE,"GVF - Global Venture Fund, CYBERCORPS: SCHLAR FOR SER",7/1/2017,7/21/2017,Howard Shrobe,"Shrobe, H","Shrobe, H",MA,Massachusetts Institute of Technology,Standard Grant,Victor P. Piotrowski,6/30/2018,"$56,193.00 ",,hes@csail.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,EHR,"054Y, 1668","5946, 5980, 9178, 9179, SMET",$0.00 ,normalFunding,"In 2015, as part of a series of cybersecurity initiatives made public by the U.K. Prime Minister and the U.S. President, the two nations announced that MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Cambridge, would organize a special collaborative competition in cybersecurity dubbed Cambridge2Cambridge. The event took place in 2016 at MIT and the two universities agreed to a follow-on event, to be held in the summer of 2017. Cambridge University will host this event at their campus in the U.K. and the event will include several schools from the United States. Thirty-one U.S. students have been selected based on their performance in a preliminary contest including students from MIT, Carnegie-Mellon University, Columbia University, United States Air Force Academy, Worcester Polytechnic Institute, University of Tampa and University of Puerto Rico. All of the U.K. Centers of Cyber Excellence (sponsored by the Government Communications Headquarters, GCHQ) will participate and represent the U.K.<br/><br/>This project promotes international cooperation in cybersecurity, furthering relationships between countries and among students. Several private companies with advanced cybersecurity capabilities, including Boeing, BP, Raytheon, BAE Systems, State Farm Insurance and Akamai, will provide mentors for student participants. They will encourage students to consider careers in a field that is intellectually challenging and of critical importance to U.S. and international security. This award is co-funded by the Global Venture Fund from the NSF's Office of International Science and Engineering."
852211,Partial and Point Identification of Causal Net and Mechanism Effects Under Different Treatment Assignments with Heterogeneous Effects: Theory and Applications,SES,ECONOMICS,2/15/2009,2/13/2009,Carlos Flores,"Flores, C","Flores, C",FL,University of Miami,Standard Grant,Nancy A. Lutz,1/31/2010,"$55,537.00 ",,caflores@miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,SBE,1320,"0000, OTHR",$0.00 ,normalFunding,"Within the literature on causal statistical inference, an important goal is to examine the causal mechanisms or channels through which the treatment or intervention affects the outcome of interest. Net (or direct) causal effects measure the effect of the treatment on the outcome while blocking the effect of the treatment on the variable that represents the mechanism. Hence, net effects are useful in learning about the ways in which the treatment causally affects the outcome and, as a result, can be used for policy purposes in the design, development, and evaluation of interventions. Despite their evident importance, the latest theoretical developments on the definition, identification, and estimation of this type of effects have taken place in fields outside economics. The research objectives of this proposal are to: (i) introduce developments on net and mechanism effects in other fields to economics, employing familiar econometric language; (ii) contribute to the literature on these causal effects by providing new conditions for their partial and point identification (nonparametric as well as parametric) under different treatment assignments, allowing for heterogeneous effects; and, (iii) provide relevant applications and simulations of the methods that can guide future applied research.<br/><br/>More specifically, this project first employs the potential outcomes framework (Neyman, 1923; Rubin, 1974) and related concept of principal stratification (Frangakis and Rubin, 2002) to introduce into economics the concepts of net average treatment effect (NATE) and mechanism average treatment effect (MATE). These two effects decompose the total average treatment effect (ATE). Related concepts have been previously introduced in other fields by Robins and Greenland (1992) and Pearl (2001). Second, this project provides new results for the nonparametric partial identification of net treatment effects under minimal assumptions. Subsequently, the project presents different sets of assumptions that allow parametric as well as nonparametric point identification of NATE. The nonparametric results follow from an application of the insights in the seminal work of Imbens and Angrist (1994) and Angrist, Imbens and Rubin (1996) on local average treatment effects. The analysis is done for the cases in which the treatment is randomly assigned, when selection is based on observables, and when selection is based on unobservables. This last case has not been considered in the recent literature on net effects in other fields, and it is important in economics. Finally, applications of the methodologies are provided based on substantive and well known empirical problems employing data sets available to the investigators. They will be complemented by Monte Carlo simulations. These simulations offer further insights on the application of the methods and the robustness of alternative identification assumptions.<br/><br/>This project makes a clear and significant contribution to the econometrics literature on causal inference. It also provides linkages among econometrics, statistics, epidemiology, artificial intelligence, and other areas that emphasize estimation of causal effects. The proposed research is also likely to impact many areas of economics and other sciences by adding new tools to the kit of applied researchers. This is particularly the case in those fields in which the estimation of treatment effects is important for analysis and policymaking, such as labor, public, agricultural and health economics, among others. To this effect, the project stresses the inclusion of empirical applications and simulations that will provide guidance for applied researchers as they implement the methods introduced in this proposal.<br/><br/>Broader Impacts: The results and methods developed in this project will be used as a teaching tool in graduate courses in economics and agricultural economics at the University of Florida and the University of Miami. The research assistants selected for the project ???who will help with coding the statistical programs for the empirical applications and simulations???will be well-trained in this regard, and every effort will be made to ensure that they come from underrepresented groups (which is anticipated to be no problem given the existing diversity at the principal investigators? institutions). The project also broadens the participation of underrepresented groups because both PIs, in addition to being junior faculty, are members of such a group. Finally, the project will promote synergies between the University of Miami and the University of Florida, and particularly between economics and agricultural economics, as the PIs are members of each department"
1623094,EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL),IIS,Cyberlearn & Future Learn Tech,9/1/2016,8/26/2016,Leilah Lyons,"Lyons, L","Lyons, L",NY,New York Hall of Science,Standard Grant,Amy Baylor,8/31/2019,"$55,000.00 ",,llyons@nyscience.org,47-01 111TH STREET,Corona,NY,113682950,7186990005,CSE,8020,"8045, 8841",$0.00 ,normalFunding,"The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
88319,Creation of Artificial Intelligence Laboratory,DUE,CCLI-ADAPTATION AND IMPLEMENTA,1/1/2001,8/21/2000,Anthony Chemero,"Chemero, A","Chemero, A|Helm, B",PA,Franklin and Marshall College,Standard Grant,Myles G. Boylan,12/31/2004,"$54,620.00 ",Bennett Helm,anthony.chemero@uc.edu,Office of the Provost,Lancaster,PA,176043003,7173584517,EHR,7428,"7428, 9178, SMET",$0.00 ,normalFunding,"Interdisciplinary (99) Recently much of the interesting research in artificial intelligence has involved mobile robotics and artificial life. Whether the resulting ""creatures"" are real (as with mobile robots) or virtual (as with artificial life), it is becoming increasingly clear that apparently intelligent behavior emerges most naturally out of the interactions between a creature and a complex environment. Consequently, research in these areas of artificial intelligence draws on electrical and mechanical engineering, computer science, and psychology, as well as biology and philosophy. Both mobile robotics and artificial life have proven to be highly effective at engaging students in hands-on, collaborative learning about a topic that is inherently interdisciplinary. The use of mobile robots in classrooms includes the Autonomous LEGO Robotics Course at Case Western Reserve University (See eecs.cwru.edu/courses/lego375), an Artificial Intelligence Course at Bryn Mawr (see mainline.brynmawr.edu/courses/cs372/fall98), a Robotics Course at Swarthmore College (See palantir.swarthmore.edu/~Maxwell/classes/e28), and many others. Similarly, artificial life and genetic algorithms have been successful in undergraduate courses recently. Examples are Emergence, Evolution, and Life at Reed College (see reed.edu/~mab/courses/mals555), Artificial Life Course at Cal Tech (see krl.caltech.edu/~charles/cns175), and Topics in Genetic Algorithms Course at the University of New Mexico (see cs.unm.edu/~forrest/ga-class/syllabus.html). These topics have also been used successfully in classes across the Scientific and Philosophical Studies of Mind (SPM) curriculum at Franklin & Marshall College (F&M). This project is expanding the current artificial intelligence offerings by implementing, over a three-year period, an artificial intelligence laboratory as a crucial component of the SPM curriculum. The new lab is equipped with 5 iMac computers for running various artificial life and mobile robotics experiments; HandyBoard robot controllers, sensors, and Lego pieces for building 5 additional mobile robots; and software (StarLOGO, CodeWarrior, Brainwave, and InteractiveC) to compile and upload programs to the robot controllers as well as to run artificial life simulations. During the first year of the grant, the PIs are building the necessary sensors and interface boards to create 5 new robot kits as well as to upgrade 5 existing robot kits, and adapt artificial life resources developed elsewhere to the kind of non-UNIX computing environment available at F&M. During the second year, they will integrate mobile robotics with artificial life (in particular genetic algorithms) so as to enable the robots to learn how to respond appropriately to their environments. During the third year, they will refine these implementation of robot learning so as to devise demonstrations and experiments for upper-level artificial intelligence courses in the SPM curriculum. Moreover, during the second and third years, the PIs will reassess the lab in light of student feedback and retool it where necessary. The result is that activities in the lab will allow students to develop conceptual understanding of self-organization, emergence, evolution, embodiment and the neural basis of intelligence, and practical abilities in engineering, robotics and computer programming. Indeed, given the limited resources of a liberal arts college like F&M, creating opportunities for this kind of hands-on, engineering experience is not possible without being linked in this way to fundamental components of a liberal arts education like philosophy, psychology and biology. Moreover, the lab will foster increased interdisciplinary connections among the Psychology, Philosophy, Computer Science, and Physics Departments, both affecting faculty development and increasing substantially the inter-disciplinary content of relevant courses."
9610348,CAREER ADVANCEMENT AWARD:  The Complexity of Markov         Decision Processes,CCF,THEORY OF COMPUTING,7/1/1997,7/16/1999,Judith Goldsmith,"Goldsmith, J","Goldsmith, J",KY,University of Kentucky Research Foundation,Standard Grant,Robert Sloan,6/30/2001,"$53,353.00 ",,goldsmit@cs.uky.edu,109 Kinkead Hall,Lexington,KY,405260001,8592579420,CSE,2860,"9216, 9222, HPCC",$0.00 ,normalFunding,"This project is concerned with Markov decision processes (MDPs)  and concentrates on two problems (1) Finding conditions under  which there exist easily implementable optimal policies and (2)  Determining how to recognize these policies. Variants on these  problems are also studied, in particular finding easily  implementable approximations to policies and the computational  complexity of recognizing the policies and conditions.  This  grant will support a transition from a mathematical logic-based  approach to computer science (structural complexity theory) to an  engineering application-based approach.  The applications  focussed on in this proposal come from the field of planning, as  described both by computer scientists in Artificial Intelligence,  and electrical engineers in Discrete Event Systems."
9624237,CAREER:  Using Imitation to Study Multi-Representational    Systems,IIS,"ROBOTICS, ARTIFICIAL INTELL & COGNIT SCI",6/15/1996,1/5/1998,Maja Mataric,"Mataric, M","Mataric, M",MA,Brandeis University,Continuing grant,Larry H. Reeker,8/26/1998,"$52,320.00 ",,mataric@usc.edu,415 SOUTH ST MAILSTOP 116,WALTHAM,MA,24532728,7817362121,CSE,"6840, 6856","1045, 9146, MANU",$0.00 ,normalFunding,"This is a joint research and educational program that focuses on an interdisciplinary study of adaptive behavior in complex systems whole behavior is determined by the dynamics of interaction that do not lend themselves to simple models, abstraction, or simulation.  The project aims to develop a strong, coherent program of courses, seminars, laboratories, and research projects within the Brandeis Center for Complex Systems whose goal is to promote interaction among faculty from related fields, and to provide undergraduate and graduate students with opportunities for interdisciplinary research and training.  The project uses imitation as the domain for studying multi-representional cognitive systems, and applys it to three experimental areas: 1) dynamics simulation, using a physically realistic human model, 2) robotics, using a group of up to 24 mobile robots, and 3) software agents, using two different multi-agent simulations.  Imitation involves the interaction of multiple-representations from perceptual, memory, and action/motor subsystems, thus bringing up the key integration issue of Artificial Intelligence and Control.  Imitation is a rich domain for scaling up complete, multi-modal cognitive systems, and insights from this work can be applied to various applications spanning different branches of AI, including skill learning, automated assembly planning, cooperative multi-robot systems, and multi-agent cooperation."
609678,Steering a young science: Workshop proposal for 50th anniversary of American AI,IIS,ARTIFICIAL INTELL & COGNIT SCI,1/1/2006,9/12/2006,James Hendler,"Hendler, J","Hendler, J|Mitchell, T",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,C.S. George Lee,12/31/2006,"$52,309.00 ",Tom Mitchell,hendler@cs.rpi.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"6856, 7495, 9218, HPCC",$0.00 ,normalFunding,"This workshop is intended to refocus the field of artificial intelligence (AI) on its traditional goal: to understand the nature of cognition and its embodiment in human and artificial systems. The success of the field of AI can be seen in major accomplishments throughout the past decade including the beating of the best human chess player by a computer, the autonomous operation of robots on Mars and the autonomous control of the Deep Space One asteroid and comet mission, the use of rule-based systems by tens of thousands of Americans in the preparation of their yearly income taxes and the use of natural language technology in numerous applications including web search engines and the world's most successful word processing software. Despite these successes, the intellectual mission of understanding the nature of cognition remains one of the great challenges in modern science. <br/><br/>The overall goal of this work is to develop scientific guidelines that will steer research in AI over the next several decades. The symposium will also help raise awareness by students and others both of the achievements to date of the AI field, and the exciting scientific challenges that still remain. Artificial intelligence technologies have been applied in a wide range of disciplines and are often at the core of interdisciplinary efforts in bioinformatics and ecoinformatics, efforts in genomics and elsewhere using robotic technologies, the advancement of database integration and semantic web activities in the homeland defense arena and elsewhere, and in a number of other fields where the need to manage or coordinate knowledge is crucial to success. Helping other scientists to understand the contributions of AI to date, and the potential for the future, can be expected to lead to further indisciplinary work and the greater application of AI techniques in the other sciences, as well as in priority areas such as e-commerce and homeland security.<br/>"
1339552,I-Corps: Commercializing the Integration of Human and Artificial Intelligence for Large Scale Multimedia Analysis,IIP,I-Corps,5/1/2013,4/17/2013,Gerald Friedland,"Friedland, G","Friedland, G",CA,International Computer Science Institute,Standard Grant,Rathindra DasGupta,10/31/2013,"$50,000.00 ",,fractor@icsi.berkeley.edu,1947 CENTER ST STE 600,Berkeley,CA,947044115,5106662900,ENG,8023,,$0.00 ,exceptionalFunding,"Currently, crowdsourcing platforms are only being used to perform tasks that are easy for humans. Researchers have developed methods for using these systems to do tasks that are difficult for humans. They have developed methods to accomplish difficult tasks and with these techniques can produce solutions that are more accurate and efficient than any currently present in the marketplace. This method is a hybrid approach that combines artificial intelligence systems with low-cost crowdsourced labor enabling a flexible approach to the end user that enables them to analyze a wide variety of events with high accuracy while still achieving the time and cost savings associated with artificial intelligence-based systems.<br/><br/>Multimedia content is a major part of people's ever day lives, and the ability to understand the data that is being acquired at a rapid pace will have a huge impact on society. Researchers aim to aid this by developing new techniques for the processing of large scale multimedia databases, creating methods for using existing crowdsourcing tools in a significantly more efficient and accurate way to produce high quality results, based on a n hybrid system of machine learning and human intelligence. This hybrid system could have an great public impact, leveraging the advantages of machine learning and human annotation simultaneously (having the machine learn from human crowdsourcers) providing a high accuracy solution at a lower cost than is currently possible."
526016,NeTS-NBD: Collaborative Research: Intelligent and Adaptive Networking for the Next Generation Internet,CNS,Networking Technology and Syst,8/15/2005,7/25/2005,Randy Katz,"Katz, R","Katz, R",CA,University of California-Berkeley,Standard Grant,Darleen L. Fisher,7/31/2006,"$50,000.00 ",,randy@cs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,7363,"7388, 9218, HPCC",$0.00 ,exceptionalFunding,"This project investigates the Next Generation Network Technology and Systems capable of understanding and learning the high-level perspective of the network.  The proposed approach pursues a new cognitive intelligent networking paradigm that maintains the success of today's Internet but which also incorporates cognitive intelligence in the network--a new networking technique that provides the ability for the network to know what it is being asked to do, so that it can step-by-step take care of itself as it learns more. In particular, we explore new networking architecture and network elements that will lead to a future network with (a) improved robustness and adaptability, (b) improved usability and comprehensibility, (c) improved security and stability, and (d) reduced human intervention for operation and configuration.  This project pursues a set of comprehensive studies that seek innovations through the design and modeling of a new brain-reflex cognitive intelligence architecture, an intelligent programmable network elements architecture, and an intelligent network control and management design.  <br/><br/>Broader Impact:  The team approach covering neuroscience, datamining, computer science, systems engineering, artificial intelligence, and networking will provide rich opportunities for students to learn beyond their primary fields of study.  New courses developed by the faculty members will disseminate the new material covering neuroscience and information technology.<br/><br/>"
1744159,I-Corps: Approximate Dynamic Programming and Artificial Neural Network Control for Microgrids,IIP,I-Corps,7/1/2017,7/12/2017,Shuhui Li,"Li, S","Li, S",AL,University of Alabama Tuscaloosa,Standard Grant,Pamular Mccauley,12/31/2018,"$50,000.00 ",,sli@eng.ua.edu,801 University Blvd.,Tuscaloosa,AL,354870005,2053485152,ENG,8023,9150,$0.00 ,exceptionalFunding,"The broader impact/commercial potential of this I-Corps project is to act as a catalyst in the growth of distributed generation and microgrid industries. This artificial intelligence based control system will potentially provide an electrical network that is reliable by reducing outages and restoration costs with incredibly fast bidirectional power flow, secured with real time diagnostics, self-healing and adaptive capabilities, and more economical by reducing equipment failures and minimizing power losses. The product potentially three broad markets, including utilities, distributed generation and consumer. The solution will enhance energy generation from renewables, improve microgrid efficiency, reliability, stability and power quality, and add intelligent control to conventional power systems. Inverter capabilities are presently a significant challenge for integrating distributed generation sources. The proposed innovation would potentially provide an appropriate solution to address this challenge.<br/><br/>This I-Corps project develops a neural network control technology for microgrid control and management. Microgrids are one path for integrating renewable and distributed generation sources into the grid and can generally support a future smart electricity grid.  A key challenge in microgrid adoption is adequate control of power inverters. Problems include high oscillations when connecting or disconnecting an energy source, fluctuating voltage and frequency, malfunctions and reliability, competing control between inverters, and high harmonic distortions. The proposed innovation uses adaptive dynamic programming and artificial neural networks to implement microgrid control. It integrates into one controller the advantages of conventional control methods, including optimal control, proportional integral control, predictive control, and sliding mode control. The proposed innovation has the potential to overcome the limitations of the conventional control technologies and better meet customer demands and requirements."
9720574,POWRE:  Integration of Artificial Intelligence Techniques   into a Global Cloud Mask Generation System,AGS,PROF OPPOR FOR WOMEN IN RSCH,1/1/1998,9/25/1997,Antonette Logar,"Logar, A","Logar, A",SD,South Dakota School of Mines and Technology,Standard Grant,Roddy Rogers,12/31/1999,"$50,000.00 ",,antonette.logar@sdsmt.edu,501 East Saint Joseph Street,Rapid City,SD,577013995,6053941218,GEO,1592,"0000, 1592, OTHR",$0.00 ,exceptionalFunding,"9720574  Logar     In this project, artificial intelligence techniques, specifically neural networks and fuzzy logic, will be applied to the problem of generating a global cloud mask. This system will be able to distinguish cloud from non-cloud pixels in satellite imagery and will be used by the EOS project located in Huntsville, Alabama. The presence of clouds, which is an important factor in studying global climate shifts, must be correlated over time, for the entire earth, on a daily basis. The amount of data which must be analyzed precludes the use of a human expert to determine the percentage of cloud cover in these scenes. The method for accomplishing this task will be to improve upon and extend previous work in four areas: feature selection, the use of thresholds, the impact of adding layers to the structure, and pixel unmixing.    Initial efforts have been made to incorporate a fuzzy logic component into the selection criteria, but a larger data set is needed to adequately test the effectiveness of the method. One of the difficulties faced when classifying satellite data is that of mixed pixels, that is, a single pixel which contains multiple classes. The possibility of using a neural network for this type of problem has recently been suggested and will be investigated both for the cloud classification project and on data supplied by remote sensing groups working on the ocean color problem.    This project is supported by the POWRE program, which will allow the PI to spend a sabbatical at the University of Alabama, Huntsville, where she will be able to interact with experts in the area of remote sensing and will have easy access to satellite data. This will provide a new research direction for the PI and her students, and increase the visibility of women at the South Dakota School of Mines and Technology."
9610509,Engineering Research Equipment: Fast Prototyping System for Motor Incipient Fault Detection,ECCS,"CONTROL, NETWORKS, & COMP INTE",5/15/1997,1/5/1999,Mo-Yuen Chow,"Chow, MY","Chow, MY|Trussell, HJ",NC,North Carolina State University,Standard Grant,Dagmar Niebur,10/31/1999,"$50,000.00 ",H. Joel Trussell,chow@eos.ncsu.edu,CAMPUS BOX 7514,RALEIGH,NC,276957514,9195152444,ENG,1518,"0000, OTHR",$0.00 ,exceptionalFunding,9610509 Chow The Department of Electrical and Computer Engineering at North Carolina State University will purchase the Fast Prototyping System for Motor Incipient Fault Detection equipment which will be dedicated to support research in engineering. The equipment will be used for several research projects. The main research project to be supported from this equipment grant is: A Neural/Fuzzy Approach for Motor Incipient Fault Detection. There are also several research projects which can benefit from this research equipment grant. The equipment can provide actual data for the Fast Prototype Motor Simulation System project. The IR camera will be used for research in image processing by adding an additional band to the multispectral images used in restoration work. Projects entitled Digital Color Camera Design and Nonlinear Processing of Color Images will benefit from the proposed equipment. The College of Engineering and Department of Electrical and Computer Engineering at North Carolina State University have agreed to jointly provide 33% of the total project cost as matching fund for this equipment grant A-t
1753761,I-Corps: Automated Spatiotemporal Intelligence Operations for Asset Integrity Management,IIP,I-Corps,11/1/2017,11/1/2017,Christopher Lippitt,"Lippitt, C","Lippitt, C",NM,University of New Mexico,Standard Grant,Pamular Mccauley,12/31/2018,"$50,000.00 ",,clippitt@unm.edu,"1700 Lomas Blvd. NE, Suite 2200",Albuquerque,NM,871310001,5052774186,ENG,8023,9150,$0.00 ,exceptionalFunding,"The broader impact/commercial potential of this I-Corps project includes the enabling of wide scale exploitation of the growing volume of airborne image data from unmanned aerial systems (UAS) to monitor the environment in near real-time. Persistent and tactical surveillance of infrastructure assets (e.g., critical infrastructure, roads, pipelines), military bases, agricultural fields, boarders, or other extensive assets requiring routine monitoring for tactical decision making is becoming cost feasible with the introduction of UAS, but the volume of data collected cannot be exploited using traditional, largely manual, methods. Automated processing and interpretation of large volumes of airborne imagery in near real-time will enable improved decision making and, subsequent, cost reductions and improved performance for a range of industries and agencies. The operations of infrastructure management, disaster response, security, intelligence, and agriculture are amongst the expected beneficiaries.<br/><br/>This I-Corps project explores the commercialization potential of a platform from near real-time analysis and exploitation of airborne image data. Research exploring the development of an airborne system for monitoring critical infrastructure during the response phase on natural disasters resulted in the development of an analytical model for repeat station imaging and refinement of a conceptual model for the design of time-sensitive remote sensing systems that collectively permit the design and implementation of automated change detection and monitoring systems from airborne imaging. This spatial analytics platform automates 3D scene reconstruction, and uses artificial intelligence and machine learning techniques to convert digital photos into a cataloged and indexed spatial intelligence database of changes over time.  3D/4D object classifiers are developed to extract complex features that 2D imagery is unable to represent. This method trains neural networks on volumetric data and multi-temporal spatial data to facilitate the extraction and identification of features and how they have changed. Object identification and characterization will provide the capability to semantically describe changes 3D and 4D space."
1648728,I-Corps: Artificial Intelligence and Deep Learning System for Product Search,IIP,I-Corps,8/15/2016,8/8/2016,Carol Mimura,"Mimura, C","Mimura, C",CA,University of California-Berkeley,Standard Grant,Steven Konsek,1/31/2017,"$50,000.00 ",,carolm@berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,ENG,8023,,$0.00 ,exceptionalFunding,"The broader impact/commercial potential of this I-Corps project are in various applications in ecommerce, security, robotics, etc. This project's technology enables computer systems and their users to better contextually understand products and locate them. For example, in e-commerce, this technology enables people to make informed decisions about product selection. This may enhance the e-tail experience and help to eliminate wasted time as people can easily and precisely find things they desire. The aggregated data on product searches can be used by suppliers to better understand and plan for demand. Also, in robotics, as another example, computer vision is an essential element of the technology and the multi-object detection system built into software will enable robots to be more effective as they will ""understand"" products or objects in the context of our world. In security, this technology will enable better detection of theft and threats. Overall, the technology has many applications - many that can make lives more convenient and safer.<br/><br/>This I-Corps project is based on machine learning technology.  Billions of data points that include images and textual information about products are trained into artificial neural networks. These neural networks understand products with context with both images and natural language. Further, the neural networks are able to self-learn with new information from the internet. This technology was developed after researching various machine learning methods for large scale objection detection and search. The result is that neural networks provide the most scalable and efficient technology in terms of object detection. The uniqueness of this system is that parts of the learning in the neural network can be changed without affecting the rest of the network and the network can self-learn from the internet about products and other choice-centric decisions."
957742,Collaborative Research:EAGER:Deep Architectures for Speech and Audio Processing,IIS,ROBUST INTELLIGENCE,1/1/2010,9/16/2009,Fei Sha,"Sha, F","Sha, F",CA,University of Southern California,Standard Grant,Edwina L. Rissland,12/31/2011,"$50,000.00 ",,feisha@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,"7495, 7916, 9215, HPCC",$0.00 ,exceptionalFunding,"Recent studies have demonstrated the powerful abilities of deep <br/>architectures for statistical pattern recognition.  Deep <br/>architectures transform their inputs through multiple layers of <br/>nonlinear processing.  Inspired by the connectivity of biological <br/>neural networks, the hidden layers of deep architectures encode <br/>hierarchical, distributed representations of complex sensory input.  <br/>Theoretical results suggest that such representations are needed to <br/>solve the most difficult problems of artificial intelligence.<br/><br/>Previous applications of deep architectures include visual object <br/>recognition, statistical language modeling, and nonlinear <br/>dimensionality reduction.  Building on these successes, this project <br/>develops new applications of deep architectures for problems in <br/>speech and audio processing.  Current front ends for these problems <br/>are dominated by traditional methods in statistical modeling and <br/>signal processing.  Deep architectures have the potential to <br/>overcome many limitations of current approaches.<br/><br/>This project has two research components with interrelated and <br/>overlapping goals.  The project's first component explores <br/>unsupervised learning in convolutional neural networks.  <br/>The goal of learning in these networks is to discover new <br/>features for audio event detection and automatic speech <br/>recognition.  The project's second component investigates <br/>the possibility of deep learning in kernel machines.  <br/>This possibility is suggested by a recently discovered family <br/>of kernel functions that mimic the computation in large, <br/>multilayer networks.<br/><br/>The project's research components are tightly integrated with <br/>its educational activities.   The project supports two graduate <br/>students, including one female student.  An important goal <br/>is to develop publicly available software for use by other <br/>researchers."
957560,Collaborative Research:EAGER:Deep Architectures for Speech and Audio Processing,IIS,ROBUST INTELLIGENCE,1/1/2010,9/16/2009,Lawrence Saul,"Saul, L","Saul, L",CA,University of California-San Diego,Standard Grant,Edwina L. Rissland,12/31/2011,"$50,000.00 ",,saul@cs.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,7495,"7495, 7916, 9215, HPCC",$0.00 ,exceptionalFunding,"Recent studies have demonstrated the powerful abilities of deep architectures for statistical pattern recognition. Deep architectures transform their inputs through multiple layers of nonlinear processing. Inspired by the connectivity of biological neural networks, the hidden layers of deep architectures encode hierarchical, distributed representations of complex sensory input. Theoretical results suggest that such representations are needed to solve the most difficult problems of artificial intelligence. <br/><br/>Previous applications of deep architectures include visual object recognition, statistical language modeling, and nonlinear dimensionality reduction. Building on these successes, this project develops new applications of deep architectures for problems in speech and audio processing. Current front ends for these problems are dominated by traditional methods in statistical modeling and signal processing. Deep architectures have the potential to <br/>overcome many limitations of current approaches. <br/><br/>This project has two research components with interrelated and overlapping goals. The project's first component explores unsupervised learning in convolutional neural networks. The goal of learning in these networks is to discover new features for audio event detection and automatic speech <br/>recognition. The project's second component investigates the possibility of deep learning in kernel machines. This possibility is suggested by a recently discovered family of kernel functions that mimic the computation in large, <br/>multilayer networks. <br/><br/>The project's research components are tightly integrated with its educational activities. The project supports two graduate students, including one female student. An important goal is to develop publicly available software for use by other researchers."
1208143,"Advanced Study Institute on Global Healthcare Grand Challenges and Opportunities, July 15 - 30, 2012, Antalya, Turkey",CBET,Engineering of Biomed Systems,5/1/2012,12/20/2011,Metin Akay,"Akay, M","Akay, M",TX,University of Houston,Standard Grant,Athanassios Sambanis,4/30/2015,"$50,000.00 ",,makay58@gmail.com,4800 Calhoun Boulevard,Houston,TX,772042015,7137435773,ENG,5345,"004E, 017E, 137E, 138E, 7237, 7479",$0.00 ,exceptionalFunding,"Abstract<br/>1208143, Akay<br/><br/>The National Academy of Engineering announced the 14 Grand Challenges for Engineering at the annual meeting of the American Association for the Advancement of Science. The committee also praised biomedical and biological engineering as the research field to fulfill the promise of personalized medicine. Included among these 14 challenges were Reverse-Engineering the Brain, Engineer better Medicines and Advance Health Informatics. An important way of exploiting such information would be through the development of methods that allow doctors to forecast the benefits and side effects of potential treatments or cures. ""Reverse-Engineering"" the Brain, is an emerging discipline that helps us to understand how the brain works and treats several diseases. It furthermore helps us to develop computerized artificial intelligence. Advanced computer intelligence, in turn, should enable automated diagnosis and prescriptions for treatment. Computerized catalogs of health information will enhance the medical system's ability to track the spread of disease and analyze the comparative effectiveness of different approaches to prevention and therapy. Finally, engineering new medicines will help us fight the growing danger of attacks from novel disease-causing agents. For instance, certain deadly bacteria have repeatedly evolved new properties, conferring resistance against even the most powerful antibiotics. New viruses arise with the power to kill and spread more rapidly than disease-prevention systems are designed to counteract.<br/><br/>Intellectual Merits: The main objective of the Advanced Summer Institute on Global Healthcare-- Challenges and Opportunities is to highlight and discuss these emerging grand challenges, mainly focused on the latest advances in the areas of science, engineering, technology and medicine. The institute provides a unique environment to discuss the emerging research areas, challenges and opportunities which lead to very fruitful discussions.<br/><br/>Broader Impacts: It exposes the attendees with biology and medicine backgrounds to the latest developments in these emerging enabling technologies. It is also helpful to those with engineering and science background who are interested in doing research in bionanoscience and nanomedicine, neuroscience and engineering since the advanced institute provides exceptional insights into the fundamental challenges in biology and medicine."
1110885,"Advanced Study Institute on Global Healthcare Grand Challenges and Opportunities, Antalya, Turkey, July 15-30, 2011",CBET,Engineering of Biomed Systems,5/1/2011,4/18/2011,Metin Akay,"Akay, M","Akay, M",TX,University of Houston,Standard Grant,Kaiming Ye,4/30/2013,"$50,000.00 ",,makay58@gmail.com,4800 Calhoun Boulevard,Houston,TX,772042015,7137435773,ENG,5345,"004E, 7237",$0.00 ,exceptionalFunding,"1110885, Akay<br/><br/>This award will fund the travel expenses of 10 graduate students and post-docs and 25 faculty to participate at the 2nd Advanced Study Institute on Global Healthcare Grand Challenges and Opportunities cosponsored by National Academy of Engineering (NAE), the department of Biomedical Engineering at the University of Houston and the Akdeniz University will be held on July 15-30, 2011, Antalya, Turkey.<br/><br/>The National Academy of Engineering announced the 14 Grand Challenges for Engineering at the annual meeting of the American Association for the Advancement of Science. The committee also praised biomedical and biological engineering as the research field to fulfill the promise of personalized medicine. Included among these 14 challenges were Reverse?Engineering the Brain, Engineer better Medicines and Advance Health Informatics.<br/><br/>An important way of exploiting such information would be through the development of methods that allow doctors to forecast the benefits and side effects of potential treatments or cures.<br/>""Reverse-Engineering"" the Brain, is an emerging discipline that helps us to understand how the brain works and treats several diseases. It furthermore helps us to develop computerized artificial intelligence. Advanced computer intelligence, in turn, should enable automated diagnosis and prescriptions for treatment. Computerized catalogs of health information will enhance the medical system's ability to track the spread of disease and analyze the comparative effectiveness of different approaches to prevention and therapy. Finally, engineering new medicines will help us fight the growing danger of attacks from novel disease-causing agents. For instance, certain deadly bacteria have repeatedly evolved new properties, conferring resistance against even the most powerful antibiotics. New viruses arise with the power to kill and spread more rapidly than disease-prevention systems are designed to counteract.<br/><br/>Intellectual Merits: The main objective of the Advanced Summer Institute on Global Healthcare<br/>-- Challenges and Opportunities is to highlight and discuss these emerging grand challenges, mainly focused on the latest advances in the areas of science, engineering, technology and medicine. The institute provides a unique environment to discuss the emerging research areas, challenges and opportunities which lead to very fruitful discussions.<br/><br/>Broader Impacts: It exposes the attendees with biology and medicine backgrounds to the latest developments in these emerging enabling technologies. It is also helpful to those with engineering and science background who are interested in doing research in bionanoscience and nanomedicine, neuroscience and engineering since the advanced institute provides exceptional insights into the fundamental challenges in biology and medici"
1740544,I-Corps: Accurate GPS-free Navigation and Localization,IIP,I-Corps,4/1/2017,4/3/2017,Suman Chakravorty,"Chakravorty, S","Chakravorty, S",TX,Texas A&M Engineering Experiment Station,Standard Grant,Anita J. LaSalle,3/31/2018,"$50,000.00 ",,schakrav@aero.tamu.edu,TEES State Headquarters Bldg.,College Station,TX,778454645,9798477635,ENG,8023,,$0.00 ,exceptionalFunding,"The broader impact/commercial potential of this I-Corps project is to develop autonomous navigation technology that will enable systems to robustly operate in uncertain environments without a Global Positioning System (GPS). The project is a result of a confluence of astronomy, aerospace, computational science and artificial intelligence. Commercialization of this technology has the potential to revolutionize space exploration, self-driving cars, Unmanned Aerial Vehicles (UAVs) and other such systems which need accurate position estimation. A key advantage of this project's technology is enhanced cybersecurity as it does not rely on external signals for navigation. Further, this project will contribute open-source software to the scientific community. It is envisioned that development of a software toolbox that integrates with the popular ROS (Robot Operating System) library will allow researchers to simulate autonomous navigation without GPS.<br/><br/>This I-Corps project is a result of research into the problem of Simultaneous Localization and Mapping (SLAM). In SLAM, a robot is not given prior knowledge of its environment, it must use its sensory data and actions to simultaneously build a map of its environment and position itself within its uncertain map. Competing methods in this area exhibit positioning errors which may be unsuitable for long-term navigation. The work developed here shows that by fusing orientation sensing with short-range sensing, the system attain a simplification of the underlying optimization problem. This allows fast and globally optimal solutions. In this approach, a vehicle uses a camera to track celestial bodies in the sky which allows the vehicle to estimate its orientation in space, this information is fused with short-range sensors such as lasers and cameras which track features in vicinity of the vehicle.  Using the proposed approach, a system can achieve 100x improvement in position error over existing methods."
1261052,I-Corps:  Innovation Accelerator: A New Web-based Portal Software Tool to Find Disruptive Innovative Solutions,IIP,I-Corps,10/1/2012,9/20/2012,Sundar Krishnamurty,"Krishnamurty, S","Krishnamurty, S",MA,University of Massachusetts Amherst,Standard Grant,Rathindra DasGupta,8/31/2013,"$50,000.00 ",,skrishna@ecs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,ENG,8023,,$0.00 ,exceptionalFunding,"Researchers are developing a human-machine synergism in which the machine complements human weaknesses to being innovative while the human returns the favor for the machine. This method called Innovation Assistance (IA) represents a fundamental new way of thinking about innovation and replaces the minimally successful Artificial Intelligence techniques from the 1980's that were unable to get machines to be innovative by themselves. This is accomplished by carefully understanding the fundamental axis upon which all innovation turns: every innovative solution is based upon at least one overlooked (i.e., obscure) feature of the problem. Humans and machines have different reasons for overlooking obscure features. Each partner in the human-machine interaction will help counter the other?s weaknesses. Researchers have thus far devised nearly two dozen innovation techniques that counteract the many cognitive reasons why humans overlook obscure features. <br/><br/>This technology has applications for STEM education, lawyers, the military and engineers. The problem-solving model used in this method has the potential to be used to alter innovative education in STEM fields. Techniques developed through IA will be able to more efficiently search databases for similar solutions to an entered problem. There is potential for this technology to be used in a military setting for training forces to be more innovative problem solvers in the field. Engineering applications of this technology could assist in moving projects more rapidly through research and development phases. This technology addresses a growing need to improve the innovation capabilities of individuals and organizations."
1744294,I-Corps: Data Analytics and Automated Candidate Assessment,IIP,I-Corps,7/1/2017,7/12/2017,Saman Aliari Zonouz,"Zonouz, SA","Zonouz, SA",NJ,Rutgers University New Brunswick,Standard Grant,Cindy WalkerPeach,12/31/2018,"$50,000.00 ",,saman.zonouz@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,ENG,8023,,$0.00 ,exceptionalFunding,"The broader impact and commercial potential of this I-Corps project will improve the transition quality and efficiency of university students to companies. This platform will potentially provide several customer segments such as students, companies and universities with solutions that remove many barriers that currently make job hunting and hiring a time-consuming, costly, stressful, and often biased endeavor. The impact of the product goes beyond a specific academic major, and has the potential to cover all scientific subject matters for which there is a robust job market. Most importantly, the solution will remove the current potential biases against underrepresented minorities by automating the skill assessment process and minimizing the human involvement in the process.<br/><br/>This I-Corps project will develop effective, unbiased, and automated platforms and algorithms for skill assessment. The target customers will be the companies, and university graduates that would like to enter the job market with no prior experience. This research will propose novel techniques and working tools using artificial intelligence and machine learning methods to provide interaction during the interview process between the assessment engine and the interviewee. The project further develops novel formal methods and programming language analysis techniques to analyze the answers submitted by the candidate during the interview and adaptively select the next sequence of questions for each specific candidate. A realistic test-bed infrastructures on which the candidates will be asked to perform experiments is used to assess the expertise level of the candidates.  These novel techniques for automated interviews will reduce the cost and time for both companies and students."
1759592,I-Corps: Embedded Machine Listening for Smart Acoustic Monitoring,IIP,I-Corps,11/1/2017,11/1/2017,Juan Bello,"Bello, J","Bello, J",NY,New York University,Standard Grant,Cindy WalkerPeach,4/30/2019,"$50,000.00 ",,jpbello@nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,ENG,8023,,$0.00 ,exceptionalFunding,"The broader impact/commercial potential of this I-Corps project is the use of embedded machine listening as a low-cost, turnkey solution for early detection of machinery malfunction and improve predictive maintenance. In manufacturing, sound-based condition monitoring coupled with data-driven maintenance can help significantly reduce unscheduled work stoppages, faulty products and waste of raw materials. Building management systems can be augmented by integrating real-time condition updates for critical machinery such as HVAC units, elevators, boilers and pumps, minimizing disruption for managers and users of those services. This technology is flexible, accurate and data-driven, potentially providing a low barrier to adoption for prospective customers and adaptability to various markets. Beyond predictive maintenance, applications include noise level monitoring for ensuring compliance in workplaces and airports, home and building security, early alert for traffic accidents, bio-acoustic monitoring of animal species, and outdoor noise monitoring at scale for improved enforcement in smart cities.<br/><br/>This I-Corps project further develops research at the intersection of artificial intelligence and the internet of things. The technology consists of a calibrated and highly accurate acoustic sensor with embedded sound recognition AI based on deep learning.  Sound conveys critical information about the environment that often cannot be measured by other means. In manufacturing, early stage machinery malfunction can be indicated by abnormal acoustic emissions. In smart homes and buildings, sound can be monitored for signs of alarm, distress or compliance.  Sound sensing is omnidirectional and robust to occlusion and contextual variables such as lightning conditions at different times of the day. Many existing solutions cannot identify different types of sounds or complex acoustic patterns, making them unsuited for these applications. This solution is both low cost and capable of identifying events and sources at the network edge, thus eliminating the need for sensitive audio information to be transmitted."
1624035,I-Corps: Mined Semantic Analysis Commercialization Research,IIP,I-Corps,2/15/2016,2/16/2016,Wlodek Zadrozny,"Zadrozny, W","Zadrozny, W",NC,University of North Carolina at Charlotte,Standard Grant,Steven Konsek,7/31/2017,"$50,000.00 ",,wzadrozn@uncc.edu,9201 University City Boulevard,CHARLOTTE,NC,282230001,7046871888,ENG,8023,,$0.00 ,exceptionalFunding,"This I-Corps Teams project will help evaluate the commercial feasibility of improving knowledge work with Mined Semantic Analysis (MSA) software. A recent report on Artificial Intelligence, estimated a $2 trillion impact on knowledge work from machine automation/augmentation. As a solution that offers highly usable access to relevant domain knowledge, thereby enabling this economic shift, MSA potentially addresses millions of users. Applications include 1) Innovation management (technical document search) 2) Biomedical research (literature search) and 3) Business management (market/competitive research. MSA's concept based approach improves user interface visual prioritization, rapid comprehension and facile navigation to refine search. The software enables practical application of knowledge from billions of hours of human effort, thereby reducing the gap between novice and expert users.<br/><br/>The project aims to validate product market fit of MSA software through customer exploration and MVP prototype development. Building on work done over the past several months, the goal of the interviews is to identify specific market problems that the technology is capable of solving in a demonstrably better way. The I-Corps team will test high potential areas such as: Intellectual property research and analytics, Legal discovery, Investment/Consulting, Enterprise search, Knowledge management, Biomedical literature and Healthcare information search. The team's other project goal is to prototype core functionality to align with key customer performance measures. This will include quick experiments to gauge modes of user interaction and experience, visualization, and some preliminary performance testing."
817173,NSF Workshop on Human-Computer Interaction for 21st Century Discovery,OAC,"INFO INTEGRATION & INFORMATICS, Cyber-Human Systems (CHS), DATA INTEROPERABILITY NETWORKS",4/1/2008,3/31/2008,Marilyn Lombardi,"Lombardi, M","Lombardi, M",NC,University of North Carolina at Chapel Hill,Standard Grant,Sylvia J. Spengler,12/31/2008,"$50,000.00 ",,marilyn@renci.org,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,CSE,"7364, 7367, 7701","7556, 9139, HPCC",$0.00 ,exceptionalFunding,"Institution: Renaissance Computing Institute (RENCI), University of North Carolina at Chapel Hill<br/>Principal Investigator: Marilyn Lombardi<br/><br/>Today's graphical user interfaces continue to rely on WIMP (windows, icons, menus, pointing device) technology first developed in the 1960's. High performance computational science is still commonly performed in batch mode, since today's HPC architectures and software do not support real time interaction between scientists and HPC applications. How can cutting edge 21st century interaction mechanisms enable high performance science and discovery? How can new technology make science come alive for students and the general public?  Jointly sponsored by the NSF Office of Cyberinfrastructure (OCI) and the Computing and Information Science and Engineering (CISE) directorate, this two-day, invitation-only workshop will bring together a select group of thought leaders from industry and the academy to develop a guiding vision and a cross-cutting research agenda for human-centered interface and interaction design over the next decade.  The workshop represents a critical step in moving beyond independent research projects toward coherent application of national resources in the area of human-centered interface and interaction design.  Invitees drawn from computer science, engineering, robotics, artificial intelligence, the cognitive sciences, perceptual psychology, neurobiology, architecture, design, and the interactive arts will work together to address a set of key questions: Where do we want to be by the year 2018?  How do we plan on getting there in a scalable and sustainable fashion? What are the major trends in the field?  Which forces are driving change?  What impedes further progress? What are the technical, social, psychological, and legal issues requiring further study?  What are our beliefs about human-computer interaction research and its goals?  What are the funding priorities over the coming decade and what are the respective roles of the federal, non-profit, and commercial sectors in shaping the group's vision of a human-centered future?  Workshop results will be captured in a workshop report and disseminated to the National Science Foundation and the research community."
9810537,An Integrated Environment for Reasoning about regulatory    Control elements in Microbial genomes,IIS,CISE RESEARCH INFRASTRUCTURE,9/1/1998,9/8/1998,Theresa Gaasterland,"Gaasterland, T","Gaasterland, T",IL,University of Chicago,Continuing grant,Ephraim P. Glinert,6/10/1999,"$49,998.00 ",,tgaasterland@ucsd.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,CSE,2885,"9218, HPCC",$0.00 ,exceptionalFunding,"IRI-9810537<br/>Gaasterland, Theresa <gaasterl@cs.uchicago.edu><br/>University of Chicago<br/>$0 - 18 mos.     (Jointly funded with the CISE Institutional Infrastructure - Total Award $49,998)<br/><br/>CONACyT: An Integrated Environment for Reasoning about Regulatory Control<br/>Elements in Microbial Genomes<br/><br/>This research is a collaboration of the PI with Dr. Julio Collado-Vides in Mexico.  The goal is  to use artificial intelligence techniques in deciphering patterns of conservation of regulatory elements across whole bacterial genomes by integrating two different platforms for investigating genomes:  a multi-genome annotation tool that uses automated reasoning and cooperative answering methods to associate features with a genomic sequence (the already existing MAGPIE system, developed by Gaasterland) and a database of regulatory elements, operons, and related regulatory signals encoded in E. coli genomic DNA (Regulon DB, assembled by Collado-Vides). To do this, new methods need to be developed for the combination of different types of knowledge to make predictions, and the system must be able to revise prior predictions based on new knowledge.  In addition, there will be insights into appropriate knowledge representations that capture both<br/>structure and function of living organisms.  On the biological side, the infrastructure developed in the project will enable an understanding of the degree to which knowledge gained from one organism can be used to guide the exploration of a new organism.<br/><br/>http://www.cs.uchicago.edu/~gaasterl/<br/>"
9650761,"Integration of Molecular Modeling, Computational Chemistry and Artificial Intelligence Throughout the Undergraduate Science Curriculum",DUE,UNDERGRAD INSTRM & LAB IMPROVE,6/1/1996,3/29/1996,Charles Bock,"Bock, C","Bock, C|Sztandera, L|Berberian, P",PA,Philadelphia University,Standard Grant,Frank A. Settle,5/31/1998,"$49,996.00 ","Les Sztandera, Paul Berberian",chuck@larry.philau.edu,4201 Henry Avenue,Philadelphia,PA,191445497,2159512865,EHR,7400,"9178, 9267, SMET",$0.00 ,exceptionalFunding,"The project provides equipment for a computer facility that enables modern molecular modeling, computational chemistry, and selected applications of artificial intelligence, including aspects of combinational chemistry, to be incorporated throughout the undergraduate chemistry curriculum. Advances in computer technology and software have made molecular modeling an indispensable tool for practicing chemists and have made it possible to introduce the subject into the undergraduate curriculum. Implementation of this project establishes a network of high resolution graphics workstations connected to a high speed server acting as a computational engine. The computer facility significantly enhances instruction in General Chemistry, Organic Chemistry, Biochemistry, Physical Chemistry, Advanced Inorganic Chemistry, Advanced Organic Chemistry, Instrumental Methods of Analysis, and Cell Biology. Students are learning to visualize molecules in 3D; calculate energy optimized ground state geometries; calculate and display LUMOs, HUMOs and electron density maps; perform infrared spectra analysis including animation of normal modes; discover structure-activity relationships; calculate gas phase reaction thermodynamics; refine structures using restrained molecular dynamics; and use genetic algorithms in optimal conformational searches. Wherever possible, the computational exercises concentrate on aspects of compounds that are the subject of experimental studies in the course curricula. Students participating in the active undergraduate research programs in chemistry and biology also are using these modeling tools to understand and interpret their research results."
1217638,Workshop on Research Challenges and Opportunities in Knowledge Representation and Reasoning,IIS,INFO INTEGRATION & INFORMATICS,6/1/2012,6/4/2012,Natasha Noy,"Noy, N","Noy, N",CA,Stanford University,Standard Grant,Sylvia J. Spengler,5/31/2013,"$49,990.00 ",,natasha.noy@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7364,"7364, 7556",$0.00 ,exceptionalFunding,"Modern information systems in every area of science and engineering rely critically on some form of knowledge representation and inference. Established fields such as Artificial Intelligence and Software Engineering as well as emerging fields such as Semantic Web, Computational Biology, Software Agents, Social Computing, Bioinformatics, Discovery Informatics, Cyberlearning and many others both rely on and contribute to advances in knowledge representation. Formal representations of knowledge and the associated inference mechanisms provide the basis for encoding, sharing, analyzing, interpreting vast amounts of data from disparate sources as well as deciding and acting upon information in virtually every area of human endeavor. <br/><br/>This workshop aims to bring together scientists from all areas of knowledge-representation research and to discuss the new challenges and opportunities that this area faces in addressing the explosion of data and knowledge, increased reliance of scientists on computational data, its heterogeneity, and new modes of delivering, storing, and representing knowledge. This radical shift in the amount of data, in the way that scientists distribute, store, and aggregate this data, presents new challenges for knowledge representation (KR). KR researchers must consider the applicability of their methods for representation and reasoning on data and knowledge at unprecedented complexity, quantity, and heterogeneity. The distributed and open nature of the data-intensive science presents additional challenges and opportunities in KR, with regard to provenance, security, trustworthiness, and privacy. The increased adoption of Semantic Web technologies and the rapid increase in the amounts of structured knowledge that is becoming available on the Semantic Web presents additional challenges (e.g., need for coping with information with different degrees of reliability, information that holds in different contexts, information that changes over time, information that can be conflicting, information that represents beliefs and opinions, etc. The increased use of KR methods in Computer Vision, Robotics, Natural-Language Processing, Discovery Informatics, and others presents an opportunity for fruitful interdisciplinary collaborations that could dramatically alter the KR research landscape. As scientists, as well as laypersons get accustomed to social mechanisms for creating and sharing data and knowledge, it is incumbent upon the researchers in knowledge representation to develop KR mechanisms that support collaborative creation, sharing, and use of knowledge. Against this background, the workshop brings together a diverse group of researchers and practitioners in KR and related areas to identify new KR research challenges and opportunities presented by the recent developments in the world wide web, social networks and social media, collaborative and data-intensive e-science, among others.<br/><br/>Broader Impacts: The workshop will identify new areas of research for the Information and the Intelligent Systems at the intersection Knowledge Representation and Inference, Information Integration and Informatics. Given the increasingly central role of formal representations of knowledge and associated tools for inference in virtually every domain of human endeavor, the identification of KR the results of the workshop are likely to impact multiple disciplines. The workshop results, including a report summarizing new KR research challenges and opportunities, as well as publications by workshop participants will be broadly disseminated to the larger scientific community."
939188,Organization of Grand Challenges in Cyber Security,CNS,TRUSTWORTHY COMPUTING,10/1/2009,2/4/2013,Giovanni Vigna,"Vigna, G","Vigna, G",CA,University of California-Santa Barbara,Standard Grant,Jeremy Epstein,12/31/2013,"$49,968.00 ",,vigna@cs.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,CSE,7795,"7923, 9218, HPCC",$0.00 ,exceptionalFunding,"National Science Foundation <br/>CISE/CNS<br/>Form 7 Review Analysis and Recommendation<br/><br/>Proposal Number: 0939188<br/>Panel: N/A<br/>PI:  Giovanni Vigna<br/>Institution:  University of California ? Santa Barbara<br/>Title:      Organization of Grand Challenges in Cyber Security<br/>                 <br/>Proposal summary and intellectual merit: <br/><br/>Inspired by the DARPA Urban Challenge, the PI offers to run a grand challenge competition in computer security.  .  DARPA reports very positive results from its competition wherein teams who developed fully automated automobiles, the automation attained by new methods in sensing and artificial intelligence, competed for prizes and glory.  <br/><br/>The security challenge, the focus of this proposal, is to be run in conjunction with USENIX Security, 2009.  Particularly challenging for a security challenge wherein a team has to defend itself against attacks, is the need for a clear, well-specified set of rules which unambiguously define criteria for success and for choosing a winner.  <br/><br/>For this challenge, the task of the participant teams is to build a system such that the provided servers are self-defending and resilient against attacks. During the competition an automated scoring system will record the services that remain functional.  At the same time, an automated attack system will perform disruptive attacks against the services.<br/><br/>Prizes, provided by private companies, will be awarded to the teams whose servers provide the highest service level but also above a minimal threshold.<br/><br/>Together with Nicholas Weaver (ICSI) and Anup Ghosh (GMU), the PI has created the infrastructure required to run the competition, including the attacking and scoring systems. <br/><br/>The funds requested would be used to reimburse the expenses of graduate and undergraduate students participating in the competition. The workshop is to take place on August 12-13, 2009 in Montreal.  <br/><br/><br/><br/>"
456287,US-UK Workshop: Cognitive Robots and Control,OISE,Catalyzing New Intl Collab,4/1/2005,3/25/2005,Kazuhiko Kawamura,"Kawamura, K","Kawamura, K",TN,Vanderbilt University,Standard Grant,Cassandra M. Dudka,3/31/2007,"$49,956.00 ",,kawamura@vuse.vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,O/D,7299,"0000, 5946, 5980, OTHR",$0.00 ,exceptionalFunding,"This one-year award will support US participation in a U.S.-U.K. joint workshop on ""Cognitive Robots and Control,"" organized by the PI at Vanderbilt University and by William Harwin at the University of Reading, to be held in Reading, UK, in 2005. <br/><br/>Intellectual merit. The field of robotics has evolved independently of cognitive science and neuroscience except for classical artificial intelligence and neural networks. However, most robots lack robustness. One challenge for the robotics community is the realization of cognitive robots through the integration of robotic body and mind that can handle difficult or novel situations. In the effort to understand human cognition and to develop embedded cognitive artifacts, all three fields will benefit by collaboration. <br/><br/>The proposed workshop will bring together researchers and students in robotics, philosophy of mind, cognitive science, and computational neuroscience to address the following broad issues: What can the robotics community learn from advances in cognitive science and computational neuroscience to develop the next generation of robots? How can international collaboration in this emerging field be established? What kinds of research topics should be pursued? How can the robotics community contribute to the cognitive science and neuroscience communities?<br/><br/>Broader impacts. The workshop will help develop: 1) strengthened partnerships between researchers in the field of robotics, machine consciousness, cognitive science, artificial intelligence (AI), and neuroscience; 2) the development of robots and other cognitive systems capable of responding robustly in novel situations; and 3) test beds for cognitive scientists and neuroscientists to validate their cognitive and learning algorithms and models. By including students and underrepresented groups, the workshop will foster the development of new researchers in this interdisciplinary area."
908947,"US-Turkey Advanced Study Institute on Biomedical Engineering Grand Challenges, September 20 -27, 2009,  Antalya, Turkey",OISE,"Engineering of Biomed Systems, OTHER GLOBAL LEARNING & TRNING",9/1/2009,9/4/2009,Metin Akay,"Akay, M","Akay, M",AZ,Arizona State University,Standard Grant,Osman Shinaishin,6/30/2010,"$49,919.00 ",,makay58@gmail.com,ORSPA,TEMPE,AZ,852816011,4809655479,O/D,"5345, 7731","0000, 004E, 5940, 5976, 7237, OTHR",$0.00 ,exceptionalFunding,"<br/>Proposal Number:  OISE-0908947<br/><br/>Principal Investigator:  Metin Akay<br/><br/>Institution:  Arizona State University<br/><br/>Title: US-Turkey Advanced Study Institute on Biomedical Engineering Grand Challenges, Anatalya, Turkey<br/><br/>The PI is organizing an advanced study institute to highlight the use of artificial intelligence in understanding brain function.  The National Academy of Engineering announced the 14 Grand Challenges for Engineering at the annual meeting of the American Association for the Advancement of Science. Included among these 14 challenges were Reverse?Engineer the Brain, Engineer better Medicines, and Advance Health Informatics.  Reverse-Engineering the Brain is an emerging discipline that promotes understanding of how the brain works.  Advanced computer intelligence should enable automated diagnosis and prescriptions for treatment.  To highlight these emerging disciplines, the First Advanced Study Institute on Biomedical Engineering will be devoted to Grand Challenges-Reverse Engineering the Brain and related research. It will be held Istanbul, Turkey and will introduce the attendees with biology backgrounds to the latest developments in the neural engineering. It will also be helpful to students in computer science and mathematics who are interested in doing research in neuroscience and neural engineering, as the advanced study institute will provide insights into the fundamental challenges in neuroscience and biology.   In terms of the broader impacts, further development of these topics may lead to the development of methods that allow doctors to forecast the benefits and side effects of potential treatments or cures.  The Advanced Study Institute is an opportunity for students to meet with leaders in the field.  This study institute will further stimulate interdisciplinary research and collaborations among engineers, mathematicians, computer scientists, neuroscientists and medical researchers.  In addition the study institute will aid in the understanding of complex neural systems and signals and in identifying the new directions of neuroscience and neural engineering. Options will be discussed for collaboration among researchers and students internationally.  This award is co-funded by Office of International Science and Engineering and the Biomedical Engineering Program.<br/><br/>"
1036000,"US-Turkey Advanced Study Institute on Biomedical Engineering Grand Challenges, September 20 -27, 2009,  Antalya, Turkey",OISE,"Engineering of Biomed Systems, OTHER GLOBAL LEARNING & TRNING",1/18/2010,5/10/2010,Metin Akay,"Akay, M","Akay, M",TX,University of Houston,Standard Grant,Carleen Maitland,8/31/2011,"$49,919.00 ",,makay58@gmail.com,4800 Calhoun Boulevard,Houston,TX,772042015,7137435773,O/D,"5345, 7731","0000, 004E, 5940, 5976, 7237, OTHR",$0.00 ,exceptionalFunding,"<br/>Proposal Number:  OISE-0908947<br/><br/>Principal Investigator:  Metin Akay<br/><br/>Institution:  Arizona State University<br/><br/>Title: US-Turkey Advanced Study Institute on Biomedical Engineering Grand Challenges, Anatalya, Turkey<br/><br/>The PI is organizing an advanced study institute to highlight the use of artificial intelligence in understanding brain function.  The National Academy of Engineering announced the 14 Grand Challenges for Engineering at the annual meeting of the American Association for the Advancement of Science. Included among these 14 challenges were Reverse?Engineer the Brain, Engineer better Medicines, and Advance Health Informatics.  Reverse-Engineering the Brain is an emerging discipline that promotes understanding of how the brain works.  Advanced computer intelligence should enable automated diagnosis and prescriptions for treatment.  To highlight these emerging disciplines, the First Advanced Study Institute on Biomedical Engineering will be devoted to Grand Challenges-Reverse Engineering the Brain and related research. It will be held Istanbul, Turkey and will introduce the attendees with biology backgrounds to the latest developments in the neural engineering. It will also be helpful to students in computer science and mathematics who are interested in doing research in neuroscience and neural engineering, as the advanced study institute will provide insights into the fundamental challenges in neuroscience and biology.   In terms of the broader impacts, further development of these topics may lead to the development of methods that allow doctors to forecast the benefits and side effects of potential treatments or cures.  The Advanced Study Institute is an opportunity for students to meet with leaders in the field.  This study institute will further stimulate interdisciplinary research and collaborations among engineers, mathematicians, computer scientists, neuroscientists and medical researchers.  In addition the study institute will aid in the understanding of complex neural systems and signals and in identifying the new directions of neuroscience and neural engineering. Options will be discussed for collaboration among researchers and students internationally.  This award is co-funded by Office of International Science and Engineering and the Biomedical Engineering Program.<br/><br/>"
80580,Bayesian Networks in Philosophy of Science and Epistemology,SES,Hist & Philosophy of SET,8/1/2000,6/20/2001,Luc Bovens,"Bovens, L","Bovens, L",CO,University of Colorado at Boulder,Continuing grant,Keith R. Benson,7/31/2003,"$49,898.00 ",,bovens@spot.colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,SBE,1353,"0000, OTHR",$0.00 ,exceptionalFunding,"SES 00-80580 - Luc J. Bovens (University of Colorado at Boulder) <br/>""Bayesian Networks in Philosophy of Science and Epistemology""<br/><br/>There is a long philosophical tradition of addressing questions in philosophy of science and epistemology by means of the tools of Bayesian probability theory. In the late 1970s, an axiomatic approach to conditional independence was developed within a Bayesian framework. This approach in conjunction with developments in graph theory are the two pillars of the theory of Bayesian Networks, which is a theory of probabilistic reasoning in artificial intelligence. The theory has been very successful over the last two decades and has found a wide array of applications ranging from medical diagnosis to safety systems for hazardous industries. Aside from some excellent work in the theory of causation, philosophers have been sadly absent in reaping the fruits from these new developments in artificial intelligence. This is unfortunate, since there are some long-standing questions in philosophy of science and epistemology in which the route to progress has been blocked by a type of complexity that is precisely the type of complexity that Bayesian Networks are designed to deal with: questions in which there are multiple variables in play and the conditional independences between these variables can be clearly identified. Integrating Bayesian Networks into philosophical research leads to theoretical advances on long-standing questions in philosophy and has a potential for practical applications.<br/><br/>In philosophy of science, there is the question of how we can confirm a hypothesis with unreliable instruments. What is the impact of repeating the experiment many times over? Of repeating the experiment with different instruments? Of developing a theoretical underpinning that boosts the reliability of the instrument? Of calibrating the instrument? These are the sort of questions that can be fruitfully modeled by means of Bayesian Networks. The results have surprising repercussions on standard theses in philosophy of science (e.g. the variety of evidence thesis and the Duhem-Quine thesis) and yield some novel theoretical insights. As to practical applications, our methodology will be applied to a case study on the discovery of the top quark: what makes this case interesting is that the theory at hand and the methods that are used to analyze the data that confirm the theory are probabilistically dependent.<br/><br/>In epistemology, foundational questions have not been addressed sufficiently within a probabilistic framework. There is the sceptical challenge dating back to Descartes' Meditations that we cannot trust our senses and that our empirical knowledge has no justification. The coherentist answer is that even though the processes by means of which we gather information about the world may be less than fully reliable, the very fact that the scientific story fits together, i.e. has an internal coherence, provides justification that the story is true. But how are we to understand the claim that our information gathering processes are less than fully reliable? How are we to understand the claim that a story is internally coherent? There are many open questions about these central notions in coherentism. Within the framework of Bayesian Networks, multiple notions of less-than-full reliability can be modeled and a probabilistic measure of coherence, which has been a long-time dream of coherentists, can be developed. With a clear understanding of these central notions in hand, the coherentist answer to the Cartesian sceptic can be assessed.<br/><br/>This theoretical work on reliability and coherence has practical applications in the theory of belief change. How does a cognitive system (a person or an expert system) update its beliefs when it receives new information as its input? Under what conditions does it add this new item of information to its previous beliefs? Under what conditions does it discard some of its previous beliefs? On the standard approach, new information is added to the belief set until an inconsistency appears. It is more realistic to let belief change be determined by two factors, viz. how reliable are our information sources and how well does the new information cohere with what we already believe. These factors can be directly modeled by Bayesian Networks. Such modeling yields novel theoretical insights about belief change and carries a promise of applications to information management in expert systems."
94989,Workshop:  Distributed Collective Practices,IIS,DIGITAL SOCIETY&TECHNOLOGIES,9/1/2000,8/13/2003,Leslie Gasser,"Gasser, L","Gasser, L",IL,University of Illinois at Urbana-Champaign,Standard Grant,C. Suzanne Iacono,8/31/2004,"$49,870.00 ",,gasser@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,6850,"9216, HPCC",$0.00 ,exceptionalFunding,"This is a twenty-four month standard award to support an extended, computer-mediated workshop on technical, cognitive, and social processes and infrastructures for distributed collective practices (DCP). DCP is conceptualized along the dimensions of social organization, cognitive processes, and technical infrastructures. A fourth crosscutting area of considerable emerging importance is the development of very large distributed, shareable information bases, community memory projects, and data warehouses, that create computer-mediated collective memory practices.  This workshop brings together computer scientists, cognitive scientists, library and information scientists, artificial intelligence researchers, and social scientists, with the aim of strengthening and focusing the emergent multidisciplinary, international research community in this area.  The workshop will be structured as a two-year web-based discussion, punctuated with two face-to-face meetings.  The first year will establish a seed community, elaborate an international research program, and involve international scientific communities and the general public.  The second year will assess progress, synthesize the results of discussions and joint work, develop and refocus the program's objectives, and produce documentation. This project involves four participating groups from France and the US, including the CNRS Laboratoire d'Informatique pour la Mecanique et les Sciences de l'Ingenieur (LIMSI); the Ecole Nationale Superieure des Telecommunications (ENST); the University of Illinois at Urbana-Champaign, and the University of California at San Diego (UCSD). Collaborative funding is being provided by the UNESCO Management Of Social Transformations Program and the Societe Francaise des Sciences de l'Information et de la Communication."
1763224,"Workshop on Intelligent Cognitive Assistants (ICA). To Be Held November 14-15, 2017 in San Jose, California.",ECCS,"COMMS, CIRCUITS & SENS SYS, ENERGY,POWER,ADAPTIVE SYS, ENG NNI SPECIAL STUDIES",10/15/2017,10/23/2017,David Wallach,"Wallach, D","Wallach, D",NC,Semiconductor Research Corporation,Standard Grant,Shubhra Gangopadhyay,6/30/2018,"$49,500.00 ",,david.wallach@src.org,4819 Emperor Blvd.,Durham,NC,277035420,9199419400,ENG,"7564, 7607, 7681","1653, 7556",$0.00 ,exceptionalFunding,"The PI requests that the CCSS program, within the ECCS Division of the Engineering Directorate at the NSF, to support a workshop titled workshop titled ""Workshop on Intelligent Cognitive Assistants (ICA)"" to be held at IBM Almaden Research Center, San Jose, CA on November 14-15,2017. The goal of the workshop titled ""Workshop on Intelligent Cognitive Assistants (ICA)"" is to identify gaps in science, engineering and technology for developing intelligent, energy-efficient, brain-inspired perception and corresponding devices and systems to support human daily activities and address emerging applications.<br/><br/>The proposed ICA workshop will gather experts from fields spanning psychology, sociology, artificial intelligence and machine learning, robotics, computer science and engineering, to identify the highest priority research needed to address the scientific and engineering challenges of creating the most effective and beneficial Intelligent Assistant-Human collaboration to address applications such as: elder care, autonomous vehicles, smarter communities, and workplace activities."
9633661,Ontological Foundations for Experimental Science Knowledge  Bases,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/1/1996,12/23/1997,Carole Hafner,"Hafner, C","Hafner, C",MA,Northeastern University,Standard Grant,Ephraim P. Glinert,7/31/1998,"$48,971.00 ",,hafner@ccs.neu.edu,360 HUNTINGTON AVE,BOSTON,MA,21155005,6173733004,CSE,6856,"9216, 9237, HPCC",$0.00 ,exceptionalFunding,"The research aims at developing an integrated set of ontological  conventions that addresses the needs of experimental sciences.  In the researchersO earlier work in developing knowledge models  for experimental biology, it was discovered that  there were  several important areas where the knowledge to be represented  poses fundamental challenges to standard ontological frameworks.  For example: 1) the traditional part-of hierarchy is ill-suited  to model the complex substances and mixtures described in  scientific experiments; 2) the primacy of categorization in  knowledge representation, which fundamentally defines entities in  terms of category membership, is at odds with the need to  represent events (such as biochemical reactions) that convert one  substance into another.  The proposed research will improve the  likelihood that ongoing artificial intelligence in knowledge  sharing technology will be of benefit to researchers in  experimental sciences."
1349355,Workshop: Robot Planning in the Real World: Research Challenges and Opportunities,IIS,ROBUST INTELLIGENCE,8/15/2013,6/19/2015,Ron Alterovitz,"Alterovitz, R","Alterovitz, R|Koenig, S|Likhachev, M",NC,University of North Carolina at Chapel Hill,Standard Grant,Jeffrey Trinkle,7/31/2016,"$48,058.00 ","Sven Koenig, Maxim Likhachev",ron@cs.unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"Planning is one of the key technologies in robotics. Yet, robots are deployed in only a small number of niche areas, and most deployed robots have very minimal planning capability. This workshop discusses how the field of robot planning should progress to make robots deployable more widely, performing more novel tasks and relying less on human supervision. It brings together researchers from robotics, artificial intelligence, and related research disciplines to discuss the state of the art in planning, its use in various robotic applications and current research challenges. By studying planning research across different applications, analyzing planning challenges as part of complete robot architectures, and discussing the interaction of planning with other robot modules (such as perception, control, and user interfaces), the workshop participants will gain new insights into how planning can help robots become more robust and efficient. The workshop consists of invited talks, breakout sessions, panels and a final discussion aiming to converge on the roadmap for the field of robot planning that will be summarized in a report. The report and all presentations will be posted on the workshop website. The workshop is expected to stimulate future research towards robot planning in the real world and have strong potential to enable advances in all areas of robotics, from home assistance to medicine to exploration to manufacturing."
1136452,"Workshop on Mechanical Engineering Design Knowledge Modeling; Washington, DC; 28 August 2011",CMMI,ENGINEERING DESIGN AND INNOVAT,8/1/2011,7/20/2011,David Rosen,"Rosen, D","Rosen, D|Summers, J",GA,Georgia Tech Research Corporation,Standard Grant,Paul Collopy,7/31/2013,"$47,314.00 ",Joshua Summers,david.rosen@me.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,ENG,1464,"067E, 068E, 073E, 7556",$0.00 ,exceptionalFunding,"The objective of this award will be to conduct a one day workshop with the aim of clearly defining a research program for capturing, representing, and modeling mechanical engineering design knowledge that the research, academic, and industrial community can pursue in both the near and long term. A formalized language of mechanical engineering is envisioned that will allow engineers to communicate more precisely between each other and with computers. The resulting formalized ME design knowledge and language will be encoded and implemented in an open-knowledge repository. Such a knowledge repository could capture the disparate and representationally diverse ME knowledge of typical undergraduate students providing numerous benefits, including: 1) a standard for ME knowledge; 2) a knowledge base to support engineering design; 3) a knowledge base for computer-aided tutoring systems; and 4) a key component of the ME research and education infrastructure. A convergence of artificial intelligence, engineering informatics, description logics, and the semantic web with mechanical engineering design research will be the enabling factor to realize the vision of this research proposal and workshop. <br/><br/>If successful, the work may impact US economic and national security since a ME knowledge repository could increase the value of US graduates who have expertise beyond just the application of engineering science principles. Successful definition of a research agenda toward an ME knowledge repository has the potential for transformational outcomes. Increased awareness in the research community of high-impact research areas will increase interest in knowledge modeling. Establishing an ME knowledge repository as part of the educational infrastructure enables myriad methods and tools. The knowledge repository also has the potential to be a valuable resource for ME education research, as well as ME research in general. The networking function of the workshop will establish new relationships between individuals spanning widely across the field. This opportunity will provide a stimulus for new interactions and collaboration to advance the state of the art in engineering knowledge modeling. An understanding should emerge of the potential for this work to impact critical areas of engineering education, engineering information modeling, knowledge modeling, and the semantic web. The results will be disseminated through presentations, conference papers, and journal articles."
1242938,LIVE DEMONSTRATION EVENT at the14TH GEC in BOSTON,CNS,Networking Technology and Syst,6/1/2012,6/15/2012,Karen Sollins,"Sollins, K","Sollins, K",MA,Massachusetts Institute of Technology,Standard Grant,Joseph Lyles,5/31/2013,"$45,722.00 ",,sollins@csail.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7363,,$0.00 ,exceptionalFunding,"The Global Environment for Network Innovations 'GENI' is a suite of research infrastructure supported by the NSF that is rapidly emerging in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for 'at scale' experiments in future internets. <br/><br/>The GENI Project Office organizes three major GENI Engineering conferences (GEC) per year, in which the entire GENI community meets to review current status, and to decide on subsequent steps in GENI's evolution. These GECs include community-based working groups leading GENI's design and planning, and demonstrating progress with live experiments. <br/><br/>MIT is hosting the fourteenth edition of the GENI Engineering conference. This project supports organizing the demo session to be held on the MIT Campus. About 400 leading researchers and Ph.D. students from diverse US institutions will gather at MIT to showcase their ideas and results. The campus venue has an existing 10GB link which will provide access to the National Lambda Rail (NLR) network in addition to MIT's more standard Internet services.  Each demo will be provided with 1G wired connection to the GENI infrastructure.    Additionally, because MIT and its Computer Science and Artificial Intelligence Laboratory (CSAIL) provide wireless access to all guests, wireless will be available for demonstrations and participants.  <br/><br/>Broader Impact: The GEC Demo sessions provide graduate students with both an opportunity to demonstrate and explain their work to the GENI community prior to formal publication. It helps new graduate students understand what is being done with GENI and encourages cross-university cooperation by providing a method for students and faculty to discover who amongst their peers at other institutions might be valuable resources. It also supports outreach to new community members, including the emerging US Ignite community."
1142505,"Collaborative Research: EAGER: Network for Science, Engineering, Arts and Design (NSEAD)",IIS,Cyber-Human Systems (CHS),8/1/2011,7/14/2011,Gunalan Nadarajan,"Nadarajan, G","Nadarajan, G",MD,Maryland Institute College of Art,Standard Grant,William Bainbridge,7/31/2012,"$45,618.00 ",,guna@mica.edu,1300 Mount Royal Avenue,Baltimore,MD,212174134,3016699200,CSE,7367,"7367, 7916",$0.00 ,exceptionalFunding,"The Network to support Science, Engineering, Arts and Design (NSEAD) will support transformative research and pedagogy that are only possible through the combined expertise of diverse knowledge domains and disciplines.  For example, as physicists and engineers developed new imaging techniques, visual artists experimented with the new expressive potentials they enabled, often influencing development of the technologies. Visual artists and musicians have created and continue to create computer languages and algorithms while pushing technologies for composing and recording in fields of software engineering, artificial intelligence, graphics and visualization. Students who are involved in the arts have higher math, verbal, and composite SAT scores than students who are not involved in the arts. (Vaughn and Winner, 2000).   There is a growing movement by higher education academic institutions in the United States to integrate the Arts and STEM disciplines to educate the whole student while leveraging creative cognitive skills for solving complex problems in science and technology disciplines.  And finally, diverse ecosystem of academic programs in pre-K to gray formal and informal STEM learning; scientific research conferences; exhibitions, and cultural institution programs continues to emerge as new information technologies, creativity support and social networking tools become pervasive in our society. This project envisions a network that addresses fundamental challenges including the need to align academic pedagogies with 21st century thinking skills; to promote diversity of perspectives, approaches, and people in the creative information technology economy; and to benchmark best practices that create critical thinkers and leaders for the ever-changing technology-driven job market. The development of such a network will provide a platform to disseminate and generate public dialogue about the intellectual, cultural, and economic potential of intersections of science, technology and creativity. <br/><br/>NSEAD will be a platform to support the burgeoning research community of Computer Scientists, Engineers, Artists and Designers engaged in integrative research and pedagogy across these disciplines. NSEAD will provide a bridge for academic institutions, non-profit organizations, industry liaisons, and resource providers to collaborate, share best practices in research and pedagogy, and build stronger affinities. It will serve as a junction for elements such as: 1) research community development;  2) collaboration and project matchmaking opportunities; 3) skills expertise referrals; 4) inter-institutional collaborations; 5) forums to share best practices in pre-K to gray STEM learning and creative enrichment; and 6) strategies for network leadership and resource sustainability."
9616764,Computational Mechanics Workbench,ECCS,"ELECT, PHOTONICS, & MAG DEVICE",10/1/1996,9/5/1996,Gerald Sussman,"Sussman, G","Sussman, G",MA,Massachusetts Institute of Technology,Standard Grant,Vladimir J. Lumelsky,9/30/1998,"$45,000.00 ",,gjs@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,ENG,1517,"0000, OTHR",$0.00 ,exceptionalFunding,"9616764 Sussman, Gerald J. The goal of this research is to create the architectural and algorithmic foundations for intelligent analysis and interpretation of massive numerical datasets. The aim is to provide the technology to reduce the complexity in the analysis of specific engineering problems, and at the same time use these specific problems as a focus to develop general principles that advance the frontiers of Artificial Intelligence. Smart data interpretation programs must exploit visual recognition and symbolic abstraction capabilities. Tracking a multiplicity of interacting, deforming objects might well be too taxing for the human visual system. It is both necessary and exciting to endow our computers with the capability to draw pictures for themselves to see and use what they saw to guide their own future actions. AI programs that integrate 'reasoning with images"" with symbolic computations have been implemented to solve problems in several applications areas, such as dynamical system analysis, controller design, mechanism kinematics. This paradigm can be expected to be integral part of future engineering analysis and design environments. A computational environment will be provided for fluid dynamicists to efficiently extract structures and isolate interaction patterns form simulated or experimental turbulence data, and to perform control experiments on structure interactions. The objectives are : (1) to cut post-processing time of CFD data by one to two order of magnitude, (2) to provide symbolic descriptions of data for summarization and comparison, and (3) to develop symbolic and geometric techniques to encode coherent structures, their evolution, and interactions rules. ***"
1416980,An Intelligent Ecosystem for Science Writing Instruction,DRL,DISCOVERY RESEARCH K-12,9/1/2014,3/29/2016,Christian Schunn,"Schunn, C","Schunn, C|Litman, D|Godley, A",PA,University of Pittsburgh,Standard Grant,David B. Campbell,3/31/2016,"$44,009.00 ","Diane Litman, Amanda Godley",schunn@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,EHR,7645,,$0.00 ,exceptionalFunding,"The ability to express scientific ideas in both written and oral form is an important 21st century skill.   Teachers, employers, and college faculty lament the inability of many high school graduates to write clearly.  This deficit in writing is due in part because teachers do not have the time to provide appropriate, timely feedback to students on their writing. This project would help teachers help students achieve these skills through automating an effective feedback process, in ways that are customized to particular disciplines and local classroom needs, particularly in high needs districts.  The project will contribute to knowledge about how students learn to write and how computer assisted systems can support this learning.<br/><br/>This project will develop and test three tools:  1) Teaching resources organized as developmental trajectories for teachers to use (e.g. from more simple to more complex; with diagnostics and strategies for addressing particular challenges); 2) A teacher dashboard that uses Artificial Intelligence tools to provide timely formative assessment to teachers by highlighting problem areas in their students' writing and peer reviews; and 3) An online teacher resource exchange to rapidly grow the set of appropriate assignments that can be used with this approach, critically filtered by student performance metrics.  The project builds on a current system called SWoRD, which supports student peer reviewing in many disciplines within and beyond science.  Working with six lead teachers and larger set of pilot teachers, the project  will develop a trajectory of effective writing assignments in Biology, Chemistry, and Physics.  In year three, there will be a summative evaluation with 90 teachers."
1142663,"Collaborative Research: EAGER: Network for Science, Engineering, Arts and Design (NSEAD)",IIS,Cyber-Human Systems (CHS),8/1/2011,7/14/2011,Carol Strohecker,"Strohecker, C","Strohecker, C",NC,Winston-Salem State University,Standard Grant,Kevin Crowston,7/31/2012,"$43,493.00 ",,cs@CenterforDesignInnovation.org,601 S Martin Luther King Jr Dr,Winston Salem,NC,271100003,3367502413,CSE,7367,"7367, 7916",$0.00 ,exceptionalFunding,"The Network to support Science, Engineering, Arts and Design (NSEAD) will support transformative research and pedagogy that are only possible through the combined expertise of diverse knowledge domains and disciplines.  For example, as physicists and engineers developed new imaging techniques, visual artists experimented with the new expressive potentials they enabled, often influencing development of the technologies. Visual artists and musicians have created and continue to create computer languages and algorithms while pushing technologies for composing and recording in fields of software engineering, artificial intelligence, graphics and visualization. Students who are involved in the arts have higher math, verbal, and composite SAT scores than students who are not involved in the arts. (Vaughn and Winner, 2000).   There is a growing movement by higher education academic institutions in the United States to integrate the Arts and STEM disciplines to educate the whole student while leveraging creative cognitive skills for solving complex problems in science and technology disciplines.  And finally, diverse ecosystem of academic programs in pre-K to gray formal and informal STEM learning; scientific research conferences; exhibitions, and cultural institution programs continues to emerge as new information technologies, creativity support and social networking tools become pervasive in our society. This project envisions a network that addresses fundamental challenges including the need to align academic pedagogies with 21st century thinking skills; to promote diversity of perspectives, approaches, and people in the creative information technology economy; and to benchmark best practices that create critical thinkers and leaders for the ever-changing technology-driven job market. The development of such a network will provide a platform to disseminate and generate public dialogue about the intellectual, cultural, and economic potential of intersections of science, technology and creativity. <br/><br/>NSEAD will be a platform to support the burgeoning research community of Computer Scientists, Engineers, Artists and Designers engaged in integrative research and pedagogy across these disciplines. NSEAD will provide a bridge for academic institutions, non-profit organizations, industry liaisons, and resource providers to collaborate, share best practices in research and pedagogy, and build stronger affinities. It will serve as a junction for elements such as: 1) research community development;  2) collaboration and project matchmaking opportunities; 3) skills expertise referrals; 4) inter-institutional collaborations; 5) forums to share best practices in pre-K to gray STEM learning and creative enrichment; and 6) strategies for network leadership and resource sustainability."
9980999,Undergraduate Robotics Laboratory,DUE,CCLI-ADAPTATION AND IMPLEMENTA,5/1/2000,4/17/2000,Robert Harlan,"Harlan, R","Harlan, R|Levine, D",NY,Saint Bonaventure University,Standard Grant,Jane Prey,4/30/2002,"$41,423.00 ",David Levine,rharlan@sbu.edu,PO Box 2500,St. Bonaventure,NY,147782500,7163752435,EHR,7428,"7428, 9178, SMET",$0.00 ,exceptionalFunding,"Computer Science (31)<br/><br/>This project builds a robotics laboratory and provides integrated experiences in the undergraduate computer science curriculum through new courses and modified course experiences. It adapts aspects of existing exemplary projects at MIT and Swarthmore College as appropriate to meet the local needs. The undergraduate robotics laboratory enables undergraduate computer science majors to study, design and implement control algorithms for autonomous robots as well as to explore techniques for object recognition and manipulation. It also permits robotics to be introduced to lower division majors through a lab using a robotics simulator and to majors in artificial intelligence through a lab that enables an integrated planning and natural language processing system to control a robot. The lab supports a survey course on human and artificial intelligence designed for non-majors, a course that will form part of a three-course sequence on cognitive science. Most students overestimate the capabilities and intelligence of robots and computers. By permitting them to study control algorithms for low-level behaviors, they gain an understanding of what robots and computers can and cannot do and an appreciation of the contribution computer science has made to the study of human intelligence.<br/><br/><br/>"
1724537,WORKSHOP: The Pioneers Workshop at the 2017 ACM/IEEE International Conference on Human-Robot Interaction,IIS,Cyber-Human Systems (CHS),3/1/2017,2/21/2017,Brian Scassellati,"Scassellati, B","Scassellati, B",CT,Yale University,Standard Grant,Ephraim P. Glinert,2/28/2018,"$40,950.00 ",,brian.scassellati@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Pioneers Workshop (doctoral consortium) of approximately 24 graduate students (12 of whom are from the United States and therefore eligible for funding), along with distinguished research faculty.  The event will take place as part of the first day of activities at the 12th International Conference on Human Robot Interaction (HRI 2017), to be held March 6-9 in Vienna, Austria, and which is jointly sponsored by ACM and IEEE.  HRI is the premier conference for showcasing the very best interdisciplinary and multidisciplinary research on human-robot interaction, with roots in diverse fields including robotics, artificial intelligence, social psychology, cognitive science, human-computer interaction, human factors, engineering, and many more.  It is a single-track, highly selective annual international conference that invites broad participation.  Building on the ""Smart City Wien"" initiative, the theme of HRI 2017 is ""Smart Interaction.""  The conference seeks contributions from a broad set of perspectives, including technical, design, methodological, behavioral, and theoretical, that advance fundamental and applied knowledge and methods in human-robot interaction, with the goal of enabling human-robot interaction through new technical advances, novel robot designs, new guidelines for design, and advanced methods for understanding and evaluating interaction.  More information about the conference is available online at http://humanrobotinteraction.org/2017.  The Pioneers Workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities.  This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives.  Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  Participants will also gain leadership and service experience, as the workshop is largely student organized and student led.  The PI has expressed his strong commitment to recruiting women and members from under-represented groups.  To further ensure diversity the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, will recruit students who are just beginning their graduate degree programs in addition to students who are further along in their degrees, and will strive to limit the number of participants accepted from a particular institution to at most two.  As a new feature this year, the organizers will also invite 3 undergraduate students (all eligible for funding) to help increase diversity in the pipeline of students entering this field.<br/> <br/>The Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference.  During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries.  To these ends, the workshop format will encompass a variety of activities including three keynotes, a distinguished panel session, and breakout sessions.  To start the day, all workshop attendees will briefly introduce themselves and their interests.  Following the opening keynote, approximately half of the participants will present 3-minute overviews of their work, leading into an interactive poster session.  This will enable all participants to share their research and receive feedback from students and senior researchers in an informal setting.  The workshop organizers will facilitate the post-presentation discussion and will encourage participants to ask questions of their peers during the interactive break and poster session.  After lunch, the remaining workshop participants will give their 3-minute overviews, followed by presentation of their posters during a second interactive poster session.  Senior researchers (in addition to those on the panel) will be invited to attend the student presentations and poster sessions in order to provide feedback to participants, and workshop participants will be invited to present their posters during the main poster session of the HRI conference as well.  The conversations between the panel and participants will continue over lunch and during dinner."
740093,Workshop on The Living Heritage of Artificial Intelligence,IIS,INFO INTEGRATION & INFORMATICS,8/1/2007,3/3/2009,Gerald Sussman,"Sussman, G","Sussman, G|Minsky, M|Abelson, H",MA,Massachusetts Institute of Technology,Standard Grant,Sylvia J. Spengler,2/28/2010,"$40,320.00 ","Marvin Minsky, Harold Abelson",gjs@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7364,"9216, HPCC, 7364",$0.00 ,exceptionalFunding,"Abstract<br/><br/>IIS - 0740093<br/>Workshop on The Living Heritage of Artificial Intelligence Sussman, Gerald J. <br/>Massachusetts Institute of Technology<br/><br/>This proposal is to convene a workshop and begin an extended dialogue on the emergence of ""Artificial Intelligence"", it's topical evolution over the past 50 years and begin a process of developing possible roadmaps of future work in AI informed by an analysis of the successes and failures of the past. Simultaneously, it will produce a plan and suggest processes for the preservation of key materials from past research milestones in ways that facilitate new discoveries and new perspectives. From a preservation research perspective, special challenges exist with regard to artifactual materials such as tapes, punch cards, documents, hardware and the interfaces to the materials. One theme of the workshop will address current preservation efforts from a variety of perspectives and backgrounds."
834034,Computer Science and Computational Approaches to Music for Middle School and High School Students,IIS,"Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, CreativeIT",6/15/2008,4/30/2009,Adam Meyers,"Meyers, A","Meyers, A",NY,New York University,Standard Grant,Tatiana D. Korelsky,11/30/2009,"$40,000.00 ",,meyers@cs.nyu.edu,70 WASHINGTON SQUARE S,NEW YORK,NY,100121019,2129982121,CSE,"7367, 7495, 7788","7495, 9215, 9237, HPCC",$0.00 ,exceptionalFunding,"This Small Grant for Exploratory Research (SGER) supports a pilot study at New York University<br/>(NYU), under which computer science (CS) is being taught to math and music savvy children in<br/>grades 7-12. They are learning how CS principles apply to music, a technical field with known<br/>computational applications including sound manipulation, music information retrieval, and musicrelated<br/>artificial intelligence. The focus is on fundamental scientific concepts like algorithms and<br/>data structures and how they apply to technical problems. This contrasts with previous approaches<br/>to teaching pre-college CS, e.g., AP computer science classes focus on a currently popular computer<br/>language (JAVA) and other classes focus on currently popular computer applications (word<br/>processing, spreadsheets, etc.). Follow up studies are anticipated for teaching other computational<br/>domains, such as robotics and artificial intelligence approaches to solving games. Again, the focus<br/>will be on formal computational problem solving, rather than the use of currently popular computer<br/>languages and applications.<br/>This study explores the incorporation of basic CS into the middle/high school curricula, a<br/>significant question for the educational and scientific research communities. The ubiquitousness<br/>of computational thinking in current intellectual thought makes this an extremely significant line<br/>of research.<br/>The teaching materials created in this pilot study will be available on the world wide web and<br/>results will be submitted for publication. This pilot study is intended as a stepping stone to a real<br/>computer science curriculum for pre-college students, which should prove essential to the future<br/>economic and intellectual development of the United States."
9750858,An Undergraduate Laboratory for Building and Programming Intelligent Mobile Robots,DUE,UNDERGRAD INSTRM & LAB IMPROVE,7/1/1997,2/25/2000,Chitta Baral,"Baral, C","Baral, C|Gelfond, M",TX,University of Texas at El Paso,Standard Grant,Jane Prey,6/30/2000,"$40,000.00 ",Michael Gelfond,chitta@asu.edu,ADMIN BLDG RM 209,El Paso,TX,799680001,9157475680,EHR,7400,"SMET, 9178, 9267",$0.00 ,exceptionalFunding,"This project establishes an undergraduate laboratory for building and programming intelligent mobile robots. This laboratory is mainly used in the undergraduate courses titled Building and Programming Mobile Robots (BPMR), Artificial Intelligence (AI), and Computer Control. The BPMR course is a new course that adapts materials from the MIT 6.270 robot contest OMS+ and the course on robots taught at Stanford by Konolige to this urban university of 17,000 that has 62.7 Hispanic students. The current course on AI will be significantly modified to incorporate hands-on exercise on mobile robots. The goals behind establishing the laboratory include increasing the number of computer science majors, the number of students from the area pursuing computer science, the number of computer science graduates with a significant background in robotics, the number of computer science undergraduates involved in research, and the number of computer science undergraduates continuing on to a graduate program or to a research career. The faculty associated with this project have ongoing research programs on topics, such as reasoning about actions, planning, robot navigation, fuzzy control, and neural networks, that play a big role in creating an autonomous mobile robot. Undergraduate students, after taking courses that use the new laboratory, are able to participate in the related research programs. As a motivational tool, a team that includes undergraduate students is sent to the annual AAAI/IJCAI robot contests. Robot building workshops are provided, as are robot demonstrations for high school students and teachers and other university students. These workshops encourage a larger number of students to pursue a degree in computer science."
1344017,Machine Learning Summer School Pittsburgh 2014,IIS,"INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE",9/1/2013,8/28/2013,Alexander Smola,"Smola, A","Smola, A|Kolter, Z",PA,Carnegie-Mellon University,Standard Grant,Sylvia J. Spengler,8/31/2014,"$40,000.00 ",Zico Kolter,smola@cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"7364, 7495","7364, 7495, 7556",$0.00 ,exceptionalFunding,"Machine learning has many important applications in science and industry. Modern machine learning uses a mix of insights from different disciplines, most notably artificial intelligence, statistics and optimization - areas that traditionally have not had much overlap. The participants will take part in tutorials given by experts from several different areas of machine learning - an opportunity that many students do not have at their home institutions. <br/><br/>The project supports student participation in a Machine Learning Summer School to be held at Carnegie Mellon University in Pittsburgh during June 16-27, 2014. The summer school emphasizes big data and scalable machine learning algorithms. It features speakers from academia and industry with established experience in large scale data analysis. Approximately 50 graduate students from around the U.S. are expected to participate in person. The content will be streamed live as well as archived online making it possible for a much larger number of students from academia and industry to benefit from the summer school. In addition to in-depth tutorial lectures given by leading researchers, the summer school will include exercise sessions that provide the participants hands-on experience with large scale data (using the Kaggle platform and Amazon cloud services). <br/><br/>Broader Impact: The Summer School provides state-of-the art knowledge of machine learning and big data analytics to graduate students - an opportunity that many students do not have at their home institutions. Thus, it would not only help train an new generation of machine learning and big data analytics researchers, but also reduce the barrier to entry of researchers who want to apply state-of-the-art machine learning techniques to applications in areas such as social network analytics, bioinformatics etc."
9617307,"CISE Research Instrumentation:  Active Learning for Text,   Scene, and Biosequence Analysis",EIA,CISE RESEARCH RESOURCES,2/1/1997,1/30/1997,Garrison Cottrell,"Cottrell, G","Cottrell, G|Belew, R|Mjolsness, E|Elkan, C",CA,University of California-San Diego,Standard Grant,Frederica Darema,1/31/1999,"$40,000.00 ","Richard Belew, Eric Mjolsness, Charles Elkan",gary@cs.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,2890,"9218, HPCC",$0.00 ,exceptionalFunding,"9617307  Cottrell, Garrison W.  Charles Elkan,  University of California, San Diego    CISE Research Instrumentation: Active Learning for Text, Scene, and Biosequence Analysis     Adaptation to changing environments and changing goals through autonomous learning is a central theme of research in the artificial intelligence laboratory at UCSD.  The workstations, robots, and neural network hardware acquired through this grant will enable recently developed learning methods to be tested in four large-scale, real-world applications.-Learning Semantic Representations for Information Retrieval-Embedded Virtual Agents-MEME: A New Software Tool for Sequence Analysis-Real Time Face and Object Recognition in Embedded Agents.  The first subproject will apply new algorithms for document rerepresentation and response to human feedback to gigabytes of text in the national TREC competition. Another project will port to the worldwide web software agents that learn and interact now in a simulated artificial life environment. A third project will scale up new software for finding patterns in DNA and protein sequences into a tool capable of autonomously analyzing entire genomes.  Finally, a fourth project will validate new active vision methods for recognizing and tracking objects by implementing these methods in mobile robots with controllable cameras."
548304,"NSF Workshop: Bridging the Gap Between Operations Research and Approximate Dynamic Programming, April 16-20, 2005, in Cancun, Mexico",CMMI,OPERATIONS RESEARCH,1/1/2006,8/19/2005,Warren Powell,"Powell, W","Powell, W",NJ,Princeton University,Standard Grant,Stephen G. Nash,12/31/2007,"$40,000.00 ",,powell@princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,ENG,5514,"9146, 9147, MANU",$0.00 ,exceptionalFunding,"Dynamic programming has long held the promise of solving some of the more challenging decision problems.  However, these approaches have suffered from the well known ""curse of dimensionality"" which essentially limits their applicability to decision problems with a few state variables.  Recent advances in approximating these decision problems have led to methods known as approximate dynamic programming.  These methods are intimately related to several other methods such as linear programming, and stochastic programming.  This workshop will explore connections among these methods, as well as several important applications arising in transportation, power systems, and others.  This workshop will bring together researchers and students from several disciplines, such as artificial intelligence, neural networks, and operations research to focus on new breakthroughs in approximate dynamic programming, and related areas.  <br/><br/>"
1038216,Million Book Project Partners Meeting 2010,IIS,Cyber-Human Systems (CHS),8/1/2010,7/27/2010,Gloriana St. Clair,"Clair, GS","Clair, GS",PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,7/31/2011,"$39,970.00 ",,gstclair@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,7367,,$0.00 ,exceptionalFunding,"This proposal requests funds for a ""Million Book Project"" partners research and coordination meeting.  Begun in 2000, the Million Book Project has scanned over 1.6 million books in China, India, Egypt and Australia and made great strides in research areas relevant to large-scale, multi-lingual database storage and retrieval. Project partners intend to continue to work together on issues related to human computer interactions, usability, automatic metadata detection and correction using artificial intelligence, intellectual property, machine translation and summarization, improving and providing centralized access to metadata, long term data storage and access issues, diversity and education.  Funding provided by the National Science Foundation has attracted international partners and matching funds exceeding $100 million U.S. dollars."
324742,US-South Africa Cooperative Research: Intelligent Knowledge Acquisition and Service Delivery,OISE,"AFRICA, NEAR EAST, & SO ASIA",10/1/2003,9/9/2009,Harry Keeling,"Keeling, H","Keeling, H|Keeling, H",DC,Howard University,Standard Grant,DeAndra Beck,9/30/2009,"$37,338.00 ",Harry Keeling,hkeeling@howard.edu,2400 Sixth Street N W,Washington,DC,200599000,2028064759,O/D,5976,"0000, 1066, OTHR",$0.00 ,exceptionalFunding,"This project links research conducted by the University of Western Cape's (UWC) in South Africa with Howard University's efforts in ""Intelligent Systems and Knowledge Acquisition"".  The highlight of this effort is that each year an investigator from Howard University and three graduate students from Howard University will travel to UWC to conduct research with UWC faculty and students.  Their work will focus on the emerging intelligent-based internet computing - ""The Semantic Web"" with its evolving languages and ontologies.  According to Fensel and Musen, ""in a few years, it [the Web] will interweave one billion people and penetrate not just computers but also other devices, including cars, refrigerators, coffee machines, and even clothes."" The new millennium has ushered in the era of ""intelligent knowledge engineering and management"" (IKEM).  <br/><br/> This project will have an immediate and long-range impact on several existing and proposed courses at both universities.  Existing courses include Artificial Intelligence, Expert Systems, Computer Networks, Modeling and Simulation, Multimedia Systems, Systems Management, Large Scale Systems, and Web Services.  Proposed courses include Advanced Intelligent Systems, and Human Computer Interaction.  Advances in the development of an IKEM system will promote the utilization of digital libraries, semantic web services and real-time knowledge manipulation.  Linking IKEM system development and utilization will provide a number of possibilities for extending this initial effort. <br/>"
1418922,WORKSHOP: HRI 2014 Pioneers,IIS,"INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems (CHS)",1/15/2014,1/9/2014,Robin Murphy,"Murphy, R","Murphy, R",TX,Texas A&M Engineering Experiment Station,Standard Grant,Ephraim P. Glinert,12/31/2014,"$35,016.00 ",,murphy@cse.tamu.edu,TEES State Headquarters Bldg.,College Station,TX,778454645,9798477635,CSE,"1640, 7367","7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Pioneers Workshop (doctoral consortium) of approximately 18 graduate students and post-docs (including about 12 U.S. participants) from diverse research communities (e.g., computer science and engineering, psychology, cognitive science, robotics, human factors, human-computer interaction design, and communications), along with distinguished research faculty. NSF funding will be used solely to cover travel, housing, and subsistence for eligible U.S. attendees. The event will take place on Monday, March 3, 2014, immediately preceding the Ninth International Conference on Human Robot Interaction (HRI 2014), to be held March 4-6 in Bielefeld, Germany, and which is jointly sponsored by ACM and IEEE. HRI is a single-track, highly selective annual international conference that seeks to showcase the very best inter- and multi-disciplinary research in human-robot interaction with roots in social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology and many more, and invites broad participation. The theme of HRI 2014 is ""(E)Merging Perspectives"" which seeks to combine both user and system perspectives to advance new and possibly unorthodox methodologies. To extend the current singular approaches, this year's conference emphasizes papers that demonstrate the usage of novel empirical methods, the integration of empirical findings into complex robot systems, and holistic approaches in system evaluation. More information about the conference is available online at http://humanrobotinteraction.org/2014. <br/><br/>The Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference. During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries. To these ends, the workshop format will include oral presentations from 2 student attendees, poster presentations from all attendees, a hands-on meet-and-greet session, two alumni speakers, a keynote, and a panel presentation by senior researchers. The oral presentations and the interactive poster sessions will provide a forum for participants to share their research, enabling them to receive feedback on their work and to gain perspective on the field. The hands-on meet-and-greet session will involve networking and the cultivation of cross-disciplinary ideas. The alumni presentations will provide advice for short-term goals and a recent perspective on looking for jobs within the community. The keynote lecture will provide a global and future vision for HRI. The panel presentation will feature five senior HRI researchers from both academia and industry who will share insights about their own careers, answer career path questions, and provide insight into the interdisciplinary nature of the HRI community. The conversations between the panel and participants will continue over lunch and during dinner.<br/><br/>Broader Impacts: This workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities (including but not limited to computer science and engineering, psychology, robotics, human factors and ergonomics, and HCI). This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives. Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years. Participants will also gain leadership and service experience, as the workshop is largely student organized and student led. The PI has expressed her strong commitment to recruiting women and members from under-represented groups. To further ensure diversity the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, and will limit the number of participants accepted from a particular institution to two, with one being a woman if two are accepted"
1733809,Summer School on Cognitive Robotics,IIS,ROBUST INTELLIGENCE,5/1/2017,5/2/2017,Brian Williams,"Williams, B","Williams, B",MA,Massachusetts Institute of Technology,Standard Grant,Reid Simmons,4/30/2018,"$34,943.00 ",,williams@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This proposal will support a week-long summer school on Cognitive Robotics to be held in Boston, Ma in June 2017.  The summer school will be a combination of invited talks and tutorials, which are designed to introduce students to issues in planning and execution from perspectives of both Robotics and Cognitive Artificial Intelligence, and daily labs, which are designed to give students hands-on experience with robotic hardware and state-of-the-art software tools for developing robotic behaviors.  The summer school will help expose graduate students to cutting-edge ideas at the intersection of Robotics and Cognitive Systems and will help to form a new community of researchers in this interdisciplinary area."
439105,Collaborative Research:     SGER:    Computer-Assisted Interpretation of Citizen Input in Rebuilding Lower Manhattan,IIS,DIGITAL GOVERNMENT,9/1/2004,7/29/2005,Javed Mostafa,"Mostafa, J","Mostafa, J",IN,Indiana University,Standard Grant,Lawrence Brandt,8/31/2006,"$34,638.00 ",,jm@unc.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,CSE,1706,"9216, 9237, HPCC",$0.00 ,exceptionalFunding,"This is a collaborative grant with two PIs; Javed Mostafa of Indiana, and David Stark of Columbia.  <br/><br/>Intellectual Merit<br/>With a grant from the NSF Digital Government Program, David  Stark has been studying the role of information technologies in the public debate surrounding the rebuilding of Lower Manhattan in the wake of the September 11 attacks on the World Trade Center. In the process of conducting that research Stark's team has assembled an extensive digital archive containing  5,000 participant oral statements from one town hall meeting and an additional 19,000 oral statements collected at 240 different venues around New York City in the 'Imagine New York Envisioning Workshops'. These gathered statements provide a rich opportunity for testing various strategies of computer-assisted interpretation because they provide an opportunity to compare the conceptual patterns discerned by human intelligence with findings reached through the analytical methods of artificial intelligence. Supporting the initial explotation of that archive is the purpose of this grant.<br/><br/>The technical component of this grant arises from work Javed Mostafa has done under an NSF ITR grant. Data mining research concentrating on spontaneous human conversations is at an early stage of development. Mostafa's approach to data mining can offer different ways to analyze the same data. The project has three specific goals: 1) to detect emergent concepts by applying techniques that do not impose any a priori conditions; 2) to use techniques for analyzing known concepts by applying constraints on the mining process, and 3) to develop visualization of the results to facilitate interpretation by social scientists and support direct validation by citizen participants. <br/><br/>Broad Impact <br/>Computer mediated communication offers new channels for citizens to express their views to elected officials and government agencies. Often, the resulting deluge of comments poses a technical and political challenge. How can officials/agencies make sense of large-scale citizen input? How can meaningful patterns be efficiently and effectively identified? This project will contribute to advancing understanding of the opportunities and the limitations of computer-assisted interpretation. Its findings will be of considerable interest to scholars  as well as to government managers responsible for the rebuilding of lower Manhattan. <br/><br/>Summary <br/>Many challenges involved in creating new data mining tools demands an interdisciplinary collaboration for access to new data; this project offers such an opportunity. This time-critical testing of artificial intelligence methods will be important in understanding the public input to rebuilding lower Manhattan.<br/><br/>"
439096,Collaborative Research:     SGER:    Computer-Assisted Interpretation of Citizen Input in Rebuilding Lower Manhattan,IIS,DIGITAL GOVERNMENT,9/1/2004,8/18/2004,David Stark,"Stark, D","Stark, D",NY,Columbia University,Standard Grant,Lawrence Brandt,8/31/2005,"$34,619.00 ",,dcs36@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,1706,"9216, 9237, HPCC",$0.00 ,exceptionalFunding,"This is a collaborative grant with two PIs; Javed Mostafa of Indiana, and David Stark of Columbia.  <br/><br/>Intellectual Merit<br/>With a grant from the NSF Digital Government Program, David  Stark has been studying the role of information technologies in the public debate surrounding the rebuilding of Lower Manhattan in the wake of the September 11 attacks on the World Trade Center. In the process of conducting that research Stark's team has assembled an extensive digital archive containing  5,000 participant oral statements from one town hall meeting and an additional 19,000 oral statements collected at 240 different venues around New York City in the 'Imagine New York Envisioning Workshops'. These gathered statements provide a rich opportunity for testing various strategies of computer-assisted interpretation because they provide an opportunity to compare the conceptual patterns discerned by human intelligence with findings reached through the analytical methods of artificial intelligence. Supporting the initial explotation of that archive is the purpose of this grant.<br/><br/>The technical component of this grant arises from work Javed Mostafa has done under an NSF ITR grant. Data mining research concentrating on spontaneous human conversations is at an early stage of development. Mostafa's approach to data mining can offer different ways to analyze the same data. The project has three specific goals: 1) to detect emergent concepts by applying techniques that do not impose any a priori conditions; 2) to use techniques for analyzing known concepts by applying constraints on the mining process, and 3) to develop visualization of the results to facilitate interpretation by social scientists and support direct validation by citizen participants. <br/><br/>Broad Impact <br/>Computer mediated communication offers new channels for citizens to express their views to elected officials and government agencies. Often, the resulting deluge of comments poses a technical and political challenge. How can officials/agencies make sense of large-scale citizen input? How can meaningful patterns be efficiently and effectively identified? This project will contribute to advancing understanding of the opportunities and the limitations of computer-assisted interpretation. Its findings will be of considerable interest to scholars  as well as to government managers responsible for the rebuilding of lower Manhattan. <br/><br/>Summary <br/>Many challenges involved in creating new data mining tools demands an interdisciplinary collaboration for access to new data; this project offers such an opportunity. This time-critical testing of artificial intelligence methods will be important in understanding the public input to rebuilding lower Manhattan.<br/><br/>"
1311610,WORKSHOP: The 2013 HRI Pioneers Workshop at the 2013 ACM/IEEE International Conference on Human-Robot Interaction,IIS,Cyber-Human Systems (CHS),2/1/2013,1/17/2013,Peter Kahn,"Kahn, P","Kahn, P",WA,University of Washington,Standard Grant,Ephraim P. Glinert,1/31/2014,"$34,575.00 ",,pkahn@uw.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Young Pioneers Workshop (doctoral consortium) of approximately 20 graduate students and post-docs (including 15 U.S. participants) from diverse research communities (e.g., computer science and engineering, psychology, cognitive science, robotics, human factors, human-computer interaction design, and communications), along with distinguished research faculty.  NSF funding will be used solely to cover travel, housing, and subsistence for eligible U.S. attendees.  The event will take place on Sunday, March 3, 2013, immediately preceding the Eighth Annual Human Robot Interaction Conference (HRI 2013), to be held March 3-6, 2013, in Tokyo, Japan, and which is jointly sponsored by ACM and IEEE.  HRI is a single-track, highly selective annual international conference that seeks to showcase the very best inter- and multi-disciplinary research in human-robot interaction with roots in social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology and many more, and invites broad participation.  The theme of HRI 2013 is ""Holistic Human-Robot Development.""  Robotic solutions are increasingly applied to real world problems such as our aging society, renewable energy, climate control, emergency response, education and exploration. These societal problems require a holistic approach to the design and development of robots that meet human needs, address technical challenges, and foster acceptance in everyday settings.  More information about the conference is available online at http://humanrobotinteraction.org/2013.<br/><br/>The Young Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference. During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries. To these ends, the workshop format will include oral presentations from 2 student attendees, poster presentations from all student attendees, a hands-on breakout session with group presentations, a keynote, and a panel presentation by senior researchers who will share their expertise and insights on how to address the interdisciplinary challenge of HRI.  The afternoon breakout session will involve small groups of 3-5 attendees with diverse backgrounds, working to design an integrative HRI project, thereby encouraging group participation and the cultivation of cross-disciplinary ideas.  The presentation session afterward will allow each breakout group to present a summary to the entire workshop; the organizers anticipate that the discussions will continue during dinner. <br/><br/>Broader Impacts:  This workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities (including but not limited to computer science and engineering, psychology, robotics, human factors and ergonomics, and HCI).  This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives. Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  Participants will also gain leadership and service experience, as the workshop is largely student organized and student led.  The PI has expressed his strong commitment to recruiting women and members from other under-represented groups.  To further ensure diversity, the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, and no more than one applicant will be accepted from any given institution."
9901201,US-Brazil Cooperative Research: Monitoring and Diagnosis of Process System Components,OISE,AMERICAS PROGRAM,4/1/1999,4/12/2004,Belle Upadhyaya,"Upadhyaya, B","Upadhyaya, B|Hines, J",TN,University of Tennessee Knoxville,Standard Grant,Francis J. Wodarczyk,7/31/2004,"$34,000.00 ",J. Hines,bupadhya@utk.edu,1 CIRCLE PARK,KNOXVILLE,TN,379960003,8659743466,O/D,5977,"0000, 5913, OTHR",$0.00 ,exceptionalFunding,"Upadhyaya 99-01201<br/><br/>This US-Brazil award supports collaborative research between Dr. Belee R. Upadhyaya, University of Tennessee, Knoxville and Dr. Daniel K. S. Ting, Instituto de Pesquisas Energeticas e Nucleares (IPEN), San Paulo, Brazil. They will conduct a two-year research study on monitoring and diagnosis of process system components. <br/><br/>The principal goal of this research is to develop new on-line monitoring and fault detection methods to improve the operational safety, reliability, and economic gains of large industrial systems. <br/><br/>The proposed work is complementary. The US PI will have access to two IPEN research reactors and a full scale thermal-hydraulic laboratory. Access to IPEN data and an understanding of issues relative to plant aging and life extension will benefit not only the PI but has application s to US industrial interests in general. <br/>Brazil will benefit from PC based signal processing and applied artificial intelligence modules to be developed by the University of Tennessee for testing at IPEN. The Brazilian commercial nuclear power plants are the ultimate receives of this technology.<br/>***"
1444182,CNIC: U.S.-Netherlands Planning Visit for Cooperative Research on Intelligent Methods Under Uncertainty for Renewable Energy Driven Smart Grids,OISE,Catalyzing New Intl Collab,5/1/2015,4/17/2015,Prashant Doshi,"Doshi, P","Doshi, P",GA,University of Georgia Research Foundation Inc,Standard Grant,Graham M. Harrison,4/30/2017,"$33,608.00 ",,pdoshi@cs.uga.edu,310 East Campus Rd,ATHENS,GA,306021589,7065425939,O/D,7299,"5948, 5979, 8231, 8399",$0.00 ,exceptionalFunding,"This new, catalytic U.S.-Netherlands research collaboration addresses renewable energy-driven smart grids. Renewable energy sources include resources that are regularly replenished, such as sunlight, wind, rain, tidal waves, and geothermal heat.  To pursue innovative approaches for managing the uncertainty of renewable energy sources, the U.S. principal investigator (PI) and a graduate student will visit the Netherlands to begin a collaboration with counterparts at the Delft University of Technology, a leader in European smart energy research.  There they intend to work together to improve current smart grid technology for better prediction of consumer demand in the face of uncertain power generation, as is often the case in renewable energy systems.  If successful, their preliminary results should contribute to improving bidirectional communication between grid operators and consumers.  Early results and follow-on research may have broader impact by shaping management strategies through new approaches to modeling consumer energy usage.  Success could mean better long-term prediction by employing new artificial intelligence approaches (AI), i.e., smart controls for power grids.<br/><br/>The team expects to identify the challenges posed by the uncertainty of renewable energy generation and begin investigating intelligent methods for meeting these challenges in two priority areas: (a) planning for decentralized power generation and storage, and (b) managing congestion in grids due to asynchrony between renewable energy supply and consumer demand.  The PI will work with an experienced team of eminent Dutch researchers in AI, power systems, and technology policy.  They will have real operating and energy-use data from a medium voltage grid in Netherlands and intend to start developing scalable algorithms for individual decision making in multi-agent settings.  Further, broader impacts are anticipated from this collaboration with an introduction of smart energy systems into research and teaching at the University of Georgia, thereby contributing to training U.S. undergraduate and graduate students in an innovative and rapidly growing energy sector with industrial relevance."
1632236,WORKSHOP: The Pioneers Workshop at the 2016 ACM/IEEE International Conference on Human-Robot Interaction,IIS,Cyber-Human Systems (CHS),3/1/2016,2/19/2016,Maja Mataric,"Mataric, M","Mataric, M",CA,University of Southern California,Standard Grant,Ephraim P. Glinert,2/28/2017,"$33,552.00 ",,mataric@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Pioneers Workshop (doctoral consortium) of approximately 31 graduate students (16 of whom are from the United States and therefore  eligible for funding) from diverse research communities (e.g., computer science and engineering, psychology, cognitive science, robotics, human factors, human-computer interaction design, and communications), along with distinguished research faculty. The event will take place on March 7, 2016, immediately preceding the 11th International Conference on Human Robot Interaction (HRI 2016), to be held March 8-10 in Christchurch, New Zealand, and which is jointly sponsored by ACM and IEEE. HRI is a single-track, highly selective annual international conference that seeks to showcase the very best inter- and multi-disciplinary research in human-robot interaction with roots in diverse fields including social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology and many more, and to this end the conference invites broad participation. The theme of HRI 2016 is ""Natural Interaction"" which seeks contributions from a broad set of perspectives, including technical, design, methodological, behavioral, and theoretical, that advance fundamental and applied knowledge and methods in human-robot interaction, with the goal of enabling human-robot interaction through new technical advances, novel robot designs, new guidelines for design, and advanced methods for understanding and evaluating interaction. More information about the conference is available online at http://humanrobotinteraction.org/2016/. This workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities (including but not limited to computer science and engineering, psychology, robotics, human factors and ergonomics, and HCI). This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives. Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years. Participants will also gain leadership and service experience, as the workshop is largely student organized and student led. The PI has expressed her strong commitment to recruiting women and members from under-represented groups. To further ensure diversity the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, will recruit students who are just beginning their graduate degree programs in addition to students who are further along in their degrees, and will strive to limit the number of participants accepted from a particular institution to at most two.<br/><br/>The Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference. During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries. To these ends, the workshop format will encompass a variety of activities including three keynotes, a distinguished panel session, and breakout sessions. To start the day, all workshop attendees will briefly introduce themselves and their interests. Following the opening keynote, approximately half of the participants will present 3-minute overviews of their work, leading into an interactive poster session. This will enable all participants to share their research and receive feedback from students and senior researchers in an informal setting. The workshop organizers will facilitate the post-presentation discussion and will encourage participants to ask questions of their peers during the interactive break and poster session. After lunch, the remaining workshop participants will give their 3-minute overviews, followed by presentation of their posters during a second interactive poster session. Senior researchers (in addition to those on the panel) will be invited to attend the student presentations and poster sessions in order to provide feedback to participants, and workshop participants will be invited to present their posters during the main poster session of the HRI conference as well. The conversations between the panel and participants will continue over lunch and during dinner."
527138,US-China Workshop on Computer Vision,OISE,Catalyzing New Intl Collab,8/15/2005,8/12/2005,Song-Chun Zhu,"Zhu, SC","Zhu, SC",CA,University of California-Los Angeles,Standard Grant,W. Y. B. Chang,7/31/2007,"$33,000.00 ",,sczhu@stat.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,O/D,7299,"0000, 5978, 9200, OTHR",$0.00 ,exceptionalFunding,"ABSTRACT<br/><br/>OISE-0527138<br/>Zhu, Song-Chun (University of California at Los Angeles) U.S.-China Workshop on Computer Vision <br/><br/>This proposal from Dr. Song-Chun Zhu of UCLA involves a U.S.-China Workshop in the area of computational vision (including image analysis, pattern recognition, image processing, medical images, etc.) at the Lotus Hill Institute in Ezhou, China on September 1-3, 2005. The workshop is part of an ambitious plan to establish a long-term mutually beneficial collaboration between vision scientists in both the U.S. and China, and to combine complementary efforts and capabilities in addressing some fundamental bottlenecks in computational vision. A widely acknowledged bottleneck is collecting a common data set (on the order of 100,000 images) parsed by human users in a common format. Collecting and parsing such a large data set requires the collective efforts from experts in all vision areas. Participants will learn from each other's experience and discuss a common format in the workshop. Establishing the data set will benefit vision researchers in both U.S. and China in the future and enhance collaboration among participating institutions.<br/><br/>The U.S. team includes researchers, junior scientists, and students to attend a joint U.S.-China workshop from universities across the country. The Chinese counterpart group, funded by the National Science Foundation of China, Microsoft Research Institute of Asia, and others, includes scholars from the Institute of Automation of the Chinese Academy of Science; Institute of Pattern Recognition and Artificial Intelligence, HuaZhong University of Science and Technology; and Microsoft Research Institute Asia.<br/>"
9604559,Amygdalo-Cortical Interactions and Memory,IOS,BEHAVIORAL NEUROSCIENCE,2/1/1997,5/11/1998,Edward Kairiss,"Kairiss, E","Kairiss, E",CT,Yale University,Standard Grant,Emmeline Edwards,5/31/1998,"$32,675.00 ",,edward.kairiss@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,BIO,1191,"1096, 9107, BIOT",$0.00 ,exceptionalFunding,"9604559 Kairiss This project examines the connections between two brain regions that are known to be involved in memory functions, the amygdala and perirhinal cortex. It is not known how these areas interact during the storage and recall of memories. The project addresses this question by examining the details of how these areas are connected, how they communicate with each other, and how one might modulate the ability of the other to store information. It is believed that memories are formed in the brain when the connections between nerve cells change their effectiveness, thereby increasing or decreasing the communication between them. This project examines whether signals from the amygdala control how memories are formed in the cortex by influencing this process in the cortical nerve cells. Insights gained from these studies advance the understanding of the mechanisms by which different parts of the brain interact during information processing and storage. Such insights are fundamental to advancing our knowledge of how humans and artificial intelligence systems learn new information, store it, and recall it when needed."
1522485,WORKSHOP: The 2015 HRI Pioneers Workshop at the 2015 ACM/IEEE International Conference on Human-Robot Interaction,IIS,Cyber-Human Systems (CHS),3/1/2015,2/2/2015,Matthias Scheutz,"Scheutz, M","Scheutz, M",MA,Tufts University,Standard Grant,Ephraim P. Glinert,8/31/2015,"$31,600.00 ",,matthias.scheutz@tufts.edu,136 Harrison Ave,Boston,MA,21111817,6176273696,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Pioneers Workshop (doctoral consortium) of approximately 18 graduate students and post-docs from diverse research communities (e.g., computer science and engineering, psychology, cognitive science, robotics, human factors, human-computer interaction design, and communications), along with distinguished research faculty.  The event will take place on Monday, March 2, 2015, immediately preceding the Tenth International Conference on Human Robot Interaction (HRI 2015), to be held March 2-5 in Portland, Oregon, and which is jointly sponsored by ACM and IEEE.  HRI is a single-track, highly selective annual international conference that seeks to showcase the very best inter- and multi-disciplinary research in human-robot interaction with roots in social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology and many more, and invites broad participation.  The theme of HRI 2015 is ""Broadening HRI: Enabling Technologies, Designs, Methods, and Knowledge"" which seeks contributions from a broad set of perspectives, including technical, design, methodological, behavioral, and theoretical, that advance fundamental and applied knowledge and methods in human-robot interaction, with the goal of enabling human-robot interaction through new technical advances, novel robot designs, new guidelines for design, and advanced methods for understanding and evaluating interaction.  More information about the conference is available online at http://humanrobotinteraction.org/2015. <br/><br/>The Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference.  During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries.  To these ends, the workshop format will encompass a variety of activities including two keynotes, a distinguished panel session, and breakout sessions.  To start the day, all workshop attendees will briefly introduce themselves and their interests.  Following the opening keynote, approximately half of the participants will present 3-minute overviews of their work, leading into an interactive poster session.  This will enable all participants to share their research and receive feedback from students and senior researchers in an informal setting.  The workshop organizers will facilitate the post-presentation discussion and will encourage participants to ask questions of their peers during the interactive break and poster session.  After lunch, the remaining workshop participants will give their 3-minute overviews, followed by presentation of their posters during a second interactive poster session.  Senior researchers (in addition to those on the panel) will be invited to attend the student presentations and poster sessions in order to provide feedback to participants, and workshop participants will be invited to present their posters during the main poster session of the HRI conference as well.  The conversations between the panel and participants will continue over lunch and during dinner.<br/><br/>This workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities (including but not limited to computer science and engineering, psychology, robotics, human factors and ergonomics, and HCI).  This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives.  Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  Participants will also gain leadership and service experience, as the workshop is largely student organized and student led.  The PI has expressed his strong commitment to recruiting women and members from under-represented groups.  To further ensure diversity the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, will recruit students who are just beginning their graduate degree programs in addition to students who are further along in their degrees, and will limit the number of participants accepted from a particular institution to at most two (in which case, one of the participants must be female)."
931531,A Symposium on Combinatorial Search,IIS,ROBUST INTELLIGENCE,7/15/2009,7/6/2009,Wheeler Ruml,"Ruml, W","Ruml, W|Koenig, S|Zhou, R",NH,University of New Hampshire,Standard Grant,Edwina L. Rissland,6/30/2010,"$30,971.00 ","Sven Koenig, Rong Zhou",ruml@cs.unh.edu,51 COLLEGE RD SERVICE BLDG 107,Durham,NH,38243585,6038622172,CSE,7495,"7495, 9150, 9215, HPCC",$0.00 ,exceptionalFunding,"The project is the second in an international symposium series on the topic of combinatorial search. Currently, work in this area appears scattered across many conferences in several fields. The intellectual merit of this project stems from the sharing of new results, ideas, and problems across the many areas in AI and robotics where combinatorial search is used. Broad impact comes not only from this intermixing but from having a single locus of activity for efforts in combinatorial search, one that we expect to become known in the wider community as the place to look when one wants a snapshot of the latest developments in the area. The first symposium will be held as a AAAI workshop in 2008. This second meeting in the series is held just before and in the vicinity of the International Joint Conference for Artificial Intelligence in 2009. NSF funding supports authors of oral and poster presentations, as well as invited speakers."
4433,US-Turkey Cooperative Research:  Realistic Applications of Action Languages for Workflow Management,OISE,"AFRICA, NEAR EAST, & SO ASIA",3/15/2001,3/19/2001,Vladimir Lifschitz,"Lifschitz, V","Lifschitz, V",TX,University of Texas at Austin,Standard Grant,Osman Shinaishin,2/28/2005,"$30,933.00 ",,vl@cs.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,O/D,5976,"5940, 9139, HPCC",$0.00 ,exceptionalFunding,"0004433<br/>LIfschitz <br/><br/>Description: This award is for support of a cooperative project by Professor Vladimir Lifschitz, Department of Computer Science, the University of Texas, Austin, Texas, Drs. Ferda Nur Alpaslan and Ismail Hakki Totoslu, Computer Engineering Department, Middle East Technical University, Ankara, Turkey, and Dr. Varol Akman, Department of Computer Engineering, Bilkent University, Ankara Turkey.  These scientists plan to study the application of artificial intelligence to workflow management.  Action languages are formal models of parts of natural language that are used for talking about the effects of actions.  The Causal Calculator is a software system that allows the user to automate planning and reasoning about actions in domains described in an expressive action language called C.  The scientists plan to develop a translation tool that will translate from a workflow specification language into Action Language, C.  This will allow permit the  automation of the process of workflow management.  They will also design a tool for the graphical representation of C programs that will help the users to visualize the entire workflow.  <br/><br/>Scope:  In this project the collaborators plan to combine their expertise in an important area of scientific research.  The expertise of the US scientist and his team has been in the design, implementation and use of the Causal Calculator.  The Turkish researchers have been working on workflow management and its relation to action languages.  Two US graduate students from Dr. Lifschitz' department will participate in the project and will work in Turkey with their foreign counterparts, thus gaining an international research experience early in their careers. The project meets INT criteria for support of cooperative projects that are mutually beneficial, and which help give international experiences to young scientists and graduate students."
1106480,AAAI 2011 Spring Symposium on Artificial Intelligence and Sustainable Design,IIS,ROBUST INTELLIGENCE,4/1/2011,3/25/2011,Douglas Fisher,"Fisher, D","Fisher, D",TN,Vanderbilt University,Standard Grant,Tatiana D. Korelsky,3/31/2014,"$30,000.00 ",,douglas.h.fisher@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,7495,7495,$0.00 ,exceptionalFunding,"Imperatives for environmental and societal sustainability are challenging designers to consider factors that had been previously given little attention. The Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium on Artificial Intelligence and Sustainable Design, held March 21-23, 2011 at Stanford University, focuses on the challenges of sustainable design and the role that artificial intelligence (AI) plays in understanding and achieving sustainability. The presumption is that the increased complexity of design necessitated by a desire for very long-term planet sustainability, to include cradle-to-cradle design, requires application of and advances in AI. NSF funds are supporting travel, subsistence and registration of symposium participants. The symposium and follow-up discussion will elaborate current and future research directions at the intersection of AI, design, and sustainability. We anticipate that the AAAI Symposium proceedings and the nascent AI and Sustainable Design community will be of interest outside of AI and computing. Sustainable design is a topic of importance to society; bringing this topic to the attention of AI researchers has the potential for advances in sustainable design that go beyond current computational and design approaches."
9900498,Workshop on Learning on Cognitive Development,IIS,"ROBOTICS, ",9/15/1999,9/17/1999,Juyang Weng,"Weng, J","Weng, J|Stockman, I",MI,Michigan State University,Standard Grant,Jing Xiao,11/30/2000,"$30,000.00 ",Ida Stockman,weng@cse.msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,CSE,"6840, X157","9139, HPCC",$0.00 ,exceptionalFunding,"IIS-9900498<br/>Weng, John<br/>Michigan State University<br/>$30,000.00 - 15 mos.<br/><br/>Workshop on Development and Learning <br/><br/>There is a growing interest in the study of cognitive and behavioral<br/>development and the interactions between what is innate and what is<br/>learned during the development. New theories and architectures for<br/>development are being studied in fields related to both artificial and<br/>natural intelligence. Scaling up from ground, both in size and functionality,<br/>is required for dealing with real-world problems and for better<br/>understanding natural intelligence. How does an individual, biological or<br/>artificial, scale up its cognitive and behavioral capabilities through interactions <br/>with the environment? What are the common mechanisms<br/>that enable scaling up for a variety of cognitive and behavioral<br/>capabilities and their integration? Since this important subject is<br/>interdisciplinary, this workshop will bring together researchers from<br/>closely related fields, including artificial intelligence, machine learning,<br/>computer vision, pattern recognition, speech recognition, robotics,<br/>animal learning, developmental psychology, neuroscience and computational<br/>linguistics. The aim is to discuss (1) the role that development and<br/>learning can play in the development of artificial and natural intelligent<br/>agents, (2) the common principles that are shared by the development for<br/>very diverse cognitive and behavioral capabilities such as vision, speech,<br/>language, reasoning, planning, decision making, locomotion and<br/>object manipulation. (3) important directions for future research on<br/>development and learning, and (4) short-term and long-term applications.<br/>Findings of the workshop will be documented in a report which will be widely<br/>disseminated in the various related research communities. A website on<br/>development and learning will be created from this workshop as a long-term<br/>cross-disciplinary information center for those who are interested in<br/>artificial and natural intelligence."
9820138,Workshop on Research in Logic-Based Artificial Intelligence,IIS,ARTIFICIAL INTELL & COGNIT SCI,3/1/1999,2/16/1999,Jack Minker,"Minker, J","Minker, J",MD,University of Maryland College Park,Standard Grant,Ephraim P. Glinert,2/29/2000,"$30,000.00 ",,minker@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"There is a perception among certain members of the artificial intelligence community that the logic-based approach to AI has not been sufficiently recognized as important at  NSF. This workshop will bring together leading researchers in the logic-based AI community, to provide them with an opportunity to exchange information in their sub-disciplines, to learn about related work in logic-based AI, and to assess the direction of the field as a whole. A report to NSF will describes important current themes in the field which are worthy of research support, and will provide an assessment of an area of research that some of the leading figures in artificial intelligence believe to be among the most promising for significant future advances.  NSF funds will be used to partially support attendees who do not have sufficient funds to come otherwise, as well as a small number of student attendees; no funds will be used for overhead or for the PIs. The University of Maryland Institute for Advanced Computer Studies will contribute approximately $5,000 to defray the charge for use of the conference rooms, to provide preprints of papers, and for other incidentals."
9720708,"US-South Africa Workshop: Intelligent Systems in Power      Electronics, Pretoria, South Africa, July 1998",OISE,"CONTROL, NETWORKS, & COMP INTE, AFRICA, NEAR EAST, & SO ASIA",2/1/1998,1/23/1998,Thomas Habetler,"Habetler, T","Habetler, T",GA,Georgia Tech Research Corporation,Standard Grant,Patricia Jones Tsuchitani,1/31/2000,"$30,000.00 ",,thabetler@ee.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,O/D,"1518, 5976","0000, 1066, OTHR",$0.00 ,exceptionalFunding,"9720708  Habetler    This award provides support for eight US investigators to participate in a US-South Africa Workshop on Intelligent Systems in Power Electronics, Pretoria, South Africa, July 1998.  The US organizer is Professor Thomas G. Habetler of the School of Electrical Engineering, Georgia Institute of Technology, and Professor Ron Harley, Department of Electrical Engineering, University of Natal, Durban, South Africa.  The workshop will be held during and immediately following the FEPPCON (IEEE Future of Electronic Power Processing and Conversion) conference, which itself follows the IEEE International Symposium on Industrial Electronics.  The US-South Africa workshop will focus on trends in intelligent systems, algorithms and their implementation, hardware considerations, applications of artificial intelligence (AI) in power electronics (PE), and future applications.  The purpose of the workshop is to bring together US and South African researchers in the AI and PE fields to plot out a map of the important steps to take in this evolving technology.    Intelligent systems incorporating AI allows one to transfer human knowledge and skills to computers or other types of hardware.  AI also enables a hardware or computer system to use algorithms to train itself to a level that a human cannot achieve in terms of complexity and speed of decision making.  AI researchers traditionally study new algorithms and often have expertise in mathematics and the theory of algorithm development and performance.  AI has been successfully applied to pattern recognition, time series prediction, and system identification and control.  All of these functions are crucial in the operation of advanced PE system controllers.  PE researchers traditionally study the devices, circuit topologies, and control algorithms that make up power processing equipment.    The award is supported jointly by the Division of International Programs and the Division of Electrical and Communications Systems.  ***"
334391,SGER:  Neural Networked Finite Element Methodology for Health Monitored Structural Systems,CMMI,Structural and Architectural E,8/15/2003,8/25/2003,Yacoub Najjar,"Najjar, Y","Najjar, Y|Rasheed, H",KS,Kansas State University,Standard Grant,Douglas A. Foutch,7/31/2004,"$30,000.00 ",Hayder Rasheed,ymnajjar@olemiss.edu,2 FAIRCHILD HALL,Manhattan,KS,665061100,7855326804,ENG,1637,"1057, 9237, CVIS",$0.00 ,exceptionalFunding,"PI: Yacoub M. Najjar & Hayder A. Rasheed; Kansas State University <br/><br/>The objective of this proposed research is to transplant a Neural Network algorithm within a finite element analysis procedure to take over the function of its heart after a small jumpstart. The Neural Network will adapt to the internal functionality needed to re-produce the overall response of the body or  the  system,  initially  known  from  some  external  health  monitoring  measurements,  through  self-adjusting/learning analysis trials. This will build the memory and intelligence necessary to deal with similar analysis situations pretty much the same way the human mind and body interact and inter-respond  without  an  interpreter.  The  specific  objective  of  this  research  proposal  is  to  develop, formulate, and implement a proof-of-concept for an innovative Neural Network-Finite Element (NN-FE)  self-training  approach.  This  approach  can  be  used  to  accurately  characterize  the  internal mechanical  behavior  of  health  monitored  engineering  systems  such  as  buildings,  bridges,  offshore platforms, airplanes, space shuttles and other structures. Pre-generated finite element-based data-rich results  simulating  monitored  2D  structures  will  be  used  to  develop  and  validate  the  NN-FE technique.  Accordingly,  each  database  containing  load  and  displacement  history  at  some  health monitoring/control  points  of  the  system  could  be  used  to  generate  the  NN-FE  internal  behavior characterization  model.  The  developed  scheme  will  operate  in  two  distinctive-alternating  modes. <br/><br/>First, it will operate in a predictor analysis mode to capture approximate stresses and strains at the integration  points.  Subsequently,  and  based  on  deviations  between  predictions  and  actual displacement values at the health monitoring points, the NN-FE self-adapting algorithm will operate <br/>in  a  training  mode  in  order  to  reduce  these  deviations.  As  the  algorithm  is  repeatedly  applied  in <br/>analysis  and  training  modes  to  eliminate  such  deviations,  it  develops  self-learning  artificial intelligence and becomes smarter at making more accurate predictions. <br/> <br/>Intellectual Merit:  The proposed research addresses the important issue of the self-sufficient and reliable internal characterization of the mechanical response of health monitored structural systems. Success of this research will lead to better assessment of current and future structures. Accordingly, this will lead to more economical designs, protect the national investments, and ensure higher safety measures  to  the  public.  More  importantly,  by  integrating  anticipated  future  development  in  non-contact measurements,  this work  is  envisioned  to  pave  the  way  to  a  new  era  of  analysis  in  which computer systems can remotely scan objects for response data and use them to analyze the structural system  by  incorporating  the  self-training  Neural  Networked  finite  element  procedure.  This  is expected  to  impact  all  aspects  of  engineering,  science  and  life  on  the  planet Earth,  including aerospace, manufacturing, civil, mechanical, and chemical engineering fields. Furthermore, it may be extended for  utilization  in  aeronautics  and  astronautics  within  man's  quest  to  conquer  the  outer space.   <br/> <br/>Broader Impact:  The project.s broader impacts include the following aspects: <br/><br/>1)   Full involvement of a PhD graduate student. Therefore, providing the student with intensive <br/>training/research experience to address similar complex engineering systems.   <br/>2)  The  proposed  exploratory  integrated  research  will  most  likely  re-shape  the  interacting <br/>information technology-structural engineering mechanics educational curriculum. This will definitely intrigue  the  future  engineering  leaders  to  address  other  issues  in  similar  integrated  and  systematic <br/>way. Moreover,  it will  help mature the  young  graduates  into  scholars with  hands-on experience  to tackle complex health monitored structural engineering systems.  <br/>"
1239963,The 2012 Machine Learning Summer School at UC Santa Cruz,IIS,INFO INTEGRATION & INFORMATICS,7/1/2012,5/16/2012,Manfred Warmuth,"Warmuth, M","Warmuth, M",CA,University of California-Santa Cruz,Standard Grant,Sylvia J. Spengler,6/30/2013,"$30,000.00 ",,manfred@cse.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7364,"7364, 7484, 7556",$0.00 ,exceptionalFunding,"The Machine Learning Summer Schools (http://mlss.cc) were established in 2002 with the aim of bringing together world class speakers from academia, the national labs, and industry to deliver tutorial-style lectures over a two week period. This project supports the two week long Machine Learning Summer School (MLSS) at UC Santa Cruz, CA during July 9-20 2012. <br/><br/>Intellectual Merits: Machine learning has many important applications in science and industry. Modern machine learning uses a mix of insights from different disciplines, most notably artificial intelligence, statistics and optimization - areas that traditionally have not had much overlap. The participants will take part in tutorials given by experts from several different areas of machine learning - an opportunity that many students do not have at their home institutions. There is substantial integration of research and education in this activity. Furthermore, the participants will be able to interact with the tutorial speakers and with other students. <br/><br/>Broader Impact: The Machine Learning Summer School is designed to enable participants with different backgrounds to gain in-depth knowledge of the current state of the art in machine learning. The participants will interact with leading machine learning experts from academia and industry. It contributes to the creation of a diverse cadre of machine learning researchers and practitioners by offering unique training opportunities for undergraduate and graduate students from under-represented groups through personalized mentoring and scholarships."
446951,SGER: When Clones Attack: Can Fish Without Individual Variation Form Dominance Relationships?,IOS,BEHAVIORAL SYSTEMS CLUSTER,11/1/2004,10/27/2004,Ivan Chase,"Chase, I","Chase, I",NY,SUNY at Stony Brook,Standard Grant,John A. Byers,10/31/2005,"$29,970.00 ",,Ichase@notes.cc.sunysb.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,BIO,7472,"0000, 9237, OTHR",$0.00 ,exceptionalFunding,"Project Summary<br/>Research in animal behavior and the social sciences shows that differences among individuals - in genetic and non-genetic characteristics - can help to predict their positions in social structures. But are these differences necessary - fundamental in some way - to the formation of the social structures themselves? Could identical individuals not form social structures? Recent developments in genetic and reproductive technologies make it possible to investigate these questions, and this proposal describes a series of experiments designed to do so by examining the formation of dominance relationships in cloned and non-cloned fish (tilapia, Oreochromis niloticus). The principal investigator will compare the dynamics of dominance relationship formation in fish that are: (1) identical in all ways (in both genetic and non-genetic characteristics), (2) genetically identical but non-genetically variable, (3) genetically variable but non-genetically identical, and (4) variable in both genetic and non-genetic characteristics. Comparing these four groups will allow the principal investigator to determine whether or not identical individuals can form dominance relationships and hierarchies as readily as non-identical individuals, and if individual variation is important, to estimate the contribution of genetic versus non-genetic characteristics.<br/><br/>There are several broader implications of this project. First, it will help clarify the theoretical basis of social organization which is of interest not only to animal behaviorists and social scientists but also to some researchers in the military, artificial intelligence, and systems engineering. Second, it will provide a model to show how cloned animals can be used more broadly in investigations of the links between genetics and social behavior. Third, since this project involves genetics, cloned animals, and behavior, its results should be of broad interest, and the principal investigator will make these results available to both general and scientific audiences. Fourth, this project will provide educational experiences for SUNY at Stony Brook undergraduates working as research assistants, many of whom are from traditionally under-represented groups."
9651472,A Robot-based Laboratory for Teaching Artificial Intelligence,DUE,UNDERGRAD INSTRM & LAB IMPROVE,6/15/1996,6/10/1996,Lisa Meeden,"Meeden, L","Meeden, L|Kumar, D",PA,Swarthmore College,Standard Grant,Michael C. Mulder,5/31/1998,"$28,879.00 ",Deepak Kumar,meeden@cs.swarthmore.edu,500 COLLEGE AVE,Swarthmore,PA,190811390,6103288000,EHR,7400,"9178, 9267, SMET",$0.00 ,exceptionalFunding,"There is a growing consensus among computer science faculty that it is quite difficult to teach the introductory course on Artificial Intelligence (AI) well. This is because AI lacks a unified methodology, overlaps with many other disciplines, and involves a wide range of skills from very applied to quite formal. This project addresses these problems by (1) offering a unifying theme that draws together the disparate topics of AI; (2) focusing the course syllabus on the role AI plays in the core computer science curriculum; and (3) motivating the students to learn by using concrete, hands-on laboratory exercises. The main theme is to conceive of each topic in AI (such as search, planning, learning, vision) as a robotics task and then to have the students build their own robots and program them to accomplish the tasks. By constructing a physical entity in conjunction with the code to control it, the students have a unique opportunity to tackle many central issues of computer science directly including the interaction between hardware and software, space complexity in terms of the memory limitations of the robot's controller, and time complexity in terms of the speed of the robot's action decisions. More importantly, the robot theme provides a strong incentive toward learning because students want to see their inventions succeed. The goal of this project is to equip two identical robotics laboratories for teaching AI. Each laboratory contains a collection of robot building stations as well as one sophisticated off-the-shelf robot to demonstrate more advanced topics to the students. The deliverable for this project is a laboratory manual that is closely integrated with a semester-long AI course syllabus. The manual is being developed collaboratively and tested separately at the participating institutions. The overall effectiveness of this project will be determined by student feedback and performance. The project results can be disseminated through a variety of channels: a SIGART column on AI Education, special conference tracks on AI Education, summer training workshops for AI educators, and World Wide Web repositories on AI. This project offers a remedy for the difficulties facing AI educators by offering a cohesive framework for the presentation of the material that emphasizes AI's relationship with computer science and motivates the students to learn."
1627861,Doctoral Dissertation Research:   Designing Voice Analysis Technologies for Mental Health Applications in the United States,BCS,DDRI Cult Anthro,8/1/2016,8/1/2016,Graham Jones,"Jones, G","Jones, G|Semel, B",MA,Massachusetts Institute of Technology,Standard Grant,Jeffrey Mantz,1/31/2018,"$28,796.00 ",Beth Semel,gmj@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,SBE,7605,"1390, 9179",$0.00 ,exceptionalFunding,"This project, which trains a graduate student in methods of conducting empirically-grounded scientific research, asks how new, artificial intelligence (AI)-enabled technologies reshape not only the future of mental health care in the United States, but also basic assumptions about the relationship between language, mind, and brain. This research explores these questions through an ethnographic study of interdisciplinary research teams at three U.S. universities that are seeking to develop computer-assisted speech analysis technologies for mental health applications. In the research teams that this study focuses on, neuroscientists, psychiatrists, psychologists and engineers are working together to develop technology that can be used to diagnose and track mental illness by analyzing the formal, acoustic properties of speech (such as pitch, timbre, intonation, and speed), bypassing its semantic content (what the words mean) altogether. The project will have implications for the mental health researchers themselves as they move into uncharted ethical domains in regards to privacy, surveillance, and the increased diagnostic reliance on experimental technologies.<br/><br/>Beth Semel, under the supervision of Dr. Graham Jones at the Massachusetts Institute of Technology, explores how experts across disciplinary boundaries collaborate to design, develop and test artificial intelligence-enabled technologies when they appear to hold very different assumptions about the relationship between language and inner, psychological states. The researcher hypothesizes that collaborations surrounding the development of these technologies not only enact fundamental tensions within dominant views about how language works, but also reflect a re-working of claims of authority and expertise within U.S. mental health care. Increasingly, mental health researchers are eschewing traditional techniques of psychiatric diagnosis, which depend upon patients' subjective, verbal accounts of their psychological states and clinicians' observational and interpretive skills. Instead, they are enlisting the expertise of computer engineers who use AI techniques of pattern recognition to decipher the biomedical significance of behavioral symptoms. Using ethnographic participant observation, the researcher will collect data about how psychiatrists, psychologists, neuroscientists and engineers work together to design, test, and develop voice analysis technologies. Focusing on teams situated at the confluence of academic, commercial, and military arenas, this study explores the variety of ways in which mental illness is conceptualized in terms of scientific, public health, and national security concerns. By exploring how listening practices can shape assumptions about speech, and how the production of new listening techniques and technologies can reshape such assumptions, this research contributes to ongoing debates in linguistic anthropology about how culture affects understandings of the way language works."
515701,U.S.-Egypt Joint Cooperative Research:  Diagnosis and Maintenance of Relay Ladder Logic programs and PLC Ladder Logic Diagrams Using Artificial Neural Networks,OISE,,9/1/2005,8/24/2005,Houshang Darabi,"Darabi, H","Darabi, H",IL,University of Illinois at Chicago,Standard Grant,Osman Shinaishin,8/31/2010,"$28,375.00 ",,hdarabi@uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,O/D,T119,"5944, 5976, 9216, HPCC",$0.00 ,exceptionalFunding,"0515701<br/>Darabi<br/><br/>Project Description:  This project supports a collaborative research between Dr. Houshang Darabi, Mechanical and Industrial Engineering at the University of Illinois, Chicago and Dr. Magdy Abdelhameed, Ain Shams University.  They plan to focus on addressing the problem of rehabilitation and debugging of Ladder Logic Diagram (LLD) and Relay Ladder Logic (RLL) controllers. They seek to create methods and tools that use artificial intelligence systems to solve the problems of RLL and LLD based controllers. They propose a controller design based on an Artificial Neural Network (ANN) approach to be used as an alternative controller, and as a debugger for LLD faults. It also rehabilitates the RLL control circuits. They will use Recurrent Neural Network (RNN) based controllers for PLC program diagnosis.<br/><br/>Intellectual Merit:  Discrete event manufacturing systems represent more than ninety percent of the manufacturing and production lines in our world. RLL as logic controllers were used in old discrete event control systems while programmable logic controllers (PLC) with LLD as their interfacing programming language are utilized in modern discrete event control systems. However, RLL as a controller has many pitfalls. One of them is that once a RLL controller is made, it is very costly and in some cases it is even impossible to modify the controller. This means that a RLL is inflexible and therefore it is not suitable to design flexible manufacturing systems.  LLD is not inflexible - changing a LLD can be done quickly. However LLD has its own deficiency - it is hard to debug and maintain real world LLDs. This is due to many factors such as non-structured nature of LLD, the LLD programmers' background, and the huge sizes of real world LLD.  This research effort focuses on addressing the problem of rehabilitation and debugging of LLD and RLL controllers. The PIs seek to create methods and tools that use artificial intelligence systems to solve the stated problems of RLL and LLD based controllers. They propose a controller design based on an ANN approach. The resulting controller is used as an alternative controller, and as a debugger for LLD faults. It also rehabilitates the RLL control circuits. They specifically use Recurrent Neural Network (RNN) based controllers for PLC program diagnosis. The PIs present a manufacturing system example to illustrate the applicability of the proposed algorithms. The RNN is trained with sufficient data including the program sequences, faults and history of the events. Extensive experiments will be carried out to test and validate the proposed intelligent ANN based logic controller and an LLD debugger.<br/><br/>Broader Impact:  This project is expected to have an enormous impact on current manufacturing systems that use PLCs and RLL as their main controller hardware. The techniques of the RNN based controllers developed in this project will have many advantages including quick and efficient diagnosis, and low-cost maintenance of the existing PLC LLD programs<br/>especially when these programs are large in size and can be hardly modified. This project is being supported under the US-Egypt Joint Fund Program, which provides grants to scientists and engineers in both countries to carry out these cooperative activities.<br/>"
618454,Workshop on the Future of Robotics Research: Robust Intelligence,IIS,ROBOTICS,3/1/2006,7/7/2006,Yuan Zheng,"Zheng, Y","Zheng, Y|Orin, D",OH,Ohio State University Research Foundation -DO NOT USE,Standard Grant,C.S. George Lee,2/28/2007,"$28,000.00 ",David Orin,zheng@ece.osu.edu,1960 KENNY RD,Columbus,OH,432101016,6146888734,CSE,6840,"7495, 9216, HPCC",$0.00 ,exceptionalFunding,"In the past decade, robotic systems have moved from stand-alone units to more complicated<br/>systems that exhibit certain capabilities of interactions with human beings and/or<br/>environments. This development coupling with the recent re-organization of the Information<br/>and Intelligent Systems Division (IIS) of the National Science Foundation (NSF) into a<br/>cluster-research environment has prompted the necessity of organizing this workshop to<br/>discuss and explore the future research trends of robotics in a cluster-research environment.<br/>Specifically, the proposed workshop aims to address this problem with top-down and bottomup<br/>approaches:<br/>A) Top-down approach: Given that the IIS/Robotics program will be clustered with other<br/>IIS programs into cluster-research on Robust Intelligence, what are the potential<br/>innovative research areas that robotics researchers should look into so that future<br/>robotic systems will exhibit better mobility, intelligence, adaptation, and autonomy?<br/>B) Bottom-up approach: Given that many robotics researchers have their individual<br/>research areas that do not fit into this cluster-research Robust Intelligence theme, what<br/>should these researchers explore in order to propose more pertinent projects for future<br/>IIS competitions?<br/>Intellectual Merits. This workshop will bring together researchers in the robotics<br/>community, including the principal investigators (PIs) currently supported by the NSF/IIS, to<br/>explore innovative robotics research areas in this cluster-research Robust Intelligence theme.<br/>Researchers will explore the benefits of synergistic integration of robotics, computer vision,<br/>artificial intelligence, and other appropriate technical areas into future robotic systems to<br/>achieve intelligence and flexibility in reaction to dynamic and changing environments.<br/>Broader Impacts. The workshop will have significant and broader impacts on the robotics<br/>community. Through the workshop, researchers will broaden their views of future research<br/>for advancing Robust Intelligence in general, and robotic science and technologies in<br/>particular. Traditional single-PI-focused research areas such as dynamics, kinematics,<br/>control, motion planning, actuators, etc. will give way to a cluster of technologies in<br/>perception and cognition, and learning and intelligence. Equipped with this new vision,<br/>researchers will have better ideas in proposing innovative robotics research to investigate<br/>methodologies and technologies that will provide answers to design and develop future<br/>robotic systems that exhibit better autonomy, mobility, and intelligence."
624886,The Trading Agent Competition,IIS,CISE EDUCAT RES & CURRIC DEVEL,4/1/2006,4/24/2008,Amy Greenwald,"Greenwald, A","Greenwald, A",RI,Brown University,Standard Grant,William Bainbridge,3/31/2009,"$27,500.00 ",,amy@cs.brown.edu,BOX 1929,Providence,RI,29129002,4018632777,CSE,1709,"7496, 9150, 9216, HPCC",$0.00 ,exceptionalFunding,"This is a conference-related grant to support the travel, subsistence and registration expenses of approximately 16 student participants in a trading agent competition, being held in Hakodate, Japan, plus providing computational resources to enable educational experiences. The Trading Agent Competition (TAC) is an international forum designed to promote and encourage high-quality research about trading agents. TAC provides a platform for researchers to evaluate programmed trading techniques by competing with agents from other design groups in a simulated market scenario. TAC tournaments have been held annually since 2000, and have attracted participants from institutions in dozens of countries around the world. Involvement of American students will not only advance their individual careers in computer science, but will also contribute to the nation's future science and technology workforce.  This activity contributes to curriculum development by developing and demonstrating methods for involving students in the design and competitive use of artificial agents.<br/><br/>Entries in the Trading Agent Competition are software programs designed to trade in electronic markets. They are called ""agents"" because these programs operate autonomously in the market: sending bids, requesting quotes, accepting offers, and generally negotiating deals according to market rules. Although the agent's activity is ultimately determined by its programmers, the trading behavior is itself fully automated: humans do not intervene while the negotiation is in progress. Trading agents face a most challenging task. To play the market effectively, an agent must make real-time decisions in an uncertain and fast-changing environment, taking into account the actions of other agents that are doing the same. Capable agents rapidly assimilate market information from many sources, forecast future events, optimize complex offers and resource allocations, anticipate strategic interactions, and learn from experience. Successful trading agents adopt and extend state-of-the-art techniques from artificial intelligence, operations research, statistics, and other relevant fields. <br/><br/>The annual trading agent competitions were initiated to promote research and education in the technology underlying trading agents. At the annual competition, the developers of techniques in trading strategy evaluate these ideas and communicate their results in a public forum for the benefit of the broader research community. The educational function of TAC is manifest by the significant role of students on almost all teams entering the competition. Many universities use TAC as an exercise for teaching about electronic commerce and artificial intelligence techniques. TAC is a useful aid in the classroom because it is by nature a hands-on (laboratory-like) experience for computer scientists. Research and education in trading agents promises to improve the state of art and practice in their development, and ultimately lead to more effective electronic markets. Equally important, increasing public knowledge in this area promotes understanding of the behavior of autonomous software agents as such systems become more prevalent in commerce and other domains. <br/>"
9812709,SGER: Optimitation of Fermentations Through Intelligent Identification and Control,CBET,Engineering of Biomed Systems,7/15/1998,5/2/2000,Takoi Hamrita,"Hamrita, T","Hamrita, T",GA,University of Georgia Research Foundation Inc,Standard Grant,Janice M. Jenkins,12/31/2000,"$27,000.00 ",,thamrita@engr.uga.edu,310 East Campus Rd,ATHENS,GA,306021589,7065425939,ENG,5345,"0000, 9120, 9237, OTHR",$0.00 ,exceptionalFunding,"9812709 Hamrita The goal of this proposed research is to develop and apply artificial intelligence pattern recognition techniques to the process data provided by Merck & Co. to detect the different phases of the fermentation, compare the obtained results with the expert knowledge of the process operator, and determine correlations between productivity and the process variables. This research will look at fundamentally different control methods than those currently used in industry to try to overcome the problems of inaccurate models, the lack of reliable sensors, and the variable nature of fermentation processes.<br/>***"
609731,US-Egypt Cooperative Research: Online Fault Diagnostics for Induction Motor Drive Systems Through Electronic Signals and Artificial Intelligence Techniques,OISE,,1/1/2007,1/10/2007,Nabeel Demerdash,"Demerdash, N","Demerdash, N",WI,Marquette University,Standard Grant,Osman Shinaishin,12/31/2008,"$26,500.00 ",,nabeel.demerdash@marquette.edu,P.O. Box 1881,Milwaukee,WI,532011881,4142887200,O/D,T716,"5944, 5976, 9216, HPCC",$0.00 ,exceptionalFunding,"0609731<br/>Demerdash<br/>Description: This award is to support a cooperative research by Dr. Nabeel Demerdash, Department of Electrical and Computer Engineering, Marquette University, Milwaukee, Wisconsin and Dr. Faeka Khater, Electronic Research Institute, Cairo, Egypt. They plan to investigate on-line fault diagnostics for induction motor drives-system through electronic signals and artificial intelligence techniques. The goal is development of online fault diagnostic techniques using electronic signals such as motor terminal voltages and currents in conjunction with innovative signal processing diagnostic techniques and modern artificial intelligence methods such as Neural Networks and Gaussian Mixture Models. The drive system to be studied is a sensor-less Field Oriented Controlled (F.O.C) one without the need for a speed sensing device. The proposed technique will diagnose failure occurrences and identify the severity of the fault. Modeling and analytical algorithms will be used to predict the performance and enable the implementation of the diagnostic system in the drive controller. Experimental work on a 5-hp induction machine and analysis of recorded results will be used to evaluate and validate the developed fault diagnostic techniques.<br/><br/>Intellectual Merit: The problem of fault diagnostics in modern motor-drive systems (adjustable/variable speed drives) is a challenging and technically difficult one, especially if the motor-drive system is of the field oriented (vector control) closed-loop class. In such a class of motor-drives, whenever a fault or defect materializes in the motor, a corresponding compensating action takes place within the drive control system. This action usually tends to mask the existence of a fault particularly in its early stages. This research will address this compensating fault masking problem, and development of new diagnostic methods and means to detect such faults in the presence of drive control compensation actions. The results would constitute a major original contribution to the state of the art in motor-drive fault detection and diagnostics.<br/><br/>Broader Impact: Modern AC motor-drive systems are extensively used throughout the manufacturing, processing, and service industries, including critical services such as auxiliaries and life support systems in the medical field. The sophistication of the controls employed in such drives complicates the task of diagnosing faults in such systems before faults evolve into catastrophic or serious equipment failure. The unmasking of such faults in the presence of closed-loop controls would constitute a significant improvement in avoiding dangerous failures and associated consequences in practical applications, which increasingly rely on AC motor-drive systems. The results of the proposed work could have a great impact on the design of future electric drive systems to have an online fault diagnosis and detection system. The project involves high-level research, teaching, and application, as well as considerable breadth in culture exchange through the joint effort by researchers and students from the US and Egypt. Two Marquette University graduate students will participate in the project.<br/><br/>This project is being supported under the US-Egypt Joint Fund Program, which provides grants to scientists and engineers in both countries to carry out these cooperative activities."
548305,Presupposition Accommodation Conference and Intensive Course,BCS,LINGUISTICS,2/1/2006,2/2/2006,Craige Roberts,"Roberts, C","Roberts, C|Byron, D",OH,Ohio State University Research Foundation -DO NOT USE,Standard Grant,Joan Maling,4/30/2007,"$26,371.00 ",Donna Byron,roberts.21@osu.edu,1960 KENNY RD,Columbus,OH,432101016,6146888734,SBE,1311,"0000, OTHR",$0.00 ,exceptionalFunding,"Many scholars in semantics, pragmatics, psycholinguistics, artificial intelligence and philosophy of language have focused during the past decade on contextual effects in interpretation.  Presupposition accommodation is at the intersection of central issues in this area.  When an utterance presupposes information which the addressee does not already have (I'm on my way to my daughter's graduation"" presupposes the speaker has a daughter), the addressee may sometimes cooperatively accommodate that information, behaving as though he already knew it to be true, and go on to respond appropriately to the assertion (""Congratulations!"").  This project comprises a week-long intensive interdisciplinary course for students, followed by a three-day workshop on presupposition accommodation, bringing together scholars from across the five fields.  An interactive website will subsequently provide an ongoing virtual roundtable for continued interdisciplinary engagement with the questions at issue.  The main goals are to foster the development of a new stage of the literature on presupposition and context-dependence, informed by application as well as theory, and to enliven the interdisciplinary discussion through the intensive course and the on-going website.<br/><br/>Presupposition accommodation has broad implications for the theory of linguistic interpretation across the five fields involved in the project, because it involves many of the same processes and constraints as in the recognition of contextual effects generally.  In addition to its ramifications for theories of meaning in linguistics and for philosophical discussions of the nature of meaning, presupposition accommodation bears on psycholinguistic theories of human linguistic competence, illustrating the interaction between linguistic and non-linguistic (general cognitive) processes.  An appreciation of how it functions is important for the creation of software that aims to systematically interpret or produce language in context.  Significant new advances in our understanding of these issues are more likely to be made through interdisciplinary collaboration.<br/><br/>"
1449029,AAAI-15 Support for Robotic Activities,IIS,National Robotics Initiative,9/1/2014,8/28/2014,Sandip Sen,"Sen, S","Sen, S",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Jeffrey Trinkle,8/31/2015,"$26,000.00 ",,sandip@utulsa.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,8013,"7556, 8086",$0.00 ,exceptionalFunding,"The AI and Robotics research communities have benefitted from collaborations over the past several decades. However, the recent acceleration in the development of new algorithmic techniques in both fields and new hardware in robotics provide many opportunities for high-impact collaborations. The PIs are requesting funds to take advantage of this opportunity by holding the first of what is expected to be a series of meetings to encourage collaboration between these two communities. The first meeting will be held at the most important AI conference, AAAI-2015, in Austin TX. There will be events that bring some of the most accomplished researchers from Robotics to AAAI and also events that will be exciting school children and undergraduate students."
937593,Support for Participation in the 2009 International Summer School on Planning and Scheduling,IIS,ROBUST INTELLIGENCE,6/1/2009,4/13/2011,Shlomo Zilberstein,"Zilberstein, S","Zilberstein, S",MA,University of Massachusetts Amherst,Standard Grant,Jie Yang,5/31/2012,"$25,900.00 ",,shlomo@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,"7495, 9215, HPCC",$0.00 ,exceptionalFunding,"This award gives travel, housing, and registration-cost support to selected students and other young researchers from U.S. universities for their participation in the International Summer School on Planning and Scheduling, which is affiliated with the 19th International Conference on Automated Planning and Scheduling (ICAPS-09) held September 19-23 in Thessaloniki, Greece. Artificial Intelligence planning and scheduling is relevant to a wide variety of applications such as software engineering, manufacturing, transportation, and robotics. The ICAPS-09 Summer School includes a poster session, where students present their research ideas for commentary by more senior researchers, as well as intensive study of foundational material and the latest research in automated planning and scheduling. The Summer School realizes an integration of research and education in its preparation of emerging scientists."
836259,Workshop on The Question Generation Shared Task and Evaluation Challenge,IIS,ROBUST INTELLIGENCE,6/1/2008,6/10/2009,Vasile Rus,"Rus, V","Rus, V|Graesser, A",TN,University of Memphis,Standard Grant,Tatiana D. Korelsky,5/31/2010,"$25,345.00 ",Arthur Graesser,vrus@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,7495,"7495, 9150, 9218, HPCC",$0.00 ,exceptionalFunding,"The Workshop on the Question Generation Shared Task and Evaluation Challenge aims at establishing a community consensus with respect to various issues related to offering a shared task on Question Generation, including a clear definition of the main task and subtasks, data collection and annotation processes, data annotation schema, type of evaluation and evaluation metrics. The Natural Language Generation community has currently identified shared tasks as a potential venue to provide a focus of research in the field and increase the visibility of Natural Language Generation research in the wider Natural Language Processing/Computational Linguistics community. This award contributes to this effort by defining a novel shared task, the Question Generation task. The workshop organization is guided by the Desiderata for Evaluation of Natural Language Generation outlined at the recent NSF/SIGGEN Workshop on Shared Tasks and Comparative Evaluation in NLG held in 2007. The goal of a representative group of researchers from various areas of research (Natural Language Generation, Intelligent Tutoring Systems, Artificial Intelligence in Education) participating in the workshop discussions is to produce a to-do list for preparing and offering a Question Generation task at Generation Challenges 2010. A post-workshop report will outline the discussions and decisions of the workshop and will be made available to the research community. Due to the importance of Question Generation in learning technologies such as Intelligent Tutoring Systems, the workshop will have broader impact on improving the teaching and learning of STEM disciplines through improved educational software applications."
9529444,CISE Research Instrumentation for AI Planning Research,EIA,CISE RESEARCH RESOURCES,2/15/1996,2/5/1996,Dana Nau,"Nau, D","Nau, D|Hendler, J",MD,University of Maryland College Park,Standard Grant,John Cherniavsky,1/31/1998,"$25,325.00 ",James Hendler,nau@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,2890,"9218, HPCC",$0.00 ,exceptionalFunding,"CDA 9529444 Nau, Dana Hendler, James University of Maryland at College Park CISE Research Instrumentation for AI Planning Research The Department of Computer Science and the Institute for Systems Research at the University of Maryland will purchase computing machining equipment, including a small multipurpose machine tool, a pentium-based personal computer for solid modeling and input to the tool, and a large disk drive for keeping large case-based planning libraries, all of which will be dedicated to support artificial intelligence research in the area of computer and information science and engineering. The equipment will be used for several research projects, including in particular: *AI-based planning for manufacturing, *High Performance Support for Large Knowledge Bases, *Combination of generative and case-based reuse techniques in AI planning, and *Low-cost robotics. In addition, a CAD tool will be donated by Bentley Systems Inc. to facilitate experimentation with the AI planning techniques in the manufacturing domain."
1719307,Support for Student Participation in the 2017 ACM Intelligent User Interfaces Conference,IIS,Cyber-Human Systems (CHS),3/1/2017,12/23/2016,Wai-Tat Fu,"Fu, WT","Fu, WT",IL,University of Illinois at Urbana-Champaign,Standard Grant,Ephraim P. Glinert,2/28/2018,"$25,020.00 ",,wfu@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to provide financial support for approximately 20 graduate students (all from U. S. universities and working towards either their Master's degree or a Doctorate) to attend the 2017 International Conference on Intelligent User Interfaces (IUI 2017), to be held March 13-16 in Limassol, Cypress, about 10 of them as participants in a special Student Consortium (workshop), and the rest as presenters in the main conference and/or as attendees at the conference for general training purposes.  Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent interactive user interfaces.  Attracting 200-300 attendees, they are the premier forum where researchers from academia and industry worldwide who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI) come together to exchange insights and to present outstanding research and applications whose goal is to make the computerized world a more amenable place.  Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter; unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, behavioral science, cognitive science, computer graphics, design, the arts, etc.  IUI 2017 will be the 22nd conference in the series; more information about the conference is available online at http://iui.acm.org/2017.  This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons.  It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement.  The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants.  The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference.  The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community.  Women and students who are members of underrepresented groups will be particularly encouraged to participate.  To further assure diversity, no more than two students will be accepted from any given institution.<br/><br/>The IUI 2017 Student Consortium will build on the success of previous such events.  The heart of the Consortium will be a full-day workshop on March 13 in parallel with the conference workshops and the day before the start of the technical program.  Student trainees will be afforded exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of senior researchers.  A group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors.  The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field."
1724434,Doctoral Consortium at IJCAI 2017,IIS,ROBUST INTELLIGENCE,4/1/2017,3/29/2017,Maria Gini,"Gini, M","Gini, M",MN,University of Minnesota-Twin Cities,Standard Grant,Reid Simmons,3/31/2019,"$25,000.00 ",,gini@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This proposal will support US-based Ph.D. students working in artificial intelligence the opportunity to share their knowledge and interact with each other and more senior researchers, to learn about different sub-fields within AI, and to be mentored in research, publication, and career opportunities. This goal will be accomplished by partially supporting the travel costs for US-based Ph.D. students to attend the International Joint Conference on Artificial Intelligence (IJCAI), which is one of the premier international conferences on research in artificial intelligence. The conference, which in 2017 will be held in Melbourne, Australia attracts an international crowd that includes academics, industry workers, entrepreneurs, and funding agency leaders."
1343599,Doctoral Mentoring Consortium at at the 23rd International Joint Conference on Artificial Intelligence (IJCAI 2013),IIS,ROBUST INTELLIGENCE,7/1/2013,6/20/2013,Maria Gini,"Gini, M","Gini, M",MN,University of Minnesota-Twin Cities,Standard Grant,Hector Munoz-Avila,6/30/2014,"$25,000.00 ",,gini@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,7495,"7484, 7495, 7556",$0.00 ,exceptionalFunding,"This grant supports student travel for select students participating in the Doctoral Consortium at the International Joint Conference on Artificial Intelligence (IJCAI 2013), that will be held in Beijing, China, August 3-9, 2013. The biannual IJCAI conference is the premier international conference spanning all topics in AI across a fully international research community. <br/><br/>This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research. This consortium is covering topics that are important and relevant to the success of these students, including, ""funding and strings attached to them, use of subjects in research (including IRB), data collection, maintaining privacy and integrity of data, authorship (single and multi-author submissions, ghost writing), plagiarism and self-plagiarism, proper use of citations, reviewing of papers and proposals, and how to get the best out of attending a conference.""<br/><br/>Student participation in this conference has direct impact through encouraging promising U.S. students to engage in internationally-competitive research. This program will also enhance the broader scientific community through exposure to emerging research topics. IJCAI is the major international conference that will figure prominently in the research careers of these young investigators. Students gain valuable research insights from the exchange of technical ideas in this broader venue. In the process, they make valuable connections with potential collaborators from around the world. In addition, students participate in the main IJCAI conference activities. This allows them to attend presentations of the leading research in AI, as well as avail themselves of the available tutorials, workshops, and demonstrations."
1521921,Doctoral Mentoring Consortium at the 24th International Joint Conference on Artificial Intelligence (IJCAI 2015),IIS,ROBUST INTELLIGENCE,3/1/2015,3/12/2015,Maria Gini,"Gini, M","Gini, M",MN,University of Minnesota-Twin Cities,Standard Grant,Hector Munoz-Avila,2/29/2016,"$25,000.00 ",,gini@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The project funds attendance of US-based graduate students to the doctoral consortium at the International Joint Conference on Artificial Intelligence (IJCAI). The goals of doctoral consortium are for students to discuss research, have an opportunity to talk about their research, build professional connections with other researchers, and receive individual mentoring from a senior member of the community. <br/><br/>The outcomes of the project will be assessed with pre- and post-surveys administered to the students. Special efforts will be made to select students from underrepresented groups and from smaller groups who have fewer opportunities to interact with international researchers. Participation will help graduate students network with other researchers, and develop into global scientists. In the longer term, this will help advance science and high-tech industry."
1037866,Travel Support for 2010 Association for Advancement of Artificial Intelligence (AAAI) Robotics Workshop and Exhibition,IIS,ROBUST INTELLIGENCE,7/1/2010,5/19/2010,Ayanna Howard,"Howard, A","Howard, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Richard Voyles,6/30/2011,"$25,000.00 ",,ah260@gatech.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00 ,exceptionalFunding,"The project serves to support team travel to the 2010 AAAI Robotics Exhibition and Workshop.  The exhibition and workshop overlaps with the 2010 AAAI Conference being held in Atlanta July 11-15, 2010.  The Exhibition and Workshop revolves around the theme of manipulation and learning.  Events include robot challenges, demonstrations and presentations.  Funds will be used to support about 40 students and their advisors for team travel."
1014092,Student Support for the Tenth International Conference on Intelligent Tutoring Systems,IIS,Cyber-Human Systems (CHS),2/1/2010,1/19/2010,David Mostow,"Mostow, D","Mostow, D|Rose, C",PA,Carnegie-Mellon University,Standard Grant,Ephraim P. Glinert,1/31/2011,"$25,000.00 ",Carolyn Rose,mostow@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,7367,"9215, HPCC",$0.00 ,exceptionalFunding,"This is funding to support attendance by approximately 25 advanced doctoral students from the United States and abroad at the 10th International Conference on Intelligent Tutoring Systems (ITS 2010), which will take place June 14-18, 2010, in Pittsburgh. The first ITS conference was held in 1988 in Montreal, and they have continued every two years for the past 12 years in locations that include Brazil, Taiwan, France, and Canada as well as the United States. The ITS conferences offer a rare professional opportunity for interdisciplinary researchers from around the world to converge and present cutting-edge results from the fields of artificial intelligence, computer science, cognitive and learning sciences, psychology, and educational technology. The goal is to promote studies in advanced systems in computer science applied to education, cognitive science and human learning for learners of all ages. To that end, the series provides a forum for the interchange of ideas in all areas of computer science and human learning, a unique environment in which researchers and practitioners exchange ideas, theories, experiments, techniques, applications and evaluations of initiatives supporting new developments relevant for the future. Comments and feedback from each previous ITS conference indicate that the carefully structured conference format continues to be professionally rewarding and stimulating to all who attend. ITS conferences are highly refereed international events and serve as reference guidelines for the research community; each paper is generally reviewed by 4 referees so that having a paper published at ITS is a reference of quality for any researcher evaluation. The conferences operate under the auspices of an independent nonprofit organization and are funded entirely by registration fees. More information about the conference is available at http://www.cmu.edu/its2010.<br/><br/>Students supported by NSF funds will have the opportunity to attend sessions with papers, posters, tutorials, workshops, and informal interactions with accomplished researchers, the latter within the framework of a Young Researchers Track that includes special sessions for the students to present their research ideas, meet peers who have related interests, and receive feedback and mentoring from senior members of the ITS community. A structured program will be provided in which each student is matched with a mentor who will be encouraged to offer feedback and support to students as they prepare their presentations, during the doctoral consortium sessions, and in at least one 1-on-1 meeting. The doctoral consortium will be situated within the main conference program in order to encourage maximal community involvement. Its structure will facilitate as much discussion and feedback as possible. With this goal in mind, students will present their work at lunchtime poster sessions open to all attendees. To avoid competition with other events and to maximize attendance, no other talks will be scheduled at this time and posters will be in the same rooms as the buffet lunch for all conference attendees. To acquaint attendees with student work, student poster sessions will be immediately preceded by ""fire-hose"" sessions where students summarize their work very briefly. To enable poster presenters to see and discuss each other's posters, poster presentations will span all 3 days of the main conference so as to give students one day to present their posters and two days to see others. Space and logistics permitting, presenters will be able to leave their posters up all 3 days of the conference, affording additional opportunities to discuss them with other researchers, for example during coffee breaks. <br/><br/>Broader Impacts: This activity supports one of NSF's core missions, to train more advanced professionals in Science, Technology, Engineering, and Mathematics (STEM). Participating in the conference will provide the selected students with a unique opportunity to be exposed to current research directions in different research communities both domestic and foreign. This is important for the field, because it has been recognized that transformative advances in research tend to derive from the melding of cross-disciplinary knowledge and multinational perspectives. Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years. The PI will place high priority on supporting young researchers (intermediate and advanced doctoral students) from degree-granting institutions that lack the funding necessary to support attendance by their students at international conferences such as ITS."
1741034,"1st???US-Japan Workshop Enabling Global Collaborations in Big Data Research; June, 2017, Atlanta, GA",CNS,S&CC: Smart & Connected Commun,5/15/2017,5/10/2017,Calton Pu,"Pu, C","Pu, C",GA,Georgia Tech Research Corporation,Standard Grant,Meghan Houghton,4/30/2018,"$25,000.00 ",,calton@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,033Y,7556,$0.00 ,exceptionalFunding,"The 1st???US-Japan Workshop Enabling Global Collaborations in Big Data Research brings together researchers from the United States (U.S.) and Japan to discuss experiences, challenges, and opportunities in international research collaborations. The workshop provides opportunities for participants from both countries to identify mutual research interests that leverage resources and expertise to accelerate advancements in smart and connected communities, cyber-physical systems, artificial intelligence, and machine learning. The workshop includes two tracks to support a broad range of participation: track 1, for participants with prior collaboration experience and significant potential to advance the field; and track 2, for those without prior collaboration experience who may benefit significantly from the diverse training environments afforded by international collaborations. The outcomes of the workshop will be disseminated through a report describing the main strategic areas, key research opportunities, and collaboration scenarios discussed during the workshop, thereby benefiting a broader research community. The workshop is co-located with the 2017 IEEE International Conference on distributed Computing Systems (ICDCS). This engagement builds upon prior National Science Foundation (NSF)-Japan Science and Technology Agency (JST) collaborations.<br/><br/>The areas of smart and connected communities, cyber-physical systems, artificial intelligence, and machine learning present intellectual challenges of their own, as well as challenges and opportunities at their intersections. Specifically, the challenges and opportunities created by growing data, sensors, cloud and edge computing, and networking at a global scale call for international research collaborations. For example, advances in machine learning and artificial intelligence, paired with the development and implementation of large sensor networks (e.g., Array of Things in Chicago and Fujisawa Sustainable Smart Town in Japan) can enable city-scale data to improve efficiency, economic prosperity, and security in our cities and communities. The workshop will focus on research challenges that are beyond the individual reach of each participant, but that become feasible goals with effective collaboration between the two countries. This can be achieved when both sides share similar interests, but with complementary expertise and skills, (e.g., from different but related areas such as the examples mentioned above)."
1648897,"A Conference on Humans, Machines and the Future of Work",IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",11/1/2016,7/21/2016,Moshe Vardi,"Vardi, M","Vardi, M",TX,William Marsh Rice University,Standard Grant,James Donlon,10/31/2017,"$25,000.00 ",,vardi@rice.edu,6100 MAIN ST,Houston,TX,770051827,7133484820,CSE,"1640, 7495","7495, 7556",$0.00 ,exceptionalFunding,"This project supports a conference on ""Humans, Machines, and the Future of Work"" to be held at Rice University, in Houston, TX. The conference will focus on issues created by the impact of information technology on labor markets over the next 25 years, addressing questions such as: What advances in artificial intelligence, robotics and automation are expected over the next 25 years? What will be the impact of these advances on job creation, job destruction, and wages in the labor market? What skills are required for the job market of the future? How can education prepare workers for that job market? What educational changes are needed? What economic and social policies are required to integrate people whose skills do not match the needs of future labor markets? How can social mobility in such an environment be preserved and increased? The conference will feature 16 renowned speakers and panelists from academia, industry and leading think tanks with expertise in technology, economics, social sciences, and the humanities. The goal of the conference is to start a conversation between many academic disciplines on the future of work in order to make this topic a subject of ongoing academic inquiry, as well as a subject of public policy discussion.<br/><br/>The current understanding of the Information Technology Revolution is somewhat similar to the 1970s' understanding of global warming. Facts are known with some level of certainty.  Computers are eliminating some jobs involving structured tasks in manufacturing, clerical work, and some other mid-skill occupations.  At the same time,  computers are creating new jobs in many other occupations, particularly for technically skilled people. Beyond these facts lies a broad landscape of speculation.  Not much is known about the Information Technology Revolution's net effect on employment and wages. Equally important, not much is known about the speed at which the revolution is proceeding.  To the extent this uncertainty can be reduced, it will require a joint effort by computer scientists, economists, sociologists, psychologists, and others. Addressing these issues is an important national challenge."
828035,HCC: Doctoral Student Symposium at The Third International Conference on Design Computing and Cognition,IIS,Cyber-Human Systems (CHS),6/1/2008,5/22/2008,Ashok Goel,"Goel, A","Goel, A",GA,Georgia Tech Research Corporation,Standard Grant,Ephraim P. Glinert,11/30/2008,"$25,000.00 ",,ashok.goel@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"9215, HPCC, 7367",$0.00 ,exceptionalFunding,"This project supports a Doctoral Student Symposium at the Third International Conference on Design Computing and Cognition. The goals of the main conference is to describe and discuss (1) state-of-the-art research on computational, artificial intelligence, and cognitive science theories and models of design, and (2) cutting-edge intelligent, interactive, and human-centered information technologies for supporting design. The goal of the interdisciplinary doctoral student symposium is to encourage, expand and guide the participation of young researchers starting research in design computing and cognition."
1301542,"Advanced Study Institute on Global Healthcare Grand Challenges and Opportunities Conference on July 21-26, 2013 in Antalya, Turkey",CBET,Engineering of Biomed Systems,8/1/2013,4/28/2016,Metin Akay,"Akay, M","Akay, M",TX,University of Houston,Standard Grant,Michele Grimm,7/31/2017,"$25,000.00 ",,makay58@gmail.com,4800 Calhoun Boulevard,Houston,TX,772042015,7137435773,ENG,5345,"004E, 017E, 028E, 137E, 138E, 7237, 7479",$0.00 ,exceptionalFunding,"PI: Metin Akay<br/>Proposal ID: 1301542<br/><br/>The National Academy of Engineering announced the 14 Grand Challenges for Engineering at the annual meeting of the American Association for the Advancement of Science. The committee also praised biomedical and biological engineering as the research field to fulfill the promise of personalized medicine. Included among these 14 challenges were Reverse Engineering the Brain, Engineer better Medicines and Advance Health Informatics. An important way of exploiting such information would be through the development of methods that allow doctors to forecast the benefits and side effects of potential treatments or cures. ""Reverse Engineering"" the Brain, is an emerging discipline that helps us to understand how the brain works and treats several diseases. It furthermore helps us to develop computerized artificial intelligence. Advanced computer intelligence, in turn, should enable automated diagnosis and prescriptions for treatment. Computerized catalogs of health information will enhance the medical system's ability to track the spread of disease and analyze the comparative effectiveness of different approaches to prevention and therapy. Finally, engineering new medicines will help us fight the growing danger of attacks from novel disease-causing agents. For instance, certain deadly bacteria have repeatedly evolved new properties, conferring resistance against even the most powerful antibiotics. New viruses arise with the power to kill and spread more rapidly than disease-prevention systems are designed to counteract.<br/><br/>Intellectual Merits: The main objective of the ""Advanced Summer Institute on Global Healthcare--Challenges and Opportunities"" is to highlight and discuss these emerging grand challenges, mainly focused on the latest advances in the areas of science, engineering, technology and medicine. The institute provides a unique environment to discuss the emerging research areas, challenges and opportunities which lead to very fruitful discussions.<br/><br/>Broader Impacts: It exposes the attendees with biology and medicine backgrounds to the latest developments in these emerging enabling technologies. It is also helpful to those with engineering and science background who are interested in doing research in bionanoscience and nanomedicine, neuroscience and engineering since the advanced institute provides exceptional insights into the fundamental challenges in biology and medicine."
1040683,Promoting Expertise in Computational Cognitive Science,BCS,"PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",8/15/2010,8/8/2010,Tim Rogers,"Rogers, T","Rogers, T",WI,University of Wisconsin-Madison,Standard Grant,Betty H. Tuller,7/31/2011,"$25,000.00 ",,ttrogers@wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,SBE,"7252, 7495",,$0.00 ,exceptionalFunding,"This award is to support tutorials at the intersection of artificial intelligence and cognitive psychology at the 2010 meeting of the Cognitive Science Society. Encouraging computational sophistication in the next generation of cognitive scientists, and encouraging interdisciplinarity in researchers at all career stages, are key elements of the training mission of the Cognitive Science Society. Access to information presented at the conference will also be provided through Web broadcasts of the symposia and a special issue of the Society journal with an emphasis on the teaching mission of workshop attendees."
1203216,Conference on Statistical Learning and Data Mining,DMS,STATISTICS,1/1/2012,12/5/2011,Ji Zhu,"Zhu, J","Zhu, J",MI,University of Michigan Ann Arbor,Standard Grant,Gabor J. Szekely,12/31/2012,"$25,000.00 ",,jizhu@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,MPS,1269,7556,$0.00 ,exceptionalFunding,"An international conference on ""Statistical Learning and Data Mining"" will be held June 4-7, 2012 on the Ann Arbor campus of the University of Michigan. The objective is to bring together researchers in statistical learning and data mining from academia, industry, and government in a relaxed and stimulating atmosphere focused on the development of statistical learning theory, methods and applications. The conference will feature three plenary talks by internationally prominent researchers whose work are cutting-edge in the field of statistical learning and data mining. Eighteen invited breakout sessions, each with three talks, will cover additional topics with great interest to the field. These include Computational Advertisement, Function Estimation, High-dimensional Methods, Structured Learning, Graphical Models, Learning Theory, Model Selection, Covariance Estimation, Network Analysis, Computational Biology, Signal and Image Processing and Data Mining Applications. There will also be seven contributed paper sessions and two contributed poster sessions where junior investigators and graduate students are expected to participate.<br/><br/>Statistical learning is a relatively new discipline, evolving from machine learning methods of artificial intelligence and multivariate statistics. The general goals of statistical learning are discovery, classification and prediction, often in very high, effectively infinite, dimensional contexts. The advent of powerful computers with accompanying massive data sets has brought the discipline to the forefront of statistical theory and practice. The major goal of the proposed conference is to present some of the most important recent advances in the field and to discuss future research directions. A major part of the conference focuses on bringing statistical research leaders together with students, postdoctoral fellows, and young academics in a stimulating environment. The funding from the NSF will mainly support graduate students and junior researchers in American universities to attend the conference and present either a talk or a poster. The conference is expected to accelerate interactions and collaborations among researchers in the important area of statistical learning and data mining, and thereby lead to the development of new and more effective methods of modeling and inference."
325147,"Block Island Workshop on Cooperative Control.  To be Held at the Spring House Hotel in Block Island, Rhode Island.",ECCS,"CONTROL, NETWORKS, & COMP INTE, CONTROL SYSTEMS",7/1/2003,7/2/2003,A. Morse,"Morse, A","Morse, A",CT,Yale University,Standard Grant,Radhakisan S. Baheti,12/31/2003,"$25,000.00 ",,as.morse@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,ENG,"1518, 1632","0000, 7238, OTHR",$0.00 ,exceptionalFunding,"The purpose of this proposal is to request funds from the National Science Foundation in partial<br/>support of the forthcoming Block Island Workshop on Cooperative Control which is scheduled to<br/>take place on June 10 and 11, 2003 at the Spring House Hotel on Block Island, Rhode Island.<br/>The primary objective of this workshop is to bring together a small number of individuals from<br/>such fields as animal biology, robotics, automatic control, communications and sensor networks,<br/>artificial intelligence, dynamical systems, algorithms, etc. with interests in group coordination and<br/>cooperative control  not primarily to present their current work, but rather to delineate common<br/>ground and to identify fundamental unresolved problems in the rapidly evolving, cross-disciplinary<br/>field of cooperative control of natural and man-made groups.<br/>Intellectual Merit: In recent years, there has been a growing interest in understanding on the one<br/>hand, how various animal aggregations such as fish schools, bird ocks, deer herds, etc. coordinate<br/>their collective motions to perform useful tasks and on the other, how groups of mobile autonomous<br/>agents such as AUV schools, UAV ocks, etc., might be instructed to cooperate in a similar man-ner.<br/>In ecology and evolutionary biology, for example, it is of great interest to understand how<br/>natural groupings coordinate themselves and move so awlessly, often without an apparent leader<br/>or any form of centralized control. What kinds of signaling must they use? What role if any,<br/>does the physical medium, environmental context, currents, vortices, or other local environmental<br/>disturbances play in this process? Are there universal principles of coordinated group motion and<br/>if so what might they be? Could such principles be used in a robotic context to help enable a large<br/>group of autonomously functioning vehicles in the air, on land or sea or underwater, to collectively<br/>accomplish, in a safe and coordinated manner, useful tasks such as distributed, adaptive scientific<br/>data gathering, search and rescue, and reconnaissance? In broad terms, these are the questions to<br/>which this workshop is addressed.<br/>Broader Impacts: This workshop will advance discovery and understanding while promoting<br/>teaching, training and learning by including student participation at the workshop. The work-shop<br/>will broaden participation of under-represented groups by encouraging such individuals to<br/>actively participate in the workshop. Without question, this highly interdisciplinary meeting<br/>will enhance infrastructure for research and education by significantly increasing the potential for<br/>cross-disciplinary research among participants and between parent institutions. The workshop will<br/>broaden dissemination to enhance scientific and technological understanding by means of a published<br/>proceedings and well as by consequential presentations and publications to a wide semi-technical<br/>community."
647443,Workshop on Addressing the Grand Challenges of Traceability,CCF,SOFTWARE ENGINEERING AND LANGU,9/1/2006,8/28/2006,Jane Hayes,"Hayes, J","Hayes, J|Dekhtyar, A|Huang, J|Berenbach, B",KY,University of Kentucky Research Foundation,Standard Grant,Sol J. Greenspan,8/31/2008,"$25,000.00 ","Alexander Dekhtyar, Jane Huang, Brian Berenbach",hayes@cs.uky.edu,109 Kinkead Hall,Lexington,KY,405260001,8592579420,CSE,2880,"2880, 9150, 9218, HPCC",$0.00 ,exceptionalFunding,"Abstract<br/><br/>This award funds a workshop on traceability in Software Engineering, an important subject that has received only fragmented and superficial attention over the past years. The proposed workshop will bring together software engineering researchers and practitioners to define and explore challenge problems in traceability. Experts from other fields such as human computer interaction, information retrieval, and artificial intelligence are also invited to participate in the workshop to provide cross-pollination of ideas.<br/>"
1601,"US-Egypt Cooperative Research: Fault Detection, Isolation, and Accommodation of a Chemical Engineering Process Using Genetic Programming",OISE,,9/1/2000,8/29/2000,Janos Gertler,"Gertler, J","Gertler, J",VA,George Mason University,Standard Grant,Osman Shinaishin,8/31/2003,"$25,000.00 ",,jgertler@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,O/D,X376,"5944, 9216, HPCC",$0.00 ,exceptionalFunding,"0001601<br/>Gertler<br/><br/>Description: This award is to support a collaborative project by Dr. Janos Gertler, Electrical and Computer Engineering Department, George Mason University, Fairfax, Virginia, and Dr. Alaa Sheta, Computer and Systems Department, the Electronics Research Institute, Cairo, Egypt. Traditional methods for fault detection and isolation rest on the idea of analytical redundancy. In practical applications, these methods have the serious drawback that they are sensitive to modeling error. The ability to build a suitable model with minimum modeling error is a major problem in the modeling process of dynamic systems. The scientists plan to explore the advantages of using Genetic Programming (GP) to solve a number of important engineering problems. They plan to create an appropriate model structure for a chemical engineering process such that the developed model will be suitable for fault detection, isolation and accommodation of the Tennessee Eastman Test Problem. Experiments will be carried out to demonstrate the advantages of the proposed approach. <br/><br/>Scope: The US PI and the Egyptian collaborator have worked jointly in this area of research, and have developed a new technique to model system dynamics using genetic algorithms and test this technique on data from an automotive engine. The two investigators complement each other. Dr. Gertler's research interest is in the area of fault detection, isolation and accommodation. His expertise also includes system identification and real-time computer process control. Dr. Sheta's research interests are in the area of system identification, control, optimization and artificial intelligence. His interests also include the design of robust controllers for large-scale uncertain dynamical systems. He will be in charge of developing a suitable model structure for the process under study, and for the adaptation of a simulation program for the process. This proposal meets the INT objective of supporting collaborative research in areas of mutual interest. This project is being supported under the US-Egypt Joint Fund Program, which provides grants to scientists and engineers in both countries to carry out these cooperative activities."
1442208,Workshop: Doctoral Consortium for HCOMP 2014,IIS,Cyber-Human Systems (CHS),5/1/2014,4/28/2014,Matthew Lease,"Lease, M","Lease, M",TX,University of Texas at Austin,Standard Grant,William Bainbridge,4/30/2015,"$24,966.00 ",,ml@ischool.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Doctoral Consortium (workshop) of promising doctoral students and distinguished research faculty to be held in conjunction with the HCOMP 2014 Conference on Human Computation & Crowdsourcing, sponsored by the Association for the Advancement of Artificial Intelligence (AAAI). The Consortium will enhance the scientific workforce in this emerging research area by developing a group of promising young researchers interested in human computation and crowdsourcing. The award will also enable these young researchers to attend the HCOMP 2014 conference, thus allowing them to interact with other researchers and conference events; to learn of potential career paths within academia and industry; to access an international network of researchers who can support their professional development; and to observe the interdisciplinary nature, diversity and interrelationships of research in human computation.<br/><br/>The HCOMP 2014 Doctoral Consortium will be a research-focused meeting of an international group of selected Ph.D. candidates with a panel of distinguished research faculty. The Doctoral Consortium Chairs will select six additional distinguished researchers to serve as faculty mentors; this group also will serve as the review committee for student applications. Students will be selected based on a paper giving an overview of the student's dissertation research, an explanation of why the students wants to participate in the Doctoral Consortium, a CV, and an advisor's letter of support. The PIs will give preference to students who are most in need of mentoring and joining a peer group. <br/><br/>The full-day workshop event will include activities to guide the research of these promising young researchers. The Consortium will allow participants to interact with established researchers and with other students, through presentations, question-answer sessions, panel discussions, and invited presentations. Each participant will give a short presentation on their research and will receive feedback from at least one faculty mentor and from fellow students. The Consortium will include activities led by the faculty, such as a panel discussion, to give students more information about the process and lessons of research and life in academia and industry. To further integrate the Doctoral Consortium participants into the conference itself, students will have a chance to present their work as posters in an interactive poster session and their papers will be posted online on the workshop webpage. These activities will benefit the participants by offering each fresh perspectives and comments on their work from researchers outside their own institution, both from faculty and other students; providing a supportive setting for mutual feedback on participants' current research and guidance on future research directions; and enabling participants to form a cohort of new researchers."
1622831,Doctoral Consortium for the 2016 Learning Analytics and Knowledge Conference,IIS,Cyberlearn & Future Learn Tech,6/1/2016,6/3/2016,Stephanie Teasley,"Teasley, S","Teasley, S|Chen, B",MI,University of Michigan Ann Arbor,Standard Grant,Tatiana D. Korelsky,5/31/2018,"$24,930.00 ",Bodong Chen,steasley@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,8020,"7556, 8045",$0.00 ,exceptionalFunding,"Using data analytics has revolutionized many academic disciplines, such as Astrophysics and Biology. In addition, it has changed the commercial world and critical services like healthcare. The field of education research is also beginning this change. The Society for Learning Analytics Research (SoLAR) is a key player in effecting this change. This project will support a Doctoral Consortium at the SoLAR 2016 conference - the 6th Annual International Learning Analytics and Knowledge (LAK) Conference, to be held in Edinborough, UK in 2016. Participating in the consortium will prepare current doctoral students from the diverse research backgrounds that make up the interdisciplinary field of Learning Analytics (LA), including computer science, information science, psychology, communication, education, artificial intelligence, and cognitive science. It will also allow them to network with each other and with professors and practitioners who are currently engaged in learning analytics research and related work to ensure the continued development of this community. These activities are critical and timely. The upcoming generation of LA researchers will play a vital role in realizing the potential of using data to improve outcomes for elementary, secondary, and post-secondary students in learning, motivation, and perseverance.<br/><br/>Learning Analytics is an interdisciplinary field whose goal is to advance and apply knowledge about learning sciences and education to improve all aspects of learning. LA methods include data visualization, data mining, data science, and mixed methods approaches combining qualitative and quantitative methods (e.g., interviews and back-end, clickstream data analysis). Capacity building is a central concern within the LA community. SoLAR has historically addressed these needs, in part, through specialized workshops held in conjunction with the Society's major conference. The Doctoral Consortium workshops host PhD students who are grappling with their dissertation research. This grant provides travel support to US scholars selected through a competitive application process to participate in this event. They present their work for feedback both in the context of workshop, where they receive advice from a panel of expert mentors, and in a poster session in which they interact with the full conference audience. In addition, their work is published in the proceedings of the conference."
1733545,"Workshop: Innovation, Cities, and the Future of Work",SMA,"S&CC: Smart & Connected Commun, SCIENCE OF SCIENCE POLICY",6/15/2017,6/7/2017,Iyad Rahwan,"Rahwan, I","Rahwan, I",MA,Massachusetts Institute of Technology,Standard Grant,cassidy sugimoto,5/31/2018,"$24,750.00 ",,irahwan@MIT.EDU,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,SBE,"033Y, 7626","7556, 7626",$0.00 ,exceptionalFunding,"Artificial intelligence (AI) is expected to significantly change labor markets nationwide, with specific implications for job availability and productivity in urban areas. Urbanization, largely driven by job migration, produces cities which act as innovation centers and economic engines for society. Technological improvements increase efficiency of production, but the rate of changing labor demands resulting from technology may be too fast to maintain urbanization trends. As an example, existing work highlights the prominent role education can play in advancing or broadening career opportunities, but it is not obvious which occupations will remain or be redefined as a result of changing labor demands with the introduction of new technology. Understanding these dynamics will lead to informed policy that promotes preparedness for future labor demands.  Evidence based urban policy can maximize the efficiency gains from AI, while minimizing the detrimental effects on the well-being of the residents of cities, such as net employment loss and increased occupational polarization. <br/><br/>This workshop, which connects researchers specializing in urban innovation, labor economics, the impacts of automation, and urban policy aims to identify new policies targeted at mitigating the detrimental labor market effects from imminent automation technology and identify prudent unanswered questions as future work that may further inform urban policy.  Answering these questions requires understanding systemic trends as identified by the urban physics literature and linking to the causal mechanisms related to automation identified by labor economists. This understanding will inform urban policy that maximizes efficiency gains from new technology while minimizing detrimental labor effects and provide a new understanding of occupational removal or redefinition resulting from technological change. This workshop aims to inform policy aimed at retraining existing workers and preparing new workers for the labor demands in the age of AI."
726616,"Student Support for the Artificial Intelligence in Education Conference, Los Angeles, CA -July 9-13, 2007",IIS,Cyber-Human Systems (CHS),5/1/2007,5/2/2007,Roger Azevedo,"Azevedo, R","Azevedo, R|Graesser, A",TN,University of Memphis,Standard Grant,David W. McDonald,4/30/2008,"$24,500.00 ",Arthur Graesser,roger.azevedo@ucf.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,7367,"7367, 9150, 9216, HPCC",$0.00 ,exceptionalFunding,"This is funding to support travel by 20 students currently enrolled in PhD programs in the United States to participate in the AI-ED Doctoral Student Consortium, at the upcoming International Artificial Intelligence in Education Conference (AI-ED), to be held July 9-13, 2007, in Los Angeles, California.  The AI-ED International Conference is the premier biennial event for promoting promotes rigorous research and development of interactive and adaptive learning environments for learners of all ages; AI ED will be the 6th event in the series.  The interdisciplinary areas that AI-ED represents, comprising cognitive science, computer science, and educational technology, are critical research domains that enhance the effectiveness and usability of software learning systems.  Active participation of young researchers in this conference is very important, both for the health of the field and for the researchers themselves.  The AI-ED '07 Doctoral Consortium provides a unique opportunity for PhD students partway through their dissertation research to receive valuable feedback and individual mentoring from top researchers in the field.  This support for doctoral students is particularly apt given that currently only 4% of the over 600 members of the AIED society are students, even with 44 countries represented.  It is thus timely for NSF to offer this student support. The PI and co-PI both hold active leadership roles within AI-ED '07, and both hold over $2 million of NSF grants in the areas of human-language and advanced learning technologies. The AI-ED '07 Doctoral Consortium Committee will be comprised of the two PIs together with the current president of the AIED society. <br/><br/>Broader Impact: Bringing young and creative researchers to AI-ED '07 will help advance an important and socially valuable interdisciplinary research field.  For many graduate students, the cost of attending the AI-ED conference exceeds their travel budget.  Thus, NSF funding will significantly impact the careers of the next generation of AIED researchers, by enabling a number of them to take part in an important event they would otherwise have to miss; in particular, those who lack funding from other sources (e.g., advisor's grants).  The students will have an opportunity to gain wider exposure in the community for their innovative work, and to obtain feedback and guidance from senior members of the research community.  Participation will also help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development.  The PI and co-PI have indicated that they will act to assure participation by members of traditionally under-represented institutions, and will pay close attention to inclusion of minorities and women.<br/>"
1651142,Conference:   Perceptrons and Syntactic Structures at 60: Computational Modeling of Language,BCS,"LINGUISTICS, ROBUST INTELLIGENCE",8/1/2017,7/19/2017,Joseph Pater,"Pater, J","Pater, J|O'Connor, B",MA,University of Massachusetts Amherst,Standard Grant,William J. Badecker,1/31/2019,"$24,184.00 ",Brendan O'Connor,pater@linguist.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,SBE,"1311, 7495","1311, 7495, 7556",$0.00 ,exceptionalFunding,"This workshop will bring together leading researchers in cognitive science and artificial intelligence who specialize in the integration of linguistic theory with statistical approaches, especially neural networks. Neural networks have been important in many of the recent advances in language technologies (in what's called ""deep learning""), and the greater integration of linguistic structure into these models promises to lead to further breakthroughs. <br/><br/>The main focus of this meeting will be on how integration of models of linguistic structure with probabilistic learning theories may lead to a deeper understanding of the way that humans process and represent language. This sort of integration has been difficult to achieve in the past in part because of the separation of researchers in each tradition into different disciplines interacting in different conferences. In-depth analysis of the structure of human languages is conducted in mostly in Linguistics, while neural network modeling and other statistical learning research is conducted mostly in Psychology and Computer Science. The workshop will be held as part of the inaugural meeting of the Society for Computation in Linguistics, taking place concurrently with the meeting of the Linguistic Society of America. It will thus bring researchers from other disciplines into contact with linguists, and will stimulate productive intellectual exchange."
737772,"AAAI-07 Mobile Robot Competition and Exhibition to be held on July 23-25, 2007 in Vancouver, British Columbia (Canada)",IIS,"Cyber-Human Systems (CHS), ROBUST INTELLIGENCE",7/1/2007,6/29/2007,Jeffrey Forbes,"Forbes, J","Forbes, J",NC,Duke University,Standard Grant,Douglas H. Fisher,6/30/2008,"$24,032.00 ",,forbes@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,"7367, 7495","7484, 9102, 9215, HPCC",$0.00 ,exceptionalFunding,"The 16th Annual AAAI Mobile Robot Competition and Exhibition will be held July 23-25, 2007, in Vancouver, British Columbia (Canada), in conjunction with the 22nd International Conference on Artificial Intelligence (AAAI-07).  The mobile robot program serves the research community in two ways.  First, it provides a venue for demonstrations of the latest research in AI and robotics.  Second, robot program activities serve as a terrific opportunity for exposing undergraduate and graduate students to the latest research in AI and for allowing them to make valuable connections early in their research careers.   From new approaches to canonical robotics problems to groundbreaking research in emerging areas, the mobile robot program provides a forum for a diverse range of projects in mobile robotics.  Recent years have witnessed a rise in the accessibility of mobile robot platforms with reasonably capable platforms being available for relatively low cost and not requiring a substantial effort to build hardware or software architectures.  Some participants exhibit a range of projects using commodity robots, while others showcased unique construction.  As robots become more accessible, the robot program is able to showcase work from a wide range of contributors.  For the past two years, the event has increasingly promoted research projects that encourage human-machine interaction as well as adaptation and learning in natural human settings.  This trend is one that will continue in 2007, where the program will include two challenges: Semantic Robot Vision (SRVC) and Human-Robot Interaction (HRI).<br/><br/>This is funding to support travel to and participation by student teams from the United States in the HRI challenge, which will provide a structured framework that allows teams to compete directly in seven predefined categories that are aimed at human-robot interaction and involve activities that intrinsically integrate perception and action.  There are six separate categories that the robots can enter: recognition of and reaction to human motions and/or gesture; emotion recognition and appropriate emotion expression; natural language understanding and action execution; perceptual learning through human teaching and subsequent, recognition and categorization of people, objects, locations or actions; perception, reasoning, and action; and shared attention, common workspace, intent detection.  The seventh and final category is the integration challenge - that is, a demonstration of an extended, multimodal interaction that combines at least three of the above six categories.  Judges will evaluate the AI techniques employed and their level of sophistication.  The results of the event will be disseminated through abstracts in the AAAI-07 conference proceedings, through research papers in the proceedings of the mobile robot workshop, and via a summary article in AI Magazine.<br/><br/>Broader Impacts:    The annual AAAI Mobile Robot Competition and Exhibition is the only major venue that establishes and maintains the vital connection between the robotics and AI communities.  Thus, these events have the potential to significantly impact robotics education and research.  Exhibits will identify and publicize innovative educational programs that show how mobile robotics can be used as a motivating domain in the classroom and the research lab.  The organizers will make special efforts to recruit participants for the event that specifically target student populations and institutions that are often under-represented in the field."
1636983,WORKSHOP: Doctoral Consortium at HCOMP 2016,IIS,Cyber-Human Systems (CHS),6/1/2016,5/18/2016,Haoqi Zhang,"Zhang, H","Zhang, H",IL,Northwestern University,Standard Grant,Ephraim P. Glinert,5/31/2017,"$23,772.00 ",,hq@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support a Doctoral Consortium (workshop) of approximately 12 promising doctoral students (at least 8 of whom will be from U.S. educational institutions) along with distinguished research faculty, to be held in conjunction with the HCOMP 2016 Conference on Human Computation & Crowdsourcing, which will take place October 31-November 3 in Austin, Texas, and which is sponsored by the Association for the Advancement of Artificial Intelligence (AAAI).  HCOMP is a cross-disciplinary conference that combines human-centered methods and traditional computer science to address fundamental issues in human computation and crowdsourcing.  It brings together researchers and practitioners from diverse areas such as human-computer interaction, psychology, economics, social computing, machine learning, information retrieval, databases and systems.  More information about the conference is available online at http://www.humancomputation.com/2016/.  The Doctoral Consortium will be a research-focused meeting that immediately precedes the conference, on October 30, and will enhance the scientific workforce in this emerging research area by developing a group of promising young researchers interested in human computation and crowdsourcing. The award will also enable these young researchers to attend the HCOMP 2016 conference, thus allowing them to interact with other researchers and conference events; to learn of potential career paths within academia and industry; to access an international network of researchers who can support their professional development; and to observe the interdisciplinary nature, diversity and interrelationships of research in human computation.  The Doctoral Consortium Chairs will select about six additional distinguished researchers to serve as faculty mentors; this group also will serve as the review committee for student applications. Students will be selected based on a paper giving an overview of the student's dissertation research, an explanation of why the student wants to participate in the Doctoral Consortium, a CV, and a letter of support from the student's advisor. The organizers will give preference to students who are most in need of mentoring and joining a peer group.  Moreover, the organizers will promote diversity among the selected students by selecting no more than two students from any one school, and by prioritizing the selection of women and underrepresented minorities. <br/><br/>The full-day Doctoral Consortium will include activities to guide the research of these promising young researchers. The Consortium will allow participants to interact with established researchers and with other students, through presentations, question-answer sessions, panel discussions, and invited presentations. Each participant will give a short presentation on their research and will receive feedback from at least one faculty mentor and from fellow students. The feedback will be geared toward helping the student participants understand and articulate how their research is positioned relative to other work on human computation and crowdsourcing.  The feedback will also address whether the students' topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are being appropriately analyzed and presented.  Activities led by the faculty will include a panel discussion to give students more information about the process and lessons of research and life in academia and industry. To further integrate the Doctoral Consortium participants into the conference itself, students will have a chance to present their work as posters in an interactive poster session and their papers will be posted online on the workshop webpage. These activities will benefit the participants by offering each fresh perspectives and comments on their work from researchers outside their own institution, both from faculty and other students; providing a supportive setting for mutual feedback on participants' current research and guidance on future research directions; and enabling participants to form a cohort of new researchers."
9551414,Laboratory for Computational Neuroscience,DUE,"COMPUTATIONAL NEUROSCIENCE, UNDERGRAD INSTRM & LAB IMPROVE",6/1/1995,6/17/1996,Roderick Jensen,"Jensen, R","Jensen, R",CT,Wesleyan University,Standard Grant,Myra O. Smith,5/31/1998,"$23,493.00 ",,rjensen@wesleyan.edu,237 HIGH ST,Middletown,CT,64593208,8606853683,EHR,"1162, 7400","9178, 9251, 9267, SMET",$0.00 ,exceptionalFunding,"Mathematical and numerical models play a very important role in our understanding of biophysical processes in the nervous system. With the advent of high-speed graphics workstations and new mathematical and numerical methods for describing complex dynamical systems, many difficult problems in neuroscience can now be addressed. Coupled with the explosion in experimental neurobiological data, these new developments have lead to the emergence of the rapidly growing field of computational neuroscience which represents a remarkable coalition of interrelated disciplines: neurobiology, computer science, biochemistry, artificial intelligence, molecular biology, mathematics, psychology, physics, and philosophy. The project lays the foundation for a Laboratory for Computational Neuroscience at Wesleyan University. Because of the new computer technologies and new theoretical and numerical methods for describing complex systems, this exciting interdisciplinary field should be both accessible and appealing to undergraduate students. The proposed facility will provide the foundation for both undergraduate courses and research opportunities in the modelling of neurobiological processes from the electrophysiological behavior of single neurons to the spatio-temporal patterns of activity in neural networks. In addition, these facilities will also be available for the further development of courses and research projects in other interdisciplinary areas of computational science."
1622402,CAREER: Reasoning under Uncertainty in Cybersecurity,CNS,Secure &Trustworthy Cyberspace,8/7/2015,2/11/2016,Xinming Ou,"Ou, X","Ou, X",FL,University of South Florida,Continuing grant,Sylvia J. Spengler,2/28/2017,"$23,249.00 ",,xou@usf.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,CSE,8060,1045,$0.00 ,exceptionalFunding,"Cyber security, like security in the physical world, relies upon investigation methodologies that piece together dispersed evidence spread across multiple places, and come to a conclusion on what security breaches have happened and how they happened. While effective evidential reasoning based on manual analysis are used in the physical world by law-enforcement agencies, in the cyber world we need automated reasoning methodologies to handle the automated cyber attacks against our nation's information infrastructures every day. This research aims at discovering and developing such automated reasoning methodologies. The problem is  difficult due to the uncertain nature of such reasoning, which is compounded by the characteristics of cyber attacks.<br/><br/>The uncertainty in cyber security comes from two sources. The first is the uncertainty from not knowing the attacker's actions and choices. Since hackers are essentially invisible in the cyberworld, we have to rely upon various types of sensors that report symptoms of potential attacks. The second source of uncertainty comes from these sensors. Since in most cases the symptoms of cyber<br/>attacks significantly overlap with symptoms from benign network activities, it is not possible to rely on a single sensor to give an absolutely correct judgment on whether an attack has happened and succeeded. A key question is how to use these imperfect sensors to conduct reasoning so that one can come up with almost certain conclusions regarding a system's security status. <br/><br/>This challenge of reasoning under uncertainty is not new. In the past four decades computer science researchers have developed an array of reasoning models and methods for uncertainty, especially in the area of artificial intelligence. However, the emergence of cyber threats poses a new<br/>challenge to this problem. The existing methodologies typically require a knowledge-engineering process to build a knowledge model for the problem domain. This has worked reasonably well with the more static and well-behaved problem domains such as disease diagnosis. A key difference between these problem domains and cyber security is that the latter has to deal with an active<br/>malicious attacker who will try to break whatever assumptions made in the reasoning model. For this reason, the knowledge model for cyber security cannot be static because then they can be easily evaded. What will be an effective and practical knowledge engineering approach to handle the uncertainty in cyber security is the biggest open problem that needs to be answered from the<br/>research.<br/><br/>This research adopts an empirical, bottom-up approach to tackle the above challenges. Instead of starting from the existing theories, the PI will start from empirical study on how a human security analysts would reason about cyber events and try to capture the essence of the reasoning in the process. Then, the PI will carry out this empirical study by running intrusion detection sensors on production networks and work with system administrators to understand and reason about the alerts. The next step is to develop a reasoning model that simulates the human reasoning process, and apply the automated reasoning engine on fresh new data to see how it fares. In this spiral theory development process the PI can always make sure that the methodologies are applicable to real cyber-security analysis and constantly find gaps in the model that reveal what will be the most appropriate theories and how to apply them in this problem. The eventual goal is to find the right theoretical framework for reasoning under uncertainty in cyber-security, and validate such theories through repeatable experiments on data from production systems.<br/><br/>This research is tightly integrated into the PI?s education efforts both for students and targeted at the society at large. The empirical nature of the research provides a valuable venue for dialogue between security practitioners and researchers, which will result in a two-way education process: students working on the project can acquire the essential skills of applying advanced knowledge to a practical problem; and security practitioners like system administrators can learn the state-of-the art in cyber security technology through collaborative work with the research team. The empirical study carried out from the research will provide endless data and examples to refresh the materials of the cyber-security courses taught by the PI. New courses with a focus on uncertainty in cyber security defense will be developed. There will be a number of undergraduate students who take part in the research efforts, which will provide a unique education experience for them. Moreover, the test-bed infrastructure produced from the research will also be used as an education platform for the general public about cyber-security problems, with the help of the out-reach programs already established at Kansas State University."
1650295,CAP: The Seventh Symposium on Educational Advances in Artificial Intelligence (EAAI-17),IIS,Cyberlearn & Future Learn Tech,9/1/2016,9/2/2016,ERIC EATON,"EATON, E","EATON, E",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Tatiana D. Korelsky,8/31/2018,"$22,600.00 ",,eeaton@seas.upenn.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,8020,"7556, 8045, 8055",$0.00 ,exceptionalFunding,"The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning CAP projects build capacity for research and development in the field of cyberlearning by improving technical infrastructure, human capital, and in other ways. The Symposium on Educational Advances in Artificial Intelligence, affiliated with the AAAI (Association for the Advancement of Artificial Intelligence) conference in San Francisco in February 2017 is a premier venue for sharing knowledge about how to use AI in education and how to teach about AI. This grant helps support participation of US students and teachers in the conference, as well as early career faculty and organizers of REU (Research Experiences for Undergraduates) sites. <br/><br/>The symposium includes a variety of activities that advance the field and train the next generation of AI researchers and investigators. Peer reviewed papers and keynote addresses are complemented by sessions on model classroom assignments in teaching AI, and a competition for undergrads to create innovative tasks for students learning robotics. A discussion group will share best practices among REU site coordinators. Tracks will consider outreach and ethics in teaching AI. Broader impacts beyond the participants at the symposium are supported by the materials produced and shared among the community, such as the database of open educational materials, and the outputs of the student competition."
76319,Workshop:  Support for International Travel of Graduate Students to Agents Conference,IIS,ARTIFICIAL INTELL & COGNIT SCI,6/15/2000,6/13/2000,Maria Gini,"Gini, M","Gini, M",MN,University of Minnesota-Twin Cities,Standard Grant,William Bainbridge,5/31/2002,"$22,500.00 ",,gini@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This is funding to subsidize travel and housing expenses of a select group of US graduate students to attend the ACM International Conference on Autonomous Agents (AGENTS 2000), to be held June 3-7 in Barcelona, Spain.  This is the premier conference devoted entirely to agents research, an area of artificial intelligence which is central to the success of the World Wide Web and the Internet revolution.  Attending the conference will allow a diverse group of graduate students whose research spans a range of topic areas and methodologies to present their work to and receive feedback from the agents community.   The students will be selected by a committee, and special mentoring activities will be planned for them with the goal of fostering interactions with senior researchers.   This, in turn, will help set the directions of future research in the field, and guarantee continued growth and development of agents technology."
1239062,EAGER: RI: Collecting and Filtering Online Information in Science,IIS,ROBUST INTELLIGENCE,5/1/2012,6/26/2012,Bruce Buchanan,"Buchanan, B","Buchanan, B",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,4/30/2013,"$21,982.00 ",,buchanan@cs.pitt.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7916",$0.00 ,exceptionalFunding,"This proposal focuses on developing methods to automate the time-consuming process of selecting good overview and review articles from on-line new sources. The goal is to select articles understandable by persons outside the field and use them on the AITopics information portal maintained by the AAAI. The AITopics website is a widely used authoritative source about Artificial Intelligence that is used by a wide variety of people seeking information about AI: novices, students, the press, etc.  AITopics is intended to provide explanatory, accessible material about multiple subtopics that make up the field of AI. This project will develop new methods for this finding/filtering such articles and build on methods already used by AITopics. The resulting software will be open-source and is intended in the long run to be applicable to other scientific discipline beyond AI, particularly by their professional societies.<br/><br/>The project will pursue two thrusts to generalize the current NewsFinder program, which was developed as a part of AITopics and currently finds many types of news stories about AI. The first thrust of this project is to enable it to find overview and review articles automatically. The second thrust is to enable the program to learn from data collected from readers and administrators."
1748375,WORKSHOP:   Doctoral Consortium at HCOMP 2017,IIS,INFORMATION TECHNOLOGY RESEARC,8/1/2017,8/2/2017,Brent Hecht,"Hecht, B","Hecht, B",IL,Northwestern University,Standard Grant,Ephraim P. Glinert,7/31/2018,"$21,870.00 ",,bhecht@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,1640,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to support participation of at least 8 promising doctoral students from U.S. educational institutions at a Doctoral Consortium (workshop)along with distinguished research faculty, to be held in conjunction with the 5th AAAI Conference on Human Computation & Crowdsourcing (HCOMP 2017), which will take place October 24-26 in Quebec City, Canada, and which is sponsored by the Association for the Advancement of Artificial Intelligence.  HCOMP is the premier venue for disseminating the latest research findings on crowdsourcing and human computation.  While artificial intelligence (AI) and human-computer interaction (HCI) represent traditional mainstays of this cross-disciplinary conference, HCOMP believes strongly in inviting, fostering, and promoting broad, interdisciplinary research.  The diverse disciplines the field draws upon, and contributes to, range from human-centered qualitative studies and HCI design, to computer science and artificial intelligence, economics and the social sciences, all the way to digital humanities, policy, and ethics.  More information about the conference is available online at http://www.humancomputation.com/2017/.  The Doctoral Consortium will be a research-focused full day meeting that immediately precedes the conference, on October 23.  It will enhance the scientific workforce in this emerging research area by nurturing a group of promising young investigators interested in human computation and crowdsourcing. The award will also allow these young researchers to attend the HCOMP 2017 conference, thereby allowing them: to interact with other researchers and conference events; to learn of potential career paths within academia and industry; to access an international network of researchers who can support their professional development; and to observe the interdisciplinary nature, diversity and interrelationships of research in human computation.  The Doctoral Consortium Chairs will select up to 6 additional distinguished researchers to serve as faculty mentors; this group also will serve as the review committee for student applications. Students will be accepted based on a paper giving an overview of the student's dissertation research, an explanation of why the student wants to participate in the Doctoral Consortium, a CV, and a letter of support from the student's advisor. The organizers will give preference to students who are most in need of mentoring and joining a peer group.  Moreover, the organizers will promote diversity among the selected students by selecting no more than one or two students from any one school, and by prioritizing the selection of women and underrepresented minorities.   In accordance with CISE policy, NSF funds will only be used to support students from U.S.-based educational institutions.<br/><br/>The full-day Doctoral Consortium will include activities to guide the research of these promising young researchers. The Consortium will allow participants to interact with established researchers and with other students, through presentations, question-answer sessions, panel discussions, and invited presentations. Each participant will give a short presentation on their research and will receive feedback from at least one faculty mentor and from fellow students. The feedback will be geared toward helping the student participants understand and articulate how their research is positioned relative to other work on human computation and crowdsourcing.  The feedback will also address whether the students' topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are being appropriately analyzed and presented.  Activities led by the faculty will include a panel discussion to give students more information about the process and lessons of research and life in academia and industry. To further integrate the Doctoral Consortium participants into the conference itself, students will have a chance to present their work as posters in an interactive poster session and their papers will be posted online on the workshop webpage. These activities will benefit the participants by offering each fresh perspectives and comments on their work from researchers outside their own institution, both from faculty and other students; providing a supportive setting for mutual feedback on participants' current research and guidance on future research directions; and enabling participants to form a cohort of new researchers."
918684,Student Support for the AIED 2009 Artificial Intelligence in Education Conference,IIS,Cyber-Human Systems (CHS),5/1/2009,4/30/2009,Roger Azevedo,"Azevedo, R","Azevedo, R|Graesser, A",TN,University of Memphis,Standard Grant,William Bainbridge,4/30/2010,"$21,600.00 ",Arthur Graesser,roger.azevedo@ucf.edu,Administration 315,Memphis,TN,381523370,9016783251,CSE,7367,"7367, 9150, 9215, HPCC",$0.00 ,exceptionalFunding,"This is funding to support travel by 18 intermediate and advanced doctoral students to participate in the AI-ED Doctoral Student Consortium, at the upcoming International Artificial Intelligence in Education Conference (AI-ED), to be held to be held in Brighton, United Kingdom from July 6 to 10, 2009. The AI-ED International Conference is the premier biennial event for promoting promotes rigorous research and development of interactive and adaptive learning environments for learners of all ages; AI ED will be the 7th event in the series. The interdisciplinary areas that AI-ED represents, comprising cognitive science, computer science, and educational technology, are critical research domains that enhance the effectiveness and usability of software learning systems. Active participation of young researchers in this conference is very important, both for the health of the field and for the researchers themselves. The AI-ED Doctoral Consortium provides a unique opportunity for PhD students partway through their dissertation research to receive valuable feedback and individual mentoring from top researchers in the field. The PI and co-PI both hold active leadership roles within AI-ED, and both hold over $2 million of NSF grants in the areas of human-language and advanced learning technologies. The AI-ED Doctoral Consortium Committee will be comprised of the two PIs together with two other senior professors/researchers. <br/><br/>Broader Impact: Bringing young and creative researchers to AI-ED will help advance an important and socially valuable interdisciplinary research field. For many graduate students, the cost of attending the AI-ED conference exceeds their travel budget. Thus, NSF funding will significantly impact the careers of the next generation of AIED researchers, by enabling a number of them to take part in an important event they would otherwise have to miss; in particular, those who lack funding from other sources (e.g., advisor's grants). The students will have an opportunity to gain wider exposure in the community for their innovative work, and to obtain feedback and guidance from senior members of the research community. Participation will also help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. The PI and co-PI have indicated that they will act to assure participation by members of traditionally under-represented institutions, and will pay close attention to inclusion of minorities and women."
334013,Symposium: Multidisciplinary Approaches to the Science of Face Perception,BCS,COGNEURO,9/15/2003,9/4/2003,James Haxby,"Haxby, J","Haxby, J",NJ,Princeton University,Standard Grant,Lynne Bernstein,8/31/2004,"$21,598.00 ",,james.v.haxby@dartmouth.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,SBE,1699,"0000, 1699, OTHR",$0.00 ,exceptionalFunding,"    With National Science Foundation support, Dr. Haxby and colleagues will hold a symposium that will bring together investigators who are working on models of face perception within different disciplines and provide a forum for them to interact through presentations, discussions, and informal interactions.  The aim of this symposium is to facilitate interdisciplinary transfer of ideas and fostering collaborative research projects.  The symposium will include speakers with backgrounds in cognitive and computational models of face perception, neuropsychology, non-human primate neurophysiology, functional neuroimaging, and social psychology.  These researchers are working on inter-related problems concerning how faces are perceived and represented.  All faculty participants are asked to bring a graduate student or postdoctoral fellow from their laboratories with them.  These students and fellows will be asked to present posters at the symposium.  The inclusion of these younger investigators is expected to enhance the impact of this symposium on future interdisciplinary collaborations. <br/>    Proceedings of this meeting will be published on a web-site.  The talks will be available as PowerPoint files with auditory and video recordings, and will include the discussion.  By publishing the proceedings as a web-site with streaming media, the information will be disseminated much sooner than would be the case with a published volume.  The talks will also then be available for instructional purposes to everyone. <br/>   The invited participants include most of the investigators who have made the study of face perception a scientific endeavor.  The symposium is both broad in terms of the number of disciplines that are represented, but is also focused on a specific domain of inquiry.  Recent advances in computational models for artificial intelligence systems that can recognize face identity and interpret face action can potentially be integrated with functional neuroimaging and social cognitive investigations of face perception.  Conversely, better understanding of how face perception is implemented in the human brain can provide new ideas that could be incorporated in a computational system.   Better understanding of neural and computational systems may provide new insights for investigating social cognition and disorders of social cognition. Bringing investigators from various disciplines together in this symposium should provide a forum to transfer information among these disciplines and opportunities for establishing new collaborative relationships. <br/>   This symposium will provide a multidisciplinary synthesis of state-of-the-art knowledge about computational and neural systems for representing and interpreting faces.  Fostering new collaborative relationships will advance the field in all of the disciplines represented at the meeting.  The inclusion of students and fellows will help to educate the next generation of investigators in this area.  In addition, we will encourage graduate students at Princeton University who have an interest in face perception to attend the symposium and present posters on their research."
1747486,Real-world language: Future directions in the science of communication and the communication of science,BCS,"PERCEPTION, ACTION & COGNITION",9/15/2017,7/17/2017,James Magnuson,"Magnuson, J","Magnuson, J",CT,University of Connecticut,Standard Grant,Betty H. Tuller,2/28/2019,"$20,943.00 ",,james.magnuson@uconn.edu,438 Whitney Road Ext.,Storrs,CT,62691133,8604863622,SBE,7252,"7252, 7556",$0.00 ,exceptionalFunding,"This award will support the organization of a two-day workshop on future challenges in language science, with integrated discussion of science communication (making language science research accessible to specialist peers, scientists in other fields, and the general public). The workshop will take place in Madison, WI, immediately following the 2018 Cognitive Science Society annual meeting. Language science is an interdisciplinary area drawing on theories and methods from linguistics, cognitive psychology, developmental psychology, and artificial intelligence, among other fields. The primary goal is basic scientific understanding of the human capacity for language and potential longer-term impact on technology, education, and health.???<br/><br/>Invited speakers will 1) provide critical reviews of different theoretical perspectives, methodological approaches, and tools (such as eye tracking, electroencephalography, or functional magnetic resonance imaging); 2) focus on near- and long-term challenges facing language science; or 3) focus on science communication and education. In an effort to spark discussion and collaboration,  research interest groups will be formed that will hold videoconference meetings in Fall, 2018. Plans include strategies for promoting student participation and inclusion of women and members of under-represented groups."
1125978,AAAI/SIGART 2011 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,7/1/2011,2/28/2011,Bradley Clement,"Clement, B","Clement, B|Sklar, E",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,6/30/2012,"$20,340.00 ",Elizabeth Sklar,bclement@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00 ,exceptionalFunding,"This award supports participation of doctoral students in the Doctoral Consortium of the 25th AAAI Conference on Artificial Intelligence (AAAI-11) to be held on August 7-11, 2011 in San Francisco, CA. The Doctoral Consortium (DC) will be held on August 7-8. This award supports travel stipends for 13 US student participants and one-on-one mentoring lunches, a group dinner, and a poster session for all participants. The Doctoral Consortium will extend over two days and will include participant presentations, panel discussions, feedback to the participants from mentors, informal discussions (over lunch and during breaks), a group dinner for students and mentors, and a poster session. Each participant will give a 20-minute presentation that will be followed by 20 minutes of discussion led by an assigned mentor to provide feedback on the research and the presentation itself. To help the participants make the transition from being students to embarking on a research career, there will be a presentation on guidelines for developing a successful research program. In addition, there will be panel discussions addressing issues such as research strategies, job search, publishing, and establishing research funding."
353204,CAREER: Mathematical Foundations of Computer Graphics,CCF,"NUMERIC, SYMBOLIC & GEO COMPUT",3/1/2004,8/15/2005,James Arvo,"Arvo, J","Arvo, J",CA,University of California-Irvine,Continuing grant,Robert B Grafton,8/31/2005,"$20,212.00 ",,arvo@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,2865,"1045, 9216, HPCC",$0.00 ,exceptionalFunding,"The objective of this research is to strengthen the theoretical foundations of computer graphics by carefully formulating its mathematical underpinnings, applying formal methods of computer science, and exploring fundamental connections with other disciplines. The work plan is organized into four categories: 1) mathematical underpinnings, 2) numerical methods, 3) computational complexity, and 4) formal methods. Within each category several specific projects are described.<br/>Work done under this grant will depart from previous work in both the tools applied and in the areas investigated. Among the novel tools to be applied are mathematical methods from functional analysis (e.g. measure theory), information-based complexity (e.g. radius of information), and formal <br/>methods of computer science (e.g. refinement calculus); these tools will be applied to fundamental problems of computer graphics, such as deriving and clarifying radiometric principles, placing a priori limits on the accuracy of image-based rendering, and differentiating images of non-Lambertian scenes. These projects are firmly rooted in previous work performed by the author.<br/><br/>Among the novel areas to be investigated are proving the correctness of rendering algorithms, ""inverting"" rendering algorithms in response to user queries, and formalizing the use of default assumptions, ambiguity, and contradiction in human-computer interaction. The fundamental educational objectives of this work are to infuse computer graphics with appropriate mathematical structure, to train future graphics researchers in the art of constructing rigorous proofs and formally verifiable algorithms, and to integrate the tools and fundamental concepts of computer graphics into the core computer science curriculum. These goals cannot be attained through the introduction of a single course, but will instead require exposing students to the necessary concepts at many levels. Toward this end, elements of computer graphics will be introduced into an existing sophomore-level course on the theory of computation, and an advanced graduate-level course will be devised that explores the interplay of computer graphics, human-computer interaction, and artificial intelligence, while emphasizing the role of mathematical abstraction and formal verification."
946632,Travel Support for 2009 IJCAI Robotics Workshop and Exhibition,IIS,ROBUST INTELLIGENCE,9/1/2009,8/31/2009,Ayanna Howard,"Howard, A","Howard, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Thomas C. Henderson,8/31/2010,"$20,000.00 ",,ah260@gatech.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"0000, 7495, OTHR",$0.00 ,exceptionalFunding,"In 2005, the NSF hosted ?Robots: An Exhibition of U.S. Automatons from the Leading Edge of Research?, which was the result of a 2-year comprehensive study assessing robotics programs in the U.S., Asia, and Europe. The subsequent report concluded that America is in danger of losing its leading position in robotics. Arguably, the U.S. remains the world leader in artificial intelligence (AI) and machine learning research. Such research is critical to advancing the cognition that robots need to interact with people and manipulate objects in unstructured environments. This need for machine cognition thus provides American roboticists with opportunities to fill critical gaps and both vertically advance and lead the field. The annual IJCAI event (International Joint Conference on Artificial Intelligence) is a venue that can bring American and International roboticists and AI experts together. For over a decade-and-a-half, the IJCAI has held the Robotics Workshop and Exhibition as part of the overall conference. Such a venue provides a unique opportunity for the community to formulate roadmaps that leverage and apply America?s strengths in artificial intelligence to robotics. Towards this, the 2009 IJCAI Robotics Exhibition and Workshop (Pasadena CA July 13-17, 2009) will emphasize the use of robotics outside of academia by creating a joint forum with the commercial and amateur sectors.<br/><br/>Intellectual Merit: The workshop ?Beyond Academia: Exploring the Lessons and Best Practices in Commercial and Amateur Robotics? focuses on sharing the needs and expectations of robotics from all communities.  Speakers from Willow Garage, iRobot and the amateur robotics publication Make Magazine will offer unique perspectives and approaches to common challenges from the perspective of repeatability, measurement and situated deployment.  The cross-pollination of these ideas and experiences is crucial to the successful integration of AI into robotics. The ultimate goal of the workshop is to generate a white paper describing joint research opportunities. This has intellectual merit because both the AI and robotics communities are at a crossroads regarding how to best move robotics forward toward algorithms and experimental approaches that produce repeatable results in unstructured environments.  The exhibition consists of four themes that relate to subsequent robotics challenges: 1) multirobot teaming, 2) learning by demonstration, 3) manipulation, and 4) undergraduate robotics challenges.  Each of these areas has been identified as focus areas for the integration of AI and robotics by previous NSF supported workshops.<br/>Broader Impact: Complementing the workshop discussions and panel will be a significant number of hands-on exhibits. Here, research teams will showcase working demonstrations that support the challenge themes of learning, teaming and manipulation. Exhibits will be on display for 2 full days during the general IJCAI Conference, providing an excellent opportunity to engage a broad technical audience. The exhibits will also be open to the general public to raise awareness of the state-of-the-art. Students from local schools and summer camps will be invited to visit.  In previous years, the exhibition attracted local school groups that attended via a day field trip.  Access to the exhibits provides an opportunity for students and leaders to learn how robotics and AI play important roles in society.<br/>"
1138158,Student Travel Support for the 15th International Conference in Artificial Intelligence in Education (AIED 2011),IIS,Cyberlearn & Future Learn Tech,6/1/2011,5/25/2011,Gautam Biswas,"Biswas, G","Biswas, G",TN,Vanderbilt University,Standard Grant,Janet L. Kolodner,5/31/2012,"$20,000.00 ",,gautam.biswas@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,8020,"7556, 8045, 9150",$0.00 ,exceptionalFunding,"This proposal seeks funding to support the travel of advanced doctoral students so that they can participate in the 15th International Conference in Artificial Intelligence in Education and in the Young Researchers Track (YRT) that is part of that conference. The Young Researchers Track provides a forum for Ph.D. students to present and discuss their work with mentors from outside of their home institutions and to meet peers with similar interests. Mentoring happens in two ways -- as part of the Young Researchers Track, where they will be encouraged and offered feedback by three mentors, and through an individual mentoring program where each doctoral student will be matched with a mentor with expertise in the student's research area. Mentors will be senior AI and ED researchers.<br/><br/>Participants in the Young Researchers Track are members of the next generation of cyberlearning researchers. Participation in the proposed program will supplement their education at their home institutions and help prepare them to be leaders in transforming education through the use of learning technologies."
1741706,Support for Doctoral Students from U.S. Universities to Attend AIED 2017 and/or  EDM 2017,IIS,"Core R&D Programs, Cyberlearn & Future Learn Tech",6/1/2017,5/19/2017,Erin Walker,"Walker, E","Walker, E",AZ,Arizona State University,Standard Grant,Amy Baylor,11/30/2018,"$20,000.00 ",,Erin.A.Walker@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,"7980, 8020","7556, 8045, 8083",$0.00 ,exceptionalFunding,"The United States has historically been the global leader in the field of artificial intelligence in education (AIED), or ways to use computerized artificial intelligence to enhance teaching and learning in contexts ranging from children learning math in school, to soldiers learning highly technical jobs in the US military. The preeminent conference in this field is the AIED conference; at this conference the latest research is presented and practitioners learn the state of the art techniques that allow creation of these important educational technologies. A related conference that is equally significant is the Educational Data Mining (EDM) conference, which focuses on research on big data and analytics for education.<br/><br/>This proposal would provide partial travel support for 20 Ph.D. students, selected through a competitive process, to attend either or both of the AIED or EDM conference, present their work, and receive additional mentoring outside of their dissertation committees as part of a doctoral consortium. The intellectual merit of the work rests on the studies the graduate students submit to be considered for participation in the early career track of the conference; this work is then enhanced by guidance from world-class mentors who meet with the students in a structured format to improve their research. The broader impact includes the career impact on the twenty selected students, especially since promising graduate students whose advisors may not have funding to send them to the conference can still be included, and their work can be showcased and improved. Possible long-term broader impacts include building the field of artificial intelligence in education and data analytics researchers and thus eventually, improving the quality of education."
1640830,Support for Young Researchers to attend the  2016 Intelligent Tutoring Systems Conference,IIS,Cyberlearn & Future Learn Tech,6/1/2016,7/6/2016,Beverly Woolf,"Woolf, B","Woolf, B",MA,University of Massachusetts Amherst,Standard Grant,Tatiana D. Korelsky,5/31/2019,"$20,000.00 ",,bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,8020,"7556, 8045",$0.00 ,exceptionalFunding,"The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning CAP projects build capacity for research and development in the field of Cyberlearning by improving technical infrastructure, human capital, and in other ways. The Intelligent Tutoring Systems (ITS) 2016 conference offers a rare professional opportunity for interdisciplinary students to converge and present cutting-edge research from the fields of artificial intelligence (AI), learning science, computer science, cognitive and learning sciences, psychology, and educational technology. <br/><br/>This project supports travel for selected advanced graduate students to attend the doctoral consortium at the ITS 2016 conference in Croatia.  The conference has a special Young Research Track within the main conference for advanced graduate students. In this track a special session supports students to share their research with papers, posters, tutorials, workshops, and informal interactions with accomplished researchers. Students present their research ideas and receive feedback from researchers in the ITS community. An important goal of the doctoral consortium is to build the new generation of researchers in the forward-looking technical area of intelligent tutoring systems."
1238095,CAP: Support for Young Researchers to attend the International Intelligent Tutoring Systems Conference 2012,IIS,Cyberlearn & Future Learn Tech,6/15/2012,6/7/2012,Beverly Woolf,"Woolf, B","Woolf, B",MA,University of Massachusetts Amherst,Standard Grant,Lee L. Zia,11/30/2013,"$20,000.00 ",,bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,8020,"7556, 8045, 8055",$0.00 ,exceptionalFunding,"The International Conference on Intelligent Tutoring Systems (ITS) provides a forum for interchange of ideas around the applications of computer science to education and human learning. Presentations at the conference focus on developments and rigorous research around the design and use of interactive and adaptive learning technologies for learners of all ages, for subject matters that span the school curriculum, and for professional applications in industry, the military, and medicine. The conferences promotes cross-fertilization of information and ideas from several cyberlearning related fields: artificial intelligence, cognitive science, education, learning sciences, human-computer interaction, educational technology, psychology, and STEM disciplines.<br/><br/>This project will support travel for advanced graduate students from US universities to attend the 11th International Conference on Intelligent Tutoring Systems (ITS), to be held in Chania, Crete, in Greece, from June 15 to 18, 2012 (http://its2012.teicrete.gr). Those advanced graduate students will participate in the Young Research Track at the conference. That track is designed to provide young researchers with mentoring beyond what they get at their home institutions that will help them transition from graduate school to a fruitful research career. Young Researcher activities include structured poster sessions in which students present their work and one-on-one mentoring throughout the conference from a senior member of the ITS community who shares research interests with a young researcher and who comes from a different university and has a different approach than the young researcher experiences in his/her home institution. It is expected that conversations between peers and between mentors and mentees will continue throughout each young researcher's career. <br/><br/>This activity supports the mission of NSF to train more advanced professionals in Science, Technology, Engineering, and Mathematics. This conference is unique in its synthesis and cross-fertilization across three STEM capacities: building cutting-edge learning technologies, investigating pedagogical methods that are theoretically grounded in the cognitive, social, and learning sciences, and rigorously testing the learning environments for their effectiveness at promoting learning (in STEM disciplines and other disciplines) among K-12, college, and workplace populations."
840358,Robotics and Creativity Workshop (Part of AAAI 2008),IIS,"ROBUST INTELLIGENCE, CreativeIT",9/1/2008,8/18/2008,Youngmoo Kim,"Kim, Y","Kim, Y",PA,Drexel University,Standard Grant,Pamela L. Jennings,2/28/2009,"$20,000.00 ",,ykim@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,"7495, 7788","7495, 7788, 9215, HPCC",$0.00 ,exceptionalFunding,"This workshop brings together topics of robotics and creativity in the context of the premier artificial intelligence conference in the United States. The annual AAAI Conference is a venue that brings together American roboticists and AI experts. For over a decade-and-a-half, the AAAI has held the Robotics Workshop and Exhibition as part of the overall Conference. This established venue provides a unique opportunity for the community to formulate roadmaps that leverage and apply America?s strengths in artificial intelligence to robotics. The 2008 AAAI  Robotics Exhibition and Workshop (Chicago July 13-17, 2008) emphasizes multi-disciplinary research in the area of ?Robotics and Creativity?, which will provide novel opportunities to establish new paradigms merging AI and robotics. The workshop will emphasize research in which robots display creativity as well as cases where creativity is combined with design and engineering to stimulate robotics research at a variety of educational levels. A focus on creativity can lead to new paradigms for robotics research. A tangible output of the workshop is a White Paper describing a research roadmap for the community."
1259780,"The 17th International Conference on Cognitive and Neural Systems (ICCNS), - May-June, 2013 - Boston, MA",BCS,"DECISION RISK & MANAGEMENT SCI, COGNEURO, PERCEPTION, ACTION & COGNITION",2/1/2013,1/31/2013,Stephen Grossberg,"Grossberg, S","Grossberg, S",MA,Trustees of Boston University,Standard Grant,Betty H. Tuller,1/31/2014,"$20,000.00 ",,steve@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,SBE,"1321, 1699, 7252",7556,$0.00 ,exceptionalFunding,"Major themes of the International Conference on Cognitive and Neural Systems (ICCNS) are: How does the brain control behavior? How can technology emulate biological intelligence? The conference is aimed at researchers and students in experimental and theoretical cognitive science and neuroscience, neural networks, computer science, neuromorphic engineering, artificial intelligence, mathematics, and physics. It includes invited lectures by distinguished scientists and engineers (with good representation of female scholars), and contributed lectures and posters by students and experts on the biology and technology of how the brain and other intelligent systems adapt to a changing world. There is an emphasis on enabling young scientists and students to present their work."
1745535,Student Travel Support for 2017 Workshop for Women and Underrepresented Minorities in NLP,IIS,ROBUST INTELLIGENCE,7/1/2017,6/21/2017,Marine Carpuat,"Carpuat, M","Carpuat, M",MD,University of Maryland College Park,Standard Grant,Tatiana D. Korelsky,6/30/2018,"$20,000.00 ",,marine@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing.  It also is one of the primary application areas for researchers in  machine learning and artificial intelligence.  The proceedings of its annual meeting provide the foundation of the field; it is the most cited and most respected publication in computational linguistics. Yet demographic representation within the authors and leaders in the ACL community is notably lop-sided. This project is to subsidize travel to the workshop for women and underrepresented minorities in NLP (WiNLP), which will be a part of the 2017 meeting of the ACL held in Vancouver, Canada  on July 30, 2017.  The workshop aims to highlight and foster the work by researchers of diverse backgrounds within the ACL community. This contributes to America's pool of researchers with the variety of backgrounds, experiences, interests and areas of expertise required for science and engineering to be successful and benefit broad segments of society.<br/> <br/>The WiNLP workshop provides a venue for women and underrepresented minorities to present their work, and to get feedback and advice from mentors who are senior researchers in the field. The workshop solicits submissions in the form of a 2-page extended abstract focusing on all areas of NLP. Accepted abstracts are presented either as a poster of a talk. The workshop will also include a mentoring sessions and invited talks by established researchers in the field. This enables women and underrepresented minorities to get feedback from the broad ACL community, to participate in that community, and for that community to become more aware of their work."
731741,2007 RoboCup International Symposium,IIS,ROBUST INTELLIGENCE,6/1/2007,4/4/2007,Tucker Balch,"Balch, T","Balch, T|Dellaert, F",GA,Georgia Tech Research Corporation,Standard Grant,Jie Yang,5/31/2008,"$20,000.00 ",Frank Dellaert,tucker@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7495,"9218, 7495, HPCC",$0.00 ,exceptionalFunding,"Title: 2007 RoboCup International Symposium<br/>PIs: Tucker Balch and Frank Dellaert<br/>Institution: Georgia Institute of Technology<br/><br/>The RoboCup International Symposium is the premier meeting for presentation and discussion of scientific advances in diverse areas inspired by the RoboCup Initiative, including: robot soccer, rescue robotics, and robots and people. The Symposium's scope encompasses research and education activities in the fields of computer vision, artificial intelligence, human robot interaction, multi-agent systems, robot mechanisms, and robot locomotion. The 11th annual RoboCup International Symposium will be held in conjunction with RoboCup 2007 in Atlanta, July 9-10, 2007.<br/><br/>Scientific Merit: The symposium offers an excellent opportunity to introduce new techniques to disciplines and people who have not been exposed to them before. The experimental, interactive and benchmark character of the RoboCup initiative creates an opportunity to present, learn and evaluate novel ideas and approaches across a variety of disciplines. If promising, these ideas are rapidly adopted and field-tested by a large (and still strongly growing) community.<br/>Finally, the introduction of RoboCup@Home in 2006 provides additional opportunity to expand the areas of discussion at the Symposium.<br/><br/>Broader Impact: RoboCup offers a significant opportunity to provide international impact in science and technology. RoboCup draws participants from over 20 countries. This year's event marks the first time that the event will be hosted entirely on a university campus and only the second time the event has been held in the United States. One impact in this case is the opportunity for introducing international students and faculty to a leading U.S. <br/>academic<br/>environment that will encourage them to pursue additional collaborations in the U.S.<br/><br/>URL: http://www.robocup-us.org/"
125538,"Student Travel for Robocup 2001 Conference ( Seattle, Washington)",IIS,"ROBOTICS, DIGITAL SOCIETY&TECHNOLOGIES",8/15/2001,8/27/2001,Manuela Veloso,"Veloso, M","Veloso, M",PA,Carnegie-Mellon University,Standard Grant,Junku Yuh,7/31/2002,"$20,000.00 ",,veloso@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"6840, 6850","9218, HPCC",$0.00 ,exceptionalFunding,"Carnegie-Mellon University  is hosting the ROBOCUP-2001: The Fifth International Symposium, Competitions, and Demonstrations, in Seattle, Washington in the Summer 2001.  The event is sponsored by the American Association for Artificial Intelligence (AAAI). The award will pay for the travel of 40 students, $500/person, to the ROBOCUP."
1132362,Workshop: International Conference on Computational Creativity: Broadening Participation,IIS,Cyber-Human Systems (CHS),5/1/2011,4/11/2011,Dan Ventura,"Ventura, D","Ventura, D",UT,Brigham Young University,Standard Grant,Ephraim P. Glinert,4/30/2013,"$20,000.00 ",,ventura@cs.byu.edu,A-285 ASB,Provo,UT,846021231,8014223360,CSE,7367,"7556, 9150",$0.00 ,exceptionalFunding,"Computational creativity is a young, highly interdisciplinary field incorporating insights and results from cognitive science, artificial intelligence, design, human computing interaction, mathematics, art and linguistics among others.  As a result, there is still a significant communication gap amongst contributors to the field.  The International Conference on Computational Creativity seeks to bridge this gap by creating a unified forum for discussion and exchange of ideas, and the workshop session is designed to foster broad participation and act as a forum for new participants in the conversation.  The award will facilitate this participation by providing travel support for participants that would like to join the conversations who will not present peer reviewed papers, but who would be benefited by exposure to established computational creativity researchers.  In addition, it will further this cooperation by funding mentoring activities that pair established researchers with workshop participants."
1308505,Doctoral Mentoring Consortium at the Twelfth International Conference on Autonomous Agents and Multi-Agent Systems,IIS,"INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS",5/15/2013,5/3/2013,Anita Raja,"Raja, A","Raja, A",NC,University of North Carolina at Charlotte,Standard Grant,Sylvia J. Spengler,4/30/2014,"$20,000.00 ",,araja@cooper.edu,9201 University City Boulevard,CHARLOTTE,NC,282230001,7046871888,CSE,"1640, 7364","1640, 7364, 7556",$0.00 ,exceptionalFunding,"This award supports the travel of US doctoral students to, and their participation in the Twelfth International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2013), and the doctoral consortium to be held in conjunction with it. <br/><br/>AAMAS is the premier international conference devoted to all aspects of agent technology and its applications in the World Wide Web, electronic commerce, digital libraries, search, personalization, etc. The Doctoral Consortium offers the students an opportunity to present their research and receive in-depth feedback from senior researchers. Students will benefit from attending the conference, with its rich technical program of contributed and invited research talks, complemented by focused workshops, tutorials and other events. <br/><br/>The student travel awards will help enrich the eduation and training of a diverse group of young researchers, including women and members of underrepresented groups, working in Artificial Intelligence in general, and Autonomous Agents and Multi-Agent Systems in particular."
1129177,AAAI 2011 Robotics Program,IIS,"ROBUST INTELLIGENCE, Cyber-Human Systems (CHS)",7/1/2011,3/29/2011,Andrea Thomaz,"Thomaz, A","Thomaz, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Richard Voyles,6/30/2012,"$20,000.00 ",,athomaz@ece.utexas.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,"7495, 7367","7367, 7495, 7556",$0.00 ,exceptionalFunding,"The 2011 AAAI Robotics Exhibition and Workshop (San Francisco, CA August 7-11, 2011) continues a focus on key research problems in manipulation and learning through challenges in: (1) humanoid robotics, (2) learning by demonstration, and (3) samll-scale manipulation (robot chess). The teams selected for each challenge define research problems and repeatable experiments in areas that drive autonomous assistance in both military and domestic needs. The workshop enhances the challenge goals by (1) creating awareness in the larger AI community of available software tools, and (2) crafts a roadmap for development platforms that are more accessible to the general computer science research community.<br/><br/>A significant number of hands-on exhibits complement the workshop discussions and panel. Here, research teams showcase working demonstrations that support the challenge themes of learning, teaming and manipulation. Exhibits are on display for 2 full days during the AAAI Conference, providing an excellent opportunity to engage a broad technical audience. The exhibits are open to the general public to raise awareness of the state-of-the-art in robotics. Students from local schools and summer camps visit. Access to the exhibits provides an opportunity for students and leaders to learn how robotics and AI play important roles in society."
1639630,Computational Challenges in Machine Learning,CCF,SPECIAL PROJECTS - CCF,7/1/2016,5/13/2016,Richard Karp,"Karp, R","Karp, R",CA,University of California-Berkeley,Standard Grant,Tracy J. Kimbrel,6/30/2017,"$20,000.00 ",,karp@cs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,CSE,2878,7926,$0.00 ,exceptionalFunding,"The goal of this workshop is to advance the algorithmic frontier of machine learning. Target areas include Bayesian statistics, in which many of the core algorithmic problems bear similarity to problems that have been studied intensively in the theoretical computer science community; and large-scale optimization, in which a host of interesting challenges arise at the interface of theory and practical deployment.<br/><br/>The workshop will bring together researchers in algorithms, statistics, mathematics and artificial intelligence. It will be open to all potential participants, and the workshop findings (including videotapes of presentations) will be distributed to the public for comments and engagement. The organizers  will encourage students to attend the workshop, and will actively recruit scientists from a diversity of backgrounds to contribute to a wide range of algorithmic topics."
1747455,Artificial Intelligence in Interactive Digital Entertainment 2017:   Travel Support for the Doctoral Mentoring Program and the Playable Experiences Track,IIS,Cyber-Human Systems (CHS),7/1/2017,7/5/2017,Brian Magerko,"Magerko, B","Magerko, B",GA,Georgia Tech Research Corporation,Standard Grant,Ephraim P. Glinert,1/31/2018,"$19,984.00 ",,brian.magerko@lmc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"AAAI's Artificial Intelligence in Interactive Digital Entertainment (AIIDE) is a yearly conference that brings together representatives from both academia and industry to present novel research and discuss interesting problems in the area of human-centered artificial intelligence and interactive media.  AIIDE 2017, the 13th conference in the series, will take place October 5-9 at the Snowbird Resort in Utah.  This is funding to provide scholarships to support participant travel for two tracks at the conference that both have the goal of strengthening and diversifying this growing research community: (1) the AIIDE doctoral mentoring program and (2) the AIIDE playable experiences track.  The organizers expect to have 10 students participating in the doctoral mentoring program, and 5 playable experiences showcased in the playable experiences track.  Artificial intelligence in digital entertainment is an inherently interdisciplinary research area, including artificial intelligence, human-computer interaction, psychology, digital media, and modeling/simulation, as well as humanities and the arts.  AIIDE serves an important role as an interface between AI and society, through its focus on digital entertainment and related applications.  The conference investigates not just how to make intelligent machines, but how to produce transformative technology that impacts engineers, designers, and authors on potentially large scale projects with broad cultural visibility.  The conference also endeavors to grow relationships between academic research and industrial practice.  More information about the conference is available online at https://sites.google.com/view/aiide2017/.  The AIIDE doctoral mentoring program and playable experiences tracks are crucial to the health and growth of the AIIDE community.  Supporting participants to attend enriches the conference experience for all attendees, not just those who receive travel scholarships.  By providing underrepresented students with mentoring opportunities early in their career, the doctoral mentoring program will serve to broaden the diversity of the whole AIIDE community (and the other communities it interacts with).  The playable experiences track also offers an opportunity to broaden participation in AIIDE.  By offering travel support to independent scholars, practitioners, and artists in communities that have greater diversity than core computer science/AI, it is possible to promote diversity by easing financial barriers to full participation in the community.  The organizers are committed to improving diversity; to these ends, they will be specifically be doing outreach to underrepresented groups, and they will also be limiting the number of accepted students to at most two per institution,<br/><br/>The AIIDE doctoral mentoring program will invite early-stage (ideally just before thesis proposal) students to receive feedback on their proposed research program. The purpose of the program is to foster connections between student peers at different institutions, establish faculty mentoring relationships that can lead to participation on committees (including thesis proposal committees), and provide other contacts that can help guide students early enough to have a large impact on the trajectory of their research.  The mentoring program begins with lunch on the first day, asking mentors and mentees to get to know each other before their presentations and give the mentees the opportunity to deepen their professional network during the conference.  During the doctoral consortium, students will each give brief presentations of their proposed thesis topic followed by conversation and questions with the mentors and conference attendees.  These presentations will serve as encouragement for interested attendees and mentors to provide 1-on-1 feedback at the poster session.  The committee will select students who are early in their career so that mentors have an opportunity to help shape the future of their research and so students may begin to build their professional network.  Mentors for the doctoral consortium will be invited based on the research areas of the accepted students, and will be selected from senior faculty and respected industry leaders in the field.  To facilitate external feedback, mentors will be selected from outside the student's thesis committee and institution.  After students are accepted to the cohort, DC co-chairs will ask them to provide more information about their professional goals in order to best match them with academic and/or industry mentors.  During the doctoral consortium, all mentors will be invited to the presentations and poster session to encourage discussion across research areas.<br/><br/>The AIIDE playable experiences track aims to integrate research and practice through showcasing innovative, AI-based games and interactive media.   This track aims to bring independent game developers, students, industry practitioners, and researchers together.  The track fosters discussion of applications of the AI research shown in the main conference towards designing new kinds of playable experiences, and encourages interdisciplinary collaboration between conference attendees and the broader interactive digital entertainment community; it consists of published short papers about the work, a panel with representation from each playable experience to discuss the role of AI in design, and a conference session where attendees are able to play the games and discuss the work 1-on-1 with participants.  The playable experiences track is especially valuable to students in the doctoral mentoring program who are interested in pursuing careers in industry, since designers and technologists who attend the playable experiences track can be excellent mentors.  For all students, especially in the early stages of their research, it is useful to see high-quality examples of how their research might be used in polished, complete games.  To ensure the health of this track, it is important that independent developers, artists, and practitioners outside of the traditional academic AI research community have the financial means to attend and show their work; often, those who are most qualified to submit work to the playable experiences track do not come from traditional computer science backgrounds, or do not have access to travel funds of their own."
1340163,Support for Doctoral Students from U.S. Universities to Attend the AIED 2013 and EDM 2013 Conferences,IIS,"INFORMATION TECHNOLOGY RESEARC, Cyberlearn & Future Learn Tech",7/1/2013,5/24/2013,Sidney D'Mello,"D'Mello, S","D'Mello, S",IN,University of Notre Dame,Standard Grant,Christopher Hoadley,6/30/2014,"$19,860.00 ",,sdmello@nd.edu,940 Grace Hall,NOTRE DAME,IN,465565708,5746317432,CSE,"1640, 8020","1640, 7556, 8045",$0.00 ,exceptionalFunding,"The International Conference on Artificial Intelligence and Education (AIED 2013; http://aied2013.memphis.edu) and the International Conference on Educational Data Mining (EDM 2013; http://edm2013.memphis.edu) provide professional opportunity for researchers from around the world to share results of cutting-edge research from the fields of artificial intelligence (AI), data mining, computer science, cognitive and learning sciences, psychology, and educational technology that focuses on the design and effective use of advanced learning technologies. AIED researchers aim to design new technologies and advance understanding of how to use those technologies and integrate them into learning environments so that their potential is fulfilled. EDM researchers focus on working towards better use of technology for collecting, analyzing, sharing, and managing data to shed light on learning, promoting learning, and designing learning environments. Researchers from both communities aspire to better understand how people learn with technology and how technology can be used productively to help people learn, through individual use and/or through collaborations mediated by technology. <br/><br/>This project supports travel for advanced graduate students from US universities to attend these two conferences, held in Memphis, Tennessee, AIED 2013 from July 6 to 8, 2013, and EDM 2013 from July 10 to 12, 2013. Participating graduate students join the Doctoral Consortium (DC) tracks of the two conferences and are paired with a senior member of the AIED or EDM community for one-on-one mentoring throughout the conferences. The DC tracks of the conferences and mentor pairing are designed to provide young researchers with mentoring beyond what they get at their home institutions to help them transition from graduate school to a fruitful research career. DC track activities include structured poster sessions where students present their work, meetings with peers who have related interests, and interactions with senior members of the field. Each young researcher's one-on-one mentor will be senior members of the AIED/EDM community who shares research interests with the young researcher and who comes from a different university and has a different approach than the young researcher experiences in his/her home institution. It is expected that conversations between peers and between mentors and mentees will continue throughout each young researcher's career.<br/><br/>This activity supports the mission of NSF to train more advanced professionals in science, technology, engineering, and mathematics. Attending conferences is expensive for graduate students; funding their travel allows them to present their work to the larger community, speak individually with leaders in the field, and receive both support and advice from both senior researchers and peers. The AIED conference is special in its synthesis and cross-fertilization across three STEM capacities: building cutting-edge learning technologies, investigating pedagogical methods that are theoretically grounded in the cognitive, social, and learning sciences, and rigorously testing the learning environments for their effectiveness at promoting learning (in STEM and other disciplines) among K-12, college, and workplace populations. The EDM conference is special in its focus on learning how to use data collected as learners interact with learning technologies to assess learner understanding and capabilities so as to personalize feedback and advice."
538927,Artificial Intelligence:  An Academic Genealogy,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2005,3/23/2006,Benjamin Kuipers,"Kuipers, B","Kuipers, B",TX,University of Texas at Austin,Standard Grant,Douglas H. Fisher,6/30/2007,"$19,850.00 ",,kuipers@umich.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,6856,"7495, 9218, 9237, HPCC",$0.00 ,exceptionalFunding,"One's doctoral advisor is one's academic parent. This relation defines an academic genealogy of researchers that describes the academic ancestors and descendents of a particular set of researchers. While many students have a single doctoral advisor, some have more than one, so the genealogy has a lattice structure that branches both forward and backward in time. This project will build an academic genealogy for the field of Artificial Intelligence (AI), a remarkably interdisciplinary field that draws on computer science, mathematics, electrical, control, and mechanical engineering, cognitive, perceptual, and developmental psychology, linguistics, and philosophy, among other fields. AI is made up of a highly diverse collection of intellectual threads, which can often be made clear through examination of intellectual heritage.<br/>.<br/>A landmark in the creation of the field of AI was a workshop held at Dartmouth College in the summer of 1956. A number of the attendees at that workshop became the founding researchers in AI and many of their students have gone on to become leaders in the field. Although some of the founders and early leaders of AI have died in recent years, we are fortunate that many are still alive and vigorously pursuing research. It is thus a propitious time to collect historical information from these AI pioneers.<br/><br/>Developing an academic genealogy of AI will be valuable and timely for the field. This project will provide a formal definition for the genealogy task, a representation for the data to be collected, criteria for starting points, and visualization methods. The resulting genealogical data will provide a useful resource for historians and social scientists studying the nature of science as well as the particulars of the field of AI. For instance, the student-advisor relation is an important special case of intellectual influence, and one that is approximated by the formal structure of the academic genealogy. This project will help reveal the human face of science to a wider audience and demonstrate the strength and limitations of the advisor-student relationship in the ongoing process of science. It will also help demonstrate how important new ideas enter a field ""from the side"", outside of the established links of the academic genealogy. <br/><br/>"
227845,Student Travel to the AAAI Robot Competition and Exhibition,CNS,WORKFORCE,9/15/2002,9/10/2002,Holly Yanco,"Yanco, H","Yanco, H",MA,University of Massachusetts Lowell Research Foundation,Standard Grant,Lawrence Burton,8/31/2003,"$19,755.00 ",,holly@cs.uml.edu,600 Suffolk Street,Lowell,MA,18543692,9789344723,CSE,1713,"9218, HPCC",$0.00 ,exceptionalFunding,"<br/>EIA - 0227845<br/>Yanco, H <br/>Univ of Massachusetts at Lowell <br/><br/>TITLE: Student Travel to the AAAI Robot Competition and Exhibition<br/><br/>This award provides support for fifteen students, with special efforts made to incorporate women and underrepresented minorities, to attend and participate in the AAAI Robot Competition and Exhibition at the National Conference on Artificial Intelligence (AAAI-2002) in Edmonton, Alberta.  This event brings together robotics researchers from colleges, universities and research laboratories to compete and to demonstrate cutting edge, state of the art research in this area.  Students attending benefit from observing demonstrations of the research, networking with students from other institutions with similar interests, presenting and discussing their own research, and through a significant mentoring program.  Every supported student will be expected to write a one or two page report on her or his experiences at the competition and exhibition.  These reports will be used in evaluating the success of the funded student participation in the event.<br/>"
1212384,Workshop: Support for Student Participation in the Intelligent User Interface 2012 Conference,IIS,Cyber-Human Systems (CHS),2/15/2012,2/9/2012,Sharon Oviatt,"Oviatt, S","Oviatt, S",WA,Incaa Designs,Standard Grant,Ephraim P. Glinert,7/31/2012,"$19,598.00 ",,oviatt@incaadesigns.org,11140 Wing Point Drive N.E.,Bainbridge Island,WA,981102976,2068423153,CSE,7367,"7556, 7367",$0.00 ,exceptionalFunding,"This is funding to provide financial support for 10 graduate students from universities in the United States (or who are U.S. citizens) to attend the 2012 International Conference on Intelligent User Interfaces (IUI 2012), to be held in Lisbon, Portugal, on February 15-17, 2012, as participants in the doctoral session, presenters in the main conference, and attendees at the conference for general training purposes. Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent and interactive user interfaces; they are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place. Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter. Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc. IUI 2012 will be the 15th conference in the series; topics of interest this year include: Intelligent interactive interfaces, systems, and devices; Ubiquitous interfaces; Smart environments and tools; Human-centered interfaces; Mobile interfaces; Multimodal interfaces; Pen-based interfaces; Spoken and natural language interfaces; Conversational interfaces; Affective and social interfaces; Tangible interfaces; Collaborative multi-user interfaces; Adaptive interfaces; Sensor-based interfaces; User modeling and interaction with novel interfaces and devices; Interfaces for personalization and recommender systems; Interfaces for plan-based systems; Interfaces that incorporate knowledge- or agent-based approaches; Help interfaces for complex tasks; Example- and demonstration-based interfaces; Interfaces for intelligent generation and presentation of information; Intelligent authoring systems; Synthesis of multimodal virtual characters and social robots; Interfaces for games and entertainment; for learning-based interactions and for health informatics; Empirical studies and evaluations of IUI interfaces; New approaches to designing Intelligent User Interfaces. More information about the conference is available at http://iuiconf.org/. <br/><br/>This year IUI is organizing a student Doctoral Consortium (workshop) for the first time to expand student attendance and training in this area (see: http://iuiconf.org/doctoral_consortium.html). The Doctoral Consortium will be held as a day-long event on February 14, 2012, immediately preceding the conference, and is designed to give students exposure to their research community, including an opportunity to present their work to and receive constructive feedback from their peers as well as senior scientist mentors in the field. The students' work will also be featured during the main conference in the poster session, where they will gain additional experience explaining their work to others in the field. It is essential that our current generation of students receive good quality training in intelligent interactive interfaces, since such interfaces will be key components of future interactive systems in a variety of domains; therefore, the doctoral consortium is designed to encourage Ph.D. students to start building a professional support network of peers and mentors. The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community. Priority will be given to funding students representing different institutions (no more than 2 from any given institution); women, minority students, the disabled, and veterans all will be encouraged to participate.<br/><br/>Broader Impacts: This funding will enable attendance at this conference by students who might otherwise be unable to do so for financial reasons. It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement. The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants. The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference."
9813354,Workshop on Automated Learning and Discovery,IIS,"INFORMATION & KNOWLEDGE MANAGE, ARTIFICIAL INTELL & COGNIT SCI",6/1/1998,6/18/1998,Sebastian Thrun,"Thrun, S","Thrun, S|Faloutsos, C|Wasserman, L|Mitchell, T",PA,Carnegie-Mellon University,Standard Grant,Ephraim P. Glinert,5/31/1999,"$19,545.00 ","Christos Faloutsos, Larry Wasserman, Tom Mitchell",thrun@stanford.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,"6855, 6856","9216, HPCC",$0.00 ,exceptionalFunding," This award provides partial support for a cluster of eight workshops centered around automated learning and decision making based on data. The meeting is held at Carnegie Mellon University on June 11-13, 1998. It covers scientific research at the intersection of statistics, computer science, artificial intelligence, databases, social sciences and language technologies. The aim of this meeting is to initiate a dialogue between these disciplines. By doing do, it seeks to attain two types of impacts. First, it aims to generate synergy between previously separated fields, to lead to new, cross-disciplinary research collaborations and new, unified research approaches. Second, it attempts to provide guidance to the scientific community by characterizing the state-of-the-art, pointing out possible overlaps, making people aware of research results in other fields, and identifying some of the most promising cross-disciplinary research directions. One of the results of this meeting will be a written report, which will be made available to NSF and the scientific community at large, by posting it on the Web, and by submitting it to a widely accessible magazine or journal."
1415879,WORKSHOP: Student Consortium at the 2014 ACM Conference on Intelligent User Interfaces,IIS,Cyber-Human Systems (CHS),12/15/2013,12/18/2013,Joyce Chai,"Chai, J","Chai, J",MI,Michigan State University,Standard Grant,Ephraim P. Glinert,2/29/2016,"$19,250.00 ",,jchai@cse.msu.edu,Office of Sponsored Programs,East Lansing,MI,488242600,5173555040,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to provide financial support for 10 graduate students (all from U. S. universities and working towards either their Master's degree or a Doctorate) to attend the 2014 International Conference on Intelligent User Interfaces (IUI 2014), to be held February 24-27 in Haifa, Israel, as participants in a special Student Consortium (workshop), as presenters in the main conference, and as attendees at the conference for general training purposes.  Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent and interactive user interfaces; they are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place.  Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter.  Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc.  IUI 2014 will be the 17th conference in the series; topics of interest this year include: intelligent interactive interfaces, systems, and devices; ubiquitous interfaces; smart environments and tools; human-centered interfaces; mobile interfaces; multimodal interfaces; pen-based interfaces; spoken and natural language interfaces; conversational interfaces; affective and social interfaces;  tangible interfaces; collaborative multi-user interfaces; adaptive interfaces; sensor-based interfaces; user modeling and interaction with novel interfaces and devices; interfaces for personalization and recommender systems; interfaces for plan-based systems; interfaces that incorporate knowledge- or agent-based approaches; help interfaces for complex tasks; example- and demonstration-based interfaces; interfaces for intelligent generation and presentation of information; intelligent authoring systems; synthesis of multimodal virtual characters and social robots; interfaces for games and entertainment; for learning-based interactions and for health informatics; empirical studies and evaluations of IUI interfaces; and new approaches to designing intelligent user interfaces.  More information about the conference is available online at http://iuiconf.org/. <br/><br/>The IUI 2014 Student Consortium will build on the success of the previous two such events.  The heart of the Consortium will be a full-day workshop on February 24, immediately preceding the conference, and will be structured to give student trainees exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of senior researchers.  Group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors.  The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field.  The IUI conference organizers will pay for audio-visual services, two coffee breaks, and space for accommodating attendees in the student session; no funds are requested for these items from NSF.<br/><br/>Broader Impacts:  This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons.  It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement.  The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants.  The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference.  The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community.  Women, minority students, the disabled, and veterans all will be encouraged to participate.  To further assure diversity, no more than one student will be accepted from any given institution."
1636932,I-Corps: Artificial Intelligence for Analysis Of Visual Art,IIP,I-Corps,9/1/2016,8/15/2016,Ahmed Elgammal,"Elgammal, A","Elgammal, A",NJ,Rutgers University New Brunswick,Standard Grant,Lydia Mcclure,10/31/2016,"$19,201.00 ",,elgammal@cs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,ENG,8023,,$0.00 ,exceptionalFunding,"This I-Corps project utilizes artificial intelligence (AI) principles to detect abnormalities in images - in particular, it focuses on ways to enable visual information extraction.<br/><br/>Large collections of art and other images exist in digitized form but there are few automated methods for processing and indexing this data. This project facilitates a wide range of applications from education to online markets because the technology focuses on automated analysis of art and other images based on algorithmic methodologies in artificial intelligence. For example, the project's computational models might facilitate indexing large-scale collections of art and extracting useful information from this massive visual data. In this context, knowledge can be useful to online and traditional galleries, collectors, educators, authenticators and others in making informed decision regarding artwork and artist.<br/><br/>While the AI techniques are applicable to a broad range of images, the I-Corps team initially developed prototype computational models for analyzing artworks based on the visual information extracted from paintings. The computational models enable the system to perform perceptual and cognition tasks on digitized art for classification of paintings. AI algorithm can be specialized or tuned and optimized for different domains of fine-art analysis. While initially focusing on customer discovery within artistic contexts, the technology has the potential to be applicable in many different contexts. The I-Corps experience will help the team to better understand the market scope."
1539739,Support for Doctoral Students to Attend International Conferences: Artificial Intelligence in Education (AIED 2015) and Educational Data Mining Society (EDM 2015),IIS,Cyberlearn & Future Learn Tech,5/1/2015,4/10/2015,Beverly Woolf,"Woolf, B","Woolf, B",MA,University of Massachusetts Amherst,Standard Grant,christopher hoadley,4/30/2016,"$18,500.00 ",,bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,8020,"7556, 8045",$0.00 ,exceptionalFunding,"The Cyberlearning and Future Learning Technologies Program funds efforts that support envisioning the future of learning technologies and advancing what we know about how people learn in technology-rich environments. Capacity-building (CAP) projects help build the capacity of the field to do high-quality, high-impact research on learning. This project supports the mission of NSF to train more advanced professionals in Science, Technology, Engineering, and Mathematics (STEM) by supporting doctoral students attendance at the International Conference on Artificial Intelligence in Education (AIED) and the 6th International Conference on Educational Data Mining (EDM) to be held in Madrid, Spain in June of 2015. <br/><br/>The intellectual merit of the grant rests on the quality of the research being presented at the conferences. Together, the conferences provide cross-fertilization of information and ideas from artificial intelligence, cognitive science, machine learning, education, learning sciences, educational technology, psychology, philosophy, sociology, anthropology, linguistics, and the many domain-specific areas for which cyberlearning systems are designed and built. The broader impact of the work rests in the inculcation of students into this field. Doctoral students will be selected from U.S. institutions. The criteria for selection include either having a paper accepted for one of the conferences and/or or submitting an strong rationale for what the student would learn at the conference. All students receiving support will be assigned a mentor. The selecting committee will strive to ensure that there is diversity of institutions, topics, disciplines, ethnicities, and gender in the cohort of awardees. Selected students will receive up to $1,000 to partially cover expenses."
9900485,U.S.-U.K. Cooperative Research:  Constructing Diagnostic Explanations Using Schema-Structured Bayesian Networks,OISE,WESTERN EUROPE PROGRAM,7/15/1999,7/8/1999,George Luger,"Luger, G","Luger, G",NM,University of New Mexico,Standard Grant,Rose Gombay,6/30/2002,"$18,400.00 ",,luger@cs.unm.edu,"1700 Lomas Blvd. NE, Suite 2200",Albuquerque,NM,871310001,5052774186,O/D,5980,"5946, 9215, HPCC",$0.00 ,exceptionalFunding,"9900485<br/>Luger<br/><br/>This three-year award supports US-UK collaborative research in knowledge and cognitive systems between George Luger of the University of New Mexico and Brendan McGonigle at the University of Edinburgh's Laboratory for Cognitive Neuroscience and Intelligent Systems.  Their research involves the development of probabilistic models of diagnostic reasoning and testing of new algorithms developed by the US investigator. Both groups are concerned with performance improvement of robots through error identification and failure recovery.  The investigators propose that iterative performance will improve by embedding abductive reasoning in the robot's environment.  <br/><br/>The US investigator brings to this collaboration expertise in schema-based abduction, a form of causal reasoning, which employs Bayesian Networks as the underlying representation.  This is complemented by the Edinburgh group's expertise in intelligent systems and takes advantage of learning experiments utilizing their NOMAD robot.  Collaboration with the Edinburgh group provides an opportunity to study the cognitive plausibility of the US investigator's proposed model of diagnostic reasoning.<br/>"
1523316,CAP: Doctoral Consortium for the 2015 Learning Analytics and Knowledge Conference,IIS,Cyberlearn & Future Learn Tech,4/1/2015,3/30/2015,Stephanie Teasley,"Teasley, S","Teasley, S",MI,University of Michigan Ann Arbor,Standard Grant,Tatiana D. Korelsky,3/31/2017,"$18,280.00 ",,steasley@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,8020,"7556, 8045, 8055",$0.00 ,exceptionalFunding,"Using data analytics has revolutionized many academic disciplines, such as Astrophysics and Biology. In addition, it has changed the commercial world and critical services like healthcare. The field of education research is also beginning this change. The Society for Learning Analytics Research (SoLAR) is a key player in effecting this change. This project will support a Doctoral Consortium at the SoLAR 2015 conference - the 5th Annual International Learning Analytics and Knowledge (LAK) Conference, to be held in Poughkeepsie, NY in March 2015. Participating in the consortium will prepare current doctoral students from the diverse research backgrounds that make up the interdisciplinary field of Learning Analytics (LA), including computer science, information science, psychology, communication, education, artificial intelligence, and cognitive science. It will also allow them to network with each other and with professors and practitioners who are currently engaged in learning analytics research and related work to ensure the continued development of this community. These activities are critical and timely. The upcoming generation of LA researchers will play a vital role in realizing the potential of using data to improve outcomes for elementary, secondary, and post-secondary students in learning, motivation, and perseverance.<br/><br/>Learning Analytics is an interdisciplinary field whose goal is to advance and apply knowledge about learning sciences and education to improve all aspects of learning. LA methods include data visualization, data mining, data science, and mixed methods approaches combining qualitative and quantitative methods (e.g., interviews and back-end, clickstream data analysis). Capacity building is a central concern within the LA community. SoLAR has historically addressed these needs, in part, through specialized workshops held in conjunction with the Society's major conference. The Doctoral Consortium workshops host PhD students who are grappling with their dissertation research. This grant provides travel support to US scholars selected through a competitive application process to participate in this event. They present their work for feedback both in the context of workshop, where they receive advice from a panel of expert mentors, and in a poster session in which they interact with the full conference audience. In addition, their work is published in the proceedings of the conference."
124241,"2001 SIGART/AAAI Doctoral Consortium to be held August 4-10, 2001,in Settle,Washington.",IIS,ARTIFICIAL INTELL & COGNIT SCI,8/15/2001,9/19/2001,Marie Bienkowski,"Bienkowski, M","Bienkowski, M",CA,SRI International,Standard Grant,William Bainbridge,7/31/2002,"$18,218.00 ",,marie.bienkowski@sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,CSE,6856,"9218, HPCC",$0.00 ,exceptionalFunding,"<br/><br/>WORKSHOP: 2001 SIGART / AAAI Doctoral Consortium<br/><br/><br/><br/>This is a standard award to support the 6th SIGART / AAAI Doctoral Consortium, to be held as a workshop during the 17th International Joint Conference on Artificial Intelligence (IJCAI'01), August 4-10 in Seattle.  The Doctoral Consortium will provide a unique opportunity for a group of PhD students to discuss and explore their research interests and career objectives together with a panel of established researchers.  The event is similar in spirit to that funded by NSF last year, and has once again attracted a diverse group of student participants who reflect a wide range of topic areas and methodologies within artificial intelligence, and who have settled on their thesis directions but who still have significant research left to do.  Selection was based on clarity and completeness of the submission packet, stage of research, advisor's letter, and other evidence of promise such as published papers or technical reports;  a complete list of the 14 participants' names and affiliations may be found at  http://www.acm.org/sigart/DCparticipants.html.  Abstracts of the participants' presentations will be published in the issue of SIGART ""Intelligence"" that follows the consortium. The request for NSF support is higher this year than last, because Microsoft corporation chose not to cosponsor the event this time.  Doctoral Consortium co-chairs are the PI and Marie desJardins, University of Maryland at Baltimore County;  the organizing committee also included Janyce M. Wiebe, University of Pittsburgh;  Mary P. Harper, Purdue University;  Vibhu O. Mittal, Just Research and CMU;  and Evangelos Milios, Dalhousie University.  Panelists for the 2-day event will include:  Robert St. Amant, North Carolina State University;  Maria Gini, University of Minnesota; Craig Knoblock, ISI & USC; Gerhard Lakemeyer, Aachen University of Technology; Evangelos Milios, Dalhousie University; Shlomo Zilberstein, University of Massachusetts at Amherst;  Stuart Shapiro, SUNY Buffalo;  Foster Provost, NYU;  and Rebecca Bruce, University of North Carolina at Asheville.<br/>"
1023246,Doctoral Consortium Travel Support: International Conference on Automated Planning and Scheduling,IIS,ROBUST INTELLIGENCE,5/1/2010,4/28/2010,Daniel Bryce,"Bryce, D","Bryce, D",UT,Utah State University,Standard Grant,Edwina L. Rissland,4/30/2011,"$18,000.00 ",,daniel.bryce@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,CSE,7495,7495,$0.00 ,exceptionalFunding,"This award gives travel, housing, and registration-cost support to selected doctoral students from U.S. universities for their participation in the Doctoral Consortium of the 20th International Conference on Automated Planning and Scheduling (ICAPS-10) held May 13 in Toronto, Canada. ICAPS is the premier conference for research in artificial intelligence planning and scheduling, with relevance to a wide variety of applications such as software engineering, manufacturing, transportation, and robotics. The ICAPS-10 Doctoral Consortium includes a poster session, where students present their research, and a mentoring program that pairs senior scientists with doctoral students."
1243409,ICML 2012 Workshop on Machine Learning for Clinical Data Analysis,IIS,INFO INTEGRATION & INFORMATICS,6/15/2012,6/7/2012,Milos Hauskrecht,"Hauskrecht, M","Hauskrecht, M",PA,University of Pittsburgh,Standard Grant,Sylvia J. Spengler,5/31/2013,"$18,000.00 ",,milos@cs.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,7364,"7364, 7556, 8018",$0.00 ,exceptionalFunding,"The wealth and variety of data generated in modern medical and health-care settings present tremendous research challenges as well as opportunities in artificial intelligence and machine learning. Extensive electronic medical records - with thousands of fields recording patient conditions, diagnostic tests, treatments, outcomes, as well as narrative about the patients and care delivery - provide an unprecedented source of information. Tapping into this data source can bring clues leading to improvements in a wide range of health-care applications, such as disease modeling and early detection, chronic disease management, and efficient design of clinical trials.<br/><br/>Intellectual Merit: The Workshop on Machine Learning for Clinical Data Analysis (http://sites.google.com/site/mlclinicaldata) will be held during the International Conference on Machine Learning (ICML), 2012, Edinburgh, Scotland on June 30-July 1, 2012. The workshop aims to bring together machine learning and informatics researchers interested in problems and applications in the clinical domain, with the goal of bridging the gap between the theory of machine learning and the needs of the health informatics applications. The award provides funds to cover the travel costs of invited speakers and graduate students. The Ph.D. student participants will be able to present their work, interact with their peers from other universities as well as hundreds of leading researchers in machine learning from around the world. In addition to attending the workshop, they will attend the technical sessions, plenary talks, and tutorials of their choice at the conference. The  invited speakers  will present talks covering state-of-the-art research as well as open machine learning research challenges in building predictive models from clinical data. The workshop aims to educate the machine learning research community regarding machine learning research opportunities and challenges in health care applications, especially in connection with recent electronic health record initiatives; identify new machine learning problems not previously addressed by the community; and help build a community of researchers who can advance machine learning informed by the challenges and opportunities presented by clinical data analytics. <br/><br/>Broader Impacts. Machine learning is playing an increasingly important role in many emerging data-rich sciences and application domains, such as bioinformatics, computational biology, health informatics, and security informatics. Participation in the workskshop and the ICML and COLT conferences will enrich the education and training of student researchers at early stages in their careers. The travel awards will help broaden the participation of women and members of underrepresented minority groups within the Machine Learning and Health Informatics research communities."
9972414,Robots for Teaching about Autonomous Agents,DUE,CCLI-ADAPTATION AND IMPLEMENTA,7/1/1999,4/27/1999,Susan Fox,"Fox, S","Fox, S",MN,Macalester College,Standard Grant,Andrew P. Bernat,6/30/2002,"$17,685.00 ",,fox@macalester.edu,1600 Grand Avenue,Saint Paul,MN,551051801,6516966000,EHR,7428,"9178, 7428, SMET",$0.00 ,exceptionalFunding,"The purpose of this project is to create a robotics laboratory to support undergraduate teaching and learning in artificial intelligence and to provide undergraduates with experience with autonomous agents in a real-world environment. The lab will be used in junior and senior level courses on artificial intelligence, as a one- to three-week module for introductory computer science courses, and to support student capstone or honors projects in Al.<br/><br/>Autonomous agents, computer systems that take action in the world without human intervention, are increasingly important in computer science. Current developments include software agents to search the Internet, filter news articles, or schedule meetings, and robot agents to explore Mars, navigate factory floors, or explore the ocean. Undergraduate students must learn about the issues involved in creating autonomous systems, such as planning, managing uncertainty, and interacting with other agents. Robots are an intuitive platform for this purpose. While robot tasks (e.g., ""avoid obstacles"") appear simple to students, autonomous agent issues arise naturally and immediately: the real world is complex and confusing.<br/><br/>The artificial intelligence courses will be primary focuses of this project. In these courses, students will study issues of autonomous agents through hands-on work with robots. Other aspects of Al will be framed around agent issues: planning, vision, knowledge representation, and scalability of algorithms. Students performing advanced individual work - independent research, honors projects, or capstone projects - will also have access to robots for studying advanced Al issues. Students in introductory courses will use the robots as an exciting test bed for studying program design. Further in the future, we anticipate extending its use to interdisciplinary seminars on cognitive science, and perhaps outreach to area youth. This project will foster an environment of experimentation and excitement about artificial intelligence and autonomous agents."
1231683,AAAI/SIGART 2012 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,3/15/2012,3/12/2012,Elizabeth Sklar,"Sklar, E","Sklar, E",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,2/28/2013,"$17,631.00 ",,elizabeth.sklar@kcl.ac.uk,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This award supports participation of U.S.-based doctoral students in the 16th SIGART/AAAI Doctoral Consortium to be held July 22-23, 2012 in Toronto, Ontario, Canada in conjunction with the Twenty-Sixth Conference on Artificial Intelligence (AAAI-12), to be held July 22-26. This award provides travel stipends for 12 student participants as well as mentoring lunches, a group dinner, and a poster session. The participants will be selected on the basis of a packet of submitted materials that include a summary of thesis research; a curriculum vitae; and a letter of recommendation from the Ph.D. advisor.<br/><br/>The Doctoral Consortium will extend over two days and will include participant presentations, panel discussions, feedback to participants from assigned mentors, informal discussions (over lunch and during breaks), a group dinner for students and mentors, and a poster session. Each participant will give a 20-minute presentation that will be followed by 20 minutes of discussion led by an assigned mentor to provide feedback on the research and the presentation itself. To help the participants make the transition from being graduate students to launching a successful research program, there will be two panel discussions on relevant career issues: a panel of researchers who have completed their Ph.D.s within the last 5 years will focus on how to finish a dissertation and conduct a job search; and a panel of senior researchers from academia and industry will focus on establishing research funding and presenting oneself during the job search process. In addition, there will be a third panel that will further address issues on research, careers, and funding. All of these activities are in furtherance of the overarching goal of supporting the emerging next generation of researchers. The activities planned for the Doctoral Consortium have significant Intellectual Merit in that they strengthen the scientific quality of the participants' doctoral dissertation projects and provide valuable exposure to additional perspectives on their work at a critical time in their research endeavors and professional development. The Doctoral Consortium has potential for significant Broader Impact by furthering the education of the next generation of scientists, broadening participation in Robust Intelligence research, for instance, by including those from at institutions without strong programs in this area, and by fostering energetic scholarship and collaboration throughout all sectors of the community."
1444754,19th Annual SIGART/AAAI Doctoral Consortium,IIS,ROBUST INTELLIGENCE,5/15/2014,5/9/2014,Matthew Taylor,"Taylor, M","Taylor, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Hector Munoz-Avila,4/30/2015,"$17,610.00 ",,taylorm@eecs.wsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"Support to student travel for select students participating in the 19th Annual SIGART/AAAI Doctoral Consortium.  AAAI (Association for the Advancement of Artificial Intelligence) is the major professional association for AI.  This year it holds its yearly conference in Quebec City, Canada, where this DC will also take place.  At the Doctoral Consortium (DC), PhD students who are pursuing work on AI-related topics present their proposed research and receive feedback from a panel of established researchers, as well as from other student participants.  This provides the students with invaluable exposure to outside perspectives on their work at a critical time in their research and also enables them to explore their career objectives.<br/><br/>The DC program includes interactive sessions for feedback on dissertation topics from authorities in the field, collaboration-building sessions, early career advice, and well-placed networking opportunities.  It is held this year in the venue of several important, co-located conferences: 28th AAAI Conference on Artificial Intelligence (AAAI-14), the 5th Symposium on Educational Advances in Artificial Intelligence (EAAI-14), and the 36th meeting of the Cognitive Science Society (CogSCI-14).  Participation in a doctoral mentoring opportunity such as this one raises the potential to bring in participants who might not have attended an AI conference out of lack of habit or resources. This is especially true for those at smaller institutions and those which have less developed AI programs. Engaging such participants has the potential to draw more talent into AI research, improve research ideas in their formative stage, and engender collaborations across the breadth of disciplines associated with intelligent systems.<br/><br/><br/>"
1452078,The 20th SIGART/AAAI Doctoral Consortium,IIS,ROBUST INTELLIGENCE,11/15/2014,11/17/2014,David Roberts,"Roberts, D","Roberts, D",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Hector Munoz-Avila,10/31/2015,"$17,610.00 ",,robertsd@csc.ncsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The AAAI Doctoral Consortium (DC) brings together established researchers and mid-career Ph.D. students for a two-day workshop where students and faculty interact in a range of settings to provide both formal and informal career and research mentoring. As a means of encouraging young and upcoming researchers in Artificial Intelligence, the AAAI Doctoral Consortium has been proven to be a relatively inexpensive and extremely effective model. Many of the current reviewers, mentors, and panelists were once student participants.<br/><br/>The Intellectual Merit of the AAAI Doctoral Consortium lies in the unique opportunity for junior researchers to gain high quality feedback on academic and social issues relevant to their career, from senior researchers within their community. As part of the DC program, mentors and students interact in meetings, panels, working lunches, and during oral presentations and discussions. For many students, this is the only opportunity to receive focused input from researchers other than members of their dissertation committee. Students not only gain the experience of giving a talk on their thesis research and receiving specific feedback on their work, they also are given the opportunity to discuss more personal issues, such as balancing work and family. <br/><br/>The Broader Impacts of the AAAI DC are centered on bringing together a wide range of students at different stages of research, from different types of labs and universities and different regions across the US and around the world, alongside an equally diverse group of mentors and panelists. By interacting with established members of the Artificial Intelligence community, students also gain a better perspective of the AI community as a whole. The 2015 AAAI DC plans to reach out directly to more students within the AAAI community?not only to the few who are accepted to present their work, but also to the many early graduate students and undergraduate students who attend AAAI, by inviting these students to attend the panels. In doing so, the impact of the DC will extend beyond the directly-support participants by encouraging other students to interact with mentors, and hopefully apply to the DC in future years."
1611894,Twenty-First AAAI/SIGAI Doctoral Consortium,IIS,ROBUST INTELLIGENCE,1/1/2016,12/16/2015,David Roberts,"Roberts, D","Roberts, D",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Weng-keen Wong,6/30/2016,"$17,610.00 ",,robertsd@csc.ncsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The AAAI Doctoral Consortium (DC) brings together established researchers and mid-career Ph.D. students for a two-day workshop where students and faculty interact in a range of settings to provide both formal and informal career and research mentoring. As a means of encouraging young and upcoming researchers in Artificial Intelligence, the AAAI Doctoral Consortium has been proven to be a relatively inexpensive and extremely effective model. Many of the current reviewers, mentors, organizers, and panelists were once student participants in prior AAAI DCs.<br/><br/>The Intellectual Merit of the AAAI Doctoral Consortium lies in the unique opportunity for junior researchers to gain high quality feedback on academic and social issues relevant to their career, from senior researchers within their community. As part of the DC program, mentors and students interact in meetings, panels, working lunches, and during oral presentations and discussions. For many students, this is the only opportunity to receive focused input from researchers other than members of their dissertation committee at their home institution. Students not only gain the experience of giving a talk on their thesis research and receiving specific feedback on their work, they also are given the opportunity to discuss more personal issues, such as balancing work and family when pursuing a research career after completion of their Ph.D. studies."
237379,"Conference Support: North American Summer School in Logic, Language and Information at Indiana University",BCS,LINGUISTICS,8/15/2003,8/4/2003,Lawrence Moss,"Moss, L","Moss, L",IN,Indiana University,Standard Grant,Joan Maling,7/31/2004,"$17,590.00 ",,lmoss@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,SBE,1311,"0000, OTHR",$0.00 ,exceptionalFunding,"The National Science Foundation supports the North American Summer School in Logic, Language, and Information (NASSLLI), to be held at Indiana University, June 17-21, 2003. The summer school features 12 courses. The instructors are prominent junior and senior researchers from the US and Europe. NASSLLI was held for the first time at Stanford University in 2002; a sister school, the European Summer School in Logic, Language and Information (ESSLLI) is held annually. The overall areas of the school are some of the more technically sophisticated areas of linguistics, artificial intelligence, cognitive science, and related fields. At the same time, the ESSLLI and NASSLLI schools teach applied areas of logic. In short, they are mainly concerned with cutting edge subjects that are both technically demanding and in a broad sense applied.<br/><br/>The target audience for NASSLLI is graduate students, recent PhDs, and established researchers in the relevant fields. Some of the courses are for beginners, and others are for more specialized audiences. In most cases, the courses go beyond standard topics. Usually they concern topics that are only taught at a few institutions. So the summer school experience is formative for many young people. This will contribute to NASSLLI's becoming a prominent institution in the areas of computational linguistics, formal syntax and semantics, logic, and related areas of computer science. NASSLLI 2003 will attract 90-100 participants. In addition to the main courses, the school also features a session of student papers and evening lectures directed at everyone in the university community.<br/>"
1600043,Robotics Activities at Association for the Advancement of Artificial Intelligence (AAAI) 2016,IIS,ROBUST INTELLIGENCE,2/1/2016,11/18/2015,George Konidaris,"Konidaris, G","Konidaris, G",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Weng-keen Wong,7/31/2016,"$17,500.00 ",,gdk@cs.duke.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"Over the last few years, the AI and Robotics communities have begun to realize that the proliferation of relatively cheap but sophisticated robot hardware, and the development of robust and reliable robotics techniques for performing low-level control and perception. These developments have created a demand for integrative AI and robotics research to fulfill the potential of today's robots. The project aims at fostering cross-fertilization between these research fields through a series of activities at the AAAI-16 conference that will be held in Phoenix, Arizona from February 12th to 17th, 2016.<br/><br/>The project will include the following activities at the AAAI-16 conference: (1) participation of PhD students interested in integrative AI and Robotics research, (2) presentations by researchers showcasing current problems and solutions in robotics research, (3) a ""spotlight"" presentation by a young researcher showcasing new and exciting research in the field of robotics, (4) a robotics exhibition, and (5) an open house day, open for the general public."
1127650,EAAI-11: The Second Symposium on Educational Advances in Artificial Intelligence,IIS,ROBUST INTELLIGENCE,3/1/2011,2/16/2011,Kiri Wagstaff,"Wagstaff, K","Wagstaff, K|desJardins, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,2/29/2012,"$17,000.00 ",Marie desJardins,Kiri.Wagstaff@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00 ,exceptionalFunding,"This award supports participants to EAAI-11, The Second Symposium on Educational Advances in Artificial Intelligence. EAAI-11 will be collocated with the Twenty-fifth AAAI Conference on Artificial Intelligence (AAAI-11), to be held August 7-11, in San Francisco. EAAI-11 provides a venue for researchers and educators to discuss pedagogical issues and share resources related to teaching artificial intelligence (AI) and using AI in education across a variety of curricular levels (K-12 through postgraduate training), with a natural emphasis on undergraduate and graduate teaching and learning. The EAAI symposium will seek and disseminate contributions, such as model assignments, syllabi, projects, and ready-to-adopt materials for teaching AI, address how to more effectively teach AI in multi-disciplinary contexts involving subjects like biology or economics, and how themes from AI can be used generally to enhance education and engagement of students in Computer Science and STEM disciplines. EAAI will include a session ""How AI and AI education can improve CS education and outreach."""
1025375,"EAAI-10: The First Symposium on Educational Advances in Artificial Intelligence; July 2010; Atlanta, Georgia",IIS,ROBUST INTELLIGENCE,5/15/2010,5/5/2010,Kiri Wagstaff,"Wagstaff, K","Wagstaff, K|Sahami, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,4/30/2011,"$17,000.00 ",Mehran Sahami,Kiri.Wagstaff@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00 ,exceptionalFunding,"This award supports participants to EAAI-10: The First Symposium on Educational Advances in Artificial Intelligence. EAAI-10 provides a venue for researchers and educators to discuss pedagogical issues and share resources related to teaching artificial intelligence (AI) and using AI in education across a variety of curricular levels (K-12 through postgraduate training), with a natural emphasis on undergraduate and graduate teaching and learning. The symposium will seek and disseminate contributions showing how to more effectively teach AI, as well as how themes from AI may be used to enhance education more broadly. Examples of this kind of broad AI impact include its use to motivate and inspire students in introductory computing courses or as a means for fostering computational thinking. We encourage the sharing of innovative educational approaches that convey or leverage AI and its many subfields, such as robotics, machine learning, natural language, and computer vision."
1231124,EAAI-12: The Third Symposium on Educational Advances in AI,IIS,ROBUST INTELLIGENCE,3/1/2012,2/29/2012,Matthew Taylor,"Taylor, M","Taylor, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,2/28/2013,"$17,000.00 ",,taylorm@eecs.wsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This award supports participants to EAAI-12, the Third Symposium on Educational Advances in Artificial Intelligence. EAAI-12 will be collocated with the Twenty-sixth AAAI Conference on Artificial Intelligence (AAAI-12), to be held July 22-26, 2012, in Toronto. EAAI will be held on July 23 and 24. The goals of EAAI-12 are to expand the educational relevance of and benefits to researchers, educators, graduate students, and all others who may be interested within the field of Artificial Intelligence (AI). <br/><br/>EAAI-12 provides a venue for researchers and educators to discuss pedagogical issues and share resources related to teaching AI and using AI in education across a variety of curricular levels (K-12 through postgraduate training), with a natural emphasis on undergraduate and graduate teaching and learning. Materials to be presented, discussed, and shared by participants include: model AI assignments with innovative ready-to-adopt materials; syllabi, project ideas and pedagogical strategies related to teaching AI; multi-disciplinary curricula highlighting the use of AI in other contexts (e.g., computational biology, cognitive science, computational economics, philosophy); and resources for teaching specific subareas or topics within AI (e.g., machine learning, game playing, natural language processing, robotics, computer vision). There will be  a keynote lecture discussing recent experience with on-line AI classes at Stanford University. The EAAI symposium will seek to make available contributions from the symposium. Intellectual Merit and Broader Impacts of EAAI-12 include enhancements to the teaching, learning, and understanding of AI, the fostering of stronger research in AI, and increased participation of talented researchers and teachers in AI and more widely those in Computer Science and STEM disciplines."
1241561,Symposium on Combinatorial Search - 2012,IIS,ROBUST INTELLIGENCE,6/15/2012,6/7/2012,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Standard Grant,Hector Munoz-Avila,5/31/2014,"$17,000.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This award supports participation of US-based graduate student researchers in the 2012 Symposium on Combinatorial Search (SoCS 2012) to be held July 19-21, 2012 in Niagara Falls, Canada, just prior to the Twenty-Sixth Conference on Artificial Intelligence (AAAI-12) to be held July 22-26 in Toronto. The funds will help defray the travel, lodging, and registration costs for 13 graduate students as well as two invited speakers. SoCS 2012 will bring together researchers in all aspects of heuristic search and combinatorial optimization and its use in a broad range of areas in AI including core topics of Robust Intelligence like robotics, planning, constraint programming, and in other areas of interest across IIS like bioinformatics. One of the oldest subareas of research in AI, search continues to grow. Its advances include real-time search, parallel search, search using external memory, methods for using inconsistent heuristics, etc. Today it is central to solving problems in areas as diverse as optimal alignment of DNA sequences and real-time navigation. A special focus of SoCS 2012 is path-planning, which is important in robotics and computational biology. SoCS 2012 will include a new grid-based path planning competition."
1340162,Support for 18th SIGART/AAAI Doctoral Consortium,IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",6/1/2013,5/15/2013,Ayanna Howard,"Howard, A","Howard, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,5/31/2014,"$16,994.00 ",,ah260@gatech.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,"1640, 7495",7556,$0.00 ,exceptionalFunding,"This grant provides travel support for selected students attending the 8th SIGART/AAAI Doctoral Consortium. AAAI (Association for the Advancement of Artificial Intelligence) is the major professional association for AI. At the Doctoral Consortium (DC), PhD students who are pursuing work on AI-related topics present their proposed research and receive feedback from a panel of established researchers, as well as from other student participants. This provides the students with invaluable exposure to outside perspectives on their work at a critical time in their research, and also enables them to explore their career objectives."
1036262,AAAI/SIGART 2010 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,7/1/2010,6/22/2010,Christopher Brooks,"Brooks, C","Brooks, C|Clement, B",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,6/30/2011,"$16,817.00 ",Bradley Clement,cbrooks@cs.usfca.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,,$0.00 ,exceptionalFunding,"This award supports participation of doctoral students in the Fourteenth SIGART/AAAI Doctoral Consortium to be held July 11-12, 2010 in Atlanta, Geargia in conjunction with the 2010 AAAI Conference on Artificial Intelligence. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; and (3) support a new generation of researchers. The Doctoral Consortium organizers strive to recruit and include students from underrepresented groups and smaller schools and schools with less established programs in artificial intelligence. Students will give presentations and participate in discussion; there are one-on-one meeting with a faculty mentor. There will also be opportunities to discuss career issues in both academic and other career pathways. A report on the Consortium will be published in the AI Magazine."
906798,2009 SIGART/AAAI Doctoral Consortium,IIS,ROBUST INTELLIGENCE,6/1/2009,5/19/2009,Scott Wallace,"Wallace, S","Wallace, S|Brooks, C",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Jie Yang,5/31/2010,"$16,815.00 ",Christopher Brooks,wallaces@wsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9215, HPCC",$0.00 ,exceptionalFunding,"This award supports participation of doctoral students in the Thirteenth  SIGART/AAAI Doctoral Consortium to be held July 12-13, 2009 in Pasadena, CA in conjunction with the 2009 International Joint Conference on Artificial Intelligence, July 11-17, 2009. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; and (3) support a new generation of researchers. The Doctoral Consortium organizers strive to recruit and include students from underrepresented groups (e.g., women and underrepresented minorities) and smaller schools and schools with less established programs in artificial intelligence. Each student gives a 25-minute presentation to be followed by 20 minutes of discussion; there are one-on-one meeting with a faculty mentor. There will also be opportunities to discuss career issues in both academic and other career pathways. A report on the Consortium will be published in the AI Magazine."
607406,2006 SIGART/AAAI Doctoral Consortium,IIS,ARTIFICIAL INTELL & COGNIT SCI,12/15/2005,12/19/2005,Kiri Wagstaff,"Wagstaff, K","Wagstaff, K",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Daniel F. DeMenthon,11/30/2006,"$16,750.00 ",,Kiri.Wagstaff@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"6856, 7495, 9218, HPCC",$0.00 ,exceptionalFunding,"This award supports participation of doctoral students from U.S. universities in the eleventh SIGART/AAAI Doctoral Consortium to be held July 16-17, 2006 in Boston, in conjunction with the 21th National Conference on Artificial Intelligence (AAAI-06), July 16-20, 2005. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; (3) support a new generation of researchers; and (4) contribute to the conference through interaction with other researchers at the conference. The Doctoral Consortium will strive to recruit and include students from underrepresented groups (e.g., women and underrepresented minorities) and smaller schools or schools with less established programs in artificial intelligence. Each student will give a 25-minute presentation to be followed by 20 minutes of discussion guided by a faculty participant; there were also be a one-on-one meeting with the faculty participant. There will also be opportunities to discuss career issues in both academic and other career pathways. In conjunction with the general conference's activities celebrating fifty years of AI, the committee plans to solicit participation of some of the very senior or founding members of the community in the Doctoral Consortium, for instance, by having them participate in a ""20/20 Perspective: What I Wish I'd Known in Graduate School"" panel. It is expected that thesis summaries of the participants will be published in the AI Magazine."
715239,RI: SIGART/AAAI Doctoral Consortium 2007,IIS,ROBUST INTELLIGENCE,3/15/2007,3/9/2007,Terran Lane,"Lane, T","Lane, T",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,2/29/2008,"$16,750.00 ",,terran@cs.unm.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9218, HPCC",$0.00 ,exceptionalFunding,"ABSTRACT<br/><br/>This award supports participation of doctoral students from U.S. universities in the eleventh SIGART/AAAI Doctoral Consortium to be held July 22 and 23, 2007 in Vancouver, B.C. in conjunction with the 22th National Conference on Artificial Intelligence (AAAI-07), July 22-26, 2007. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; (3) support a new generation of researchers; and (4) contribute to the conference through interaction with other researchers at the conference. The Doctoral Consortium strives to recruit and include students from underrepresented groups (e.g., women and underrepresented minorities) and smaller schools or schools with less established programs in artificial intelligence. Each student will give a 25-minute presentation to be followed by 20 minutes of discussion guided by a faculty participant; there were also be a one-on-one meeting with the faculty mentor. There will also be opportunities to discuss career issues in both academic and other career pathways. A report on the Consortium will be published in the AI Magazine."
1658493,Collaborative Research: Conference on Cognitive Computational Neuroscience (CCN),BCS,"COGNEURO, CRCNS",4/1/2017,3/30/2017,Alyson Fletcher,"Fletcher, A","Fletcher, A",CA,University of California-Los Angeles,Standard Grant,Uri Hasson,3/31/2018,"$16,560.00 ",,akfletcher@ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,SBE,"1699, 7327","1699, 7327, 7556, 8089, 8091, 9150",$0.00 ,exceptionalFunding,"Cognitive Computational Neuroscience (CCN) is an annual scientific meeting for neuroscientists characterizing the neural computations that underlie complex behavior. The goal is to develop computationally defined models of brain information processing that explain rich measurements of brain activity and behavior. Such models will ultimately have to perform feats of intelligence such as perception, internal modelling and memory of the environment, decision-making, planning, action, and motor control under naturalistic conditions. Historically, different disciplines have met subsets of these goals. Cognitive science has developed computational models at the cognitive level to explain aspects of complex behavior. Computational neuroscience has developed neurobiologically plausible computational models to explain neuronal responses to sensory stimuli and certain low-dimensional decision, memory, and control processes. Cognitive neuroscience has mapped a broad range of cognitive processes onto brain regions. Artificial intelligence has developed models that perform feats of intelligence. The community must now put the pieces of the puzzle together, and CCN is unique in its focus on the intersection between these fields. CCN is envisioned not only as an engine for advancing research, but as a vehicle for making broader impacts on education and society. As evidenced by the recent trend of major corporate acquisitions of AI startups founded by neuroscientists, biological inspiration for electronics and software development is a growing trend with significant economic implications. In its early stages, the broader impact focus of CCN will be on increasing the visibility of women and scientists from underrepresented populations via speaking opportunities and travel awards.  In addition, representation on women on the female fractions on the steering and advisory committees exceed those typical in relevant fields, without compromise in qualifications. Conferences will include hands-on tutorials, and materials from these will propagate to various university curricula.<br/><br/>A central goal of neuroscience is to understand how vast populations of neurons give rise to complex behavior. Today, advances in various domains offer tangible possibilities to make fundamental conceptual breakthroughs. From an experimental point of view, neural recording technologies, such as high-resolution fMRI, dense recording arrays, magnetoencephalography (MEG), and calcium imaging, now provide opportunities to observe neural activity at unprecedented resolution and scale. At the same time, research in cognitive science has become increasingly sophisticated in identifying computational principles that may serve as the basis for human cognition, and machine learning and artificial intelligence have made great strides in building models to autonomously solve complex cognitive tasks. However, interactions among these distinct disciplines remain rare. This new conference may stimulate unifying frameworks that fully realize the cross-disciplinary potential of these individual advances. In more concrete terms, the goal of CCN is to create and foster a community that will develop models of brain information processing with several key features. These models should (1) be fully computationally defined and implemented in computer simulations; (2) be neurobiologically plausible; (3) explain measurements of brain activity (and continue to do so as spatiotemporal resolution and scale improve); (4) explain behavior for naturalistic stimuli and tasks; and (5) perform feats of intelligence such as recognition, internal modelling and representation of the environment, decision-making, planning, action, and motor control. Such models currently do not exist and are unlikely to emerge without greatly improved cross-disciplinary engagement."
9513647,U.S.-Netherland Cooperative Research in Linquistics: Polyadic Quantification and Reciprocals,OISE,WESTERN EUROPE PROGRAM,4/1/1996,3/14/1996,Stanley Peters,"Peters, S","Peters, S",CA,Stanford University,Standard Grant,Mark A. Suskin,2/29/2000,"$16,400.00 ",,peters@csli.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,O/D,5980,"0000, 5948, OTHR",$0.00 ,exceptionalFunding,"This award supports Professor Stanley Peters and three junior members of his research group at Stanford University to collaborate in linguistics research with Professor Frank Veltman and others of the Institute for Language, Logic and Computation of the University of Amsterdam, The Netherlands. They are studying abstract aspects of information content and informational equivalence, centering on the concept of `reciprocals` (the expertise of the US group) and `polyadic quantifiers` the logical tools used to define reciprocals (which is the area of expertise of the Dutch group.) The Stanford group has undertaken a comparative study of the nature of the relation between syntactic representation and semantic interpretation, taking reciprocals as a case study. The Dutch group is part of a European consortium applying new understanding of the dynamic nature of information to the interpretation of natural language. Dynamic interpretation is becoming increasingly important, not only in linguistics, but also in computer science and artificial intelligence. This research provides US participants access to a larger regional European collaborative project named DYANA (`Dynamic Interpretation of Natural Language`) funded by the European Commission, which brings together some of the most important scholars in the foundations of language and information processing in Europe. This relatively focused U.S.-Dutch research collaboration is intended to be the starting point for a broader and longer-term collaboration in the future. Their mutual goal is to develop theories of information that can be applied in a variety of areas within the study of language and computation. The results of their research are likely to have far reaching implications, not only for the study of natural languages, but also for the analysis and design of computer languages."
1036017,The Fourth Northeast Student Colloquium on Artificial Intelligence,IIS,ROBUST INTELLIGENCE,5/15/2010,5/19/2010,Andrew McCallum,"McCallum, A","McCallum, A|Learned-Miller, E",MA,University of Massachusetts Amherst,Standard Grant,Sven G. Koenig,4/30/2011,"$16,181.00 ",Erik Learned-Miller,mccallum@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,7495,$0.00 ,exceptionalFunding,"This award will help to subsidize the participation of graduate students in the fourth Northeast Student Colloquium on Artificial Intelligence (NESCAI) to be held April 16-18, 2010 at the University of Massachusetts in Amherst. This conference is to include oral and poster presentations by students,invited talks by senior AI researchers, and student-run tutorials. The conference will be largely run by a program committee consisting of doctoral students under the guidance of senior faculty. The program committee will conduct a review process to select the projects chosen for oral and poster presentations. In addition to graduate students, the conference plans to encourage attendance by outstanding senior undergraduates through a special undergraduate track, in the hope that it will increase undergraduate enthusiasm for research and thus the likelihood that they will go on to graduate work. The project integrates research and education and commits to broadening diversity."
823735,2008 SIGART/AAAI Doctoral Consortium,IIS,ROBUST INTELLIGENCE,4/1/2008,4/30/2008,Colleen van Lent,"Lent, Cv","Lent, Cv|Wallace, S",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,3/31/2009,"$16,135.00 ",Scott Wallace,cvanlent@csulb.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9215, HPCC",$0.00 ,exceptionalFunding,"This award supports participation of doctoral students from U.S. universities in the 12th SIGART/AAAI Doctoral Consortium to be held July 13-14, 2008 in Chicago, IL in conjunction with the 23rd National Conference on Artificial Intelligence, July 13-17, 2008. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; and (3) support a new generation of researchers. The Doctoral Consortium organizers strive to recruit and include students from underrepresented groups (e.g., women and underrepresented minorities) and smaller schools and schools with less established programs in artificial intelligence. Each student gives a 25-minute presentation to be followed by 20 minutes of discussion; there are one-on-one meeting with a faculty mentor. There will also be opportunities to discuss career issues in both academic and other career pathways. A report on the Consortium will be published in the AI Magazine."
1733465,Association for the Advancement of Artificial Intelligence (AAAI)-2017 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,3/15/2017,3/10/2017,David Aha,"Aha, D","Aha, D",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,8/31/2017,"$16,074.00 ",,david.aha@nrl.navy.mil,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"Support for student travel for select students participating in the 22nd AAAI/SIGAI Doctoral Consortium (DC). AAAI (Association for the Advancement of Artificial Intelligence) is the major professional association for AI. This year it holds its yearly conference in San Francisco, CA, where this DC will also take place. At the Doctoral Consortium (DC), PhD students who are pursuing work on AI-related topics present their proposed research and receive feedback from a panel of established researchers, as well as from other student participants. This provides the students with invaluable exposure to outside perspectives on their work at a critical time in their research and also enables them to explore their career objectives.<br/><br/>The DC program includes interactive sessions for feedback on dissertation topics from authorities in the field, collaboration-building sessions, early career advice, and well-placed networking opportunities. Participation in a doctoral mentoring opportunity such as this broadens participation to those who might not have attended an AI conference out of lack of habit or resources. This is especially true for those at smaller institutions and those which have less developed AI programs. Engaging such participants has the potential to draw more talent into AI research, improve research ideas in their formative stage, and engender collaborations across the breadth of disciplines associated with intelligent systems."
832347,UAS Research Directions for the National Air Space,IIS,ROBUST INTELLIGENCE,5/1/2008,5/2/2008,Robin Murphy,"Murphy, R","Murphy, R|Argrow, B",FL,University of South Florida,Standard Grant,Paul Yu Oh,4/30/2009,"$16,000.00 ",Brian Argrow,murphy@cse.tamu.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,CSE,7495,"7495, 9215, HPCC",$0.00 ,exceptionalFunding,"This 1-day workshop will bring together key members of the FAA, NSF, DHS, and other agencies and invited leaders of the national science community in order to: i) identify new basic research directions for unmanned aerial systems (UAS) in areas such as artificial intelligence, computer vision, and human-robot interaction and catalog computational issues such as software verification and secure wireless communications that will allow safe operations in the NAS, ii) identify requirements for safe operations of UAS in the NAS and translate those needs into basic research objectives for academic research, and iii) clarify and identify new mechanisms to facilitate timely academic research, especially in small UAS. The workshop will involve the larger computational sciences into the UAS community and generate a statement of research needs for UAS operations specifically for the NAS. The close interaction of the FAA with the academic research community is expected to lead to safe operation of UAS in the NAS. A list of mechanisms or programs by which researchers can apply their research to UAS or FAA problems will be created and a statement of clarification of regulations and procedures for university researchers will be prepared."
1447570,Doctoral Consortium Support for the 2014 International Conference on Automated Planning and Scheduling,IIS,ROBUST INTELLIGENCE,8/15/2014,8/3/2014,Julie Shah,"Shah, J","Shah, J",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Jie Yang,7/31/2015,"$16,000.00 ",,arnoldj@mit.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This student travel grant supports graduate/undergraduate and young researchers to attend the 2014 International Conference on Automated Planning and Scheduling and to participate in the Doctoral Consortium (ICAPS-DC). The ICAPS DC is a primary method for broadening participation and improving retention of doctoral researchers in the field of automated planning and scheduling. The DC at ICAPS 2014 is the 12th occurrence of the event, and takes place in June 2014 in Portsmouth, NH, USA. This is the first ICAPS held in the US since 2007. Those receiving awards through the Support Fund are able to participate in events, including but not limited to the DC, where they can receive career and research advice from peers and mentors, present preliminary results and plans for their dissertations, and build professional relationships. To support career development, invited speakers present emerging research opportunities, discuss research skills and the process of transitioning to the workplace after graduation. The participation of Ph.D. students at ICAPS 2014 and the DC is be beneficial to both the students and the international planning community, and to ensure cross-fertilization among researchers in areas of planning, scheduling, robotics, operations research, combinatorial search, knowledge representation and reasoning, and applications."
1343507,Doctoral Consortium Support for ICAPS 2013,IIS,ROBUST INTELLIGENCE,7/1/2013,6/19/2013,Mark Boddy,"Boddy, M","Boddy, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Hector Munoz-Avila,6/30/2014,"$16,000.00 ",,mark.boddy@adventiumlabs.com,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This grant supports student participation in a doctoral mentoring consortium at the International Conference on Automated Planning and Scheduling (ICAPS). The ICAPS Doctoral Consortium (DC) is a primary method for broadening participation and improving retention of doctoral researchers in the field of automated planning and scheduling. This DC at ICAPS 2013, June 2013 in Rome, Italy, is the eleventh occurrence of the event.<br/>This symposium is carrying on a multiyear tradition of holding DCs and summer schools, providing an important venue to encourage students and junior researchers in automated planning and scheduling. Activities include research panel discussions, lunch with mentors, and poster session held as part of the main conference. The DC brings together a broader community of researchers in planning and scheduling, promoting integration with other areas of AI and computer science, and encouraging junior researchers with a more focused attention to this area than is otherwise possible in other venues. Of particular note is the potential to involve participants who might not have attended an AI conference before. This is especially true for those outside of the usual AI research community: those at smaller institutions who use AI in teaching but not in research; those from smaller/liberal arts institutions; and those from institutions that are poorly represented in STEM disciplines."
1519252,Support for the ICAPS-15 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,2/1/2015,1/28/2015,Sven Koenig,"Koenig, S","Koenig, S",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,1/31/2017,"$16,000.00 ",,skoenig@usc.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The proposal requests travel, housing funding and conference registration for US-based doctoral students selected to participate in the Doctoral Consortium (DC). The DC is co-located with The 25th International Conference on Automated Planning and Scheduling (ICAPS), which will be held in Jerusalem in May 4-8, 2015. ICAPS is the main international conference on automated planning. The ICAPS DC aims at broadening the participating of US-based PhD students into the planning area as well as improving the retention of these students. <br/>"
1229739,"Conference: Meeting: Molluscan Neuroscience in the Genomic Era: from Gastropods to Cephalopods, in Jupiter, FL on May 16 - 19, 2012",IOS,ACTIVATION,5/15/2012,5/14/2012,David Glanzman,"Glanzman, D","Glanzman, D",CA,University of California-Los Angeles,Standard Grant,David Coppola,4/30/2013,"$15,845.00 ",,dglanzman@physci.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,BIO,7713,"1096, 1228, 9179",$0.00 ,exceptionalFunding,"Historically, many of the most important advances in cellular neurobiology have been made studying mollusks, such as squid and snails, as model systems because mollusks have exceptionally large nerve cells. The giant nerve cells of squid enabled the analysis of the mechanism of the action potentials found in nerve cells and the mechanisms by which neurotransmitters, such as serotonin, are released at synapses. Snails, with their very large nerve cells and simple neural circuitry, have enabled major advances in our<br/>understanding of molecular mechanisms of learning and memory. Many key cellular and molecular discoveries in mollusks have proved generalizable to the brains of mammals, because these mechanisms have been conserved throughout evolution.<br/><br/>This meeting will bring together neurobiologists who work on two important molluscan groups, the simpler gastropods (e.g. snails) and the more complex cephalopods (e.g.squid and octopus) to freely discuss their latest findings. Octopus and squid represent advanced forms of intelligence that evolved entirely independently from vertebrates.  These distinct forms of intelligence have the potential for providing influential models for developing artificial intelligence and computer-controlled precise motion of artificial appendages.<br/><br/>The meeting will generate novel collaborations among attendees, particularly because this is a unique venue for discussions between leaders in gastropod and cephalopod neuroscience. Cellular, molecular and genomic advances in gastropods have the potential for greatly benefiting research in more complex cephalopods. Abstracts of talks will be available on an open website, along with new methodologies presented. This will accelerate the pace of research, leading to new discoveries that can provide insights into the basic functioning of the brain. Graduate students and postdoctoral fellows will present their research to senior scientists in the field, and interact with them at mentoring sessions, which will benefit their development as researchers."
957438,Collaborative Research: CI-ADDO-NEW: *-EXEC: A Cross-Community Solver Execution Service,CNS,COMPUTING RES INFRASTRUCTURE,5/1/2010,5/5/2010,Geoffrey Sutcliffe,"Sutcliffe, G","Sutcliffe, G",FL,University of Miami,Standard Grant,Edwina L. Rissland,4/30/2012,"$15,750.00 ",,geoff@cs.miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,CSE,7359,"9218, HPCC",$0.00 ,exceptionalFunding,"Ongoing breakthroughs in nationally important research areas like Verification and Artificial Intelligence depend on continuing advances in high-performance automated theorem proving tools. The typical use of these tools is as backends: application problems are translated by an application tool into (typically very large and complex) logic formulas, which are then handed off to a logic solver. Different tradeoffs between linguistic expressiveness and the difficulty of solving the resulting problems give rise to different logics. Solver communities, formed around these different logics, have developed their own community research infrastructures to encourage innovation and ease adoption of their solver technology. Such infrastructure includes standard formats for logic formulas, libraries of benchmark formulas, and regular solver competitions to spur solver advances. <br/><br/>Currently, these different infrastructures are all developed separately, at significant cost in equipment and support. These costs are paid again and again for the different services, since there is currently no global piece of computing infrastructure suitable for the logic solving domain, which all these communities can use. This project is building a simplified proof-of-concept of a single piece of shared computing infrastructure, which could eventually be used by many different logic solver communities. The award also provides other support for soliciting research community feedback on the prototype and the design of a comprehensive infrastructure."
1338936,Planning Grant: I/UCRC for Semantic Computing,CNS,INDUSTRY/UNIV COOP RES CENTERS,8/15/2013,8/9/2013,Phillip Sheu,"Sheu, P","Sheu, P",CA,University of California-Irvine,Standard Grant,Thyagarajan Nandagopal,7/31/2015,"$15,624.00 ",,,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,5761,"5761, 8039",$0.00 ,exceptionalFunding,"Semantic Computing (SC) is an emerging field that addresses computing technologies which allow users to search, create, manipulate and connect computational resources. The research efforts will be anchored by the University of California-Irvine as the lead institution, partnered with the University of California-Los Angeles and the University of California-San Diego. <br/><br/>Semantic Computing includes the computing technologies (e.g., artificial intelligence, natural language, software engineering, data and knowledge engineering, computer systems, signal processing, etc.), and their interactions, that may be used to extract or process computational content and descriptions. The proposed I/UCRC will focus on providing technologies that lead to a Semantic Problem Solving (SPS) network where distributed resources can be easily connected based on semantics for the purpose of problem solving. While some areas of Semantic Computing have appeared as isolated pieces in individual disciplines, Semantic Computing glues these pieces together into an integrated theme with synergetic interactions. It addresses not only the analysis and transformation of signals (e.g., pixels, words) into useful information, but also how such information can be accessed and used to synthesize new signals. The three proposed campuses have complementary areas of strength and have emphasized different aspects of Semantic Computing systems. All participating faculty are prominent researchers in one or more areas related to Semantic Computing. <br/><br/>The technologies developed by the proposed I/UCRC may support new inter-connectivity that has not been realized by the Internet today. It therefore may facilitate the transition of the Internet into Web 3.0 and stimulate new business models for a better economy that everyone can benefit. The technologies developed by the proposed I/UCRC will be delivered to the public via the Internet, and the PIs expect to create broader impacts in areas other than the five selected. The five areas are chosen as they characterize different aspects of problem solving, e.g., creativity (IT, entertainment), learning (education) and decision making (health, finance), which are applicable to many other areas such as manufacturing, science, engineering, and the humanities."
1135374,"Supporting Students Attending the User Modeling, Adaptation and Personalization 2011 Conference",IIS,Cyber-Human Systems (CHS),4/15/2011,4/14/2011,Peter Brusilovsky,"Brusilovsky, P","Brusilovsky, P",PA,University of Pittsburgh,Standard Grant,Ephraim P. Glinert,3/31/2012,"$15,396.00 ",,peterb@mail.sis.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,7367,"7484, 7556",$0.00 ,exceptionalFunding,"This is funding to support travel by 6-8 students currently enrolled in PhD programs in the United States to present their accepted papers and posters and/or to take part in the Doctoral Consortium at the 2011 International Conference on User Modeling, Adaptation, and Personalization (UMAP) to be held in Girona, Spain, on July 11-15, 2011.   UMAP, the premier user modeling conference in the world, was formed in 2009 as a merger of the long-running and successful biennial conference series on User Modeling (UM, 1986-2007) and the Adaptive Hypermedia and Adaptive Web-Based Systems (AH, 2000-2008); the former provided a forum where academic and industrial researchers from the many fields involved in user modeling research (artificial intelligence, human-computer interaction, education, linguistics, psychology, and information science) could exchange their complementary insights on user modeling issues, while the latter provided a forum for dissemination of adaptive technology for hypermedia and other web-based systems.  User modeling has been found to significantly enhance the effectiveness and usability of software systems in a variety of areas.  A user model is an explicit representation of properties of a particular user; a system that constructs and consults user models can adapt diverse aspects of its performance to individual users.  Applications for user modeling range from electronic commerce and intelligent learning environments to health care and assistive technologies.  Relevant platforms for user modeling include mobile and wearable systems, and smart environments, as well as individual desktop systems, groupware, adaptive hypermedia, and other web-based systems.   More information about the conference is available at http://www.umap2011.org. <br/><br/>The UMAP 2011 Doctoral Consortium will provide a unique opportunity for PhD students partway through their dissertation research to receive valuable feedback from top researchers in the field.  The event will be held in a special session that is open to all students, not only those accepted to present, as well as to regular conference attendees, and which is designed so as to provide a great educational opportunity for all attending students, a unique event where a community as a whole can engage in a discussion with students about emerging topics, expected rigor, evaluation approaches, etc.  Each student participant will be allotted 15 minutes in which to present his/her work (including a short demo if appropriate), with an additional 15 minutes allocated to questions and for discussion.  Both during the question/discussion period and in subsequent informal interactions, committee members and other conference participants will provide constructive comments on the student's work and attempt to address any aspects of the work on which s/he has requested advice.  Student papers will be published in the main proceedings of the conference.  <br/><br/>Broader Impacts:  Bringing young and creative researchers to UMAP 2011 will help advance an important and socially valuable research field.  NSF funding will significantly impact the careers of the next generation of User Modeling researchers, by enabling a number of them to take part in an important event they would otherwise have to miss.  The students will have an opportunity to gain wider exposure in the community for their innovative work, and to obtain feedback and guidance from senior members of the research community.  Participation will help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior investigators at a critical stage in their professional development.  In allocating NSF funds to participants, the organizers will give preference to students who are placed at a disadvantage due to the conference's location in Europe; they will strive for diversity among the selected students across a number of dimensions (gender, racial, ethnic, disabilities, institutional, etc.), and they will also take special steps to promote participation from institutions with relatively large numbers of students from under-represented groups."
1631562,Doctoral Mentoring Consortium at the 25th International Joint Conference on Artificial Intelligence (IJCAI 2016),IIS,ROBUST INTELLIGENCE,4/1/2016,4/19/2016,ERIC EATON,"EATON, E","EATON, E",PA,University of Pennsylvania,Standard Grant,James Donlon,3/31/2017,"$15,000.00 ",,eeaton@seas.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The purpose of this project is to support the participation of a select group of US-based PhD students in the doctoral consortium at the 2016 International Joint Conference on Artificial Intelligence (IJCAI). IJCAI is a premier conference in Artificial Intelligence (AI), drawing wide domestic and international participation, including many top researchers. In particular, the doctoral consortium seeks to broaden the participation of underrepresented groups in this field of research, and we expect to have diverse participation in terms of gender, ethnic background, academic institution, and geographic location. In addition to technical exposure, this experience will give students the opportunity to interact with a broad range of researchers and educators involved in the AI field. This will help the students to become members of the international community of scholars, and to develop into the global scientists that are needed for the future. In the longer term, having engaged and informed scientists will help advance science and high-tech industry in the US.<br/><br/>The wide variety and significance of the topics typically presented at IJCAI, in both the technical program and the doctoral consortium, will provide a great opportunity for students to share, exchange information, and learn from each other and from the best in the field. Participation in a conference is a great motivator for graduate students, and we expect the IJCAI doctoral consortium will generate additional long-term interest among graduate students in pursuing a research-oriented career in artificial intelligence.  Doctoral consortium participants will also have the opportunity to receive feedback on their doctoral research from established scientists who will serve as mentors throughout the proceedings."
1242748,AAAI Fall Symposium: AI for Gerontechnology Student Travel Support,IIS,Smart and Connected Health,2/1/2013,9/12/2013,Narayanan Chatapuram Krishnan,"Krishnan, NC","Krishnan, NC|Rashidi, P|Cook, D",WA,Washington State University,Standard Grant,Sylvia J. Spengler,1/31/2014,"$15,000.00 ","Parisa Rashidi, Diane Cook",ckn@eecs.wsu.edu,280 Lighty,PULLMAN,WA,991641060,5093359661,CSE,8018,"7556, 8018",$0.00 ,exceptionalFunding,"This  project is providing  support for graduate students to attend a workshop organized in conjunction with the fall 2012 annual symposium of the Association for Advancement in Artificial Intelligence. The workshop entitled Artificial Intelligence for Gerontechnology was held November 2nd to November 4th, 2012, in Arlington, Virginia.  Gerontechnology  is an interdisciplinary academic and professional field combining the study of aspects of aging and technology to address the challenges arising from the demographic changes due to aging society.   Artificial intelligence techniques are considered to be among the key components of the solutions within the gerontechnology domain supporting care for elders. Intellectual Merit: The symposium advances the state of the art in artificial intelligence by considering problems and solutions that are inspired by the challenges in developing gerontechnology. Specifically, the topics addressed include the following: 1) novel approaches for dealing with sparsely annotated data, 2) innovative machine learning techniques that can improve the generalization of technological solutions across a wide range of real-world settings and 3) design of modeling algorithms that take advantage of domain knowledge. Broader Impacts: While the goal of the symposium was to advance the field of AI with the focus on elder care applications, the solutions resulting from the symposium can also be applied to other health care areas such as assisting chronic patients in hospitals and homes. In addition, the educational aspect of this workshop provides the opportunity to educate future workforce with expertise at the intersection of computer science, artificial intelligence and care for the elders."
1624673,III: Student Travel to Workshop on Intelligent Systems for Supporting Distributed Human Teamwork,IIS,INFO INTEGRATION & INFORMATICS,3/15/2016,2/25/2016,Barbara Grosz,"Grosz, B","Grosz, B",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Sylvia J. Spengler,2/28/2017,"$15,000.00 ",,grosz@eecs.harvard.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7364,"7364, 7556",$0.00 ,exceptionalFunding,"This award will support the travel and housing expenses of students selected to participate in the AAAI Spring Symposium on Intelligent Systems for Supporting Distributed Human Teamwork, which will be held on March 21-23, 2016, in Palo Alto, California. The symposium is part of the annual AAAI Spring Symposia series. The symposium will bring together researchers studying teamwork in different fields, including artificial intelligence, human-computer interaction, and the social sciences. For student participants, this experience will provide a unique opportunity to interact with researchers from multiple disciplines and learn about research in different fields. Students will receive feedback on their own research and will work closely with senior researchers and other students to shape a new research agenda for the development of intelligent systems for supporting human teamwork. The symposium will be a starting point for forming a new cross-disciplinary community of researchers who are interested in the development of intelligent systems for supporting teamwork. New approaches and systems for supporting teamwork are needed for supporting increasingly more complex distributed teamwork in such areas as healthcare, education and disaster relief."
1658406,Collaborative Research: Conference on Cognitive Computational Neuroscience (CCN),BCS,"COGNEURO, CRCNS",4/1/2017,3/30/2017,Thomas Naselaris,"Naselaris, T","Naselaris, T",SC,Medical University of South Carolina,Standard Grant,Uri Hasson,3/31/2018,"$15,000.00 ",,tnaselar@musc.edu,171 ASHLEY AVE,CHARLESTON,SC,294258908,8437923838,SBE,"1699, 7327","1699, 7327, 7556, 8089, 8091, 9150",$0.00 ,exceptionalFunding,"Cognitive Computational Neuroscience (CCN) is an annual scientific meeting for neuroscientists characterizing the neural computations that underlie complex behavior. The goal is to develop computationally defined models of brain information processing that explain rich measurements of brain activity and behavior. Such models will ultimately have to perform feats of intelligence such as perception, internal modelling and memory of the environment, decision-making, planning, action, and motor control under naturalistic conditions. Historically, different disciplines have met subsets of these goals. Cognitive science has developed computational models at the cognitive level to explain aspects of complex behavior. Computational neuroscience has developed neurobiologically plausible computational models to explain neuronal responses to sensory stimuli and certain low-dimensional decision, memory, and control processes. Cognitive neuroscience has mapped a broad range of cognitive processes onto brain regions. Artificial intelligence has developed models that perform feats of intelligence. The community must now put the pieces of the puzzle together, and CCN is unique in its focus on the intersection between these fields. CCN is envisioned not only as an engine for advancing research, but as a vehicle for making broader impacts on education and society. As evidenced by the recent trend of major corporate acquisitions of AI startups founded by neuroscientists, biological inspiration for electronics and software development is a growing trend with significant economic implications. In its early stages, the broader impact focus of CCN will be on increasing the visibility of women and scientists from underrepresented populations via speaking opportunities and travel awards.  In addition, representation on women on the female fractions on the steering and advisory committees exceed those typical in relevant fields, without compromise in qualifications. Conferences will include hands-on tutorials, and materials from these will propagate to various university curricula.<br/><br/>A central goal of neuroscience is to understand how vast populations of neurons give rise to complex behavior. Today, advances in various domains offer tangible possibilities to make fundamental conceptual breakthroughs. From an experimental point of view, neural recording technologies, such as high-resolution fMRI, dense recording arrays, magnetoencephalography (MEG), and calcium imaging, now provide opportunities to observe neural activity at unprecedented resolution and scale. At the same time, research in cognitive science has become increasingly sophisticated in identifying computational principles that may serve as the basis for human cognition, and machine learning and artificial intelligence have made great strides in building models to autonomously solve complex cognitive tasks. However, interactions among these distinct disciplines remain rare. This new conference may stimulate unifying frameworks that fully realize the cross-disciplinary potential of these individual advances. In more concrete terms, the goal of CCN is to create and foster a community that will develop models of brain information processing with several key features. These models should (1) be fully computationally defined and implemented in computer simulations; (2) be neurobiologically plausible; (3) explain measurements of brain activity (and continue to do so as spatiotemporal resolution and scale improve); (4) explain behavior for naturalistic stimuli and tasks; and (5) perform feats of intelligence such as recognition, internal modelling and representation of the environment, decision-making, planning, action, and motor control. Such models currently do not exist and are unlikely to emerge without greatly improved cross-disciplinary engagement."
937540,Travel Support for Graduate Students to Attend ICAPS09 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,7/1/2009,6/17/2009,Adele Howe,"Howe, A","Howe, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,6/30/2010,"$15,000.00 ",,howe@CS.ColoState.EDU,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9102, 9215, HPCC",$0.00 ,exceptionalFunding,"This award gives travel, housing, and registration-cost support to selected doctoral students from U.S. universities for their participation in the Doctoral Consortium of the 19th International Conference on Automated Planning and Scheduling (ICAPS-09) held September 19-23 in Thessaloniki, Greece. ICAPS is the premier conference for research in artificial intelligence planning and scheduling, with relevance to a wide variety of applications such as software engineering, manufacturing, transportation, and robotics. The ICAPS-09 Doctoral Consortium includes a poster session, where students present their research, and a mentoring program that pairs senior scientists with doctoral students."
737954,Doctoral Consortium Support for International Conference on Automated Planning and Scheduling,IIS,ROBUST INTELLIGENCE,7/1/2007,6/18/2007,Mark Boddy,"Boddy, M","Boddy, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,1/31/2008,"$15,000.00 ",,mark.boddy@adventiumenterprises.com,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7495, 9218, HPCC",$0.00 ,exceptionalFunding,"Proposal 0737954<br/>""""Doctoral Consortium Support for International Conference on Automated Planning and Scheduling""""<br/>PI: Mark Boddy<br/>AAAI<br/><br/><br/>ABSTRACT<br/>This award supports the participation of doctoral students from U.S. universities in the Doctoral Consortium of the 17th International Conference on Automated Planning and Scheduling (ICAPS-07) to be held September 22-26 in Providence, Rhode Island. ICAPS is the premier conference for research in artificial intelligence planning and scheduling. Topics include all aspects of scheduling theory and practice, including a wide spectrum of applications (e.g., software, manufacturing, robotics). At this year's conference, there will be a specific focus on incorporating work in two related areas of research: machine learning and model-based reasoning. This Doctoral Consortium will provide participants with the opportunity to interact with established researchers as well as fellow doctoral students. The overall goals of the ICAPS Doctoral Consortium include providing participants with valuable feedback and exposure to additional perspectives on their work at a critical time in their doctoral research projects as well as providing helpful career advice at a critical time in their professional development. Participants will receive feedback and advice from assigned mentors and fellow participants through activities and discussions at the Consortium as well as through a Poster Session of the main ICAPS conference. Participants in the Doctoral Consortium will be invited to publish their research abstracts on the conference web site and in the proceedings that will be distributed to all conference attendees"
608564,Doctoral Consortium Support for International Conference on Automated Planning and Scheduling,IIS,ARTIFICIAL INTELL & COGNIT SCI,2/1/2006,1/6/2006,Stephen Smith,"Smith, S","Smith, S|Frank, J",PA,Carnegie-Mellon University,Standard Grant,Douglas H. Fisher,1/31/2007,"$15,000.00 ",Jeremy Frank,sfs@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,CSE,6856,"6856, 7495, 9218, HPCC",$0.00 ,exceptionalFunding,"This award supports the participation of doctoral students from U.S. universities in the Doctoral Consortium of the 16th International Conference on Automated Planning and Scheduling (ICAPS) to be held June 6-10, 2006, Ambleside, England. ICAPS is the premier conference for research in artificial intelligence planning and scheduling. This Doctoral Consortium will provide participants with the opportunity to interact with established researchers as well as fellow doctoral students. The overall goals of the ICAPS Doctoral Consortium include providing participants with valuable feedback and exposure to additional perspectives on their work at a critical time in their doctoral research projects as well as providing helpful career advice at a critical time in their professional development. Participants will receive feedback and advice from mentors and fellow participants through activities and discussions at the Consortium as well as through a Poster Session of the main ICAPS conference. Participants in the Doctoral Consortium will be invited to publish their research abstracts on the conference web site and in a stand-alone proceedings that will be distributed to all conference attendees"
836896,Doctoral Consortium Support for International Conference on Automated Planning and Scheduling,IIS,ROBUST INTELLIGENCE,8/1/2008,7/16/2008,Robert Sloan,"Sloan, R","Sloan, R",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,7/31/2009,"$15,000.00 ",,sloan@uic.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,"7484, 9215, HPCC",$0.00 ,exceptionalFunding,"This award gives travel, housing, and registration-cost support to selected doctoral students from U.S. universities for their participation in the Doctoral Consortium of the 18th International Conference on Automated Planning and Scheduling (ICAPS-08) held September 14-18 in Sydney, Australia. ICAPS is the premier conference for research in artificial intelligence planning and scheduling, with relevance to a wide variety of applications such as software engineering, manufacturing, transportation, and robotics. The ICAPS-08 Doctoral Consortium includes a poster session, where students present their research, and a mentoring program that pairs senior scientists with doctoral students."
1714855,ACL 2017 Student Research Workshop,IIS,ROBUST INTELLIGENCE,2/1/2017,1/18/2017,Marine Carpuat,"Carpuat, M","Carpuat, M",MD,University of Maryland College Park,Standard Grant,Tatiana D. Korelsky,1/31/2019,"$15,000.00 ",,marine@cs.umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing.  It also is one of the primary application areas for researchers in machine learning and artificial intelligence.  The proceedings of its annual meeting provide the foundation of the field; it is the most cited and most respected publication in computational linguistics.  Thus, it is also the most important gathering of researchers in computational linguistics and natural language processing. This project is to subsidize travel, conference and housing expenses of students selected to participate in the ACL Student Research Workshop, which will take place during the main ACL conference from July 31 - August 2, 2017 in Vancouver, Canada.  The Student Research Workshop helps create a new generation of researchers with a more thorough understanding of their field, with connections and collaborations across institutions, and with innovative and exciting research programs.  This contributes to America's pool of researchers with the needed scientific and engineering knowledge and skills. The workshop encourages a spirit of collaborative research and builds a supportive environment for a new generation of computational linguists.<br/><br/>The Student Research Workshop solicits two categories of submissions: research papers and research proposals. The research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student (at either the graduate or undergraduate level).  The workshop is a venue for students to receive constructive critical feedback on their work from experts outside of their institution, and to connect with other students and senior researchers in their field.  The students gain exposure by presenting their work earlier than they would otherwise (i.e., in a form not yet ready for the main conference). This is particularly valuable for students from smaller institutions and undergraduate students. In addition, the workshop is organized and run by students. The student organizers gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference."
1650587,University of Oregon Planning Proposal: I/UCRC for Big Learning,CNS,INDUSTRY/UNIV COOP RES CENTERS,2/15/2017,2/21/2017,Dejing Dou,"Dou, D","Dou, D|Phan, H|Fickas, S|Lowd, D|Malony, A",OR,University of Oregon Eugene,Standard Grant,Dmitri Perkins,1/31/2018,"$15,000.00 ","Hai Phan, Stephen Fickas, Daniel Lowd, Allen Malony",dou@cs.uoregon.edu,5219 UNIVERSITY OF OREGON,Eugene,OR,974035219,5413465131,CSE,5761,5761,$0.00 ,exceptionalFunding,"The proposed NSF I/UCRC Center for Big Learning (CBL) consists of multi-disciplinary experts at the four founding universities that are geographically distributed across the country: University of Oregon (UO, West), Carnegie Mellon University (CMU, East), University of Missouri at Kansas City (UMKC, Central), and University of Florida (UF, South).  The mission of this center is to explore research frontiers in the design of novel algorithms and developing efficient systems for deep learning research and its applications in the era of big data and big systems. Through a multi-site and multi-disciplinary consortium, the CBL center at the UO will focus on key applications of large-scale deep learning involving multi-modal media (i.e., text, image, and Q&A) in various domains (i.e., health, life science, IoT/mobile, and business) relying on strong support from the industry partners. The proposed multidisciplinary center will offer important opportunities for training new scientists and graduate students, and provide an environment for cross-disciplinary engagement.<br/><br/>The research team at the UO includes experts in data science, artificial intelligence, machine learning, high performance computing, IoT, health informatics, and bioinformatics. The CBL at the UO seeks to catalyze the fusion of expertise from academia, government, and industry stakeholders related to the rapid innovation in algorithms, systems, applications as well as education, and technology transfer into cutting-edge products and services with real-world relevance and significance. The UO site will explore several research projects related to health behavior modeling, activity recommendation, social network analysis, and privacy preserving by deploying various deep learning models. The planning activities will lead to a successful proposal for the establishment of the CBL center with a solid consortium across multiple campuses and a large number of industry partners. Our proposed meetings, forums, conferences, and planned training sessions will greatly promote and broaden the research and materialization of large-scale deep learning."
1619855,Conference on Statistical Machine Learning and Data Science,DMS,STATISTICS,6/15/2016,6/9/2016,Yufeng Liu,"Liu, Y","Liu, Y",NC,University of North Carolina at Chapel Hill,Standard Grant,Gabor J. Szekely,5/31/2017,"$15,000.00 ",,yfliu@email.unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,MPS,1269,7556,$0.00 ,exceptionalFunding,"The University of North Carolina at Chapel Hill will host a three day conference on Statistical Machine Learning and Data Science from June 6-8, 2016. (See http://www.unc.edu/~yfliu/sldm2016/.) The objective is to bring together researchers in statistical learning and data science from academia, industry, and government in a stimulating atmosphere focused on the development of statistical learning theory, methods and applications. Statistical machine learning is a relatively new discipline, evolving from machine learning methods of artificial intelligence and multivariate statistics. It also plays an essential role for the new important area of data science and big data. NSF funding will provide travel support to increase the number of junior researchers who are able to attend.<br/><br/>The Section on Statistical Machine Learning and Data Science of the American Statistical Association will hold a meeting at the University of North Carolina at Chapel Hill from June 6-8, 2016. Topics of the conference include, but are not limited to, big data analytics, classification, computational biology, covariance estimation, graphical models, high dimensional data, learning theory, model selection, network analysis, precision medicine, and signal and image processing. This award will provide travel support for junior researchers."
925663,"Supporting Students Attending the International Conference on User Modeling, Adaptation, and Personalization",IIS,Cyber-Human Systems (CHS),4/1/2009,3/3/2009,Mary Carberry,"Carberry, M","Carberry, M",DE,University of Delaware,Standard Grant,Ephraim P. Glinert,9/30/2009,"$14,800.00 ",,carberry@cis.udel.edu,210 Hullihen Hall,Newark,DE,197162553,3028312136,CSE,7367,"7367, 9150, 9215, HPCC",$0.00 ,exceptionalFunding,"This is funding to support travel by 6-9 students currently enrolled in PhD programs in the United States to present their accepted papers and posters, and to take part in the Doctoral Consortium, at the First International Conference on User Modeling, Adaptation, and Personalization (UMAP 2009), to be held in Trento, Italy, on June 22-26, 2009.   UMAP, the premier user modeling conference in the world, is a merger of the long-running and successful biennial conference series on User Modeling (UM, 1986-2007) and the Adaptive Hypermedia and Adaptive Web-Based Systems (AH, 2000-2008); the former provided a forum in which academic and industrial researchers from the many fields involved in user modeling research (artificial intelligence, education, psychology, linguistics, human-computer interaction, and information science) could exchange their complementary insights on user modeling issues, while the latter provided a forum for dissemination of adaptive technology for hypermedia and other web-based systems.  User modeling has been found to significantly enhance the effectiveness and usability of software systems in a variety of areas.  A user model is an explicit representation of properties of a particular user; a system that constructs and consults user models can adapt diverse aspects of its performance to individual users.  Applications for user modeling range from electronic commerce and intelligent learning environments to health care and assistive technologies.  Relevant platforms for user modeling include mobile and wearable systems, and smart environments, as well as individual desktop systems, groupware, adaptive hypermedia, and other web-based systems.  The UMAP 2009 Doctoral Consortium will provide a unique opportunity for PhD students partway through their dissertation research to receive valuable feedback from top researchers in the field.  Participants will present their work to the conference (15 minutes, which may include a short demo if appropriate), with additional time allocated to questions and for discussion (15 minutes).  Both during the question/discussion period and in subsequent informal interactions, committee members and other conference participants will provide constructive comments on the student's work and attempt to address the aspects of the work on which s/he requested advice.   Student papers will be published in the adjunct proceedings of the conference, while summaries will be included in the proceedings.  In allocating NSF funds to participants, the Doctoral Consortium Co-chairs will give preference to students who can reasonably prove financial hardship, and they will also strive for diversity (gender, racial, ethnic, disabilities, institutional, etc.) among the selected students.<br/><br/>Broader Impacts:  Bringing young and creative researchers to UMAP 2009 will help advance an important and socially valuable research field.  NSF funding will significantly impact the careers of the next generation of User Modeling researchers, by enabling a number of them to take part in an important event they would otherwise have to miss.  The students will have an opportunity to gain wider exposure in the community for their innovative work, and to obtain feedback and guidance from senior members of the research community.  Participation will also help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development."
1252557,Planning Future Directions in SE & AI,CCF,SOFTWARE & HARDWARE FOUNDATION,9/1/2012,8/27/2012,Timothy Menzies,"Menzies, T","Menzies, T",WV,West Virginia University Research Corporation,Standard Grant,Sol J. Greenspan,8/31/2013,"$14,700.00 ",,tim.menzies@gmail.com,P.O. Box 6845,Morgantown,WV,265066845,3042933998,CSE,7798,"7944, 9150",$0.00 ,exceptionalFunding,"The grant funds travel to a meeting of Software Engineering (SE) and Artificial Intelligence (AI) researchers to promote synergies between the two fields. Advances in several AI areas, such as data mining, natural language understanding and constraint solving, have become ready for application in many domains, including SE. SE as an area for AI -- automating the activities of programmers -- is still a long-term vision for AI. SE goals, such as component-based, evolvable software containing valid world models and correct code, are important to AI as they are to other fields. The workshop will explore synergies between the fields and serve as a planning meeting for future interactions."
303781,"2003 American Association for Artificial Intelligence/Special Interest Group on ArtificialIntelligence/ IJCAI Doctoral Consortium;  August 10-11, 2003;  Acapulco, Mexico",IIS,ARTIFICIAL INTELL & COGNIT SCI,4/15/2003,4/14/2003,Marie desJardins,"desJardins, M","desJardins, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,3/31/2004,"$14,650.00 ",,mariedj@cs.umbc.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"6856, 9218, HPCC",$0.00 ,exceptionalFunding,"This award provides funds to subsidize the travel and housing expenses of students selected to participate in the eighth SIGART/AAAI Doctoral Consortium, which will be held on August 10-11, 2003, in Acapulco, Mexico. The consortium will be collocated with the National Conference on Artificial Intelligence (NCAI), which will be held from August 10-15 in Acapulco. ACM/SIGART and AAAI together organized the first seven Doctoral Consortia, which have also been collated with either NCAI or  IJCAI (International Joint Conference on Artificial Intelligence). <br/> <br/>At the consortium, Ph.D. students who are doing their dissertations on AI-related topics present their proposed research, and receive feedback from a panel of established researchers as well as from the other students.  This provides the students with invaluable exposure to outside perspectives on their work, at a critical time in their research, and also enables them to explore their career objectives. This workshop contributes to the professional development of young scientists who will lead this growing field in the coming decades.<br/>"
914591,Supporting Students Attending IUI 2009 Conference,IIS,Cyber-Human Systems (CHS),2/1/2009,2/2/2009,Daniel Weld,"Weld, D","Weld, D",WA,University of Washington,Standard Grant,Ephraim P. Glinert,1/31/2010,"$14,400.00 ",,weld@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7367,"7367, 9215, HPCC",$0.00 ,exceptionalFunding,"This is funding to support participation by approximately 15 graduate students currently enrolled in Ph.D. programs in the United States and abroad in the 2009 International Conference on Intelligent User Interfaces (IUI 2009), to be held in Sanibel Island, Florida, on February 8-11, 2009.  Sponsored by ACM, the annual IUI conferences are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place.  Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter.  Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition.  To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc.  IUI 2009 will be the 12th conference in the series; topics of interest this year include user input, generation of system output, ubiquitous computing, help, categories of intelligence, IUI design, and user studies.  NSF funds will be used to support two groups of participants: students who are the primary author of a submission that has been accepted as a full paper or poster but whose institution is either unable to provide any funding for conference attendance or able to provide only partial funding that is insufficient to cover the student?s expenses; and other students who would benefit from the conference but who would be unable to attend due to restrictions by their department on funding conference travel for non-authors.  The IUI 2009 organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community, and also that the bulk of students supported (70-80%) will be from U.S. institutions.<br/><br/>Broader Impacts:  This funding will enable attendance at this conference by students who might otherwise be unable to do so for financial reasons.  It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement.  The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants.  The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference."
9650799,AI Technologies Laboratory,DUE,UNDERGRAD INSTRM & LAB IMPROVE,8/1/1996,6/25/1996,Jesse Schmeller,"Schmeller, J","Schmeller, J|Omholt, T|Mathieson, J|Kramer, A",NY,SUNY Maritime College,Standard Grant,Eric J. Sheppard,7/31/1998,"$14,078.00 ","Thore Omholt, John Mathieson, Aaron Kramer",,Fort Schuyler,Bronx,NY,104654198,7184097349,EHR,7400,"9178, 9267, SMET",$0.00 ,exceptionalFunding,"The Marine Engineering Department has initiated a project to study the application of developing artificial intelligence (AI) technologies for monitoring the performance of systems and equipment typically found in power plants. To facilitate the study, the department is purchasing apparatus that may become part of an AI laboratory and expand on current AI capabilities. The AI laboratory has a number of devices, such as heat exchangers, that can be interconnected to simulate a fluid system. A data acquisition system is used to gather information about the operation of the system or one of its components. AI technologies are then trained to use that information to recognize different operating conditions. The problem was that the existing laboratory equipment was not capable of simulating a typical system and was limiting the ability to make the study realistic. The purpose of this project is the development of sets of devices that can simulate typical systems in power plants. Work has already been done by junior and senior engineering students enrolled in independent study courses. They have successfully used a data acquisition system to gather information about the operation of a laboratory heat exchanger and pressure drop device. The information was supplied to a neural network which was trained to recognize normal and abnormal fluid flow characteristics for that equipment. The significance of this project is that new laboratory equipment is giving the students the chance to be involved in applying AI technologies. The project should also be of interest to the maritime industry as it looks to improve the operation and safety of its ships. Plans have been made to disseminate the results through professional organizations such as the Society of Naval Architects and Marine Engineers, American Society of Engineering Education, and industry."
646959,SGER:  Developing Keys to AI Science,IIS,ARTIFICIAL INTELL & COGNIT SCI,9/15/2006,9/13/2007,David Leake,"Leake, D","Leake, D",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Douglas H. Fisher,2/29/2008,"$14,000.00 ",,leake@cs.indiana.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"7495, 9218, 9237, HPCC",$0.00 ,exceptionalFunding,"Proposal 0646959<br/>""Developing Keys to AI Science""<br/>PI: David Leake<br/>American Association for Artificial Intelligence<br/><br/><br/>ABSTRACT<br/><br/>The goals of the proposed work are (1) to analyze the field of artificial intelligence research to develop a framework for understanding key aspects of the science of artificial intelligence and its components, and (2) to use this analysis to design effective methods to disseminate key principles for outreach. This outreach will be aimed at educating faculty, students and others about the science of artificial intelligence, increasing their understanding of this important area of computer science, and spurring them to increase their knowledge of the field.  The products of this project will be a poster and an accompanying Web site, serving as a bridge from the poster to relevant on-line resources and using the poster to place those resources in context.<br/>"
407103,"2004 SIGART/AAAI Doctoral Consortium; July 25-26, 2004; San Jose, CA",IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2004,3/23/2004,Robert St. Amant,"Amant, RS","Amant, RS",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,6/30/2005,"$14,000.00 ",,stamant@csc.ncsu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This proposal supports participation of doctoral students from U.S. universities in the ninth SIGART/AAAI Doctoral Consortium to be held July 25-26, 2004 in San Jose, CA., in conjunction with the 19th National Conference on Artificial Intelligence (AAAI-04), July, 25-29, 2004. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; (3) support a new generation of researchers; and (4) contribute to the conference through interaction with other researchers at the conference. The Doctoral Consortium will aim to recruit and include students from under-represented groups (e.g., women and under-represented minorities) and smaller schools or schools with less established programs in artificial intelligence. Each student will give a 25-minute presentation to be followed by 20 minutes of discussion lead by a faculty participant. In addition, each student will have a one-on-one meeting with the faculty participant. There will also be a panel to discuss career issues in both academic and other career pathways."
1441892,Support for Young Researchers to attend the 2014 Intelligent Tutoring Systems Conference,IIS,"REAL, Cyberlearn & Future Learn Tech",6/1/2014,5/5/2014,Beverly Woolf,"Woolf, B","Woolf, B",MA,University of Massachusetts Amherst,Standard Grant,christopher hoadley,5/31/2015,"$14,000.00 ",,bev@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"7625, 8020","7556, 8045, 8055",$0.00 ,exceptionalFunding,"The United States has historically been the global leader in the field of Intelligent Tutoring Systems, or ways to use computerized artificial intelligence to enhance teaching and learning in contexts ranging from children learning math in school, to soldiers learning highly technical jobs in the US military. The preeminent conference in this field is the ITS conference; at this conference the latest research is presented and practitioners learn the state of the art techniques that allow creation of these important educational technologies. <br/><br/>This proposal would support seven Ph.D. students, selected through a competitive process, to attend the conference, present their work, and receive additional mentoring outside of their dissertation committees. The intellectual merit of the work rests on the studies the graduate students submit to be considered for participation in the early career track of the conference; this work is then enhanced by guidance from world-class mentors who meet with the students in a structured format to improve their research. The broader impact includes the career impact on the seven selected students, especially since promising graduate students whose advisors may not have funding to send them to the conference can still be included, and their work can be showcased and improved. Possible long-term broader impacts include building the field of ITS researchers and improving the quality of tutoring systems, and thus eventually, improving the quality of education."
404713,"ICAPS-2004 Doctoral Consortium; June 3-7, 2004; Whistler, Canada",IIS,ARTIFICIAL INTELL & COGNIT SCI,2/15/2004,1/28/2004,Eric Hansen,"Hansen, E","Hansen, E",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,1/31/2005,"$14,000.00 ",,hansen@cse.msstate.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This proposal supports the participation of doctoral students from U.S. universities in the Doctoral Consortium of the 14th International Conference on Automated Planning and Scheduling (ICAPS) to be held June 3-7, 2004 in Whistler, B.C., Canada. ICAPS is the premier conference for research in artificial intelligence planning and scheduling. This Doctoral Consortium includes a Poster Session and a mentoring program that matches PhD students with established researchers with similar interests. The goals of the Doctoral Consortium include providing doctoral students with valuable exposure to additional perspectives on their work at a critical time in their research projects as well as providing helpful career advice at a critical time in their professional development."
511705,ICAPS 2005 Doctoral Consortium Student Travel Support,IIS,ARTIFICIAL INTELL & COGNIT SCI,3/1/2005,1/10/2005,Adele Howe,"Howe, A","Howe, A",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,8/31/2005,"$14,000.00 ",,howe@cs.colostate.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"9218, HPCC",$0.00 ,exceptionalFunding,"This award supports the participation of doctoral students from U.S. universities in the Doctoral Consortium of the 15th International Conference on Automated Planning and Scheduling (ICAPS) to be held June 5-10, 2004 in Monterey, California. ICAPS is the premier conference for research in artificial intelligence planning and scheduling. This Doctoral Consortium will provide participants with the opportunity to interact with established researchers as well as fellow doctoral students. The overall goals of the ICAPS Doctoral Consortium include providing participants with valuable feedback and exposure to additional perspectives on their work at a critical time in their doctoral research projects as well as providing helpful career advice at a critical time in their professional development. Participants will receive feedback and advice through activities and discussions at the Consortium as well as through the poster session of the main ICAPS conference."
511718,2005 SIGART/AAAI Doctoral Consortium,IIS,ARTIFICIAL INTELL & COGNIT SCI,3/15/2005,3/7/2005,Kiri Wagstaff,"Wagstaff, K","Wagstaff, K",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,2/28/2006,"$13,750.00 ",,Kiri.Wagstaff@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"9218, HPCC",$0.00 ,exceptionalFunding,"This award supports participation of doctoral students from U.S. universities in the tenth SIGART/AAAI Doctoral Consortium to be held July 9-10, 2005 in Pittsburgh, PA, in conjunction with the 20th National Conference on Artificial Intelligence (AAAI-05), July, 9-13, 2005. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; (3) support a new generation of researchers; and (4) contribute to the conference through interaction with other researchers at the conference. The Doctoral Consortium will strive to recruit and include students from underrepresented groups (e.g., women and underrepresented minorities) and smaller schools or schools with less established programs in artificial intelligence. Each student will give a 25-minute presentation to be followed by 20 minutes of discussion lead by a faculty participant. In addition, each student will have a one-on-one meeting with the faculty participant. There will also be opportunities to discuss career issues in both academic and other career pathways. It is expected that thesis summaries of the participants will be published in the AI Magazine"
225754,AAAI-2002 SIGART/AAAI Doctoral Consortium,IIS,ARTIFICIAL INTELL & COGNIT SCI,10/1/2002,9/19/2002,Marie desJardins,"desJardins, M","desJardins, M",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,William Bainbridge,9/30/2003,"$13,200.00 ",,mariedj@cs.umbc.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,6856,"9218, HPCC",$0.00 ,exceptionalFunding,"This award provides funds to subsidize the travel and housing expenses of students selected to participate in the sixth SIGART/AAAI Doctoral Consortium, which will be held on July 28 and 29, 2002, in Edmonton, Canada. The consortium will be collocated with the Eighteenth National Conference on Artificial Intelligence (NCAI), which will be held from July 28 to August 1 in Edmonton. ACM/SIGART and AAAI together organized the first six Doctoral Consortia, which have also been collated with NCAI (except for last year, when the consortium was collocated with the International Joint Conference on Artificial Intelligence (IJCAI)). <br/> <br/>At the consortium, Ph.D. students who are doing their dissertations on AI-related topics present their proposed research, and receive feedback from a panel of established researchers as well as from the other students.  This provides the students with invaluable exposure to outside perspectives on their work, at a critical time in their research, and also enables them to explore their career objectives. There will also be a panel on career options as part of the consortium. This workshop contributes to the professional development of young scientists who will lead this growing field in the coming decades.<br/>"
737816,Travel and Registration Support for Third Bertinoro Workshop on Future of Distributed Computing,CNS,Computer Systems Research (CSR,8/1/2007,8/9/2007,Lorenzo Alvisi,"Alvisi, L","Alvisi, L",TX,University of Texas at Austin,Standard Grant,D. Helen Gill,7/31/2009,"$12,500.00 ",,la13@cornell.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7354,"7354, 9218, HPCC",$0.00 ,exceptionalFunding,"Distributed systems are increasingly deployed over Multiple Administrative Domains (MADs) in which no single authority controls all participating nodes. Traditionally, nodes in distributed systems deviate from their specification because they are broken (e.g., because of  bugs, hardware failures, configuration errors, or even malicious attacks). MAD systems add a new dimension: without a central administrator ensuring that each unbroken node follows the assigned protocol, nodes may deviate to selfishly maximize their utility.<br/><br/>Byzantine Fault Tolerance handles broken nodes well. However, the Byzantine model classifies all deviations as faults and requires a bound on the number of faults that is impossible to establish when nodes can be selfish. Conversely, traditional game-theoretic models handle selfish nodes well, but are vulnerable to arbitrary disruptions if even one broken node behaves irrationally.<br/><br/>The goal of the FuDiCo III  international workshop, held from June 4th to June 7th 2007, is to identify the conceptual and practical foundations on which to build dependable MAD distributed systems.   The workshop, the third in the prestigious Future of Distributed Computing (FuDiCo) series, brings together leading senior researchers and promising graduate students from different areas  (security, distributed computing, artificial intelligence, networking, and economics) for a ?multicultural? approach to this challenging and multi-faceted problem.  The objective is to produce a series of written reports (targeted for  SIGACT and SIGOPS News) that provide a snapshot of the current research in the area and identify promising avenues for future research."
1337085,EAAI-13: The Fourth Annual Symposium on Educational Advances in Artificial Intelligence,IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",5/15/2013,5/16/2013,Laura Brown,"Brown, L","Brown, L",CA,Association for the Advancement of Artificial Intelligence,Standard Grant,James Donlon,4/30/2014,"$12,000.00 ",,lebrown@mtu.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,"1640, 7495","7495, 7556",$0.00 ,exceptionalFunding,"This grant provides travel support for selected students attending the annual Symposium on Combinatorial Search (SoCS). Student participation in SoCS encourages young investigators in their research in combinatorial search. This symposium carries on a tradition of bringing together researchers and students around issues of pattern-database heuristics, inconsistent heuristics, real-time search, path-finding for physical robots and computer-game agents, parallel search, and search using external memory. These search techniques have a significant place in broader AI application in areas such as robotics, computer games, planning, and bioinformatics. In addition, SoCS 13 includes a special focus on graph search engineering."
9909952,U.S.- Germany Cooperative Research:  Proof Search in Logical Frameworks,OISE,WESTERN EUROPE PROGRAM,1/15/2000,1/7/2003,Frank Pfenning,"Pfenning, F","Pfenning, F",PA,Carnegie-Mellon University,Standard Grant,Jennifer Slimowitz Pearl,8/31/2003,"$12,000.00 ",,fp@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122689527,O/D,5980,"0000, 5936, OTHR",$0.00 ,exceptionalFunding,"9909952<br/>Pfenning<br/><br/>This award supports Frank Pfenning and two students from Carnegie Mellon University in a collaboration with Dieter Hutter of the German Research Institute for Artificial Intelligence (DFKI) in Saarbruecken, Germany.  The project will focus on the development of a generic meta-langauge (or logical framework) in which various systems for formal reasoning can be encoded concisely.  The central objective of this collaboration is to further the understanding of how standard techniques of redundancy elimination, efficient implementation, and heuristic search from specific logics can be generalized and applied to logical frameworks.  Intended applications include formal methods and inductive reasoning about programming languages and logics.  This work will make possible new advances in software engineering and artificial intelligence.<br/>"
1240710,Support for student participation in a 2012 AAAI Fall Series Symposium,IIS,ROBUST INTELLIGENCE,9/1/2012,8/27/2012,Victor Raskin,"Raskin, V","Raskin, V|Rayz, J",IN,Purdue University,Standard Grant,Tatiana D. Korelsky,8/31/2014,"$12,000.00 ",Julia Rayz,vraskin@purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The American Association for Artificial Intelligence (AAAI) Fall Series Symposium (FSS) is the first international gathering in North America in the field of computational aspects of affective narrative, bringing together participants from a long list of contributing disciplines. One of the aims of the Symposium is to attract students to a new and exciting multidisciplinary area, where it is still easier to attract the experts' attention and mentoring. The goal of this grant is to subsidize travel, registration fees, and housing expenses of students selected to participate in the Symposium which will be held, along with several other AAAI Fall Symposia, on November 2-4, 2012, in Arlington, VA. <br/><br/>The Symposium calls for long and short papers both from leaders in the field of computational aspects of affective narrative and pertinent areas and from graduate students as well as poster presentations from the undergraduate students interested in the subject. Papers from undergraduates, attracted through Research Experience for Undergraduates (REU) and Senior Research Opportunity Program (SROP) networks as well as solo graduate contributions will be carefully mentored to the level of poster or short paper eligibility. The multi-format program of the Symposium will also accommodate special student sessions, especially for promising but not fully developed ideas. <br/><br/>The AAAI FSS Symposium on computational aspects of affective narrative provides a valuable opportunity for the next generation of multidisciplinary researchers in a variety of pertinent disciplines to enter the computational affective narrative research community.  It is expected that the Symposium will attract underrepresented populations as well as provide benefit to future development of computational systems from better understanding of affective narrative as the inherently human phenomenon."
9908433,"Workshop:  1999 SIGART/AAAI Doctoral Consortium, Orlando, Florida",IIS,ARTIFICIAL INTELL & COGNIT SCI,8/1/1999,7/20/1999,Janyce Wiebe,"Wiebe, J","Wiebe, J",NM,New Mexico State University,Standard Grant,Ephraim P. Glinert,12/31/1999,"$12,000.00 ",,wiebe@cs.pitt.edu,Corner of Espina St. & Stewart,Las Cruces,NM,880038002,5756461590,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"The 4th AAAI Doctoral Consortium, to be held as a workshop on July 18-19, 1999, immediately preceding the AAAI-99 conference in Orlando, Florida, will provide a unique opportunity for a group of PhD students to discuss and explore their research interests and career objectives together with a panel of established researchers.  The consortium has the following objectives:<br/><br/>               * To provide a setting for mutual feedback on participants' current research, and<br/>  guidance on future research directions<br/>               * To develop a supportive community of scholars and a spirit of collaborative<br/>  research<br/>               * To support a new generation of researchers with information and advice on<br/>  academic, research, industrial, and non-traditional career paths<br/>               * To contribute to the conference goals through interaction with other researchers<br/>  and participation in conference events.<br/><br/>The Doctoral Consortium will be held concurrently with other workshops preceding the AAAI'99 conference.   It is expected that it will attract a diverse group of student participants who reflect a wide range of topic areas and methodologies within artificial intelligence, and who have settled on their thesis directions but who still have significant research left to do.  Selection will be based on clarity and completeness of the submission packet, stage of research, advisor's letter, and other evidence of promise such as published papers or technical reports. Participants' thesis summaries will be published in the AAAI-99 conference proceedings.  NSF funds will be used to provide student participants with a travel reimbursement of $750.  Participants will also receive complimentary conference registration.   The organizing committee for the workshop consists of: Janyce M. Wiebe, Chair, New Mexico State University; Mary P. Harper, Purdue University; Evangelos E. Milios, Dalhousie University; Vibhu O. Mittal, Just Research and Carnegie Mellon University; Leora Morgenstern, IBM T.J. Watson Research; and Loren Terveen, AT&T Labs.   Panelists will include: Bonnie Holte Bennett , University of St. Thomas;  Claire Cardie, Cornell University;  Russell Greiner, University of Alberta,  Mary P. Harper, Purdue University;  Evangelos E. Milios, Dalhousie University; Raymond J. Mooney, University of Texas at Austin;  Leora Morgenstern, IBM T.J. Watson Research; and Nils J. Nilsson, Stanford University.<br/>"
9708559,"Doctoral Consortium for Students in AI; July 28, 1997;      Providence, RI",IIS,HUMAN COMPUTER INTER PROGRAM,4/1/1997,12/22/1997,Bruce Buchanan,"Buchanan, B","Buchanan, B",PA,University of Pittsburgh,Standard Grant,Gary W Strong,3/31/1998,"$11,920.00 ",,buchanan@cs.pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,6845,"9216, HPCC",$0.00 ,exceptionalFunding,"One  of  the most important aspects in learning  how  to  do  research  is  early  and  detailed  discussions  on  various  aspects  of  the  research  plan with  experienced  mentors.  Unfortunately,  most students get little feedback  on  their  thesis  at  the  initial stages except from their  immediate  advisors.  Attending conferences can be a good way  to  meet  other researchers and discuss work.  However, the chances of  a  student  at  an early stage of his/her work  getting  the  opportunity  to  discuss their preliminary ideas  with  well  established  researchers are not very  good.   The  Doctoral  Consortium  (DC) at the American Association for  Artificial  Intelligence conference was planned as a way to improve this  situation.   Students about to begin their thesis  work  are  chosen  to present their research plans in front of a  group  of carefully selected faculty panelists.  Unlike traditional  conference presentations, the bulk of the time in  a  DC  is  devoted  to discussions between the students and the faculty  panelists.   Each student is also assigned a faculty  mentor  who  works  with  the  student at  a  more  detailed  level.  Students learn from both their own presentations as well  as  watching  other  students  being  advised  by  the   faculty  panelists.  A survey taken after the first DC held last year  found  all participants (both students and faculty) agreeing  that the DC was tremendously useful.  We anticipate that all  students  attending the DC this year (both as presenters  as  well  as  those  just  attending) will  leave  with  renewed  confidence  in  their work, suggestions for improving  their  thesis  plans  and  a clearer idea of what constitutes  good  research practice."
1727336,Doctoral Dissertation Research: The interaction of expectations and evidence in pragmatic inference and generalizations,BCS,DDRI Linguistics,8/1/2017,7/20/2017,Chigusa Kurumada,"Kurumada, C","Kurumada, C|Pogue, A",NY,University of Rochester,Standard Grant,William J. Badecker,1/31/2019,"$11,813.00 ",Amanda Pogue,ckuruma2@ur.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,SBE,8374,"1311, 9179",$0.00 ,exceptionalFunding,"Spoken language not only communicates information about a speaker's thoughts or desires; it also conveys information about the speaker's identity. By simply listening to speakers' voices, accents, and word choice, we can learn a great deal about them, in addition to what is being talked about. Previous studies of language processing, however,???have almost exclusively focused on the linguistic signal abstracted from individual speakers, investigating what listeners think is true about the world based on what an individual speaker has said. The project aims to???explore the mechanism by which listeners extract information about the speaker???through processing the linguistic signal. It then addresses the question of whether, and if so how, the increased knowledge about the speaker facilitates language comprehension.???This research, consequently allows researchers to build a foundation for exploring how???young children may learn speaker differences, which can contribute to new pedagogical???tools for helping children to better interact with, and learn from, diverse populations.???Secondly, the work will likely have industry applications for artificial intelligence technology,???allowing it to better adapt its functionality to an individual user's talking style.???<br/><br/>This dissertation project employs two approaches to investigating what information listeners extract from spoken utterances. First,???a large-scale online survey???technique will be used to solicit responses from participants from a wider variety of linguistic???and cultural backgrounds than those included in previous studies. Participants are exposed to utterances produced by???two speakers and subsequently answer questions that probe their sensitivity to across-speaker differences. In the second set of experiments, a combination of???an artificial language learning???paradigm???and an eye-tracking methodology will be used to study real-time language comprehension behaviors.???Listeners' eye-gaze will be used to gain fine-grained information about???the real-time development of???their linguistic expectations. By combining these experimental approaches,???the researchers elucidate???how the human language comprehension system derives fine-grained???expectations for future linguistic???input and how the mechanism develops as a function of increased knowledge about linguistic communication."
1338935,Planning Grant:  I/UCRC for Semantic Computing,IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2013,8/9/2013,Mihaela van der Schaar,"Schaar, Mvd","Schaar, Mvd|Zame, W|Alwan, A|Xiao, H",CA,University of California-Los Angeles,Standard Grant,Thyagarajan Nandagopal,1/31/2015,"$11,500.00 ","William Zame, Abeer Alwan, Hu Xiao",mihaela@ee.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,ENG,5761,"5761, 8039",$0.00 ,exceptionalFunding,"Semantic Computing (SC) is an emerging field that addresses computing technologies which allow users to search, create, manipulate and connect computational resources. The research efforts will be anchored by the University of California-Irvine as the lead institution, partnered with the University of California-Los Angeles and the University of California-San Diego. <br/><br/>Semantic Computing includes the computing technologies (e.g., artificial intelligence, natural language, software engineering, data and knowledge engineering, computer systems, signal processing, etc.), and their interactions, that may be used to extract or process computational content and descriptions. The proposed I/UCRC will focus on providing technologies that lead to a Semantic Problem Solving (SPS) network where distributed resources can be easily connected based on semantics for the purpose of problem solving. While some areas of Semantic Computing have appeared as isolated pieces in individual disciplines, Semantic Computing glues these pieces together into an integrated theme with synergetic interactions. It addresses not only the analysis and transformation of signals (e.g., pixels, words) into useful information, but also how such information can be accessed and used to synthesize new signals. The three proposed campuses have complementary areas of strength and have emphasized different aspects of Semantic Computing systems. All participating faculty are prominent researchers in one or more areas related to Semantic Computing. <br/><br/>The technologies developed by the proposed I/UCRC may support new inter-connectivity that has not been realized by the Internet today. It therefore may facilitate the transition of the Internet into Web 3.0 and stimulate new business models for a better economy that everyone can benefit. The technologies developed by the proposed I/UCRC will be delivered to the public via the Internet, and the PIs expect to create broader impacts in areas other than the five selected. The five areas are chosen as they characterize different aspects of problem solving, e.g., creativity (IT, entertainment), learning (education) and decision making (health, finance), which are applicable to many other areas such as manufacturing, science, engineering, and the humanities."
1338934,Planning Grant:  I/UCRC for Semantic Computing,CNS,INDUSTRY/UNIV COOP RES CENTERS,8/15/2013,8/9/2013,Shlomo Dubnov,"Dubnov, S","Dubnov, S",CA,University of California-San Diego,Standard Grant,Thyagarajan Nandagopal,7/31/2015,"$11,499.00 ",,sdubnov@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,5761,"5761, 8039",$0.00 ,exceptionalFunding,"Semantic Computing (SC) is an emerging field that addresses computing technologies which allow users to search, create, manipulate and connect computational resources. The research efforts will be anchored by the University of California-Irvine as the lead institution, partnered with the University of California-Los Angeles and the University of California-San Diego. <br/><br/>Semantic Computing includes the computing technologies (e.g., artificial intelligence, natural language, software engineering, data and knowledge engineering, computer systems, signal processing, etc.), and their interactions, that may be used to extract or process computational content and descriptions. The proposed I/UCRC will focus on providing technologies that lead to a Semantic Problem Solving (SPS) network where distributed resources can be easily connected based on semantics for the purpose of problem solving. While some areas of Semantic Computing have appeared as isolated pieces in individual disciplines, Semantic Computing glues these pieces together into an integrated theme with synergetic interactions. It addresses not only the analysis and transformation of signals (e.g., pixels, words) into useful information, but also how such information can be accessed and used to synthesize new signals. The three proposed campuses have complementary areas of strength and have emphasized different aspects of Semantic Computing systems. All participating faculty are prominent researchers in one or more areas related to Semantic Computing. <br/><br/>The technologies developed by the proposed I/UCRC may support new inter-connectivity that has not been realized by the Internet today. It therefore may facilitate the transition of the Internet into Web 3.0 and stimulate new business models for a better economy that everyone can benefit. The technologies developed by the proposed I/UCRC will be delivered to the public via the Internet, and the PIs expect to create broader impacts in areas other than the five selected. The five areas are chosen as they characterize different aspects of problem solving, e.g., creativity (IT, entertainment), learning (education) and decision making (health, finance), which are applicable to many other areas such as manufacturing, science, engineering, and the humanities."
1545471,2015 Association for Computational Linquistics (ACL) Student Research Workshop,IIS,ROBUST INTELLIGENCE,7/1/2015,5/28/2015,Emily Bender,"Bender, E","Bender, E",WA,University of Washington,Standard Grant,Tatiana D. Korelsky,6/30/2017,"$10,500.00 ",,ebender@u.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing.  It also is one of the primary application areas for researchers in machine learning and artificial intelligence.  The proceedings of its annual meeting provide the foundation of the field; it is the most cited and most respected publication in computational linguistics.  Thus, it is also the most important gathering of researchers in computational linguistics and natural language processing.  ACL has a twenty-year history of including a Student Research Workshop, which helps create a new generation of researchers with a more thorough understanding of their field, with connections and collaborations across institutions, and with innovative and exciting research programs.  This contributes to America's pool of researchers with the needed scientific and engineering knowledge and skills. The workshop encourages a spirit of collaborative research and builds a supportive environment for a new generation of computational linguists. To this end, the grant will subsidize travel, registration and accommodation expenses for student participants and organizers traveling from the US to the ACL in Beijing.<br/><br/>The student research workshop will be a part of the 2015 meeting of the ACL held in Beijing, China from July 27 to July 29.  The workshop will solicit submissions in two categories: (1) thesis proposals for advanced students who have decided on a thesis topic and wish to receive feedback and (2) research papers describing completed work or work in progress with significant preliminary results.  Each accepted paper will be assigned an established research mentor who will meet with the student during the conference to provide individual feedback.  Both paper types will be presented in the poster session of the main conference.  The Student Research Workshop enriches the intellectual life of the participating students.  Each student is mentored by an experienced researcher; this not only shapes the student's specific project but helps build the student's awareness of the field.  The students gain exposure by presenting their work earlier than they would otherwise (i.e., in a form not yet ready for the main conference).  This is particularly valuable for researchers from smaller institutions and undergraduate students. The student organizers also benefit from the organization of the workshop, gaining experience with the full process from soliciting reviewers, to managing the review process, producing the proceedings, and running the event.  They also build connections with the senior researchers who participate as mentors in the event.  This grant will subsidize the travel, conference registration and lodging for both student participants and student organizers."
1313847,WORKSHOP: Student Consortium at the 2013 ACM Conference on Intelligent User Interfaces,IIS,Cyber-Human Systems (CHS),2/1/2013,1/17/2013,Henry Lieberman,"Lieberman, H","Lieberman, H",MA,Massachusetts Institute of Technology,Standard Grant,Ephraim P. Glinert,1/31/2015,"$10,368.00 ",,lieber@media.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7367,"7367, 7556",$0.00 ,exceptionalFunding,"This is funding to provide financial support for 10 graduate students (at least 8 of them registered at U.S. universities and working towards either their Master's degree or a Doctorate) to attend the 2013 International Conference on Intelligent User Interfaces (IUI 2013), to be held March 19-22 in Santa Monica, California, as participants in a special Student Consortium (workshop), as presenters in the main conference, and as attendees at the conference for general training purposes. Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent and interactive user interfaces; they are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place. Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter. Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc. IUI 2013 will be the 16th conference in the series; topics of interest this year include: intelligent interactive interfaces, systems, and devices; ubiquitous interfaces; smart environments and tools; human-centered interfaces; mobile interfaces; multimodal interfaces; pen-based interfaces; spoken and natural language interfaces; conversational interfaces; affective and social interfaces; tangible interfaces; collaborative multi-user interfaces; adaptive interfaces; sensor-based interfaces; user modeling and interaction with novel interfaces and devices; interfaces for personalization and recommender systems; interfaces for plan-based systems; interfaces that incorporate knowledge- or agent-based approaches; help interfaces for complex tasks; example- and demonstration-based interfaces; interfaces for intelligent generation and presentation of information; intelligent authoring systems; synthesis of multimodal virtual characters and social robots; interfaces for games and entertainment; for learning-based interactions and for health informatics; empirical studies and evaluations of IUI interfaces; and new approaches to designing intelligent user interfaces. More information about the conference is available online at http://iuiconf.org/. <br/><br/>The IUI 2013 Student Consortium will build on the success of the first such event last year. The heart of the Consortium will be a full-day workshop on March 19, immediately preceding the conference, and will be structured to give student trainees exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of 4-5 senior researchers. Group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors. The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field. The IUI conference organizers will pay for audio-visual services, two coffee breaks, and space for accommodating attendees in the student session; no funds are requested for these items from NSF.<br/><br/>Broader Impacts: This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons. It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement. The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants. The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference. The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community. Women, minority students, the disabled, and veterans all will be encouraged to participate. To further assure diversity, no more than one student will be accepted from any given institution."
315909,Creating the First International Probabilistic Planning Competition,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/1/2003,5/5/2003,Michael Littman,"Littman, M","Littman, M",NJ,Rutgers University New Brunswick,Standard Grant,Edwina L. Rissland,4/30/2004,"$10,232.00 ",,mlittman@cs.brown.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,6856,"6846, 9218, HPCC",$0.00 ,exceptionalFunding,"This small planning grant will support efforts to launch the first international probabilistic planning competition, slated to be held in conjunction with the 2004 International Conference on Automated Planning and Scheduling (ICAPS-04).  The competition is being organized as a parallel track of the Fourth International Planning Competition (IPC) at ICAPS-04.  The IPC was first held in 1998 in conjunction with the Artificial Intelligence Planning and Scheduling conference (AIPS).  Follow-up competitions were held in 2000 and 2002, and it is widely believed that the competitions have been enormously valuable to the planning community, spurring advances in algorithms and representations and rapidly disseminating them throughout the field.<br/><br/>The organizers of ICAPS-04 will be hosting the 4th IPC, which has focused exclusively on classical planning, involving sequential decision making when the effects of all decisions are deterministic.  Over the past decade, as computers have become more and more integrated with the physical world, researchers have begun to study models that can represent the inherent uncertainty present in the effects of many decisions.  In this setting, plans are evaluated by how likely they are to achieve desired outcomes.  The dominant mathematical model in this community is the Markov decision process (MDP) model, and there are research groups all over the world studying MDPs for planning.  However, progress in the field is inhibited by the lack of a unified metric for progress and little sharing of results between groups.  A probabilistic planning competition could give the probabilistic planning community a much needed opportunity to come together and move forward.  <br/><br/>This award will support adaptation of a plan validator program and travel to facilitate organizing of the competition.  Its broader impacts include training a graduate student and improvement of computerized planning systems to plan many kinds of real-world activities.<br/><br/>"
813924,The Third Northeast Student Colloquium on Artificial Intelligence,IIS,ROBUST INTELLIGENCE,4/1/2008,2/29/2008,Joseph Halpern,"Halpern, J","Halpern, J",NY,Cornell University,Standard Grant,Douglas H. Fisher,3/31/2009,"$10,000.00 ",,halpern@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7495,"0000, 7495, OTHR",$0.00 ,exceptionalFunding,"This award will help to subsidize the participation of graduate students in the third Northeast Student Colloquium on Artificial Intelligence (NESCAI) to be held May 2-4, 2008 at Cornell University in Ithaca, New York. This conference is to include oral and poster presentations by students and invited talks and tutorials by senior AI researchers. The conference will be largely run by a program committee consisting of doctoral students under the guidance of senior faculty. The program committee will conduct a review process to select the projects chosen for oral and poster presentations. In addition to graduate students, the conference plans to encourage attendance by a few outstanding senior undergraduates in the hope that it will increase their enthusiasm for research and thus the likelihood that they will go on to graduate work. The project integrates research and education and commits to broadening diversity."
444023,Preplanning Workshop for US 5th Anniversary of Artificial Intelligence,IIS,ARTIFICIAL INTELL & COGNIT SCI,10/1/2004,9/16/2004,James Hendler,"Hendler, J","Hendler, J",MD,University of Maryland College Park,Standard Grant,Tatiana D. Korelsky,9/30/2006,"$10,000.00 ",,hendler@cs.rpi.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,CSE,6856,"9218, HPCC",$0.00 ,exceptionalFunding,"This grant supports participants in two one-day meetings to be held at the University of Maryland during the Fall of 2004 and Winter of 2005. The purpose of these meetings will be to discuss and plan for symposia, workshops, and other events in 2006 to mark the approximately 50 years of research and experience in the field of Artificial Intelligence. Participants will discuss ways to mark progress in AI, assess the current state of the art, and single out key areas for future work. In addition to planning how to mark a historical moment with appropriate activities, the participants in these meetings will discuss activities that can serve as a springboard for the field to focus on new challenges and directions. The results of these meetings will have impact across the entire spectrum of the AI community, including seasoned researchers, current doctoral, and undergraduate students, as well as other areas of computer science, historians of science, and the public at large, which is often not well versed in the goals, accomplishments, and history of AI."
1637547,RI:   Doctoral Student Consortium at the Twenty Fourth International Conference on Case-Based Reasoning,IIS,ROBUST INTELLIGENCE,7/15/2016,7/17/2018,Ashok Goel,"Goel, A","Goel, A",GA,Georgia Tech Research Corporation,Standard Grant,James Donlon,12/31/2018,"$10,000.00 ",,ashok.goel@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This project will support of the Doctoral Student Consortium at the Twenty Fourth International Conference on Case-Based Reasoning (ICCBR'16) to be held at Georgia Institute of Technology in Atlanta, USA, from October 31st through November 2nd 2016. ICCBR is an international conference series covering all aspects of research on case-based reasoning, such as memory, problem solving, decision making, learning, recommender systems, analogy, creativity, and applications in industry, business and government. Research on case-based reasoning often is interdisciplinary, with connections to artificial intelligence and intelligent agents, cognitive science and cognitive computing, human-centered computing and interactive systems, and human learning as well as machine learning.<br/><br/>With the resurgence of cognitive systems cognitive computing as evidenced by IBM's Watson system and Apple?s Siri program among many others, the ICCBR community is growing once again. The ICCBR conferences attempt to foster research carried out in the original spirit of AI, which aimed to design and implement computer programs that exhibited the breadth, generality, and flexibility often observed in human intelligence on one hand, and use the design of AI systems for insights into human intelligence on the other. We expect ICCBR'16 to significantly increase our understanding of case-based cognitive systems, and add momentum to the development of new theories, techniques and tools for case-based cognitive computing. The conference sessions and workshops will help develop human research capital by enabling interactions between senior and junior researchers and catalyzing new collaborations. The doctoral consortium will increase the exposure and visibility of young graduate student researchers in these areas, and train them by providing early input and feedback in the field in an interactive and constructive environment."
9815915,1998 AAAI Sigman Workshop,IIS,ARTIFICIAL INTELL & COGNIT SCI,8/15/1998,8/11/1998,William Regli,"Regli, W","Regli, W",PA,Drexel University,Standard Grant,Ephraim P. Glinert,7/31/1999,"$10,000.00 ",,regli@umd.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"Partial funding is being awarded for the 1998 Artificial Intelligence and Manufacturing Workshop.    Artificial Intelligence concepts and techniques continue to find favor - and offer even more promise - in   manufacturing, and these applications and potential applications continue to provide challenging drivers   for fundamental research in the field. This workshop follows another in 1996, and surveys progress, as   well as problems still outstanding.  The development of intelligent computer integrated design and   manufacturing systems is still on the horizon, but meetings like this to evaluate the state of the art and   practice and discuss particulars of needed research, the advance toward that horizon can more efficiently   be undertaken."
1545721,"RI: Student Travel Support for the 2015 International Conference on Case-Based Reasoning; September 28-30, 2015; Frankfurt, Germany",IIS,"INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE",8/1/2015,7/20/2015,David Wilson,"Wilson, D","Wilson, D",NC,University of North Carolina at Charlotte,Standard Grant,James Donlon,7/31/2017,"$10,000.00 ",,davils@uncc.edu,9201 University City Boulevard,CHARLOTTE,NC,282230001,7046871888,CSE,"1640, 7495","7495, 7556",$0.00 ,exceptionalFunding,"This proposal provides international and domestic travel support for U.S. based student participants to attend the 23rd International Conference on Case-Based Reasoning (ICCBR 2015), which will take place from the 28th to 30th of September 2015 in Frankfurt am Main, Germany. ICCBR is the premier, annual meeting of the Case-Based Reasoning (CBR) community and the primary international conference on this topic, bringing together researchers across artificial intelligence, machine learning, cognitive science, and domain application areas.  The CBR community welcomes interdisciplinary participation and experts from industry and other related academic areas.  ICCBR has a rich history of encouraging strong student participation in the conference program.  Today's students are tomorrow's international leaders in the research community.  As part of this, the ICCBR organizers aim to facilitate and encourage student participation by providing support for students to attend the conference.  In addition to the main technical program, the conference features opportunities for student participation and mentoring, including themed workshops, an application domain challenge competition, and the 7th in a successful doctoral consortium series.  A strong representation of U.S. based researchers, and students in particular, is useful in maintaining U.S. scientific and technical competitiveness in the field and also contributes to the career development of the students.<br/> <br/><br/>ICCBR is the premier conference in the field of Case-Based Reasoning and has contributed significantly to scientific and industry advances across the broader areas of artificial intelligence, cognitive science, and cognate disciplines since 1993. ICCBR provides a dynamic and comprehensive program for research, education, publication, and interaction; it is a leading international forum for CBR researchers, students, and practitioners to exchange and discover leading-edge ideas, results, tools, techniques, and experiences.  The intellectual merit of the proposal is to (1) expand the technical content, scope and depth of this forum by supporting and encouraging greater student attendance and participation; (2) foster technical advances in the field through the greater training and collaboration opportunities afforded by direct student participation in the conference. This project will provide partial support for students from U.S. institutions to attend and present research work at ICCBR 2015. ICCBR student travel support will encourage the research interests and involvement of students in the field, particularly those who are at early stages of their research or without current funding sources that might otherwise limit their participation. ICCBR 2015 students will have the opportunity to participate in the following interactive activities as partially supported by this project: main technical program, focus-area workshops, the computer cooking contest, face-to-face meetings with both peers and leading researchers, as well as a doctoral consortium. These opportunities will have a long lasting impact on the future career of the participants. The primary broader impact is to help train the future generation of leaders and workforce in the field; in turn, this will plant the seeds for future innovation and help to shape the field itself.<br/> <br/>"
1792,Workshop:  Support for Student Travel to AID,IIS,ARTIFICIAL INTELL & COGNIT SCI,5/1/2000,5/4/2000,David Brown,"Brown, D","Brown, D",MA,Worcester Polytechnic Institute,Standard Grant,Ephraim P. Glinert,3/31/2001,"$10,000.00 ",,dcb@cs.wpi.edu,100 INSTITUTE RD,WORCESTER,MA,16092247,5088315000,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This is funding to subsidize travel and housing expenses of students attending the 6th International Conference on Artificial Intelligence in Design, to be held June 26-29, 2000, at WPI.  Design is an important research topic in engineering and architecture.  It is the key to economic competitiveness and the fundamental precursor to manufacturing.  However, our understanding of design as a process and our ability to model it are still very limited.  This conference series aims to provide an international forum for the presentation and discussion of state-of-the-art, cutting edge research and developments in artificial intelligence in design.  Held every two years, this conference is the premier one in the field, attracting about 150 participants from over 10 different countries.  The current funding will provide up to 50% travel support for student attendees, and will afford them an important opportunity to present their research, to hear about the latest results and research thrusts, and to interact with peers in the international, interdisciplinary AI-in-Design community."
1743637,Symposium on Combinatorial Search - 2017,IIS,ROBUST INTELLIGENCE,5/15/2017,6/5/2017,Nathan Sturtevant,"Sturtevant, N","Sturtevant, N",CO,University of Denver,Standard Grant,James Donlon,4/30/2019,"$10,000.00 ",,sturtevant@cs.du.edu,2199 S. University Blvd.,Denver,CO,802104711,3038712000,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This grant supports student travel for select students and post-doctoral researchers to participate in the Symposium on Combinatorial Search (SoCS-2017) June 16-17 in Pittsburgh, PA.  SoCS is an annual event that brings together researchers in heuristic search and combinatorial optimization drawing from diverse areas of artificial intelligence, planning, robotics, constraint programming, operations research, bioinformatics, and computer games. This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research.  <br/><br/>Sponsoring student travel to SoCS fosters a community of researchers from otherwise diverse areas of computer science to both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  Students participating in this symposium are also more likely to take full advantage of the top-tier conference in the International Conference on Automated Planning and Scheduling (ICAPS) 2017 taking place immediately prior to this symposium, and co-located with it.  The entire event provides an opportunity for students to engage in discussion with scientists from around the world and to explore new research directions and topics."
733961,"I/UCRC Planning Grant: Safety, Security and Rescue Robots",IIP,INDUSTRY/UNIV COOP RES CENTERS,9/1/2007,7/17/2007,Paul Oh,"Oh, P","Oh, P",PA,Drexel University,Standard Grant,Rathindra DasGupta,8/31/2008,"$10,000.00 ",,paul.oh@unlv.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,ENG,5761,"0000, 1049, 122E, OTHR",$0.00 ,exceptionalFunding,"A planning meeting will be held to determine if Drexel University will become a research site of the existing Industry/University Cooperative Research Center for Safety, Security and Rescue Research Center (SSR-RC).  This center brings together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions for activities conducted by the police, FBI, FEMA, firefighters, transportation safety officials, and emergency responders to mass casualty-related activities.  Drexel University is well postured to provide expertise in unmanned aerial vehicles, civilian medical response to bioterrorism and applied communications and intelligent networking.<br/><br/>Safety and security robotics will provide proactive technologies to permit disasters, either natural or man-made, while rescue robotics will enable more effective responses to mass-casualty incidents.  It will nurture an emerging field of research and the associated industries, helping to establish the challenges of the field and acceptable research and evaluation methodologies.<br/><br/>"
522637,"The Nature and Function of Causal Thinking, Fall 2005; California Institute of Technology",SES,Hist & Philosophy of SET,8/1/2005,7/27/2005,James Woodward,"Woodward, J","Woodward, J|Hitchcock, C",CA,California Institute of Technology,Standard Grant,Frederick M Kronz,7/31/2006,"$10,000.00 ",Christopher Hitchcock,jfw@hss.caltech.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,SBE,1353,"0000, OTHR",$0.00 ,exceptionalFunding,"Funding is requested for a workshop on ""The Origins and Functions of Causal Thinking ""to be held at the California Institute of Technology in Fall, 2005. This workshop will be the second in a series of international workshops on the topic, and will focus on the connection between causation, agency, and intervention.<br/> Intellectual Merit.<br/> The workshop will bring together an international body of scholars from different disciplines, including philosophy, cognitive psychology,developmental psychology, primatology, and artificial intelligence to explore issues having to do with the structure, functions and origins of causal concepts and reasoning. The rationale for the workshop is that there are rapidly growing bodies of research in all of these disciplines that address common themes, but which have proceeded in isolation from one another. Researchers in all of these areas would benefit from more cross -disciplinary fertilization. Within philosophy, interventionist or agency oriented approaches show promise as accounts of causation as this notion figures in everyday life and in the social and biomedical sciences, but it is also unclear to what extent such approaches can be extended to cover causal notions as they figure in fundamental physics, and what follows for our understanding of the notion of causation and its place in human life if they cannot. Empirical studies of causal learning in children, adults and non-human primates suggest that the human ability to learn from interventions, as well as our ability to combine such with information obtained from passive observation, is central to human causal cognition and to what distinguishes this from the abilities of non-human animals. For all of these reasons a conference devoted to the exploration of issues related to the connections between causation, agency and intervention will have a very large intellectual pay-off and should help to shape future work in this interdisciplinary field in important ways.<br/><br/> Broader Impact. <br/><br/>Many of the participants in the workshop will be women. The<br/>workshop will be open to all interested researchers and the results will be made available to a wider public in the form of an edited volume entitled, The Origins and Functions of Causal Thinking. More generally, a better understanding of the nature of causal reasoning in humans, of the purposes to which causal reasoning is put, and of the nature of causation itself, may ultimately help to enhance people's ability to engage in causal reasoning. Current evidence suggests that people are in fact very good at learning about causal relationships among phenomena that they can directly observe or control. At the same<br/>time people are often very bad judges of causal relationships when presented with information in a more abstract form (such as of statistical data). A better understanding o fhow people reason about causation might be used to improve educational practice in disciplines (including any area of science) that focus on the provision of specific kinds of causal understanding. Moreover, citizens in a participatory democracy are often required to pass judgment on competing policy proposals. Doing so requires an understanding of the way in which the implementation of a new policy constitutes an intervention in existing causal structures, and of what the effects of such a disruption will be. An enhanced understanding of causal reasoning may enable us to better educate citizens on  policy issues and enable them to make decisions that are better informed.<br/><br/>"
831110,Collaborative Research: Establishing an I/UCRC Center for Multicore Productivity Research (CMPR),IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2008,8/9/2009,David Bader,"Bader, D","Bader, D|Clark, N|Gavrilovska, A|Vuduc, R",GA,Georgia Tech Research Corporation,Standard Grant,Rathindra DasGupta,10/31/2009,"$10,000.00 ","Nate Clark, Ada Gavrilovska, Richard Vuduc",bader@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,ENG,5761,"0000, 1049, 122E, OTHR",$0.00 ,exceptionalFunding,"0831875 University of Maryland, Baltimore County (lead institution) - Milton Halem <br/>0831358 University of California, San Diego - Sheldon Brown <br/>0831110 Georgia Institute of Technology - David Bader <br/>     <br/>The objective of this planning grant proposal is to establish a ""Center of Multicore Productivity Research"" (CMPR). The CMPR consists of sites at the University of Maryland, Baltimore County, the Georgia Institute of Technology, and the University of California, San Diego. The proposed center will develop, test and optimize prototype formulations of computationally intensive applications and systems relevant to industry and government partnering sponsors on emerging multicore processors.  The proposed work addresses a real-world problem, and there is a number of processor-intensive computer processes that can benefit immediately from this technology.  The unifying theme uniting these separate research institutions into a Center for Multicore Productivity Research is their synergistic computational research endeavors in multicore computing, available multicore processor resources and the expertise of their staffs to support the computer science inherent in the parallel processing algorithms that are required to optimize the performance and scalability of intensive computations.<br/><br/>The broader impact of CMPR addresses the future needs of the computer industry as this new multi core processor technology evolves. Breakthroughs in multi core productivity will enable real-time use of more sophisticated artificial-intelligence based control systems, providing additional productivity savings to multiple manufacturing and process industries. All CMPR sites are incorporating multicore computing into their core course curricula, and CMPR plans to significantly expand the number of industry or government organizations sponsoring relevant student research.  CMPR also plans to capitalize on its relationships with local schools to provide opportunities for high school educators and students to participate in projects at the center.  The collaboration with Maryland public schools and the charter school at UCSD are highly innovative.  The Meyerhoff program and the Georgia Tech interaction with Atlanta area HCBUs should provide an excellent source for research students. <br/>"
1643098,"The 22nd International Conference on Computing in High Energy and Nuclear Physics, CHEP 2016; October 10-14, 2016 in Marriott Marquis, San Francisco",PHY,COMPUTATIONAL PHYSICS,8/1/2016,7/29/2016,Lauren Tompkins,"Tompkins, L","Tompkins, L",CA,Stanford University,Standard Grant,Bogdan Mihaila,7/31/2017,"$10,000.00 ",,laurenat@stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,MPS,7244,"7433, 7569, 8084",$0.00 ,exceptionalFunding,"This project will allow for partial support for students participating in the 22nd International Conference on Computing in High Energy and Nuclear Physics, CHEP 2016, that will be held in San Francisco, October 10-14, 2016. CHEP is a global conference with participation by leaders in physics, computing, and large-scale data analysis from the top universities and laboratories around the world. The CHEP speakers will address challenges in computing, networking and software for the world's leading data-intensive science experiments. The participation of students in this conference is important for training purposes and future workforce development activities. <br/><br/>CHEP 2016 is organized jointly by Stanford University, SLAC National Accelerator Laboratory (SLAC) and Lawrence Berkeley National Laboratory (LBNL). Approximately 600 computing experts and scientists are expected to attend CHEP 2016 with strong participation from the science programs at CERN, Fermilab and other major experimental facilities. CHEP 2016 will exploit this environment to stress the increasing importance of the computing-related connections between high-energy and nuclear physics and data-intensive astronomy, X-ray science and computational science. The program spans a wide range of subjects including trigger, data acquisition and control systems, reconstruction and data analysis algorithms, data processing workflows and computing models, artificial intelligence, network systems and security, and many additional topics."
831358,Collaborative Research: Establishing an I/UCRC Center for Multicore Productivity Research (CMPR),IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2008,8/11/2008,Sheldon Brown,"Brown, S","Brown, S",CA,University of California-San Diego,Standard Grant,Rathindra DasGupta,7/31/2009,"$10,000.00 ",,sgbrown@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,ENG,5761,"0000, 1049, 122E, OTHR",$0.00 ,exceptionalFunding,"0831875 University of Maryland, Baltimore County (lead institution) - Milton Halem <br/>0831358 University of California, San Diego - Sheldon Brown <br/>0831110 Georgia Institute of Technology - David Bader <br/>     <br/>The objective of this planning grant proposal is to establish a ""Center of Multicore Productivity Research"" (CMPR). The CMPR consists of sites at the University of Maryland, Baltimore County, the Georgia Institute of Technology, and the University of California, San Diego. The proposed center will develop, test and optimize prototype formulations of computationally intensive applications and systems relevant to industry and government partnering sponsors on emerging multicore processors.  The proposed work addresses a real-world problem, and there is a number of processor-intensive computer processes that can benefit immediately from this technology.  The unifying theme uniting these separate research institutions into a Center for Multicore Productivity Research is their synergistic computational research endeavors in multicore computing, available multicore processor resources and the expertise of their staffs to support the computer science inherent in the parallel processing algorithms that are required to optimize the performance and scalability of intensive computations.<br/><br/>The broader impact of CMPR addresses the future needs of the computer industry as this new multi core processor technology evolves. Breakthroughs in multi core productivity will enable real-time use of more sophisticated artificial-intelligence based control systems, providing additional productivity savings to multiple manufacturing and process industries. All CMPR sites are incorporating multicore computing into their core course curricula, and CMPR plans to significantly expand the number of industry or government organizations sponsoring relevant student research.  CMPR also plans to capitalize on its relationships with local schools to provide opportunities for high school educators and students to participate in projects at the center.  The collaboration with Maryland public schools and the charter school at UCSD are highly innovative.  The Meyerhoff program and the Georgia Tech interaction with Atlanta area HCBUs should provide an excellent source for research students. <br/>"
938402,Individual:  Fueling the STEM Pipeline by Mentoring Across the Age Span,DUE,PRES AWDS FOR EXCELL IN SCI,8/15/2011,5/15/2015,Maja Mataric,"Mataric, M","Mataric, M",CA,University of Southern California,Standard Grant,Martha L. James,7/31/2016,"$10,000.00 ",,mataric@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,EHR,1593,"9178, SMET",$0.00 ,exceptionalFunding,"Dr. Maja Mataric received her Ph.D. in Computer Science and Artificial Intelligence from MIT in 1994. She is Professor of Computer Science and  Neuroscience, and Pediatrics Director of the Center for Robotics and Embedded Systems, Co-Director of the Robotics Research Lab, and Senior Associate Dean for Research at the Viterbi School of Engineering at the University of Southern California. Dr. Mataric has established a mentoring philosophy that encompasses the need to encourage students continuously as they progress in their educations. Her stated philosophy is that mentoring must be viewed as a pipeline process, in which role models and training opportunities are provided from as early as possible and the pipeline is continually fueled. The pipeline mentoring program is based on the established literature about critical times for capturing interest and recruiting women and underrepresented students into STEM areas. To build the pipeline, the comprehensive spectrum of mentoring activities performed to date span: K-12 STEM outreach and teacher training, undergraduate student mentoring toward placement in graduate programs, graduate and postdoctoral student mentoring and placement in academic positions, peer mentoring of female faculty, mentoring of junior faculty in engineering, and developing a culture of mentoring at USC. Dr. Mataric's mentoring programs have resulted in new courses and programs at the K-12 level that have trained generations of teachers and students and continue to recruit generations of inner-city at-risk students into STEM topics. Approaches have yielded the recruitment of underrepresented groups at each level, from all-girls elementary school teams winning robotics contests at the state level, to outstanding placement of Ph.D. students and postdoctoral fellows in academic positions, to outstanding outcomes in female faculty mentoring leading toward nationally competitive research grants, to developing novel mentoring programs with impact across the entire university. The programs have resulted in the placement of Ph.D. students in minority serving universities and of Ph.D. students from underrepresented groups (women and African Americans) in top research universities in the US and world-wide. The programs have also established a role-modeling and networking pipeline between the K-12 inner city institutions, USC undergraduates, Ph.D. students, and faculty. Dr. Mataric's mentoring programs have effectively aided in the recruitment and retention of women faculty in engineering at USC and have had a significant impact on institutional-wide cultural change."
332043,"Collaborative Research: Center for Safety, Security, and Rescue Robotics",IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2003,8/13/2003,Richard Voyles,"Voyles, R","Voyles, R|Roumeliotis, S|Gini, M|Papanikolopoulos, N",MN,University of Minnesota-Twin Cities,Standard Grant,alexander schwarzkopf,7/31/2004,"$10,000.00 ","Stergios Roumeliotis, Maria Gini, Nikolaos Papanikolopoulos",rvoyles@purdue.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,ENG,5761,"0000, OTHR",$0.00 ,exceptionalFunding,"This award supports the planning a multi-university, multi-disciplinary Industry/University Cooperative Research Center (I/UCRC) for Safety, Security and Rescue Robots (C-SSRR). C-SSRR will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions for activities conducted by the police, FBI, FEMA, firefighters, transportation safety officials, and emergency responders to mass casualty-related activities. The need for SSRR has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics in February 2003.<br/><br/>The Center will be built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at the University of South Florida and the University of Minnesota. Together, the two institutions support a research program in control of vehicles, human-robot interaction, and sensors and sensor fusion combined with rapid prototyping capabilities and access to users and high-fidelity testing sites throughout the country."
831875,Collaborative Research: Establishing an I/UCRC Center for Multicore Productivity Research (CMPR),IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2008,8/11/2008,Milton Halem,"Halem, M","Halem, M|Yesha, Y",MD,University of Maryland Baltimore County,Standard Grant,Rathindra DasGupta,7/31/2009,"$10,000.00 ",Yelena Yesha,halem@umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,ENG,5761,"0000, 1049, 122E, OTHR",$0.00 ,exceptionalFunding,"0831875 University of Maryland, Baltimore County (lead institution) - Milton Halem <br/>0831358 University of California, San Diego - Sheldon Brown <br/>0831110 Georgia Institute of Technology - David Bader <br/><br/>The objective of this planning grant proposal is to establish a ""Center of Multicore Productivity Research"" (CMPR). The CMPR consists of sites at the University of Maryland, Baltimore County, the Georgia Institute of Technology, and the University of California, San Diego. The proposed center will develop, test and optimize prototype formulations of computationally intensive applications and systems relevant to industry and government partnering sponsors on emerging multicore processors. The proposed work addresses a real-world problem, and there is a number of processor-intensive computer processes that can benefit immediately from this technology. The unifying theme uniting these separate research institutions into a Center for Multicore Productivity Research is their synergistic computational research endeavors in multicore computing, available multicore processor resources and the expertise of their staffs to support the computer science inherent in the parallel processing algorithms that are required to optimize the performance and scalability of intensive computations.<br/><br/>The broader impact of CMPR addresses the future needs of the computer industry as this new multi core processor technology evolves. Breakthroughs in multi core productivity will enable real-time use of more sophisticated artificial-intelligence based control systems, providing additional productivity savings to multiple manufacturing and process industries. All CMPR sites are incorporating multicore computing into their core course curricula, and CMPR plans to significantly expand the number of industry or government organizations sponsoring relevant student research. CMPR also plans to capitalize on its relationships with local schools to provide opportunities for high school educators and students to participate in projects at the center. The collaboration with Maryland public schools and the charter school at UCSD are highly innovative. The Meyerhoff program and the Georgia Tech interaction with Atlanta area HCBUs should provide an excellent source for research students."
332029,"I/UCRC Center for Safety, Security and Rescue Robotics (C-SSRR)",IIP,INDUSTRY/UNIV COOP RES CENTERS,10/1/2003,8/13/2003,Robin Murphy,"Murphy, R","Murphy, R",FL,University of South Florida,Standard Grant,alexander schwarzkopf,9/30/2004,"$10,000.00 ",,murphy@cse.tamu.edu,3702 Spectrum Blvd.,Tampa,FL,336129446,8139742897,ENG,5761,"0000, OTHR",$0.00 ,exceptionalFunding,"This award supports the planning a multi-university, multi-disciplinary Industry/University Cooperative Research Center (I/UCRC) for Safety, Security and Rescue Robots (C-SSRR). C-SSRR will bring together industry, academe, and public sector users together to provide integrative robotics and artificial intelligence solutions for activities conducted by the police, FBI, FEMA, firefighters, transportation safety officials, and emergency responders to mass casualty-related activities. The need for SSRR has accelerated in the aftermath of 9/11 and a new research community is forming, as witnessed by the first IEEE Workshop on Safety, Security and Rescue Robotics in February 2003.<br/><br/>The Center will be built upon the knowledge and expertise of multi-disciplinary researchers in computer science, engineering, industrial organization, psychology, public health, and marine sciences at the University of South Florida and the University of Minnesota. Together, the two institutions support a research program in control of vehicles, human-robot interaction, and sensors and sensor fusion combined with rapid prototyping capabilities and access to users and high-fidelity testing sites throughout the country."
1154889,Doctoral Dissertation Research: On Negotiating the Role of Computers in Developing Mathematical Proofs,SES,"SCIENCE, TECH & SOCIETY",3/15/2012,2/22/2012,Peter Galison,"Galison, P","Galison, P|Dick, S",MA,Harvard University,Standard Grant,Frederick M Kronz,2/28/2014,"$9,941.00 ",Stephanie Dick,galison@fas.harvard.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,SBE,7603,1353,$0.00 ,exceptionalFunding,"Introduction<br/>Digital computing changed mathematics at every level down to the core of mathematical practice, the search for proofs. This award supports doctoral dissertation research that traces how computers have been used in the development of proofs and how their use changed mathematical knowledge and practice in the United States. The project is motivated historically, anthropologically, and philosophically to explore the following questions. How are mathematical ideas related to the technologies with which they are discovered and explored? How is the cognitive work of mathematics altered by the introduction of computing? How is human intelligence understood through attempts to build reasoning machines? The period of interest begins in the mid-1950s with early Artificial Intelligence, and it concludes with the contemporary work of Fields medalist Vladimir Voevodksy. <br/><br/>Intellectual Merit<br/>This project engages the ongoing interest of Science Studies in knowledge making, especially at the interface between humans and machines. It will explore mathematical knowledge and its material dimensions, which has until now been largely unexplored. Using archival materials, interviews, and technical documents including operations manuals and source code, the doctoral candidate will explore transformations in the institutional setting, material constitution, practices, and cognitive landscape of mathematical research that manifested around the digital computer. The intellectual merit of this project lies in its synthesizing and intervening in theoretical scholarship from science studies, history of mathematics, history of technology, and history of science (often pursued separately). <br/><br/>Potential Broader Impact<br/>The significance of computer proof assistance in mathematical research is intensifying. This project can assist current researchers and funding agencies in the assessment and pursuit of new projects in light of past research and historical context. Further, an analysis of the multifarious past and present strategies for using computing in mathematics can suggest new possibilities for using computer assistance in other disciplines that may otherwise be unaware of them."
9724058,"US-Pakistan Workshop:  Motion-Based Recognition,            Karachi, Pakistan, Jan. 1998",OISE,"AFRICA, NEAR EAST, & SO ASIA",8/1/1997,7/25/1997,Mubarak Shah,"Shah, M","Shah, M",FL,University of Central Florida,Standard Grant,Osman Shinaishin,7/31/1999,"$9,500.00 ",,shah@eecs.ucf.edu,4000 CNTRL FLORIDA BLVD,ORLANDO,FL,328168005,4078230387,O/D,5976,"5943, 9216, HPCC",$0.00 ,exceptionalFunding,"  Description: This award is for support of US scientists' participation in a `US-Pakistan Workshop on Motion-Based recognition`, to be held in January 1998, in Karachi, Pakistan.  The US team leader is Dr. Mubarak Shah, Department of Computer Science at the University of Central Florida in Orlando.   The Pakistani co-organizer is Dr. Javaid Laghari, of the Shaheed Zulfikar Ali Bhutto Institute of Science and Technology in Karachi, Pakistan.  The areas to be emphasized in the workshop include: cyclic motion detection, activity recognition, event recognition, lip-reading, gesture recognition, and facial expression recognition.  The proceedings, including the technical presentations and the recommendations, will be published.  The workshop is to be held just before the International Conference on Computer Vision (ICCV) planned in January 1998, in Bombay, India.  The proximity of the two sites should help increase the participation in the Karachi workshop by US scientists.  Scope:  This project is to bring US and Pakistani scientists to discuss recent developments in a relatively new and important area of computer graphics, namely the area of motion-based recognition.  The applications of this technology are wide, such as in manufacturing (industrial automation and robotics), in surveillance and monitoring, in traffic control, in object tracking, in measurement of cloud and wind motions, and in biomedical imaging.  It is planned to focus attention during the workshop on the scientific questions that can be addressed through US-Pakistan collaboration.  There is a relatively inexpensive, skilled, scientific manpower in Pakistan, which can effectively carry part of the research work in the field of computer imaging and software development.  This project should help establish the infrastructure necessary for developments in industry in Pakistan, and for Western companies wishing to invest in manufacturing in this growing market.   The invited US participants are eminent researchers from universities, industry and government laboratories, and they include one woman who is an expert on artificial intelligence and signal processing, and at least two junior scientists.  The proposal meets INT criteria for supporting activities likely to enhance collaboration between US and foreign scientists in areas of mutual interest, and for encouraging the participation of women scientists and junior scientists in international activities ."
3142,Workshop:  AAAI-2000 Sigart / AAAI Doctoral Consortium,IIS,ARTIFICIAL INTELL & COGNIT SCI,6/1/2000,7/5/2000,Marie Bienkowski,"Bienkowski, M","Bienkowski, M",CA,SRI International,Standard Grant,Ephraim P. Glinert,11/30/2000,"$8,991.00 ",,marie.bienkowski@sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This is a standard award to support the 5th AAAI Doctoral Consortium to be held as a workshop during the 17th AAAI conference in Austin, Texas.  The workshop will provide a unique opportunity for a group of PhD students to discuss and explore their research interests and career objectives together with a panel of established researchers.  The consortium has the following objectives:<br/><br/> * To provide a setting for mutual feedback on participants' current research, and   guidance on future research directions<br/> * To develop a supportive community of scholars and a spirit of collaborative research<br/> * To support a new generation of researchers with information and advice on academic,   research, industrial, and non-traditional career paths<br/> * To contribute to the conference goals through interaction with other researchers and   participation in conference events.<br/><br/>The Doctoral Consortium will be held concurrently with other workshops preceding the AAAI'00 conference.   It is expected that it will attract a diverse group of student participants who reflect a wide range of topic areas and methodologies within artificial intelligence, and who have settled on their thesis directions but who still have significant research left to do.  Selection will be based on clarity and completeness of the submission packet, stage of research, advisor's letter, and other evidence of promise such as published papers or technical reports. Participants' thesis summaries will be published in the AAAI-00 conference proceedings.  NSF funds will be supplemented by a contribution from Microsoft Research to provide student participants with a travel reimbursement of $800.   Participants will also receive complimentary conference registration.   The organizing committee for the workshop consists of:   Marie A. Bienkowski, Chair, SRI International;  Janyce M. Wiebe, New Mexico State University;   Mary P. Harper, Purdue University;   Vibhu O. Mittal, Just Research and Carnegie Mellon University;   and Loren Terveen, AT&T Labs.   Panelists will include:   Bonnie Holte Bennett , University of St. Thomas;   Claire Cardie, Cornell University;  Russell Greiner, University of Alberta;   Mary P. Harper, Purdue University;   Evangelos E. Milios, Dalhousie University;    Raymond J. Mooney, University of Texas at Austin;    Leora Morgenstern, IBM T.J. Watson Research;   and Nils J. Nilsson, Stanford University.<br/>"
728898,The Second Northeast Student Colloquium on Artificial Intelligence,IIS,ROBUST INTELLIGENCE,4/15/2007,4/12/2007,Joseph Halpern,"Halpern, J","Halpern, J",NY,Cornell University,Standard Grant,Douglas H. Fisher,3/31/2008,"$8,000.00 ",,halpern@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,7495,"7495, 9218, 9251, HPCC",$0.00 ,exceptionalFunding,"<br/>Proposal 0728898<br/>""The Second Northeast Student Colloquium on Artificial Intelligence""<br/>PI: Joseph Y. Halpern<br/>Cornell University<br/><br/><br/>ABSTRACT<br/>This award will help to subsidize the participation of graduate students in the second Northeast Student Colloquium on Artificial Intelligence (NESCAI) to be held April 13-15, 2007 at Cornell University in Ithaca, New York. This conference is to include oral and poster presentations by students and invited talks and tutorials by senior AI researchers. The conference will be largely run by a program committee consisting of doctoral students under the guidance of senior faulty, particularly the PI. The program committee will conduct a review process to select the projects chosen for oral presentations. In addition to graduate students, the conference plans to encourage attendance by a few outstanding senior undergraduates in the hope that it will increase their enthusiasm for research and thus the likelihood that they will go on to graduate work.<br/>"
1630047,"Symposium on Combinatorial Search, SoCS-2016",IIS,ROBUST INTELLIGENCE,7/1/2016,6/17/2016,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Standard Grant,James Donlon,6/30/2019,"$7,000.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This grant is to provide partial support for U.S.-based graduate and undergraduate students to attend the Ninth Symposium on Combinatorial Search (SoCS-2016), a scientific conference to be held at Tarrytown, NY from July 6-8, 2016. Combinatorial search is an area of artificial intelligence that deals with systematic trial-and-error exploration of a very large number of alternative solutions to a problem.   NSF funding is crucial to support students who would otherwise not be able to attend the symposium.  Attending such meetings and presenting their research is an important part of the professional development of students, addressing a critical shortage of highly-skilled computer scientists in the U.S.<br/><br/>SOCS brings together researchers in heuristic search and combinatorial optimization from all areas of artificial intelligence, planning, robotics, constraint programming, operations research, and bioinformatics.  The intellectual merit of this activity stems from bringing together in one place at one time researchers from otherwise diverse areas of computer science that both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  The broader impacts come from cross-fertilization of different fields that advance and/or use these tools, by promoting research in this area by providing a small intimate meeting on these topics, a forum for presenting such work, and archival proceedings for publishing work in this area.  These latter goals are instrumental to training new researchers in this area."
1745800,IIS-RI: International Conference on Automated Planning and Scheduling (ICAPS) 2017 Doctoral Consortium Travel Awards,IIS,ROBUST INTELLIGENCE,7/1/2017,6/28/2017,Emma Brunskill,"Brunskill, E","Brunskill, E",CA,Stanford University,Standard Grant,James Donlon,6/30/2018,"$6,888.00 ",,ebrun@cs.stanford.edu,3160 Porter Drive,Palo Alto,CA,943041212,6507232300,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This grant supports student travel for select students to participate in the Doctoral Consortium (DC) at the International Conference on Automated Planning and Scheduling (ICAPS), to be held in June 2017 in Pittsburgh, PA.  ICAPS is a top-tier conference for researchers and practitioners to share and learn from each other in the field of planning and scheduling using artificial intelligence techniques. This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research.  <br/><br/>Sponsoring student travel to ICAPS fosters a community of research in theoretical and algorithmic advances in planning and scheduling, as well as a range of applications of such automated planning, such as in manufacturing, health care, logistics, space systems, software engineering, robotics, and entertainment.  The entire event provides an opportunity for students to engage in discussion with scientists from around the world and to explore new research directions and topics."
87963,Robots in an Introductory Survey Course in Computer Science,DUE,CCLI-ADAPTATION AND IMPLEMENTA,1/15/2001,11/8/2000,Lonnie Fairchild,"Fairchild, L","Fairchild, L|Lavelle, C",NY,SUNY College at Plattsburgh,Standard Grant,Ernest L. McDuffie,6/30/2003,"$6,423.00 ",Catherine Lavelle,fairchlr@plattsburgh.edu,P.O. Box 9,Albany,NY,122010009,5185642155,EHR,7428,"7428, 9178, SMET",$0.00 ,exceptionalFunding,"Computer Science (31) <br/>We are using mobile robots as a unifying theme in an introductory survey course in computer science, for students of all majors. Our breadth-first survey course covers topics in logic circuits, machine organization and assembly-level programming, programming in a higher-level language, computability, artificial intelligence, and social concerns. Breadth-first courses are useful for non-majors as well as computer science majors, but face the problem of providing enough depth and suitable projects to develop real understanding of the material. Our projects involving the design and construction of simple robots provide a means for connecting the different topics of a survey course and enable a pedagogical approach in which students learn by doing (rather than by being told). Interesting problems with multiple kinds of solutions are being used to challenge a broad range of students and encourage participation by those who have been hesitant about their abilities in technology, science, or mathematics. <br/><br/>We are building upon work performed at MIT, Swarthmore, Wellesley and Colby where robots have been used to generate interest and make the course material more accessible to students. Our adaption is to take the work from these highly selective institutions and bring it to our students while simultaneously enhancing the content to include machine organization."
1614024,EAPSI: Generating Word Embeddings using Extreme Learning Machines for Classifying Clinical Texts,OISE,EAPSI,6/15/2016,7/8/2016,Paula Lauren,"Lauren, P","Lauren, P",MI,Lauren                  Paula,Fellowship,Anne L. Emig,5/31/2017,"$5,400.00 ",,,,Royal Oak,MI,480735310,,O/D,7316,"5927, 5978, 7316",$0.00 ,exceptionalFunding,"In 1950, the computer scientist Alan Turing proposed a test for true artificial intelligence. In Turing's view, a computer must be considered intelligent if it could understand human language.  After more than 60 years of research, this is still an ongoing effort. Recent methods, including neural language models that use advanced statistics, have made great strides towards realizing Turing's vision.  This study builds on existing research to explore methods for improving computer-based natural language understanding.  The research will be conducted under the mentorship of Professor Guang-bin Huang, a noted expert on machine learning, of Nanyang Technological University.<br/><br/>Natural language processing (NLP) involves the development of computer-based algorithms to understand natural language. Statistical language models are typically used for various NLP tasks, including machine translation and text categorization.  Language models based on neural networks, also known as neural embeddings, map words (or phrases) to a numerical representation in a low-dimensional space. Typically, neural networks use back-propagation for training a neural network, which results in slow training. Extreme Learning Machines (ELM) is a type of neural network, where hidden neurons are randomly generated hidden nodes. This study involves the use of ELM for faster training in the generation of neural embeddings.<br/><br/>This award under the East Asia and Pacific Summer Institutes program supports summer research by a U.S. graduate student and is jointly funded by NSF and the National Research Foundation of Singapore."
1713952,EAPSI: Learning Semantic Decomposition in Support of Commonsense Reasoning,OISE,EAPSI,6/1/2017,5/10/2017,William Hancock,"Hancock, W","Hancock, W",GA,Hancock                 William,Fellowship,Anne L. Emig,5/31/2018,"$5,400.00 ",,,,Atlanta,GA,303187959,,O/D,7316,"5921, 5978, 7316",$0.00 ,exceptionalFunding,"Commonsense reasoning is the ability for humans to use everyday facts about the world to support planning. To create a story about a bank robbery, one must have knowledge of what a bank is, why one would wish to rob it, etc. Artificial intelligence (AI) agents can learn a lot about the world by reading existing text sources, such as Wikipedia or narrative. However, the information learned so far from these sources tends to be explicit, such as, person A was born at location B. This project will investigate methods that can be used to learn implicit knowledge from text such as spatial or temporal properties of concepts. This knowledge can then support many different current challenges in AI, such as narrative generation. This project will be conducted at Toyota Technological University under the mentorship of Dr. Makoto Miwa. The collaboration provides access to unique data that will enable new insights into how humans process everyday concepts.<br/><br/>Current work on information extraction tends to learn propositions that are explicitly encoded in text. Implicit information is equally or more important in giving cognitive agents the ability to reason about the world. Under the supervision of Dr. Miwa, I will apply machine learning and analogical techniques to the task of associative concept learning. I will specifically look at low level qualia related attributes including temporality, space, sentiment, aesthetics, etc. I will use various corpora in support of this task. Dr. Miwa, along with his research group at Toyota Technological University, are leaders in information extraction techniques. Subsequently, Dr. Miwa's insight and expertise will be an invaluable aid in developing techniques for machine learning implicit knowledge.<br/><br/>This award, under the East Asia and Pacific Summer Institutes program, supports summer research by a U.S. graduate student and is jointly funded by NSF and the Japan Society for the Promotion of Science."
1515258,EAPSI: Identifying Relations between Computer-Generated and Manually Annotated Interpretations of Activities for Planning and Plan Recognition Tasks,OISE,EAPSI,6/1/2015,6/3/2015,Richard Freedman,"Freedman, R","Freedman, R",MA,Freedman Richard G,Fellowship,Anne L. Emig,5/31/2016,"$5,070.00 ",,,,Amherst,MA,10021372,,O/D,7316,"5921, 5978, 7316",$0.00 ,exceptionalFunding,"While humans perceive activities using words and cluster similar activities by some properties, computers using unsupervised learning algorithms do not necessarily identify them the same way and thus generate different interpretations. The goal of this research is to develop an analogy between human and machine definitions of activities so that artificial intelligence planning and plan recognition methods do not need to be adjusted for each set of definitions. Usually, either humans define the activities in a way which is too vague for machines to make accurate computations or computers define activities such that people cannot understand the underlying reasoning. Developing an interpreter for each entity will not only smooth the interaction between users and devices when solving problems together, but also contribute to bridging the human-computer gap. This project will use techniques in the research areas of interest to Dr. Alex Fukunaga at the University of Tokyo who studies many facets of artificial intelligence, especially those regarding autonomous planning, search, and optimization.<br/><br/>Extending prior research on unsupervised activity recognition using topic models, this work proposes a two-step approach consisting of constraint optimization and heuristic search. The first phase uses constraint optimization to align a computer's recognized activity sequence with a given human's annotation of the same sequence. Then the second phase similarly aligns a computer's recognized activity sequence with an annotation of the sequence derived by heuristic search over a human-defined hierarchical task network. To develop these methods, the project will include formalizing the constraint and search problems, coding their formulations, and testing results of the identified mappings between the two definition sets. This test will be performed by combining an unsupervised activity recognition method previously developed by the PI for machine-interpreted actions with a commonly used plan recognition method that uses human-perceived action representations. This NSF EAPSI award is funded in collaboration with the Japan Society for the Promotion of Science."
1311059,NSF East Asia and Pacific Summer Institute (EAPSI) for FY 2013 in Japan,OISE,EAPSI,6/1/2013,5/16/2013,Erik Steinmetz,"Steinmetz, E","Steinmetz, E",MN,Steinmetz Erik S,Fellowship,Anne L. Emig,5/31/2014,"$5,070.00 ",,,,Minneapolis,MN,554182128,,O/D,7316,"5921, 5978, 7316",$0.00 ,exceptionalFunding,"This action funds Erik Stefan Steinmetz of The University of Minnesota, Department of Computer Science and Engineering, to conduct a research project in the Computer and Information Science and Engineering area during the summer of 2013 at The Nara Institute of Science and Technology (NIST) in Nara, Japan. The project title is ""Improving Opening Strategy in Computer Go Players."" The host scientist is Kenichi Matsumoto.<br/><br/>This project explores a method of improving the artificial intelligence search technique known as Monte Carlo search. The avenues being explored in this research allow the application of expert knowledge to a technique which normally relies on not being restricted by contextual knowledge (to allow randomness to properly explore a search tree). Preliminary results showed one such measure which improved play of a computer Go engine that used Monte Carlo search, and this project develops further measures along with discovering their effectiveness and limitations. By studying these modifications which touch the very nature of Monte Carlo search, this project explores the applicability and limitations of Monte Carlo search in general and whether or not hybrid methods offer an opportunity for their improvement. This research will be directly applicable to other problems using the Monte Carlo search method such as military simulation software, along with some large online simulation software systems.<br/><br/>Broader impacts of an EAPSI fellowship include providing the Fellow a first-hand research experience outside the U.S.; an introduction to the science, science policy, and scientific infrastructure of the respective location; and an orientation to the society, culture and language. These activities meet the NSF goal to educate for international collaborations early in the career of its scientists, engineers, and educators, thus ensuring a globally aware U.S. scientific workforce. Furthermore, the demonstration of the results of this project will be exceptionally helpful in a classroom setting. It shows a simple method to increase the effectiveness of an algorithm in a topic which is interesting to undergraduate students. By showing how key ideas such as this research can be applied directly to these interesting topics, students can be engaged and motivated at a very early stage of their undergraduate computer science careers."
1515639,EAPSI:Evaluating Anticipatory Communication Strategies for Human-Robot Teaming,OISE,EAPSI,6/1/2015,6/18/2015,Abhizna Butchibabu,"Butchibabu, A","Butchibabu, A",NJ,Butchibabu Abhizna,Fellowship,Anne L. Emig,5/31/2016,"$5,070.00 ",,,,Edison,NJ,88174229,,O/D,7316,"5912, 5978, 7316",$0.00 ,exceptionalFunding,"Robotic systems are being integrated into complex and safety critical domains, where these systems work with humans as teammates. For example, in domains such as emergency response systems, robotic systems are deployed to conduct tasks that may not be feasible by humans. One of the challenges for fluent human-robot teaming is effective communication, where the human and the robot exchange of the right information at the right time is critical. Prior work shows that high-performing human teams tend to share information by anticipating the needs of their teammates (referred as implicit coordination) and that to work effectively with a human teammate, the robot must be interpredictable and communicate in a way expected by the human teammate. The objective of the project is to develop a computational model for the robot where the robot will proactively communicate with human teammates using implicit coordination strategies. This is one of the first studies to address how anticipated communication strategies could be used by robots to improve team performance when working with humans and how these strategies could be learned by the robots using machine learning artificial intelligence (AI) techniques. This award will provide a U.S. graduate student with the opportunity to work in collaboration with Professor Liz Sonenberg, an expert in human-robot teaming, in the Department of Computing and Information Systems at the University of Melbourne, Australia.<br/><br/>To computationally model the robot?s AI, a Mixed Observability Markov Decision Process (MOMDP) framework will be used. This framework is commonly used as part of machine learning to learn from prior data and optimize on a reward function. The MOMDP framework for this study will use previously collected human-human team communication data. In this framework, a reward function will be implemented where using implicit coordination will provide higher reward for the robot. This will enable the robot to compute the optimal policy and solution space for communicating with the human teammate. This model will be then evaluated through human-subject experiments at MIT starting in September after the EAPSI program. <br/><br/>This NSF EAPSI award is funded in collaboration with the Australian Academy of Science."
631821,Qualitative Reasoning Workshop Graduate Student Travel Support,IIS,ARTIFICIAL INTELL & COGNIT SCI,7/1/2006,5/30/2006,Christopher Bailey-Kellogg,"Bailey-Kellogg, C","Bailey-Kellogg, C",NH,Dartmouth College,Standard Grant,Sylvia J. Spengler,6/30/2007,"$5,000.00 ",,cbk@cs.dartmouth.edu,OFFICE OF SPONSORED PROJECTS,HANOVER,NH,37551404,6036463007,CSE,6856,"7495, 9150, 9216, HPCC",$0.00 ,exceptionalFunding,"<br/>ABSTRACT<br/><br/>Proposal 0631821<br/>Ttitle: ""Qualitative Reasoning Workshop Graduate Student Travel Support""<br/>PI: Christopher Bailey-Kellogg<br/>Dartmouth College<br/><br/>This award provides funding to help defray travel costs of graduate student participating in the 20th International Conference on Qualitative Reasoning (QR-06) to be held July 10-12, 2006 at Dartmouth College. Qualitative Reasoning is an important core area in Artificial Intelligence and addresses issues in knowledge representation, cognitive modeling, qualitative simulation, dynamical systems, and task-level reasoning. Its concerns are at the interface of AI, Cognitive Science, Engineering and Science. The conference will hold a special session on graduate study in QR. It will be designed to enable students to receive feedback on their work from leading researchers in QR and to become integrated into the international QR community. The session will discuss the rewards and challenges of graduate study in interdisciplinary research areas such as Qualitative Reasoning. Topics to be addressed include selection of appropriate research problems, evaluation of results with respect to the standards of multiple fields, and publication in multiple venues. These activities will deepen the base of researchers by enabling graduate students to become knowledgeable in both qualitative reasoning and the rigors of interdisciplinary research. <br/>"
1543845,Symposium on Combinatorial Search - 2015,IIS,ROBUST INTELLIGENCE,6/15/2015,6/23/2015,Richard Korf,"Korf, R","Korf, R",CA,University of California-Los Angeles,Standard Grant,James Donlon,11/30/2016,"$5,000.00 ",,korf@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,"7495, 7556",$0.00 ,exceptionalFunding,"This grant is to provide partial support for U.S.-based graduate and undergraduate students to attend the Eighth Symposium on Combinatorial Search (SoCS), a scientific conference to be held at the Dead Sea in Israel from June 11-15, 2015.  The general field of the meeting is computer science.  Combinatorial search is an area of computer science that deals with systematic trial-and-error exploration of a very large number of alternative solutions to a problem.  For example, a package delivery truck needs to visit all the addresses to which packages must be delivered, and return to its home base, ideally via the shortest possible route.  NSF funding is crucial to support students who would otherwise not be able to attend the symposium.  Attending such meetings and presenting their research is an important part of the professional development of students, addressing a critical shortage of highly-skilled computer scientists in the U.S.<br/><br/>SoCS brings together researchers in heuristic search and combinatorial optimization from all areas of artificial intelligence, planning, robotics, constraint programming, operations research, bioinformatics, and computer games.  The intellectual merit of this activity stems from bringing together in one place at one time researchers from otherwise diverse areas of computer science that both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  The broader impacts come from cross-fertilization of different fields that advance and/or use these tools, by promoting research in this area by providing a small intimate meeting on these topics, a forum for presenting such work, and archival proceedings for publishing work in this area.  These latter goals are instrumental to training new researchers in this area."
124653,"Bioinformatics Symposium: Computer-based Medical Instrumentation and Information Technologies, Hartford, Connecticut, October 12, 2001",CBET,Engineering of Biomed Systems,9/1/2001,8/2/2001,Joseph Bronzino,"Bronzino, J","Bronzino, J",CT,Trinity College,Standard Grant,Gilbert B. Devey,8/31/2002,"$5,000.00 ",,joseph.bronzino@trincoll.edu,300 Summit Street,Hartford,CT,61063100,8602975347,ENG,5345,"0000, OTHR",$0.00 ,exceptionalFunding,"0124653<br/>Bronzino<br/>Bioinformatics is a scientifically broad discipline involving the use of computer technology to develop new medical (virtual) instruments, create and protect computerized patient records, enhance the operation of medical imaging systems, utilize artificial intelligence techniques (i.e. expert systems, neural networks, etc.) to develop decision support systems, create efficient and effective data mining and modeling approaches, and use robotics in a host of medical applications. This field is vast and it is difficult to cover all of the topics. Therefore, the Symposium is to focus on computer-based instrumentation in medical systems. <br/><br/>The primary objectives of the Bioinformatics Symposium are:<br/>Present insights into the new research and development efforts underway in virtual instrumentation, medical imaging and storage, and decision support systems.<br/><br/>Present examples of successful academic/industrial collaborations in these areas.<br/><br/>Provide an opportunity for students in biomedical engineering, computer science and health sciences to learn more about the field of Bioinformatics.<br/><br/>The convening of academic and industrial professionals from the various disciplines involved in Bioinformatics at the Symposium and associated Technology Fair will facilitate interdisciplinary and inter-institutional collaborations in research and development efforts within the realm of Bioinformatics. The Bioinformatics Symposium and associated Technology Fair offers a timely opportunity to facilitate the development of innovations in this emerging area of biomedical engineering. <br/><br/>This award provides support for the publication of printed proceedings of the meeting."
424601,"Symposium on Reasoning and Learning in Cognitive Systems; Palo Alto, CA",IIS,ARTIFICIAL INTELL & COGNIT SCI,4/1/2004,3/29/2004,Seth Rogers,"Rogers, S","Rogers, S|Langley, P",CA,Institute for the Study of Learning and Expertise,Standard Grant,Edwina L. Rissland,3/31/2005,"$4,500.00 ",Pat Langley,srogers@csli.stanford.edu,2164 Staunton Court,Palo Alto,CA,943061438,6504943884,CSE,6856,"9216, HPCC",$0.00 ,exceptionalFunding,"This award supports participants in a two-day symposium on reasoning and learning in cognitive systems to be held at Stanford University on March 20-21, 2004. The purpose of the symposium is to bring together researchers and students in order to allow them to share recent results from their own specialties within artificial intelligence and cognitive science, particularly about machine learning and reasoning, in order to foster collaborations and new research directions that reflect facets of cognitive systems currently overlooked in current research. A central aspect of the symposium will be invited talks and commentaries to be given by established researchers whose work provides a good sampling of research at the intersection of reasoning and learning."
848412,"Dissertation Award: Post-Industrial Engineering: Computer Science and the Organization of Work, 1950-1975",SES,"SCIENCE, TECH & SOCIETY",2/1/2009,1/14/2009,Cathryn Carson,"Carson, C","Carson, C|Mamo, A",CA,University of California-Berkeley,Standard Grant,Kelly A. Joyce,1/31/2010,"$4,040.00 ",Andrew Mamo,clcarson@berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947045940,5106428109,SBE,7603,"0000, 1353, OTHR",$0.00 ,exceptionalFunding,"This dissertation research, supported by the Science, Technology, and Society Program at NSF, investigates the relationship of computer development to management theory in the United States during the 1950s and 1960s. The goal of the interview and archival research is to examine how the designs of early artificial intelligence machines, such as Logic Theorist and the General Problem Solver at Carnegie Mellon, and of interactive, time-shared computing systems, such as Project MAC at MIT, were part of contemporary efforts to redefine the roles of clerical workers and middle management. These research programs involved major figures who contributed both to management theory and to computer engineering, such as Herbert Simon, Jay Forrester, and J. C. R. Licklider. This dissertation therefore seeks out the connections between technical research and analyses of industrial management in the Cold War years, examining how computer design was a site for conflict among competing social ideals.<br/><br/>The archival work supported by this grant will be carried out at Carnegie Mellon University, where innovations in computation in the Graduate School of Industrial Administration were part of a larger project of creating a scientific basis for management theory; and at the Charles Babbage Institute in Minneapolis, a major repository for diverse collections from the information processing industry. Oral history interviews will be carried out with several prominent computer scientists and social theorists from the period.<br/><br/>By considering social thought and technology as fundamentally intertwined, the research supported by this grant reframes the development of interactive computing from being primarily a story of mathematical logic to one of organizational theory. As modern information technology creates new spaces for economic and political engagement and new forms of social organization, this project helps create a theoretical framework and a historical context for understanding how expanding access to technology can be related to evolving social ideals."
331478,"Symposium JJ ""Combinatorial and Artificial Intelligence Methods in Materials Science II"" held at the Materials Research Society (MRS); Boston, MA; December 1-5, 2003",DMR,"SOLID STATE & MATERIALS CHEMIS, POLYMERS",12/1/2003,11/24/2003,Robert Pachavis,"Pachavis, R","Pachavis, R",PA,Materials Research Society,Standard Grant,David Nelson,11/30/2004,"$3,000.00 ",,pachavis@mrs.org,506 KEYSTONE DR,Warrendale,PA,150867573,7247792732,MPS,"1762, 1773","9161, AMPP",$0.00 ,exceptionalFunding,"The Materials Research Society Symposium on Combinatorial and Artificial Intelligence Methods in Materials Science II will be held in Boston, MA December 1-5, 2003. The goal of the conference is to facilitate multidisciplinary interactions and information exchange within a broad spectrum of researchers, to include graduate students, post doctoral scholars and junior faculty working in priority areas of the broad field of combinatorial and high throughput materials science. The NSF funds will be used exclusively to offset the expenses associated with attending the symposium for U.S. participants, specifically graduate students, postdoctoral scholars, junior faculty and selected plenary speakers in this new area of materials research. <br/>%%% <br/>The materials research community continues to have a direct impact on important technological areas that are crucial to advancing society through the design, synthesis and application new materials. Such areas include the fundamental scientific aspects as well as advanced applications of combinatorial materials science, artificial intelligence needs for automation, data mining and knowledge discovery. Since these technical areas are of very high priority to industry, students educated and trained in these multidisciplinary areas compete very well in the job market and go on to contribute in many significant ways to the global economy.<br/>***"
1991,"Recovery, Evaluation and Dissemination of New Archive Documents on History of Computing",SES,Hist & Philosophy of SET,8/1/2000,12/13/2000,Colin Burke,"Burke, C","Burke, C",MD,"Burke, Colin B",Standard Grant,Frederick M Kronz,7/31/2001,"$3,000.00 ",,,,Baltimore,MD,21228,,SBE,1353,"0000, 9237, OTHR",$0.00 ,exceptionalFunding,"SES 00-01991 -- Colin Burke (Independent Scholar) <br/>SGER: ""Recovery, Evaluation and Dissemination of New Archive Documents on the History of Computing""<br/><br/>This Small Grant for Exploratory Research supports the principal investigator's survey of an important collection of newly declassified documents recently released to England's Public Record Office. The newly available documents relate to Allied codebreaking in World War II, and to the path-breaking computer and information management projects tied to those cryptanalytic projects. Through these projects scientists and scientific institutions played a major role in the creation of advanced technology and methods. Among the many important scientists and institutions associated with the efforts were Alan Turing and Vannevar Bush and MIT and Cambridge University.<br/><br/>With the support of this grant the PI will secure copies of the more important items and prepare articles to alert the historical community of the importance of the new collection. The PI will also create an Internet site that will contain indexed and annotated copies of the documents."
339959,SBIR Phase I:  Expanding the Reach of Cognitive Tutors with a Software Development Kit,IIP,EDUCATIONAL RESEARCH INITIATIV,1/1/2004,8/6/2004,Steven Ritter,"Ritter, S","Ritter, S",PA,Carnegie Learning,Standard Grant,Glenn H. Larsen,6/30/2004,$0.00 ,,sritter@carnegielearning.com,Union Trust Building,Pittsburgh,PA,152194447,4126902442,ENG,7180,"9177, SMET",$0.00 ,exceptionalFunding,"This Small Business Innovation Research (SBIR) Phase I project addresses the difficulties of authoring intelligent tutoring systems.  Intelligent Tutoring Systems have proven to be highly effective in delivering computer-based instruction, but have historically been expensive and difficult to build, requiring specialized skill in Artificial Intelligence and production systems programming.  This proposal describes a Software Development Kit (SDK) composed of four components: Cognitive Model Authoring, Problem Authoring, Tool Authoring, and Curriculum Authoring.  The proposed research activity centers around the first of these components: Cognitive Model Authoring.  Cognitive Model Authoring is comprised of three separate steps: defining an object hierarchy, defining the goal structure of the problem task, and representing the behavior of the instructional system.  The proposal seeks to define an object-oriented visualization of these steps, so that non-cognitive scientists can create cognitive tutors.  This tool will decrease the amount of time it an experienced cognitive modeler to author the cognitive model portion of a tutor, and it will also decrease the amount of time it takes to enable a person with no cognitive modeling experience to create cognitive models.<br/><br/>The broader impact of the Cognitive Tutor SDK is two-fold: (1) the easier production of new Cognitive Tutors, and hence the ability to bring them to market more quickly;  and (2) the development of a Software Development Kit that could be independently marketed, so that other companies can produce intelligent tutors in other domains, languages, countries and markets.<br/>"
1133316,The Development of a Hexacopter With a Dexterous Manipulator,IIP,INDUSTRY/UNIV COOP RES CENTERS,8/15/2011,5/10/2012,Carlotta Berry,"Berry, C","Berry, C",IN,Rose-Hulman Institute of Technology,Standard Grant,Rathindra DasGupta,7/31/2013,$0.00 ,,berry123@rose-hulman.edu,5500 Wabash Avenue,Terre Haute,IN,478033920,8128778972,ENG,5761,"5761, 8042",$0.00 ,exceptionalFunding,"IIP 1133316 <br/>Rose-Hulman Institute of Technology; Carlotta Berry <br/><br/>The purpose of this unsolicited proposal is to create a collaborative effort between Rose-Hulman Institute of Technology (RHIT) and the NSF Industry/University Cooperative Research Center for Safety, Security and Rescue Research Center (SSR-RC) at the University of Denver (DU). This work seeks to capitalize on the faculty, undergraduate and graduate student resources at this primarily undergraduate engineering institution, RHIT, and the research equipment and resources available at DU. The SSR-RC provides integrative robotics and artificial intelligence solutions in robotics for activities conducted by emergency response personnel. <br/><br/>The intellectual merits of this work lie in the fact that the utility of an unmanned air vehicle (UAV) is extensive in military and civil applications. The design of a robust UAV with vertical take-off and landing will allow for surveillance and maneuverability in narrow spaces. In addition, UAVs rarely include a manipulator; thus, the inclusion of one through this work will allow for more flexibility with respect to the UAV interacting with its environment. The funding of this project will illustrate a practical integration of research and education at two very different types of institutions. <br/><br/>The broader impacts of the proposed work are primarily related to the inclusion of faculty, undergraduate and graduate students at RHIT into the high-level research available through the laboratory at DU. The relationship is expected to enhance the infrastructure for research and education at both of these schools. If the hexacopter proves to be a viable resource, then it will affect populations far beyond academia. In addition, since the students will need to consider the novice end user in their design, it will require them to have an awareness of societal needs and capabilities."
